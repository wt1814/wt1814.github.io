

<!-- TOC -->

- [1. ES集群](#1-es集群)
    - [1.1. 基本概念](#11-基本概念)
    - [1.2. zen discovery集群发现机制](#12-zen-discovery集群发现机制)
        - [1.2.1. 集群配置](#121-集群配置)
        - [1.2.2. 集群发现的一般步骤](#122-集群发现的一般步骤)
        - [1.2.3. master选举](#123-master选举)
        - [1.2.4. 集群健康状态](#124-集群健康状态)
    - [1.3. 高可用性(集群规模和容量规划)](#13-高可用性集群规模和容量规划)
    - [1.4. 集群容错](#14-集群容错)
        - [1.4.1. ※※※集群故障探查](#141-※※※集群故障探查)
        - [1.4.2. 集群状态更新](#142-集群状态更新)
        - [1.4.3. ※※※split-brain(脑分裂问题)](#143-※※※split-brain脑分裂问题)
        - [1.4.4. minimum_master_nodes动态修改](#144-minimum_master_nodes动态修改)
        - [1.4.5. 集群重启问题](#145-集群重启问题)
    - [1.5. 小结：提高ES分布式系统的可用性以及性能最大化](#15-小结提高es分布式系统的可用性以及性能最大化)

<!-- /TOC -->


![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-21.png)  

# 1. ES集群  
<!--
&emsp; 公司es的集群架构，索引数据大小，分片有多少。  
如实结合自己的实践场景回答即可。比如： ES 集群架构 13 个节点， 索引根据通道不同共 20+索引， 根据日期， 每日递增 20+， 索引： 10 分片， 每日递增 1 亿+数据， 每个通道每天索引大小控制： 150GB 之内。  

-->

## 1.1. 基本概念
&emsp; 在数据库系统中，为了保证高可用性，可能会做主从复制、分库分表等操作。在ES中也有相同的基本操作。以下为ES集群中的一些基本概念：    

1. 节点（Node）  
&emsp; 运行了单个实例的ES主机称为节点，它是集群的一个成员，可以存储数据、参与集群索引及搜索操作。节点通过为其配置的ES集群名称确定其所要加入的集群。  
2. 集群（cluster）  
&emsp; ES可以作为一个独立的单个搜索服务器。不过，一般为了处理大型数据集，实现容错和高可用性，ES可以运行在许多互相合作的服务器上。这些服务器的集合称为集群。  
&emsp; **<font color = "red">ES集群节点类型：</font>**  
&emsp; 集群由多个节点构成，每一台主机则称为一台节点，在伪集群中每一个 ES 实例则为一个节点。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-4.png)  
&emsp; 上述图中则为一个集群，其中 Node-1 是主节点，主节点有权限控制整个集群，有权限控制整个集群。每个节点都有三个分片，其中P0 P1 P2代表 Primary 为主分片，R开头的则代表为每个主分片对应的副本分片，一共是 3 个主分片，每个主分片有两个对应的副本分片。  
&emsp; **集群中节点分类：**  
* Master：主节点，每个集群都有且只有一个  
  * 尽量避免Master节点 node.data ＝ true
  * 主节点的主要职责是和集群操作相关的内容，如创建或删除索引，跟踪哪些节点是群集的一部分，并决定哪些分片分配给相关的节点。稳定的主节点对集群的健康是非常重要的，默认情况下任何一个集群中的节点都有可能被选为主节点，索引数据和搜索查询等操作会占用大量的cpu，内存，io资源，为了确保一个集群的稳定，分离主节点和数据节点是一个比较好的选择。
* voting：投票节点  
  * Node.voting_only = true（仅投票节点，即使配置了data.master = true，也不会参选, 但是仍然可以作为数据节点）。  
* coordinating：协调节点  
  * 每一个节点都隐式的是一个协调节点，如果同时设置了data.master = false和data.data=false，那么此节点将成为仅协调节点。
4)Master-eligible node（候选节点）：	  
5)Data node（数据节点）：  
&emsp; **关于集群节点类型的两个配置：node.master和node.data**   
&emsp; 1)node.master = true	 node.data = true  
&emsp; 这是ES节点默认配置，既作为候选节点又作为数据节点，这样的节点一旦被选举为Master，压力是比较大的，通常来说Master节点应该只承担较为轻量级的任务，比如创建删除索引，分片均衡等。  
&emsp; 2)node.master = true	 node.data = false  
&emsp; 只作为候选节点，不作为数据节点，可参选Master节点，当选后成为真正的Master节点。  
&emsp; 3)node.master = false	 node.data = false  
&emsp; 既不当候选节点，也不作为数据节点，那就是仅协调节点，负责负载均衡  
&emsp; 4)node.master=false		node.data=true  
&emsp; 不作为候选节点，但是作为数据节点，这样的节点主要负责数据存储和查询服务。    


<!-- 
* **主节点**：即 Master 节点。主节点的主要职责是和集群操作相关的内容，如创建或删除索引，跟踪哪些节点是群集的一部分，并决定哪些分片分配给相关的节点。稳定的主节点对集群的健康是非常重要的。默认情况下任何一个集群中的节点都有可能被选为主节点。索引数据和搜索查询等操作会占用大量的 cpu，内存，io 资源，为了确保一个集群的稳定，分离主节点和数据节点是一个比较好的选择。虽然主节点也可以协调节点，路由搜索和从客户端新增数据到数据节点，但最好不要使用这些专用的主节点。一个重要的原则是，尽可能做尽量少的工作；  
* **数据节点**：即 Data 节点。数据节点主要是存储索引数据的节点，主要对文档进行增删改查操作，聚合操作等。数据节点对 CPU、内存、IO 要求较高，在优化的时候需要监控数据节点的状态，当资源不够的时候，需要在集群中添加新的节点；  
* **负载均衡节点**：也称作 Client 节点，也称作客户端节点。当一个节点既不配置为主节点，也不配置为数据节点时，该节点只能处理路由请求，处理搜索，分发索引操作等，从本质上来说该客户节点表现为智能负载平衡器。独立的客户端节点在一个比较大的集群中是非常有用的，它协调主节点和数据节点，客户端节点加入集群可以得到集群的状态，根据集群的状态可以直接路由请求；  
* **预处理节点**：也称作 Ingest 节点，在索引数据之前可以先对数据做预处理操作，所有节点其实默认都是支持 Ingest 操作的，也可以专门将某个节点配置为 Ingest 节点。以上就是节点几种类型，一个节点其实可以对应不同的类型，如一个节点可以同时成为主节点和数据节点和预处理节点，但如果一个节点既不是主节点也不是数据节点，那么它就是负载均衡节点。具体的类型可以通过具体的配置文件来设置；  
-->
3. 分片（Shard）  
&emsp; **ES的“分片(shard)”机制可将一个索引内部的数据分布地存储于多个节点，**它通过将一个索引切分为多个底层物理的Lucene索引完成索引数据的分割存储功能，这每一个物理的Lucene索引称为一个分片(shard)。  
&emsp; 这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。降低单服务器的压力，构成分布式搜索，提高整体检索的效率（分片数的最优值与硬件参数和数据量大小有关）。分片的数量只能在索引创建前指定，并且索引创建后不能更改。  
4. 副本（Replica）  
&emsp; 副本是一个分片的精确复制，每个分片可以有零个或多个副本。<font color = "red">副本的作用：一是提高系统的容错性，当某个节点某个分片损坏或丢失时可以从副本中恢复；二是提高es的查询效率，es会自动对搜索请求进行负载均衡。</font>  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-75.png)  

## 1.2. zen discovery集群发现机制  
&emsp; es的discovery机制：集群中各个节点互相发现然后组成一个集群的机制，同时discovery机制也负责es集群的master选举。  

### 1.2.1. 集群配置  
&emsp; Zen Discovery是Elasticsearch集群发现机制的默认实现，底层通信依赖transport组件，完成Elasticsearch集群的配置主要有下面几个参数：  

* cluster.name 指定集群的名称。  
* node.name 节点名称。  
* network.host 节点绑定的IP。  
* node.master 可选值为true/false，决定该节点类型为master eligible或data node。  
* discovery.zen.ping.unicast.hosts gossip路由服务的IP地址，即集群发现协议通信的公共节点，可以写多个，有节点启动时会向里面的IP发送消息，获取集群其他节点的信息，最后加入集群。  

&emsp; Elasticsearch集群是点对点(P2P)的分布式系统架构，数据索引、搜索操作是node之间直接通信的，没有中心式的master节点，但Elasticsearch集群内的节点也分成master node和data node两种角色。  

&emsp; 正常情况下，Elasticsearch集群只有一个master节点，它负责维护整个集群的状态信息，集群的元数据信息，有新的node加入或集群内node宕机下线时，重新分配shard，并同步node的状态信息给所有的node节点，这样所有的node节点都有一份完整的cluster state信息。  

### 1.2.2. 集群发现的一般步骤

1. 节点配置文件network.host绑定内网地址，配置各自的node.name信息，cluster.name设置为相同的值。  
2. discovery.zen.ping.unicast.hosts配置了几个gossip路由的node。  
3. 所有node都可以发送ping消息到路由node，再从路由node获取cluster state回来。  
4. 所有node执行master选举。  
5. 所有node都会跟master进行通信，然后加入master的集群。  

### 1.2.3. master选举
&emsp; 配置文件elasticsearch.yml中node.master设置为true的，将成为master eligible node，也叫master候选节点，只有master eligible node才能被选举成master node。如果是个小集群，那么所有节点都可以是master eligible node，10个节点以上的集群，可以考虑拆分master node和data node，一般建议master eligible node给3个即可。  

&emsp; master选举过程是自动完成的，有几个参数可以影响选举的过程：  

* discovery.zen.ping_timeout: 选举超时时间，默认3秒，网络状况不好时可以增加超时时间。
discovery.zen.join_timeout: 有新的node加入集群时，会发送一个join request到master node，同样因为网络原因可以调大，如果一次超时，默认最多重试20次。  
* discovery.zen.master_election.ignore_non_master_pings：如果master node意外宕机了，集群进行重新选举，如果此值为true，那么只有master eligible node才有资格被选为master。  
* discovery.zen.minimum_master_nodes: 新选举master时，要求必须有多少个 master eligible node去连接那个新选举的master。而且还用于设置一个集群中必须拥有的master eligible node。如果这些要求没有被满足，那么master node就会被停止，然后会重新选举一个新的master。这个参数必须设置为master eligible node的quorum数量。一般避免说只有两个master eligible node，因为2的quorum还是2。如果在那个情况下，任何一个master候选节点宕机了，集群就无法正常运作了。  

### 1.2.4. 集群健康状态  
&emsp; 要检查群集运行状况，可以在 Kibana 控制台中运行以下命令 GET /_cluster/health，得到如下信息：  

```json
{
  "cluster_name" : "xxxBug",
  "status" : "yellow",
  "timed_out" : false,
  "number_of_nodes" : 1,
  "number_of_data_nodes" : 1,
  "active_primary_shards" : 9,
  "active_shards" : 9,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 5,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 64.28571428571429
}
```

&emsp; <font color = "red">Elasticsearch集群存在三种健康状态</font>（单节点 Elasticsearch 也可以算是一个集群）。  

* 绿色：集群健康完好，一切功能齐全正常，所有分片和副本都可以正常工作。  
* 黄色：预警状态，所有主分片功能正常，但至少有一个副本是不能正常工作的。此时集群是可以正常工作的，但是高可用性在某种程度上会受影响。  
* **红色：集群不可正常使用。某个或某些分片及其副本异常不可用，这时集群的查询操作还能执行，但是返回的结果会不准确。对于分配到这个分片的写入请求将会报错，最终会导致数据的丢失。**  

&emsp; <font color = "red">当集群状态为红色时，它将会继续从可用的分片提供搜索请求服务，但是需要尽快修复那些未分配的分片。</font>  

## 1.3. 高可用性(集群规模和容量规划)  
<!-- 
Elasticsearch集群规模和容量规划的底层逻辑 
https://mp.weixin.qq.com/s?__biz=MzI2NDY1MTA3OQ==&mid=2247484628&idx=1&sn=666e416ae28b93e42c26f26b208dea84&chksm=eaa82cfcdddfa5eacfcddb0cf54edcecb3ad86ca2cafd6f4f2d90cf8a4033d83eb16cb2a56f0&scene=21#wechat_redirect


ES在分配单个索引的分片时会将每个分片尽可能分配到更多的节点上。但是，实际情况取决于集群拥有的分片和索引的数量以及它们的大小，所以这种情况只是理想状况。
ES不允许Primary和它的Replica放在同一个节点中（为了容错），并且同一个节点不接受完全相同的两个Replica，也就是说，因为同一个节点存放两个相同的副本既不能提升吞吐量，也不能提升查询速度，徒耗磁盘空间。  
每台节点的shard数量越少，每个shard分配的CPU、内存和IO资源越多，单个shard的性能越好，当一台机器一个Shard时，单个Shard性能最好。  
相同资源分配相同的前提下，单个shard的体积越大，查询性能越低，速度越慢  
稳定的Master节点对于群集健康非常重要！理论上讲，应该尽可能的减轻Master节点的压力，分片数量越多，Master节点维护管理shard的任务越重，并且节点可能就要承担更多的数据转发任务，可增加“仅协调”节点来缓解Master节点和Data节点的压力，但是在集群中添加过多的仅协调节点会增加整个集群的负担，因为选择的主节点必须等待每个节点的集群状态更新确认。  
如果相同资源分配相同的前提下，shard数量越少，单个shard的体积越大，查询性能越低，速度越慢，这个取舍应根据实际集群状况和结合应用场景等因素综合考虑  
数据节点和Master节点一定要分开，集群规模越大，这样做的意义也就越大  
数据节点处理与数据相关的操作，例如CRUD，搜索和聚合。这些操作是I / O，内存和CPU密集型的，所以他们需要更高配置的服务器以及更高的带宽，并且集群的性能冗余非常重要  
由于投票节不参与Master竞选，所以和真正的Master节点相比，它需要的内存和CPU较少。但是，所有候选节点以及仅投票节点都可能是数据节点，所以他们都需要快速稳定低延迟的网络
高可用性（HA）群集至少需要三个主节点，其中至少两个不是仅投票节点。即使其中一个节点发生故障，这样的群集也将能够选举一个主节点。生产环境最好设置3台仅Master候选节点（node.master = true	 node.data = true）。
为确保群集仍然可用，集群不能同时停止投票配置中的一半或更多节点。只要有一半以上的投票节点可用，群集仍可以正常工作。这意味着，如果存在三个或四个主节点合格的节点，则群集可以容忍其中一个节点不可用。如果有两个或更少的主机资格节点，则它们必须都保持可用  

-->
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-77.png)  



## 1.4. 集群容错  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-76.png)  
&emsp; ①第一步：Master选举（假如宕机节点是Master）  
&emsp; &emsp; 1)脑裂：可能会产生多个Master节点  
&emsp; &emsp; 2)解决：discovery.zen.minimum_master_nodes=N/2+1  
&emsp; ②第二步：Replica容错，新的（或者原有）Master节点会将丢失的Primary对应的某个副本提升为Primary  
&emsp; ③第三步：Master节点会尝试重启故障机  
&emsp; ④第四步：数据同步，Master会将宕机期间丢失的数据同步到重启机器对应的分片上去  

### 1.4.1. ※※※集群故障探查
<!-- 
Elasticsearch 集群故障排查及修复指南 
https://mp.weixin.qq.com/s/7pWdS_zPDNiXKzrUOCTVfg
-->

&emsp; 有两种集群故障探查机制：  

* master主动对集群中所有的其他node发起ping命令，判断它们是否是存活着的。
* 每个node向master node发送ping请求，判断master node是否存活，否则就会发起一个选举过程。

&emsp; 有下面三个参数用来配置集群故障的探查过程：  

* ping_interval：ping一次node的间隔时间，默认是1s  
* ping_timeout：每次ping的timeout等待时长，默认是30s  
* ping_retries：对node的ping请求失败了，重试次数，默认3次。  


### 1.4.2. 集群状态更新
&emsp; master node是集群中唯一可以对cluster state进行更新的node。更新的步骤如下：  
1. master node收到更新事件，如shard移动，可能会有多条事件，但master node一次只处理一个集群状态的更新事件。  
2. master node将事件更新到本地，并发布publish message到集群所有的node上。  
3. node接收publish message后，对这个message返回ack响应，但是不会立即更新。  
4. 如果master没有在指定的时间内（discovery.zen.commit_timeout配置项，默认是30s），从至少N个节点（discovery.zen.minimum_master_nodes配置项）获取ack响应，那么这次cluster state change事件就会被reject，最终不会被提交。  
5. 如果在指定时间内，指定数量的node都返回了ack消息，那么cluster state就会被commit，然后master node把 commit message发送给所有的node。所有的node接收到那个commit message之后，接着才会将之前接收到的集群状态应用到自己本地的状态副本中去。
6. master会等待所有node的commit message 的ack消息，在一个等待超时时长内，如果接收到了响应，表示状态更新成功，master node继续处理内存queue中保存的下一个更新事件。  

&emsp; discovery.zen.publish_timeout默认是30s，这个超时等待时长是从plublish cluster state开始计算的。  

&emsp; 可以参照此图：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-5.png)  


### 1.4.3. ※※※split-brain(脑分裂问题)  
<!-- 
Elasticsearch 中的节点（比如共 20 个），其中的 10 个 选了一个master，另外 10 个选了另一个master，怎么办？  
1、当集群 master 候选数量不小于 3 个时， 可以通过设置最少投票通过数量 （ discovery.zen.minimum_master_nodes） 超过所有候选节点一半以上来解决脑裂问题；  
2、当候选数量为两个时， 只能修改为唯一的一个 master 候选， 其他作为 data 节 点， 避免脑裂问题。  
-->
&emsp; 在Elasticsearch集群中，master node非常重要，并且只有一个，相当于整个集群的大脑，控制将整个集群状态的更新，如果Elasticsearch集群节点之间出现区域性的网络中断，比如10个节点的Elasticsearch集群，4台node部署在机房A区，6台node部署在机房B区，如果A区与B区的交换机故障，导致两个区隔离开来了，那么没有master node的那个区，会触发master选举，如果选举了新的master，那么 **<font color = "red">整个集群会出现两个master node，这种现象叫做脑分裂。</font>**  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-6.png)  
&emsp; 这样现象很严重，会破坏集群的数据，该如何避免呢？  
&emsp; **<font color = "lime">正确设置最少投票通过数量(discovery.zen.minimum_master_nodes)参数，可以避免脑分裂问题。</font>**  
&emsp; discovery.zen.minimum_master_nodes参数表示至少需要多少个master eligible node，才可以成功地选举出master，否则不进行选举。  

&emsp; 足够的master eligible node计算公式：quorum = master_eligible_nodes / 2 + 1  

&emsp; 如上图10个node的集群，如果全部是master eligible node，那么quorum = 10/2 + 1 = 6。  
&emsp; 如果有3个master eligible node，7个data node，那么quorum = 3/2 + 1 = 2。  
&emsp; 如果集群只有2个节点，并且全是master eligible node，那么quorum = 2/2 + 1 = 2，问题就来了，如果随便一个node宕机，在只剩下一个node情况下，无法满足quorum的值，master永远选举不成功，集群就彻底无法写入了，所以只能设置成1，后果是只要这两个node之间网络断了，就会发生脑分裂的现象。  
&emsp; 所以一个Elasticsearch集群至少得有3个node，全部为master eligible node的话，quorum = 3/2 + 1 = 2。如果设置minimum_master_nodes=2，分析一下会不会出现脑分裂的问题。  

&emsp; 场景一：A区一个node，为master，B区两个node，为master eligible node  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-7.png)  
&emsp; A区因为只剩下一个node，无法满足quorum的条件，此时master取消当前的master角色，且无法选举成功。  
&emsp; B区两个master eligible node，满足quorum条件，成功选举出master。  
&emsp; 此时集群还是只有一个master，待网络故障恢复后，集群数据正常。  

&emsp; 场景二：A区一个node，为master eligible node，B区2个node，其中一个是master  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-8.png)    
&emsp; A区只有一个master eligible node，不满足quorum的条件，无法进行选举。  
&emsp; B区原本的master存在，不需要进行选举，并且满quorum的条件，master角色可以保留。  
&emsp; 此时集群还是一个master，正常。  

&emsp; 综上所述：3个节点的集群，全部为master eligible node，配置discovery.zen.minimum_master_nodes: 2，就可以避免脑裂问题的产生。  

### 1.4.4. minimum_master_nodes动态修改  
&emsp; 因为集群是可以动态增加和下线节点的，quorum的值也会跟着改变。minimum_master_nodes参数值需要通过api随时修改的，特别是在节点上线和下线的时候，都需要作出对应的修改。而且一旦修改过后，这个配置就会持久化保存下来。  

&emsp; 修改api请求如下：  

```
PUT /_cluster/settings
{
    "persistent" : {
        "discovery.zen.minimum_master_nodes" : 2
    }
}
```

&emsp; 响应报文：  

```
{
  "acknowledged": true,
  "persistent": {
    "discovery": {
      "zen": {
        "minimum_master_nodes": "2"
      }
    }
  },
  "transient": {}
}
```

&emsp; 也可以通过命令查询当前的配置：  

```
GET /_cluster/settings
```

&emsp; 响应结果如下：  

```
{
  "persistent": {
    "discovery": {
      "zen": {
        "minimum_master_nodes": "1"
      }
    }
  },
  "transient": {}
}
```

### 1.4.5. 集群重启问题
&emsp; 如果Elasticsearch集群做了一些离线的维护操作时，如扩容磁盘，升级版本等，需要对集群进行启动，节点数较多时，从第一个节点开始启动，到最后一个节点启动完成，耗时可能较长，有时候还可能出现某几个节点因故障无法启动，排查问题、修复故障后才能加入到集群中，此时集群会干什么呢？    

&emsp; 假设10个节点的集群，每个节点有1个shard，升级后重启节点，结果有3台节点因故障未能启动，需要耗费时间排查故障，如下图所示：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-9.png)    

&emsp; 整个过程步骤如下：  
1. 集群已完成master选举(node6)，master发现未加入集群的node1、node2、node3包含的shard丢失，便立即发出shard恢复的指令。
2. 在线的7台node，将其中一个replica shard升级为primary shard，并且进行为这些primary shard复制足够的replica shard。
3. 执行shard rebalance操作。
4. 故障的3台节点已排除，启动成功后加入集群。
5. 这3台节点发现自己的shard已经在集群中的其他节点上了，便删除本地的shard数据。
6. master发现新的3台node没有shard数据，重新执行一次shard rebalance操作。

&emsp; 这个过程可以发现，多做了四次IO操作，shard复制，shard首次移动，shard本地删除，shard再次移动，这样凭空造成大量的IO压力，如果数据量是TB级别的，那费时费力不讨好。  

&emsp; 出现此类问题的原因是节点启动的间隔时间不能确定，并且节点越多，这个问题越容易出现，如果可以设置集群等待多少个节点启动后，再决定是否对shard进行移动，这样IO压力就能小很多。  

&emsp; 针对这个问题，有下面几个参数：  

* gateway.recover_after_nodes：集群必须要有多少个节点时，才开始做shard恢复操作。
* gateway.expected_nodes: 集群应该有多少个节点
* gateway.recover_after_time: 集群启动后等待的shard恢复时间

&emsp; 如上面的案例，可以这样设置：  

    gateway.recover_after_nodes: 8
    gateway.expected_nodes: 10
    gateway.recover_after_time: 5m

&emsp; 这三个参数的含义：集群总共有10个节点，必须要有8个节点加入集群时，才允许执行shard恢复操作，如果10个节点未全部启动成功，最长的等待时间为5分钟。  
&emsp; 这几个参数的值可以根据实际的集群规模来设置，并且只能在elasticsearch.yml文件里设置，没有动态修改的入口。  
&emsp; 上面的参数设置合理的情况，集群启动是没有shard移动的现象，这样集群启动的时候就可以由之前的几小时，变成几秒钟。  

## 1.5. 小结：提高ES分布式系统的可用性以及性能最大化  
&emsp; （1）每台节点的Shard数量越少，每个shard分配的CPU、内存和IO资源越多，单个Shard的性能越好，当一台机器一个Shard时，单个Shard性能最好。  
&emsp; （2）稳定的Master节点对于群集健康非常重要！理论上讲，应该尽可能的减轻Master节点的压力，分片数量越多，Master节点维护管理shard的任务越重，并且节点可能就要承担更多的数据转发任务，可增加“仅协调”节点来缓解Master节点和Data节点的压力，但是在集群中添加过多的仅协调节点会增加整个集群的负担，因为选择的主节点必须等待每个节点的集群状态更新确认。  
&emsp; （3）反过来说，如果相同资源分配相同的前提下，shard数量越少，单个shard的体积越大，查询性能越低，速度越慢，这个取舍应根据实际集群状况和结合应用场景等因素综合考虑。  
&emsp; （4）数据节点和Master节点一定要分开，集群规模越大，这样做的意义也就越大。  
&emsp; （5）数据节点处理与数据相关的操作，例如CRUD，搜索和聚合。这些操作是I / O，内存和CPU密集型的，所以他们需要更高配置的服务器以及更高的带宽，并且集群的性能冗余非常重要。  
&emsp; （6）由于仅投票节不参与Master竞选，所以和真正的Master节点相比，它需要的内存和CPU较少。但是，所有候选节点以及仅投票节点都可能是数据节点，所以他们都需要快速稳定低延迟的网络。  
&emsp; （7）高可用性（HA）群集至少需要三个主节点，其中至少两个不是仅投票节点。即使其中一个节点发生故障，这样的群集也将能够选举一个主节点。生产环境最好设置3台仅Master候选节点（node.master = true	 node.data = true）。  
&emsp; （8）为确保群集仍然可用，集群不能同时停止投票配置中的一半或更多节点。只要有一半以上的投票节点可用，群集仍可以正常工作。这意味着，如果存在三个或四个主节点合格的节点，则群集可以容忍其中一个节点不可用。如果有两个或更少的主机资格节点，则它们必须都保持可用。  


