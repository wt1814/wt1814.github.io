

<!-- TOC -->

- [1. ES集群](#1-es集群)
    - [1.1. 基本概念](#11-基本概念)
    - [1.2. 集群健康状态](#12-集群健康状态)
    - [1.3. 集群发现机制](#13-集群发现机制)
        - [1.3.1. 集群配置](#131-集群配置)
        - [1.3.2. 集群发现的一般步骤](#132-集群发现的一般步骤)
        - [1.3.3. master选举](#133-master选举)
        - [1.3.4. 集群故障探查](#134-集群故障探查)
        - [1.3.5. 集群状态更新](#135-集群状态更新)
        - [1.3.6. ※※※split-brain(脑分裂问题)](#136-※※※split-brain脑分裂问题)
        - [1.3.7. minimum_master_nodes动态修改](#137-minimum_master_nodes动态修改)
        - [1.3.8. 集群重启问题](#138-集群重启问题)
    - [1.4. heap内存设置最佳实践](#14-heap内存设置最佳实践)
        - [1.4.1. 分配规则](#141-分配规则)
        - [1.4.2. 最佳实践建议](#142-最佳实践建议)
        - [1.4.3. swapping问题](#143-swapping问题)

<!-- /TOC -->


![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-21.png)  

# 1. ES集群  
<!--  https://mp.weixin.qq.com/s/yBGlmH_CVDhwgz1_KTawQA -->
&emsp; 公司es的集群架构，索引数据大小，分片有多少。  
如实结合自己的实践场景回答即可。比如： ES 集群架构 13 个节点， 索引根据通道不同共 20+索引， 根据日期， 每日递增 20+， 索引： 10 分片， 每日递增 1 亿+数据， 每个通道每天索引大小控制： 150GB 之内。  


## 1.1. 基本概念
&emsp; 在数据库系统中，为了保证高可用性，可能会做主从复制、分库分表等操作。在ES中也有相同的基本操作。以下为ES集群中的一些基本概念：    

1. 节点（Node）  
&emsp; 运行了单个实例的ES主机称为节点，它是集群的一个成员，可以存储数据、参与集群索引及搜索操作。节点通过为其配置的ES集群名称确定其所要加入的集群。  
2. 集群（cluster）  
&emsp; ES可以作为一个独立的单个搜索服务器。不过，一般为了处理大型数据集，实现容错和高可用性，ES可以运行在许多互相合作的服务器上。这些服务器的集合称为集群。  
3. 分片（Shard）  
&emsp; ES的“分片(shard)”机制可将一个索引内部的数据分布地存储于多个节点，它通过将一个索引切分为多个底层物理的Lucene索引完成索引数据的分割存储功能，这每一个物理的Lucene索引称为一个分片(shard)。  
&emsp; 这样的好处是可以把一个大的索引拆分成多个，分布到不同的节点上。降低单服务器的压力，构成分布式搜索，提高整体检索的效率（分片数的最优值与硬件参数和数据量大小有关）。分片的数量只能在索引创建前指定，并且索引创建后不能更改。  
4. 副本（Replica）  
&emsp; 副本是一个分片的精确复制，每个分片可以有零个或多个副本。副本的作用一是提高系统的容错性，当某个节点某个分片损坏或丢失时可以从副本中恢复。二是提高es的查询效率，es会自动对搜索请求进行负载均衡。  

&emsp; **<font color = "red">ES集群节点类型：</font>**  
&emsp; 集群由多个节点构成，每一台主机则称为一台节点，在伪集群中每一个 ES 实例则为一个节点。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-4.png)  
&emsp; 上述图中则为一个集群，其中 Node-1 是主节点，主节点有权限控制整个集群，有权限控制整个集群。每个节点都有三个分片，其中P0 P1 P2代表 Primary 为主分片，R开头的则代表为每个主分片对应的副本分片，一共是 3 个主分片，每个主分片有两个对应的副本分片。  
* **主节点**：即 Master 节点。主节点的主要职责是和集群操作相关的内容，如创建或删除索引，跟踪哪些节点是群集的一部分，并决定哪些分片分配给相关的节点。稳定的主节点对集群的健康是非常重要的。默认情况下任何一个集群中的节点都有可能被选为主节点。索引数据和搜索查询等操作会占用大量的 cpu，内存，io 资源，为了确保一个集群的稳定，分离主节点和数据节点是一个比较好的选择。虽然主节点也可以协调节点，路由搜索和从客户端新增数据到数据节点，但最好不要使用这些专用的主节点。一个重要的原则是，尽可能做尽量少的工作；  
* **数据节点**：即 Data 节点。数据节点主要是存储索引数据的节点，主要对文档进行增删改查操作，聚合操作等。数据节点对 CPU、内存、IO 要求较高，在优化的时候需要监控数据节点的状态，当资源不够的时候，需要在集群中添加新的节点；  
* **负载均衡节点**：也称作 Client 节点，也称作客户端节点。当一个节点既不配置为主节点，也不配置为数据节点时，该节点只能处理路由请求，处理搜索，分发索引操作等，从本质上来说该客户节点表现为智能负载平衡器。独立的客户端节点在一个比较大的集群中是非常有用的，它协调主节点和数据节点，客户端节点加入集群可以得到集群的状态，根据集群的状态可以直接路由请求；  
* **预处理节点**：也称作 Ingest 节点，在索引数据之前可以先对数据做预处理操作，所有节点其实默认都是支持 Ingest 操作的，也可以专门将某个节点配置为 Ingest 节点。以上就是节点几种类型，一个节点其实可以对应不同的类型，如一个节点可以同时成为主节点和数据节点和预处理节点，但如果一个节点既不是主节点也不是数据节点，那么它就是负载均衡节点。具体的类型可以通过具体的配置文件来设置；  

## 1.2. 集群健康状态  
&emsp; 要检查群集运行状况，可以在 Kibana 控制台中运行以下命令 GET /_cluster/health，得到如下信息：  

```json
{
  "cluster_name" : "xxxBug",
  "status" : "yellow",
  "timed_out" : false,
  "number_of_nodes" : 1,
  "number_of_data_nodes" : 1,
  "active_primary_shards" : 9,
  "active_shards" : 9,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 5,
  "delayed_unassigned_shards" : 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch" : 0,
  "task_max_waiting_in_queue_millis" : 0,
  "active_shards_percent_as_number" : 64.28571428571429
}
```

&emsp; <font color = "red">Elasticsearch集群存在三种健康状态</font>（单节点 Elasticsearch 也可以算是一个集群）。  

* 绿色：集群健康完好，一切功能齐全正常，所有分片和副本都可以正常工作。  
* 黄色：预警状态，所有主分片功能正常，但至少有一个副本是不能正常工作的。此时集群是可以正常工作的，但是高可用性在某种程度上会受影响。  
* 红色：集群不可正常使用。某个或某些分片及其副本异常不可用，这时集群的查询操作还能执行，但是返回的结果会不准确。对于分配到这个分片的写入请求将会报错，最终会导致数据的丢失。  

&emsp; <font color = "red">当集群状态为红色时，它将会继续从可用的分片提供搜索请求服务，但是需要尽快修复那些未分配的分片。</font>  

## 1.3. 集群发现机制  
### 1.3.1. 集群配置  
&emsp; Zen Discovery是Elasticsearch集群发现机制的默认实现，底层通信依赖transport组件，完成Elasticsearch集群的配置主要有下面几个参数：  

* cluster.name 指定集群的名称。  
* node.name 节点名称。  
* network.host 节点绑定的IP。  
* node.master 可选值为true/false，决定该节点类型为master eligible或data node。  
* discovery.zen.ping.unicast.hosts gossip路由服务的IP地址，即集群发现协议通信的公共节点，可以写多个，有节点启动时会向里面的IP发送消息，获取集群其他节点的信息，最后加入集群。  

&emsp; Elasticsearch集群是点对点(P2P)的分布式系统架构，数据索引、搜索操作是node之间直接通信的，没有中心式的master节点，但Elasticsearch集群内的节点也分成master node和data node两种角色。  

&emsp; 正常情况下，Elasticsearch集群只有一个master节点，它负责维护整个集群的状态信息，集群的元数据信息，有新的node加入或集群内node宕机下线时，重新分配shard，并同步node的状态信息给所有的node节点，这样所有的node节点都有一份完整的cluster state信息。  

### 1.3.2. 集群发现的一般步骤

1. 节点配置文件network.host绑定内网地址，配置各自的node.name信息，cluster.name设置为相同的值。  
2. discovery.zen.ping.unicast.hosts配置了几个gossip路由的node。  
3. 所有node都可以发送ping消息到路由node，再从路由node获取cluster state回来。  
4. 所有node执行master选举。  
5. 所有node都会跟master进行通信，然后加入master的集群。  

### 1.3.3. master选举
&emsp; 配置文件elasticsearch.yml中node.master设置为true的，将成为master eligible node，也叫master候选节点，只有master eligible node才能被选举成master node。如果是个小集群，那么所有节点都可以是master eligible node，10个节点以上的集群，可以考虑拆分master node和data node，一般建议master eligible node给3个即可。  

&emsp; master选举过程是自动完成的，有几个参数可以影响选举的过程：  

* discovery.zen.ping_timeout: 选举超时时间，默认3秒，网络状况不好时可以增加超时时间。
discovery.zen.join_timeout: 有新的node加入集群时，会发送一个join request到master node，同样因为网络原因可以调大，如果一次超时，默认最多重试20次。  
* discovery.zen.master_election.ignore_non_master_pings：如果master node意外宕机了，集群进行重新选举，如果此值为true，那么只有master eligible node才有资格被选为master。  
* discovery.zen.minimum_master_nodes: 新选举master时，要求必须有多少个 master eligible node去连接那个新选举的master。而且还用于设置一个集群中必须拥有的master eligible node。如果这些要求没有被满足，那么master node就会被停止，然后会重新选举一个新的master。这个参数必须设置为master eligible node的quorum数量。一般避免说只有两个master eligible node，因为2的quorum还是2。如果在那个情况下，任何一个master候选节点宕机了，集群就无法正常运作了。  

### 1.3.4. 集群故障探查

&emsp; 有两种集群故障探查机制：  

* master主动对集群中所有的其他node发起ping命令，判断它们是否是存活着的。
* 每个node向master node发送ping请求，判断master node是否存活，否则就会发起一个选举过程。

&emsp; 有下面三个参数用来配置集群故障的探查过程：  

* ping_interval：ping一次node的间隔时间，默认是1s  
* ping_timeout：每次ping的timeout等待时长，默认是30s  
* ping_retries：对node的ping请求失败了，重试次数，默认3次。  


### 1.3.5. 集群状态更新

&emsp; master node是集群中唯一可以对cluster state进行更新的node。更新的步骤如下：  
1. master node收到更新事件，如shard移动，可能会有多条事件，但master node一次只处理一个集群状态的更新事件。  
2. master node将事件更新到本地，并发布publish message到集群所有的node上。  
3. node接收publish message后，对这个message返回ack响应，但是不会立即更新。  
4. 如果master没有在指定的时间内（discovery.zen.commit_timeout配置项，默认是30s），从至少N个节点（discovery.zen.minimum_master_nodes配置项）获取ack响应，那么这次cluster state change事件就会被reject，最终不会被提交。  
5. 如果在指定时间内，指定数量的node都返回了ack消息，那么cluster state就会被commit，然后master node把 commit message发送给所有的node。所有的node接收到那个commit message之后，接着才会将之前接收到的集群状态应用到自己本地的状态副本中去。
6. master会等待所有node的commit message 的ack消息，在一个等待超时时长内，如果接收到了响应，表示状态更新成功，master node继续处理内存queue中保存的下一个更新事件。  

&emsp; discovery.zen.publish_timeout默认是30s，这个超时等待时长是从plublish cluster state开始计算的。  

&emsp; 可以参照此图：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-5.png)  


### 1.3.6. ※※※split-brain(脑分裂问题)  
&emsp; 在Elasticsearch集群中，master node非常重要，并且只有一个，相当于整个集群的大脑，控制将整个集群状态的更新，如果Elasticsearch集群节点之间出现区域性的网络中断，比如10个节点的Elasticsearch集群，4台node部署在机房A区，6台node部署在机房B区，如果A区与B区的交换机故障，导致两个区隔离开来了，那么没有master node的那个区，会触发master选举，如果选举了新的master，那么 **<font color = "red">整个集群会出现两个master node，这种现象叫做脑分裂。</font>**  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-6.png)  
&emsp; 这样现象很严重，会破坏集群的数据，该如何避免呢？  
&emsp; 回到前面提到的discovery.zen.minimum_master_nodes参数，这个值的正确设置，可以避免上述的脑分裂问题。  
&emsp; discovery.zen.minimum_master_nodes参数表示至少需要多少个master eligible node，才可以成功地选举出master，否则不进行选举。  

&emsp; 足够的master eligible node计算公式：quorum = master_eligible_nodes / 2 + 1  

&emsp; 如上图10个node的集群，如果全部是master eligible node，那么quorum = 10/2 + 1 = 6。  
&emsp; 如果有3个master eligible node，7个data node，那么quorum = 3/2 + 1 = 2。  
&emsp; 如果集群只有2个节点，并且全是master eligible node，那么quorum = 2/2 + 1 = 2，问题就来了，如果随便一个node宕机，在只剩下一个node情况下，无法满足quorum的值，master永远选举不成功，集群就彻底无法写入了，所以只能设置成1，后果是只要这两个node之间网络断了，就会发生脑分裂的现象。  
&emsp; 所以一个Elasticsearch集群至少得有3个node，全部为master eligible node的话，quorum = 3/2 + 1 = 2。如果设置minimum_master_nodes=2，分析一下会不会出现脑分裂的问题。  

&emsp; 场景一：A区一个node，为master，B区两个node，为master eligible node  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-7.png)  
&emsp; A区因为只剩下一个node，无法满足quorum的条件，此时master取消当前的master角色，且无法选举成功。  
&emsp; B区两个master eligible node，满足quorum条件，成功选举出master。  
&emsp; 此时集群还是只有一个master，待网络故障恢复后，集群数据正常。  

&emsp; 场景二：A区一个node，为master eligible node，B区2个node，其中一个是master  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-8.png)    
&emsp; A区只有一个master eligible node，不满足quorum的条件，无法进行选举。  
&emsp; B区原本的master存在，不需要进行选举，并且满quorum的条件，master角色可以保留。  
&emsp; 此时集群还是一个master，正常。  

&emsp; 综上所述：3个节点的集群，全部为master eligible node，配置discovery.zen.minimum_master_nodes: 2，就可以避免脑裂问题的产生。  

-----

Elasticsearch 中的节点（比如共 20 个），其中的 10 个 选了一个master，另外 10 个选了另一个master，怎么办？  
1、当集群 master 候选数量不小于 3 个时， 可以通过设置最少投票通过数量 （ discovery.zen.minimum_master_nodes） 超过所有候选节点一半以上来解 决脑裂问题；  
2、当候选数量为两个时， 只能修改为唯一的一个 master 候选， 其他作为 data 节 点， 避免脑裂问题。  


### 1.3.7. minimum_master_nodes动态修改  
&emsp; 因为集群是可以动态增加和下线节点的，quorum的值也会跟着改变。minimum_master_nodes参数值需要通过api随时修改的，特别是在节点上线和下线的时候，都需要作出对应的修改。而且一旦修改过后，这个配置就会持久化保存下来。  

&emsp; 修改api请求如下：  

```
PUT /_cluster/settings
{
    "persistent" : {
        "discovery.zen.minimum_master_nodes" : 2
    }
}
```

&emsp; 响应报文：  

```
{
  "acknowledged": true,
  "persistent": {
    "discovery": {
      "zen": {
        "minimum_master_nodes": "2"
      }
    }
  },
  "transient": {}
}
```

&emsp; 也可以通过命令查询当前的配置：  

```
GET /_cluster/settings
```

&emsp; 响应结果如下：  

```
{
  "persistent": {
    "discovery": {
      "zen": {
        "minimum_master_nodes": "1"
      }
    }
  },
  "transient": {}
}
```

### 1.3.8. 集群重启问题
&emsp; 如果Elasticsearch集群做了一些离线的维护操作时，如扩容磁盘，升级版本等，需要对集群进行启动，节点数较多时，从第一个节点开始启动，到最后一个节点启动完成，耗时可能较长，有时候还可能出现某几个节点因故障无法启动，排查问题、修复故障后才能加入到集群中，此时集群会干什么呢？    

&emsp; 假设10个节点的集群，每个节点有1个shard，升级后重启节点，结果有3台节点因故障未能启动，需要耗费时间排查故障，如下图所示：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/ES/es-9.png)    

&emsp; 整个过程步骤如下：  
1. 集群已完成master选举(node6)，master发现未加入集群的node1、node2、node3包含的shard丢失，便立即发出shard恢复的指令。
2. 在线的7台node，将其中一个replica shard升级为primary shard，并且进行为这些primary shard复制足够的replica shard。
3. 执行shard rebalance操作。
4. 故障的3台节点已排除，启动成功后加入集群。
5. 这3台节点发现自己的shard已经在集群中的其他节点上了，便删除本地的shard数据。
6. master发现新的3台node没有shard数据，重新执行一次shard rebalance操作。

&emsp; 这个过程可以发现，多做了四次IO操作，shard复制，shard首次移动，shard本地删除，shard再次移动，这样凭空造成大量的IO压力，如果数据量是TB级别的，那费时费力不讨好。  

&emsp; 出现此类问题的原因是节点启动的间隔时间不能确定，并且节点越多，这个问题越容易出现，如果可以设置集群等待多少个节点启动后，再决定是否对shard进行移动，这样IO压力就能小很多。  

&emsp; 针对这个问题，有下面几个参数：  

* gateway.recover_after_nodes：集群必须要有多少个节点时，才开始做shard恢复操作。
* gateway.expected_nodes: 集群应该有多少个节点
* gateway.recover_after_time: 集群启动后等待的shard恢复时间

&emsp; 如上面的案例，可以这样设置：  

    gateway.recover_after_nodes: 8
    gateway.expected_nodes: 10
    gateway.recover_after_time: 5m

&emsp; 这三个参数的含义：集群总共有10个节点，必须要有8个节点加入集群时，才允许执行shard恢复操作，如果10个节点未全部启动成功，最长的等待时间为5分钟。  
&emsp; 这几个参数的值可以根据实际的集群规模来设置，并且只能在elasticsearch.yml文件里设置，没有动态修改的入口。  
&emsp; 上面的参数设置合理的情况，集群启动是没有shard移动的现象，这样集群启动的时候就可以由之前的几小时，变成几秒钟。  


----
## 1.4. heap内存设置最佳实践  
&emsp; Elasticsearch默认的jvm heap内存大小是2G，如果是研发环境，会改成512MB，但在生产环境2GB有点少。  
&emsp; 在config/jvm.options文件下，可以看到heap的设置：  

    # Xms represents the initial size of total heap space
    # Xmx represents the maximum size of total heap space
    -Xms2g
    -Xmx2g 

### 1.4.1. 分配规则  
&emsp; Elasticsearch使用内存主要有两个大户：jvm heap和lucene，前者ES用来存放很多数据结构来提供更快的操作性能，后者使用os cache缓存索引文件，包括倒排索引、正排索引，os cache内存是否充足，直接影响查询检索的性能。  
&emsp; 一般的分配规则是：jvm heap占用小于一半的内存，剩下的全归lucene使用。  
&emsp; 如果单台机器总内存64GB，那么heap顶格内存分配为32GB，因为32GB内存以下，jvm会使用compressed oops来解决object pointer耗费过大空间的问题，超过32GB后，jvm的compressed oops功能关闭，这样就只能使用64位的object pointer，会耗费更多的空间，过大的object pointer还会在cpu，main memory和LLC、L1等多级缓存间移动数据的时候，吃掉更多的带宽。最终的结果可能是50GB内存的效果和32GB一样，白白浪费了十几GB内存。   
&emsp; 这里涉及到jvm的object pointer指针压缩技术，有兴趣可以单独了解一下。  
&emsp; 如果单台机器总内存小于64GB，一般heap分配为总内存的一半即可，具体要看预估的数据量是多少。  
&emsp; 如果使用超级机器，1TB内存的那种，官网不建议上那么牛逼的机器，建议分配4-32GB内存给heap，其他的全部用来做os cache，这样数据量全部缓存在内存中，不落盘查询，性能杠杠滴。  

### 1.4.2. 最佳实践建议  
1. 将heap的最小值和最大值设置为一样大。  
2. elasticsearch jvm heap设置得越大，就有越多的内存用来进行缓存，但是过大的jvm heap可能会导致长时间的gc停顿。  
3. jvm heap size的最大值不要超过物理内存的50%，才能给lucene的file system cache留下足够的内存。  
4. jvm heap size设置不要超过32GB，否则jvm无法启用compressed oops，将对象指针进行压缩，确认日志里有[node-1] heap size [1007.3mb], compressed ordinary object pointers [true] 字样出现。  
5. 最佳实践数据：heap size设置的小于zero-based compressed ooops，也就是26GB，但是有时也可以是30GB。通过-XX:+UnlockDiagnosticVMOptions -XX:+PrintCompressedOopsMode开启对应，确认有heap address: 0x00000000e0000000, size: 27648 MB, Compressed Oops mode: 32-bit字样，而不是heap address: 0x00000000f4000000, size: 28672 MB, Compressed Oops with base: 0x00000000f3ff0000字样。  

### 1.4.3. swapping问题
&emsp; 部署Elasticsearch的服务尽可能关闭到swap，如果内存缓存到磁盘上，那查询效率会由微秒级降到毫秒级，会造成性能急剧下降的隐患。  

&emsp; 关闭办法:  
1. Linux系统执行 swapoff -a 关闭swap，或在/etc/fstab文件中配置。  
2. elasticsearch.yml中可以设置：bootstrap.mlockall: true 锁住自己的内存不被swap到磁盘上。  

&emsp; 使用命令 GET _nodes?filter_path=**.mlockall 可以查看是否开启mlockall 响应信息：  

```json
{
  "nodes": {
    "A1s1uus7TpuDSiT4xFLOoQ": {
      "process": {
        "mlockall": true
      }
    }
  }
}
```


