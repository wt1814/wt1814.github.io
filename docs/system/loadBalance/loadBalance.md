
<!-- TOC -->

- [1. 负载均衡](#1-负载均衡)
    - [1.1. ~~前言：一次网络请求~~](#11-前言一次网络请求)
    - [1.2. ~~均衡技术~~](#12-均衡技术)
    - [1.3. ★★★基于网络的负载均衡的分类](#13-★★★基于网络的负载均衡的分类)
    - [1.4. 负载均衡算法](#14-负载均衡算法)
    - [1.5. 常用负载均衡工具](#15-常用负载均衡工具)

<!-- /TOC -->

&emsp; **<font color = "red">总结：</font>**  
&emsp; **<font color = "clime">★★★负载均衡方案选择</font>**  
&emsp; 小于3000万pv的，DNS轮询+监控；  
&emsp; **3000万以上的，nginx+监控；**  
&emsp; 5000万PV的，HAProxy+Keepalived,nginx，HAPROXY负责TCP的负载均衡，nginx负责7层调度；  
&emsp; **1亿以上的，LVS-DR+keepalived,nginx，LVS-DR负责TCP的负载均衡，nginx负责7层调度。**  

# 1. 负载均衡
<!--
https://www.jianshu.com/p/e3ac7d42c408
一文概括6种负载均衡技术的实现方式！
https://developer.51cto.com/art/201905/596538.htm?pc

https://blog.csdn.net/xlgen157387/article/details/78678772
亿级Web系统负载均衡几种实现方式 
https://mp.weixin.qq.com/s/cD4_yc9Lp5q76xzeys6N_g
全网最详尽的负载均衡原理图解 
https://mp.weixin.qq.com/s/JUM2W6qtNuZuSGbpAmFXnQ
不可不知的负载均衡
https://mp.weixin.qq.com/s/HRfHQm1ihSEs6VFzxoC4rQ
几种负载均衡技术的实现
https://blog.csdn.net/mengdonghui123456/article/details/53981976

-->
&emsp; 负载均衡(Load Balance)是集群技术(Cluster)的一种应用技术。负载均衡建立在现有网络结构之上，它提供了一种廉价有效透明的方法扩展网络设备和服务器的带宽、增加吞吐量、加强网络数据处理能力、提高网络的灵活性和可用性。 目前最常见的负载均衡应用是Web负载均衡。  

## 1.1. ~~前言：一次网络请求~~
&emsp; 客户端 ---> 网络链路 ---> 服务端


## 1.2. ~~均衡技术~~   
![image](http://www.wt1814.com/static/view/images/system/loadBalance/load-3.png)  

&emsp;常见的软件负载均衡技术有以下几种：  
1. 基于DNS的负载均衡  
&emsp; 由于在DNS服务器中，可以为多个不同的地址配置相同的名字，最终查询这个名字的客户机将在解析这个名字时得到其中一个地址，所以这种代理方式是通过DNS服务中的随机名字解析域名和IP来实现负载均衡。  
2. 反向代理负载均衡（如Apache+JK2+Tomcat这种组合）  
&emsp; 该种代理方式与普通的代理方式不同，标准代理方式是客户使用代理访问多个外部Web服务器，之所以被称为反向代理模式是因为这种代理方式是多个客户使用它访问内部Web服务器，而非访问外部服务器。  
3. 基于NAT(Network Address Translation)的负载均衡技术(如Linux VirtualServer，简称LVS)  
&emsp; 该技术通过一个地址转换网关将每个外部连接均匀转换为不同的内部服务器地址，因此外部网络中的计算机就各自与自己转换得到的地址上的服务器进行通信，从而达到负载均衡的目的。其中网络地址转换网关位于外部地址和内部地址之间，不仅可以实现当外部客户机访问转换网关的某一外部地址时可以转发到某一映射的内部的地址上，还可使内部地址的计算机能访问外部网络。  

&emsp; 除了软件负载均衡技术，常见的还有CDN(Content Delivery Network，内容分发网络)。通过发布机制将内容同步到大量的缓存节点，并在DNS服务器上进行扩展，找到里用户最近的缓存节点作为服务提供节点。  

--------------------


&emsp;  ~~主要应用~~
1. DNS负载均衡   
&emsp; 最早的负载均衡技术是通过DNS来实现的，在DNS中为多个地址配置同一个名字，因而查询这个名字的客户机将得到其中一个地址，从而使得不同的客户访问不同的服务器，达到负载均衡的目的。DNS负载均衡是一种简单而有效的方法，但是它不能区分服务器的差异，也不能反映服务器的当前运行状态。  
2. 代理服务器负载均衡  
&emsp; 使用代理服务器，可以将请求转发给内部的服务器，使用这种加速模式显然可以提升静态网页的访问速度。然而，也可以考虑这样一种技术，使用代理服务器将请求均匀转发给多台服务器，从而达到负载均衡的目的。  
3. 地址转换网关负载均衡    
&emsp; 支持负载均衡的地址转换网关，可以将一个外部IP地址映射为多个内部IP地址，对每次TCP连接请求动态使用其中一个内部地址，达到负载均衡的目的。  
4. 协议内部支持负载均衡    
&emsp; 除了这三种负载均衡方式之外，有的协议内部支持与负载均衡相关的功能， **<font color = "clime">例如HTTP协议中的重定向能力等，</font>** HTTP运行于TCP连接的最高层。  
5. NAT负载均衡NAT(Network Address Translation网络地址转换)   
&emsp; 简单地说就是将一个IP地址转换为另一个IP地址，一般用于未经注册的内部地址与合法的、已获注册的Internet IP地址间进行转换。适用于解决Internet IP地址紧张、不想让网络外部知道内部网络结构等的场合下。  
6. 反向代理负载均衡    
&emsp; 普通代理方式是代理内部网络用户访问internet上服务器的连接请求，客户端必须指定代理服务器，并将本来要直接发送到internet上服务器的连接请求发送给代理服务器处理。反向代理(Reverse Proxy)方式是指以代理服务器来接受internet上的连接请求，然后将请求转发给内部网络上的服务器，并将从服务器上得到的结果返回给internet上请求连接的客户端，此时代理服务器对外就表现为一个服务器。反向代理负载均衡技术是把将来自internet上的连接请求以反向代理的方式动态地转发给内部网络上的多台服务器进行处理，从而达到负载均衡的目的。  
7. 混合型负载均衡    
&emsp; 在有些大型网络，由于多个服务器群内硬件设备、各自的规模、提供的服务等的差异，可以考虑给每个服务器群采用最合适的负载均衡方式，然后又在这多个服务器群间再一次负载均衡或群集起来以一个整体向外界提供服务(即把这多个服务器群当做一个新的服务器群)，从而达到最佳的性能。将这种方式称之为混合型负载均衡。此种方式有时也用于单台均衡设备的性能不能满足大量连接请求的情况下。  

## 1.3. ★★★基于网络的负载均衡的分类  
&emsp; OSI模型有7层结构，每层都可以有几个子层。OSI的7层从上到下分别是物理层、数据链路层、网络层、传输层、会话层、表示层、应用层：  
![image](http://www.wt1814.com/static/view/images/system/loadBalance/load-1.png)  
&emsp; 根据负载均衡技术实现在OSI七层模型的不同层次，是可以给负载均衡分类的。大致可以分为以下几种，其中最常用的是四层和七层负载均衡：  
&emsp; **二层负载均衡：**负载均衡服务器对外依然提供一个VIP(虚IP)，集群中不同的机器采用相同IP地址，但机器的MAC地址不一样。当负载均衡服务器接受到请求之后，通过改写报文的目标MAC地址的方式将请求转发到目标机器实现负载均衡。  
&emsp; **三层负载均衡：**和二层负载均衡类似，负载均衡服务器对外依然提供一个VIP(虚IP)，但集群中不同的机器采用不同的IP地址。当负载均衡服务器接受到请求之后，根据不同的负载均衡算法，通过IP将请求转发至不同的真实服务器。  
&emsp; **四层负载均衡：**四层负载均衡工作在OSI模型的传输层，由于在传输层，只有TCP/UDP协议，这两种协议中除了包含源IP、目标IP以外，还包含源端口号及目的端口号。四层负载均衡服务器在接受到客户端请求后，以后通过修改数据包的地址信息(IP+端口号)将流量转发到应用服务器。  
&emsp; **七层负载均衡：**七层负载均衡工作在OSI模型的应用层，应用层协议较多，常用http、radius、DNS等。七层负载就可以基于这些协议来负载。这些应用层协议中会包含很多有意义的内容。比如同一个Web服务器的负载均衡，除了根据IP加端口进行负载外，还可根据七层的URL、浏览器类别、语言来决定是否要进行负载均衡。  
![image](http://www.wt1814.com/static/view/images/system/loadBalance/load-2.png)  
&emsp; 对于一般的应用来说，有了Nginx就够了。Nginx可以用于七层负载均衡。但是对于一些大的网站，一般会采用DNS+四层负载+七层负载的方式进行多层次负载均衡。  

<!-- 
七层负载均衡

七层负载均衡工作在 OSI 模型的应用层，应用层协议较多，常用 http、dns、ftp 等。七层负载就可以基于这些协议来负载。这些应用层协议中会包含很多有意义的内容。比如同一个 Web 服务器的负载均衡，除了根据 IP 加 port 进行负载外，还可根据 URL 来决定是否要进行负载均衡。
四层负载均衡

四层负载均衡工作在 OSI 模型的传输层，由于在传输层，只有 TCP/UDP 协议，这两种协议中除了包含源 IP、目标 IP 以外，还包含源端口及目的端口。四层负载均衡服务器在接受到客户端请求后，以后通过修改数据包的地址信息(IP+端口号)将流量转发到应用服务器。
-->

## 1.4. 负载均衡算法  
&emsp; **介绍**  
&emsp; 现有的负载均衡算法主要分为静态和动态两类。静态负载均衡算法以固定的概率分配任务，不考虑服务器的状态信息，如轮转算法、加权轮转算法等；动态负载均衡算法以服务器的实时负载状态信息来决定任务的分配，如最小连接法、加权最小连接法等。  
&emsp; **分类**
1. 轮询法：是将用户的请求轮流分配给服务器，就像是挨个数数，轮流分配。这种算法比较简单，他具有绝对均衡的优点，但是也正是因为绝对均衡它必须付出很大的代价，例如它无法保证分配任务的合理性，无法根据服务器承受能力来分配任务。  
2. 随机法：随机选择一台服务器来分配任务。它保证了请求的分散性达到了均衡的目的。同时它是没有状态的不需要维持上次的选择状态和均衡因子。但是随着任务量的增大，它的效果趋向轮询后也会具有轮询算法的部分缺点。  
3. 最小连接法：将任务分配给此时具有最小连接数的节点，因此它是动态负载均衡算法。一个节点收到一个任务后连接数就会加1，当节点故障时就将节点权值设置为0，不再给节点分配任务。  
&emsp; 最小连接法适用于各个节点处理的性能相似时。任务分发单元会将任务平滑分配给服务器。但当服务器性能差距较大时，就无法达到预期的效果。因为此时连接数并不能准确表明处理能力，连接数小而自身性能很差的服务器可能不及连接数大而自身性能极好的服务器。所以在这个时候就会导致任务无法准确的分配到剩余处理能力强的机器上。  

## 1.5. 常用负载均衡工具
&emsp; 常用的软件负载均衡软件有[Nginx](/docs/system/loadBalance/Nginx/nginx.md)、[LVS](/docs/system/loadBalance/LVS.md)、HaProxy等。  

&emsp; **<font color = "clime">★★★负载均衡方案选择</font>**  
&emsp; 小于3000万pv的，DNS轮询+监控；  
&emsp; **3000万以上的，nginx+监控；**  
&emsp; 5000万PV的，HAProxy+Keepalived,nginx，HAPROXY负责TCP的负载均衡，nginx负责7层调度；  
&emsp; **1亿以上的，LVS-DR+keepalived,nginx，LVS-DR负责TCP的负载均衡，nginx负责7层调度。**  



<!-- 




什么3层负载均衡、4层负载均衡、7层负载均衡什么的？那这是怎么分的呢，ok，是根据osi七层网络模型来分的，例如nginx是工作在应用层，应用层刚好是在第7层，因此nginx又可以称为7层负载均衡。

LVS、Nginx、HAProxy 是目前使用最广泛的三种软件负载均衡软件。
目前关于网站架构一般比较合理流行的架构方案：Web 前端采用 Nginx/HAProxy+Keepalived 作负载均衡器；后端采用 MySQ L数据库一主多从和读写分离，采用 LVS+Keepalived 的架构。

负载均衡技术方案有几种？
目前市面上最常见的负载均衡技术方案主要有三种：
基于DNS负载均衡
基于硬件负载均衡
基于软件负载均衡
三种方案各有优劣，DNS负载均衡可以实现在地域上的流量均衡，硬件负载均衡主要用于大型服务器集群中的负载需求，而软件负载均衡大多是基于机器层面的流量均衡。在实际场景中，这三种是可以组合在一起使用。

9.1.5. CDN 原理
CND 一般包含分发服务系统、负载均衡系统和管理系统

9.1.5.1. 分发服务系统
其基本的工作单元就是各个 Cache 服务器。负责直接响应用户请求，将内容快速分发到用户；同时还负责内容更新，保证和源站内容的同步。

根据内容类型和服务种类的不同，分发服务系统分为多个子服务系统，如：网页加速服务、流媒体加速服务、应用加速服务等。每个子服务系统都是一个分布式的服务集群，由功能类似、地域接近的分布部署的 Cache 集群组成。

在承担内容同步、更新和响应用户请求之外，分发服务系统还需要向上层的管理调度系统反馈各个Cache 设备的健康状况、响应情况、内容缓存状况等，以便管理调度系统能够根据设定的策略决定由哪个 Cache 设备来响应用户的请求。

9.1.5.2. 负载均衡系统：
负载均衡系统是整个 CDN 系统的中枢。负责对所有的用户请求进行调度，确定提供给用户的最终访问地址。
使用分级实现。最基本的两极调度体系包括全局负载均衡（GSLB）和本地负载均衡（SLB）。GSLB 根据用户地址和用户请求的内容，主要根据就近性原则，确定向用户服务的节点。一般通过 DNS解析或者应用层重定向（Http 3XX 重定向）的方式实现。
SLB 主要负责节点内部的负载均衡。当用户请求从 GSLB 调度到 SLB 时，SLB 会根据节点内各个Cache 设备的工作状况和内容分布情况等对用户请求重定向。SLB 的实现有四层调度（LVS）、七层调度（Nginx）和链路负载调度等。

1. 基于DNS负载均衡

基于DNS来做负载均衡其实是一种最简单的实现方案，通过在DNS服务器上做一个简单配置即可。
其原理就是当用户访问域名的时候，会先向DNS服务器去解析域名对应的IP地址，这个时候我们可以让DNS服务器根据不同地理位置的用户返回不同的IP。比如南方的用户就返回在广州业务服务器的IP，北方的用户来访问的话，就返回北京业务服务器所在的IP。

在这个模式下，用户就相当于实现了按照「就近原则」将请求分流了，既减轻了单个集群的负载压力，也提升了用户的访问速度。
使用DNS做负载均衡的方案，天然的优势就是配置简单，实现成本非常低，无需额外的开发和维护工作。
但是也有一个明显的缺点是：当配置修改后，生效不及时。这个是由于DNS的特性导致的，DNS一般会有多级缓存，所以当我们修改了DNS配置之后，由于缓存的原因，会导致IP变更不及时，从而影响负载均衡的效果。
另外，使用DNS做负载均衡的话，大多是基于地域或者干脆直接做IP轮询，没有更高级的路由策略，所以这也是DNS方案的局限所在。

2. 基于硬件负载均衡

硬件的负载均衡那就比较牛逼了，比如大名鼎鼎的 F5 Network Big-IP，也就是我们常说的 F5，它是一个网络设备，你可以简单的理解成类似于网络交换机的东西，完全通过硬件来抗压力，性能是非常的好，每秒能处理的请求数达到百万级，即 几百万/秒 的负载，当然价格也就非常非常贵了，十几万到上百万人民币都有。
因为这类设备一般用在大型互联网公司的流量入口最前端，以及政府、国企等不缺钱企业会去使用。一般的中小公司是不舍得用的。
采用 F5 这类硬件做负载均衡的话，主要就是省心省事，买一台就搞定，性能强大，一般的业务不在话下。而且在负载均衡的算法方面还支持很多灵活的策略，同时还具有一些防火墙等安全功能。但是缺点也很明显，一个字：贵。


硬件负载均衡技术只专注网络判断，不考虑业务系统与应用使用的情况。

看上去它对处理网络请求是非常专业的，但有趣的是，如果应用服务出现了流量瓶颈，而“接入层”的硬件负载均衡没有发现异常，还是让流量继续进入到应用服务器，并没有阻止，就会造成应用服务器流量过大。

所以，为了保证高可用，可以在“接入层”和“代理层”同时考虑限流的问题。

作为硬件负载均衡器，常在大企业使用。下面我们以 F5 公司的“F5 BIG-IP”产品为蓝本给大家介绍（下面简称 F5）。


优缺点总结
    优点：直接连接交换机，处理网络请求能力强，与系统无关，负载性能强。可以应用于大量设施，适应大访问量、使用简单。

    缺点：成本高，配置冗余。即使网络请求分发到服务器集群，负载均衡设施却是单点配置；无法有效掌握服务器及应使用状态。



硬件负载均衡器三大功能
①多链路负载均衡
关键业务都需要安排和配置多条 ISP（网络服务供应商）接入链路来保证网络服务的可靠性。


如果某个 ISP 停止服务或者服务异常了，那么可以利用另一个 ISP 替代服务，提高了网络的可用性。


不同的 ISP 有不同自治域，因此需要考虑两种情况：

INBOUND
OUTBOUND


INBOUND，来自网络的请求信息。F5 分别绑定两个 ISP 服务商的公网地址，解析来自两个 ISP 服务商的 DNS 解析请求。

F5 可以根据服务器状况和响应情况对 DNS 进行发送，也可以通过多条链路分别建立 DNS 连接。

OUTBOUND，返回给请求者的应答信息。F5 可以将流量分配到不同的网络接口，并做源地址的 NAT（网络地址转换），即通过 IP 地址转换为源请求地址。

也可以用接口地址自动映射，保证数据包返回时能够被源头正确接收。

②防火墙负载均衡
针对大量网络请求的情况，单一防火墙的能力就有限了，而且防火墙本身要求数据同进同出，为了解决多防火墙负载均衡的问题，F5 提出了防火墙负载均衡的“防火墙三明治"方案。

防火墙会对用户会话的双向数据流进行监控，从而确定数据的合法性。如果采取多台防火墙进行负载均衡，有可能会造成同一个用户会话的双向数据在多台防火墙上都进行处理。

而单个防火墙上看不到完成用户会话的信息，就会认为数据非法因此抛弃数据。

所以在每个防火墙的两端要架设四层交换机，可以在作流量分发的同时，维持用户会话的完整性，使同一用户的会话由一个防火墙来处理。而这种场景就需要 F5 负载均衡器协助才能完成转发。

有趣的是，F5 协调上述方案的配置和实现后，会把“交换机”，“防火墙”，“交换机”夹在了一起好像三明治一样。



③服务器负载均衡
在硬件负载均衡器挂接多个应用服务器时，需要为这些服务做负载均衡，根据规则，让请求发送到服务器上去：

    对于服务器的负载均衡的前提是，服务器都提供同样的服务，也就是同样的业务同时部署在多个服务器上。

    对于应用服务器可以在 F5 上配置并且实现负载均衡，F5 可以检查服务器的健康状态，如果发现故障，将其从负载均衡组中移除。

    F5 对于外网而言有一个真实的 IP，对于内网的每个服务器都生成一个虚拟 IP，进行负载均衡和管理工作。因此,它能够为大量的基于 TCP/IP 的网络应用提供服务器负载均衡服务。

    根据服务类型不同定义不同的服务器群组。

    根据不同服务端口将流量导向对应的服务器。甚至可以对 VIP 用户的请求进行特殊的处理，把这类请求导入到高性能的服务器使 VIP 客户得到最好的服务响应。

    根据用户访问内容的不同将流量导向指定服务器。


3. 基于软件负载均衡

软件负载均衡是指使用软件的方式来分发和均衡流量。软件负载均衡，分为7层协议 和 4层协议。
网络协议有七层，基于第四层传输层来做流量分发的方案称为4层负载均衡，例如 LVS，而基于第七层应用层来做流量分发的称为7层负载均衡，例如 Nginx。这两种在性能和灵活性上是有些区别的。
基于4层的负载均衡性能要高一些，一般能达到 几十万/秒 的处理量，而基于7层的负载均衡处理量一般只在 几万/秒 。
基于软件的负载均衡的特点也很明显，便宜。在正常的服务器上部署即可，无需额外采购，就是投入一点技术去优化优化即可，因此这种方式是互联网公司中用得最多的一种方式。

LVS、Nginx、HAProxy 是目前使用最广泛的三种软件负载均衡软件。
一般对负载均衡的使用是随着网站规模的提升根据不同的阶段来使用不同的技术。具体的应用需求还得具体分析，如果是中小型的 Web 应用，比如日 PV 小于1000万，用 Nginx 就完全可以了；如果机器不少，可以用 DNS 轮询，LVS 所耗费的机器还是比较多的；大型网站或重要的服务，且服务器比较多时，可以考虑用 LVS。

目前关于网站架构一般比较合理流行的架构方案：Web 前端采用 Nginx/HAProxy+Keepalived 作负载均衡器；后端采用 MySQ L数据库一主多从和读写分离，采用 LVS+Keepalived 的架构。


目前比较流行的有 LVS，Nginx 和 HAProxy，逐个看看他们的特点。
LVS

LVS（Linux Virtual Server） 是使用 Linux 内核集群实现的一个高性能、高可用的负载均衡服务器，它具有很好的可伸缩性（Scalability)、可靠性（Reliability)和可管理性（Manageability)。

LVS 特点是：
仅作分发之用，即把请求直接分发给应用服务器，因此没有流量的产生，对资源的消耗低。
配置简单，能够配置的项目少。
工作在第四层（传输层），支持 TCP/UDP，对应用的支持广泛。


HAProxy


HAProxy 实现了一种事件驱动, 单一进程模型，此模型支持非常大的并发连接数。

多进程或多线程模型受内存限制 、系统调度器限制以及无处不在的锁限制，很少能处理数千并发连接。

HAProxy 特点是：
支持虚拟主机。
支持 Session 保持，Cookie 引导。
通过指定的 URL 来检测应用服务器的状态。
支持 TCP/HTTP 协议转发。

HAProxy 支持两种代理模式 TCP（四层）和HTTP（七层），也是支持虚拟主机的。

HAProxy 的优点能够补充 Nginx 的一些缺点，比如支持 Session 的保持，Cookie 的引导；同时支持通过获取指定的 url 来检测后端服务器的状态。

HAProxy 跟 LVS 类似，本身就只是一款负载均衡软件；单纯从效率上来讲 HAProxy 会比 Nginx 有更出色的负载均衡速度，在并发处理上也是优于 Nginx 的。

HAProxy 支持 TCP 协议的负载均衡转发，可以对 MySQL 读进行负载均衡，对后端的 MySQL 节点进行检测和负载均衡，大家可以用 LVS+Keepalived 对 MySQL 主从做负载均衡。

HAProxy 负载均衡策略非常多：Round-robin（轮循）、Weight-round-robin（带权轮循）、source（原地址保持）、RI（请求URL）、rdp-cookie（根据cookie）。
Nginx
Nginx 是一款轻量级的 Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个 BSD-like 协议下发行。

Nginx 特点是：
工作在网络的 4/7 层，对 HTTP 应用做负载均衡策略，如：域名、目录结构。
对网络的稳定性依赖小，可以区分内网和外网的访问。
安装和配置相对简单。
能承受很高负载且稳定，处理的流量依赖于按照 Nginx 服务器的配置。
可以检测服务器的问题，可以对服务器返回的信息进行处理和过滤，避免让无法工作的服务器响应请求。
对请求可以进行异步处理。
支持 HTTP、HTTPS 和 EMAIL。






硬件和软件负载
“硬件负载均衡器”，一般安装在外部网络与内网服务器之间。比较流行的有 NetScaler，F5，Radware，Array 等产品。


硬件负载均衡器在外网和内网之间

相对于“硬件负载均衡器”来说，对内网服务器进行负载均衡就属于“软件负载均衡器”。例如：LVS，HAProxy，Nginx。
硬件负载均衡工作在“接入层”，主要任务是多链路负载均衡，防火墙负载均衡，服务器负载均衡。
软件负载均衡工作在“代理层”，主要任务是反向代理，缓存，数据验证等等。

硬件负载均衡和软件负载均衡工作在不同的层
硬件负载均衡在接入层获得网络请求，然后转交给软件负载均衡，用同样的方式处理返回的请求。


客户端是如何把请求发送到应用服务器的	
客户端把请求发送到应用服务器有如下几个步骤：
客户端请求 URL 给 DNS。
DNS 将 URL 转化成对应的 IP。
通过 IP 找到服务器。
服务器接受到请求的报文，转交给接入层处理，接入层由于采用了硬件负载均衡器，所以能够扛住大数据量。
接入层把报文再次转交给代理层（并发 5W），代理层的 Nginx 收到报文再根据反向代理的策略发送给上游服务器（应用服务器）。


硬件和软件负载均衡，分别工作在“接入层”和“代理层”。
一个专注于网络，负责多链路，防火墙以及服务器的负载均衡，例如：F5 BIG-IP。
另一个偏向于业务，主要功能是反向代理，动态代理，缓存，限流，例如：LVS，Nginx，HAProxy。



-->

