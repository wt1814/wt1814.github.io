

<!-- TOC -->

- [1. JMM](#1-jmm)
    - [1.1. JMM介绍](#11-jmm介绍)
    - [1.2. JMM中内存划分](#12-jmm中内存划分)
        - [1.2.1. 计算机内存模型](#121-计算机内存模型)
        - [1.2.2. JMM中内存划分](#122-jmm中内存划分)
        - [1.2.3. JMM内存间的交互操作](#123-jmm内存间的交互操作)
    - [1.3. 并发问题及含义](#13-并发问题及含义)
    - [1.4. 重排序](#14-重排序)
        - [1.4.1. 为什么代码会重排序？](#141-为什么代码会重排序)
        - [1.4.2. 指令重排序分类](#142-指令重排序分类)
        - [1.4.3. 重排序规则](#143-重排序规则)
            - [1.4.3.1. 重排序遵守数据依赖性](#1431-重排序遵守数据依赖性)
            - [1.4.3.2. 重排序遵守as-if-serial语义](#1432-重排序遵守as-if-serial语义)
        - [1.4.4. 重排序对多线程的影响](#144-重排序对多线程的影响)
    - [1.5. CPU的MESI缓存一致性协议](#15-cpu的mesi缓存一致性协议)
        - [1.5.1. 缓存一致性问题](#151-缓存一致性问题)
        - [1.5.2. 总线锁（性能低）](#152-总线锁性能低)
        - [1.5.3. MESI缓存一致性协议](#153-mesi缓存一致性协议)
        - [1.5.4. 总线嗅探](#154-总线嗅探)
        - [1.5.5. 总线风暴](#155-总线风暴)
    - [1.6. JMM中的happens-before原则](#16-jmm中的happens-before原则)
    - [1.7. 内存屏障](#17-内存屏障)
        - [1.7.1. 伪共享问题](#171-伪共享问题)
            - [1.7.1.1. CPU缓存架构](#1711-cpu缓存架构)
            - [1.7.1.2. CPU缓存行](#1712-cpu缓存行)
            - [1.7.1.3. 伪共享](#1713-伪共享)
            - [1.7.1.4. 避免伪共享](#1714-避免伪共享)
            - [1.7.1.5. 总结](#1715-总结)
    - [1.8. java并发原语](#18-java并发原语)

<!-- /TOC -->

![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-10.png)  

# 1. JMM  

<!-- 
https://blog.csdn.net/w1453114339/article/details/107563613
https://mp.weixin.qq.com/s/0_TDPDx8q2HmKCMyupWuNA
-->

## 1.1. JMM介绍
&emsp; JMM是Java内存模型，也就是Java Memory Model，简称JMM，本身是一种抽象的概念，实际上并不存在，它描述的是一组规则或规范，通过这组规范定义了程序中各个变量（包括实例字段，静态字段和构成数组对象的元素）的访问方式。  

1. 定义程序中各种变量的访问规则
2. 把变量值存储到内存的底层细节
3. 从内存中取出变量值的底层细节

&emsp; Java内存模型（Java Memory Model，JMM）是一种符合顺序一致内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-6.png)  
&emsp; **JMM定义了Java虚拟机（JVM）在计算机内存（RAM）中的工作方式。JMM主要规定了以下两点：**  

* 规定了一个线程如何以及何时可以看到其他线程修改过后的共享变量的值，即线程之间共享变量的可见性。  
* 如何在需要的时候对共享变量进行同步。  

&emsp; **<font color = "lime">在并发编程需要处理的两个关键问题是：线程之间如何通信和线程之间如何同步，即以上两条标准的体现。</font>** **<font color = "red">线程通信是一种手段，而线程同步是一种目的，即线程通信的主要目的是用于线程同步。线程同步是为了解决线程安全问题。</font>**

* 线程通信  

        通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。
        在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。
        在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。

* 线程同步  

        同步是指程序用于控制不同线程之间操作发生相对顺序的机制。
        在共享内存的并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。
        在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。    

&emsp; **<font color = "red">Java的并发采用的是共享内存模型</font>**，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。


## 1.2. JMM中内存划分  

### 1.2.1. 计算机内存模型

...

### 1.2.2. JMM中内存划分  
&emsp; Java线程内存模型跟cpu缓存模型类似，是基于cpu缓存模型来建立的，Java线程内存模型是标准化的，屏蔽掉了底层不同计算机的区别。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-7.png)   

* 主内存：Java 内存模型规定了所有变量都存储在主内存(Main Memory)中（此处的主内存与物理硬件的主内存RAM 名字一样，两者可以互相类比，但此处仅是虚拟机内存的一部分）。  
    * Java堆中对象实例数据部分
    * 对应于物理硬件的内存
* 工作内存：每条线程都有自己的工作内存(Working Memory，又称本地内存，可与CPU高速缓存类比)，线程的工作内存中保存了该线程使用到的主内存中的共享变量的副本拷贝。线程对变量的所有操作都必须在工作内存进行，而不能直接读写主内存中的变量。工作内存是 JMM 的一个抽象概念，并不真实存在。  
    * Java栈中的部分区域
    * 优先存储于寄存器和高速缓存

&emsp; Java内存模型的几个规范：  
1. 所有变量存储在主内存  
2. 主内存是虚拟机内存的一部分  
3. 每条线程有自己的工作内存  
4. 线程的工作内存保存变量的主内存副本  
5. 线程对变量的操作必须在工作内存中进行  
6. 不同线程之间无法直接访问对方工作内存中的变量  
7. 线程间变量值的传递均需要通过主内存来完成  

&emsp; 由于JVM运行程序的实体是线程，而每个线程创建时JVM都会为其创建一个工作内存（有些地方称为栈空间），工作内存是每个线程的私有数据区域，而Java内存模型中规定所有变量都存储在主内存，主内存是共享内存区域，所有线程都可以访问，<font color = "red">但线程对变量的操作（读取赋值等）必须在工作内存中进行，首先要将变量从主内存拷贝到自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，</font>各个线程中的工作内存中存储着主内存中的变量副本拷贝，<font color = "lime">因此不同的线程间无法访问对方的工作内存，线程间的通信（传值）必须通过主内存来完成，</font>其简要访问过程：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-42.png)   

### 1.2.3. JMM内存间的交互操作  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-8.png)   
&emsp; Java内存模型为主内存和工作内存间的变量拷贝及同步定义8种原子性操作指令。  

* read（读取）：从主内存读取数据。  
* load（载入）：将主内存读取到的数据。  
* use（使用）：从工作内存读取数据来计算。  
* assign(赋值)：将计算好的值重新赋值到工作内存中。
* store（存储）：将工作内存数据写入主内存。 
* write（写入）：将store过去的变量值赋值给主内存中的变量。 
* lock（锁定）：将主内存变量加锁，标识为线程独占状态。  
* unlock（解锁）：将主内存变量解锁，解锁后其他线程可以锁定该变量。  

&emsp; 要把一个变量从主内存中复制到工作内存，就需要按顺寻地执行read和load操作，如果把变量从工作内存中同步回主内存中，就要按顺序地执行store和write操作。  
&emsp; Java内存模型只要求上述两个操作必须按顺序执行，而没有保证必须是连续执行。也就是read和load之间，store和write之间是可以插入其他指令的。  

&emsp; Java内存模型还规定了在执行上述八种基本操作时，必须满足如下规则：  

* 不允许read和load、store和write操作之一单独出现。  
* 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中。  
* 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中。  
* 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。  
* 一个变量在同一时刻只允许一条线程对其进行lock操作，lock和unlock必须成对出现  
* 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值  
* 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。  
* 对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）。

----
## 1.3. 并发问题及含义  
&emsp; 并发编程存在原子性、可见性、有序性问题。  

* 原子性，即一系列操作要么都执行，要么都不执行。
    * 线程切换会导致原子性问题。  
* 可见性，当一个线程修改了共享变量的值时，其他线程能够立即得知这个修改。
    * 由于多核CPU，每个CPU核都有高速缓存，会缓存共享变量，某个线程对共享变量的修改会改变高速缓存中的值，但却不会马上写入内存。另一个线程读到的是另一个核缓存的共享变量的值，出现缓存不一致问题。  
* 有序性，即程序执行的顺序按照代码的先后顺序执行。  
    * 编译器和处理器会对指令进行重排，以优化指令执行性能，重排不会改变单线程执行结果，但在多线程中可能会引起各种各样的问题。  

&emsp; 关于有序性：如果在本线程内观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指“线程内似表现为串行的语义”（Within-Thread As-If-Serial Semantics），后半句是指“指令重排序”现象和“工作内存与主内存同步延迟”现象。  

<!-- 
&emsp; **总结： <font color = "red">出现线程安全问题的原因：线程切换带来的原子性问题；缓存不能及时刷新导致的可见性问题；编译器优化带来的有序性问题。“缓存不能及时刷新“和“编译器为了优化性能而改变程序中语句的先后顺序”都是重排序的一种。</font>**   
-->
----

## 1.4. 重排序  
### 1.4.1. 为什么代码会重排序？  
&emsp; 在执行程序时，为了提供性能，处理器和编译器常常会对指令进行重排序，但是<font color = "lime">不能随意重排序，它需要满足以下两个条件：</font>  

* <font color = "red">在单线程环境下不能改变程序运行的结果；</font>  
* <font color = "red">存在数据依赖关系的不允许重排序。</font>  

&emsp; 需要注意的是：重排序不会影响单线程环境的执行结果，但是会破坏多线程的执行语义。  

### 1.4.2. 指令重排序分类  
&emsp; 从Java源代码到最终实际执行的指令序列，会分别经历下面三种重排序：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-2.png)  

<!-- 
1. 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。  
2. 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。  
3. 内存系统的重排序。由于处理器使用缓存和读／写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。  
-->

1. 编译器优化：对于没有数据依赖关系的操作，编译器在编译的过程中会进行一定程度的重排。  
2. 指令重排序：CPU优化行为，也是会对不存在数据依赖关系的指令进行一定程度的重排。  
3. 内存系统重排序：内存系统没有重排序，但是由于有缓存的存在，使得程序整体上会表现出乱序的行为。  

&emsp; 上面的这些重排序都可能导致多线程程序出现内存可见性问题。对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。  
&emsp; JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。  

### 1.4.3. 重排序规则  
#### 1.4.3.1. 重排序遵守数据依赖性  
&emsp; 如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分下列三种类型：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-3.png)  
&emsp; 上面三种情况，只要重排序两个操作的执行顺序，程序的执行结果将会被改变。  

&emsp; 编译器和处理器可能会对操作做重排序。编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。  
&emsp; 注意，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。  

#### 1.4.3.2. 重排序遵守as-if-serial语义  
&emsp; **<font color = "red">as-if-serial语义的意思指：不管怎么重排序(编译器和处理器为了提高并行度)，(单线程)程序的执行结果不能被改变。编译器，runtime和处理器都必须遵守as-if-serial语义。</font>**  

### 1.4.4. 重排序对多线程的影响  
&emsp; 示例代码：  

```java
class Demo {
    int a = 0;
    boolean flag = false;

    public void write() {
        a = 1;            //1
        flag = true;    //2
    }

    public void read() {
        if(flag) {            //3
            int i = a * a;    //4
        }
    }
}
```
&emsp; 由于操作1和2没有数据依赖关系，编译器和处理器可以对这两个操作重排序；操作3和操作4没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。  

1. 当操作1和操作2重排序时，可能会产生什么效果？  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-4.png)  
&emsp; 如上图所示，操作1和操作2做了重排序。程序执行时，线程A首先写标记变量flag，随后线程B读这个变量。由于条件判断为真，线程B将读取变量a。此时，变量a还根本没有被线程A写入，在这里多线程程序的语义被重排序破坏了！  
2. 当操作3和操作4重排序时会产生什么效果（借助这个重排序，可以顺便说明控制依赖性）。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-5.png)  
&emsp; 在程序中，操作3和操作4存在控制依赖关系。当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程B 的处理器可以提前读取并计算a * a，然后把计算结果临时保存到一个名为重排序缓冲（reorder buffer ROB）的硬件缓存中。当接下来操作3的条件判断为真时，就把该计算结果写入变量i中。  

&emsp; 从图中可以看出，猜测执行实质上对操作3和4做了重排序。重排序在这里破坏了多线程程序的语义！  
&emsp; 在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。  

-----
## 1.5. CPU的MESI缓存一致性协议
### 1.5.1. 缓存一致性问题  
&emsp; 当多个CPU持有的缓存都来自同一个主内存的拷贝，当有某个CPU修改了这个主内存数据后，而其他CPU并不知道，那拷贝的内存将会和主内存不一致，这就是缓存不一致。那如何来保证缓存一致呢？这里就需要操作系统来共同制定一个同步规则来保证。  

### 1.5.2. 总线锁（性能低）  
&emsp; 早期，cpu从主内存读取数据到高速缓存，会在总线对这个数据加锁，这样其他cpu无法去读或写这个数据，直到这个cpu使用完数据释放锁之后其他cpu才能读取该数据。  

### 1.5.3. MESI缓存一致性协议  

<!-- 
&emsp; 而这个规则就有MESI协议。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-43.png)  
&emsp; 如下图所示，CPU2 偷偷将num修改为2，内存中num也被修改为2，但是CPU1和CPU3并不知道num值变了。  
-->

&emsp; **<font color = "lime">多个cpu从主内存读取同一个数据到各自的高速缓存，当其中某个cpu修改了缓存里的数据，该数据会马上同步回主内存，其他cpu通过总线嗅探机制可以感知到数据的变化从而将自己缓存里的数据失效。</font>**  

![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-47.png)  

&emsp; 当CPU写数据时，如果发现操作的变量是共享变量，即在其它CPU中也存在该变量的副本，系统会发出信号通知其它CPU将该内存变量的缓存行设置为无效。如下图所示，CPU1和CPU3 中num=1已经失效了。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-44.png)  
&emsp; 当其它CPU读取这个变量的时，发现自己缓存该变量的缓存行是无效的，那么它就会从内存中重新读取。  
&emsp; 如下图所示，CPU1和CPU3发现缓存的num值失效了，就重新从内存读取，num值更新为2。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-45.png)  

### 1.5.4. 总线嗅探  
&emsp; 那其他CPU是怎么知道要将缓存更新为失效的呢？这里是用到了总线嗅探技术。  
&emsp; **<font color = "red">每个CPU不断嗅探总线上传播的数据来检查自己缓存值是否过期了，如果处理器发现自己的缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置为无效状态，当处理器对这个数据进行修改操作的时候，会重新从内存中把数据读取到处理器缓存中。</font>**  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-46.png)  

### 1.5.5. 总线风暴
&emsp; 总线嗅探技术有哪些缺点？  
&emsp; 由于MESI缓存一致性协议，需要不断对主线进行内存嗅探，大量的交互会导致总线带宽达到峰值。因此不要滥用volatile，可以用锁来替代，看使用场景。  

## 1.6. JMM中的happens-before原则
&emsp; JSR-133内存模型 **<font color = "red">使用happens-before的概念来阐述操作之间的内存可见性。在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。</font>** 这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。  
<!-- 
&emsp; Happens-before规则主要用来约束两个操作，两个操作之间具有 happens-before关系, 并不意味着前一个操作必须要在后一个操作之前执行，happens-before 仅仅要求前一个操作(执行的结果)对后一个操作可见, (the first is visible to and ordered before the second，前一个操作的结果可以被后续的操作获取)。  
-->
&emsp; happens-before关系的分析需要分为单线程和多线程的情况：  

* 单线程下的 happens-before 字节码的先后顺序天然包含happens-before关系：因为单线程内共享一份工作内存，不存在数据一致性的问题。在程序控制流路径中靠前的字节码 happens-before 靠后的字节码，即靠前的字节码执行完之后操作结果对靠后的字节码可见。然而，这并不意味着前者一定在后者之前执行。实际上，如果后者不依赖前者的运行结果，那么它们可能会被重排序。  
* 多线程下的 happens-before 多线程由于每个线程有共享变量的副本，如果没有对共享变量做同步处理，线程1更新执行操作A共享变量的值之后，线程2开始执行操作B，此时操作A产生的结果对操作B不一定可见。  

&emsp; 为了方便程序开发，Java 内存模型实现了下述的先行发生关系：  

* 程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作。  
* 管程锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作。  
* volatile变量规则：对一个变量的写操作happens-before后面对这个变量的读操作。  
* 传递规则： 如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C。  
* 线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作。  
* 线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生。  
* 线程终结规则：线程中所有的操作都先行发生于线程的终止检测，可以通过Thread.join()方法结束 、Thread.isAlive()的返回值手段检测到线程已经终止执行。  
* 对象终结规则： 一个对象的初始化完成先行发生于它的finalize()方法的开始。  

&emsp; **<font color = "red">as-if-serial规则和happens-before规则的区别：</font>**  

* as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。  
* as-if-serial语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：正确同步的多线程程序是按happens-before指定的顺序来执行的。  
* as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。  

----

## 1.7. 内存屏障  
&emsp; **<font color = "red">Java中如何保证底层操作的有序性和可见性？可以通过内存屏障。</font>**  

&emsp; 什么是内存屏障？硬件层⾯，<font color = "red">内存屏障分两种：读屏障（Load Barrier）和写屏障（Store Barrier）。</font>  

&emsp; **<font color = "lime">内存屏障的作用：</font>**  

* **<font color = "lime">（保障有序性）阻⽌屏障两侧的指令重排序。</font>** 它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成；  
* **<font color = "lime">（保障可见性）它会强制将对缓存的修改操作立即写入主存；</font>** **<font color = "red">如果是写操作，会触发总线嗅探机制（MESI）,会导致其他CPU中对应的缓存行无效，会引发伪共享问题。</font>**  

<!-- 
内存屏障有两个作⽤：  
1. 阻⽌屏障两侧的指令重排序；  
2. 强制把写缓冲区/⾼速缓存中的脏数据等写回主内存，或者让缓存中相应的数据失效。 
&emsp; **<font color= "red">内存屏障是被插入两个CPU指令之间的一种指令，用来禁止处理器指令发生重排序，从而保障有序性的。另外，为了达到屏障的效果，它也会使处理器写入、读取值之前，将主内存的值写入高速缓存，清空无效队列，从而保障可见性。</font>**  
-->

&emsp; 例如：

    Store1;
    Store2;
    Load1;
    StoreLoad;  //内存屏障
    Store3;
    Load2;
    Load3;

&emsp; 对于上面的一组CPU指令（Store表示写入指令，Load表示读取指令），StoreLoad 屏障之前的Store指令无法与StoreLoad 屏障之后的Load指令进行交换位置，即重排序。但是StoreLoad屏障之前和之后的指令是可以互换位置的，即Store1可以和Store2互换，Load2可以和Load3互换。  

&emsp; <font color = "red">常见的4种屏障：(load载入，store存储)</font>  

|屏障类型 |简称 |指令示例|说明|
|---|---|---|---|
|StoreStore Barriers |写-写 屏障|Store1;StoreStore;Store2 |确保Store1数据对其他处理器可见（指刷新到内存）先于Store2及所有后续存储指令的存储。|
|StoreLoad Barriers |写-读 屏障 |Store1;StoreLoad;Load2 |确保Store1数据对其他处理器变得可见（指刷新到内存）先于Load2及所有后续装载指令的装载。<br/>StoreLoad Barriers会使屏障之前的所有内存访问指令（存储和装载指令）完成之后，才执行该屏障之后的内存访问指令。|
|LoadLoad Barriers|读-读 屏障 |Load1;LoadLoad;Load2 |(Load1代表加载数据，Store1表示刷新数据到内存)确保Load1数据的状态先于Load2及所有后续装载指令的装载。|
|LoadSotre Barriers|读-写 屏障|Load1;LoadStore;Store2|确保Load1数据装载先于Store2及所有后续的存储指令刷新到内存。| 

<!-- 
* LoadLoad（LL）屏障：对于这样的语句 Load1; LoadLoad; Load2，<font color = "red">在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。</font>  
* StoreStore（SS）屏障：对于这样的语句 Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。  
* LoadStore（LS）屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被执行前，保证Load1要读取的数据被读取完毕。  
* StoreLoad （SL）屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的（冲刷写缓冲器，清空无效化队列）。在大多数处理器的实现中，这个屏障也被称为全能屏障，兼具其它三种内存屏障的功能。  
-->

&emsp; **Java中对内存屏障的使用，常见的有volatile关键字修饰的代码块，还可以通过Unsafe这个类来使用内存屏障。**  

### 1.7.1. 伪共享问题

<!-- 
https://blog.csdn.net/qq_28119741/article/details/102815659
-->

#### 1.7.1.1. CPU缓存架构
&emsp; CPU是计算机的心脏，所有运算和程序最终都要由它来执行。  
&emsp; 主内存（RAM）是数据存放的地方，CPU 和主内存之间有好几级缓存，因为即使直接访问主内存也是非常慢的。  
&emsp; 如果对一块数据做相同的运算多次，那么在执行运算的时候把它加载到离 CPU 很近的地方就有意义了，比如一个循环计数，不想每次循环都跑到主内存去取这个数据来增长它吧。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-50.png)  
&emsp; <font color = "red">越靠近 CPU 的缓存越快也越小。</font>  
&emsp; 所以 L1 缓存很小但很快，并且紧靠着在使用它的 CPU 内核。  
&emsp; L2 大一些，也慢一些，并且仍然只能被一个单独的 CPU 核使用。  
&emsp; L3 在现代多核机器中更普遍，仍然更大，更慢，并且被单个插槽上的所有 CPU 核共享。  
&emsp; 最后，主存保存着程序运行的所有数据，它更大，更慢，由全部插槽上的所有 CPU 核共享。  
&emsp; 当 CPU 执行运算的时候，它先去 L1 查找所需的数据，再去 L2，然后是 L3，最后如果这些缓存中都没有，所需的数据就要去主内存拿。  
&emsp; 走得越远，运算耗费的时间就越长。  
&emsp; 所以如果进行一些很频繁的运算，要确保数据在 L1 缓存中。  

#### 1.7.1.2. CPU缓存行  
&emsp; 缓存是由缓存行组成的，通常是64字节（常用处理器的缓存行是 64 字节的，比较旧的处理器缓存行是 32 字节），并且它有效地引用主内存中的一块地址。  
&emsp; 一个Java的long类型是8字节，因此在一个缓存行中可以存8个long类型的变量。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-51.png)  
&emsp; <font color = "red">在程序运行的过程中，缓存每次更新都从主内存中加载连续的 64 个字节。因此，如果访问一个 long 类型的数组时，当数组中的一个值被加载到缓存中时，另外 7 个元素也会被加载到缓存中。</font>  
&emsp; 但是，如果使用的数据结构中的项在内存中不是彼此相邻的，比如链表，那么将得不到免费缓存加载带来的好处。  
&emsp; 不过，这种免费加载也有一个坏处。设想如果有个long类型的变量a，它不是数组的一部分，而是一个单独的变量，并且还有另外一个 long 类型的变量 b 紧挨着它，那么当加载 a 的时候将免费加载 b。  
&emsp; 看起来似乎没有什么毛病，但是如果一个 CPU 核心的线程在对a进行修改，另一个CPU核心的线程却在对b进行读取。  
&emsp; 当前者修改 a 时，会把 a 和 b 同时加载到前者核心的缓存行中，更新完 a 后其它所有包含 a 的缓存行都将失效，因为其它缓存中的 a 不是最新值了。  
&emsp; 而当后者读取 b 时，发现这个缓存行已经失效了，需要从主内存中重新加载。  
&emsp; 请记住，缓存都是以缓存行作为一个单位来处理的，所以失效 a 的缓存的同时，也会把 b 失效，反之亦然。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-52.png)  
&emsp; 这样就出现了一个问题，<font color = "red">b和a完全不相干，每次却要因为a的更新需要从主内存重新读取，它被缓存未命中给拖慢了。</font>  
&emsp; 这就是伪共享问题。  

#### 1.7.1.3. 伪共享  
&emsp; **<font color = "lime">当多线程修改互相独立的变量时，如果这些变量共享同一个缓存行，就会无意中影响彼此的性能，这就是伪共享。</font>**  
&emsp; 伪共享示例：  

```java
public class FalseSharingTest {

    public static void main(String[] args) throws InterruptedException {
        testPointer(new Pointer());
    }

    private static void testPointer(Pointer pointer) throws InterruptedException {
        long start = System.currentTimeMillis();
        Thread t1 = new Thread(() -> {
            for (int i = 0; i < 100000000; i++) {
                pointer.x++;
            }
        });

        Thread t2 = new Thread(() -> {
            for (int i = 0; i < 100000000; i++) {
                pointer.y++;
            }
        });

        t1.start();
        t2.start();
        t1.join();
        t2.join();

        System.out.println(System.currentTimeMillis() - start);
        System.out.println(pointer);
    }
}

class Pointer {
    volatile long x;
    volatile long y;
}
```
&emsp; 这个例子中，声明了一个 Pointer 的类，它包含x和y两个变量，一个线程对 x 进行自增1亿次，一个线程对y进行自增1亿次。  
&emsp; 可以看到，x和y完全没有任何关系，但是更新 x 的时候会把其它包含x的缓存行失效，同时也就失效了y，运行这段程序输出的时间为3890ms。  


#### 1.7.1.4. 避免伪共享  

&emsp; 伪共享的原理中，一个缓存行是 64 个字节，一个 long 类型是 8 个字节，所以避免伪共享也很简单，笔者总结了下大概有以下三种方式：

1. <font color = "red">在两个long类型的变量之间再加7个long类型</font>  
    &emsp; 可以把上面的Pointer改成下面这个结构：

    ```java
    class Pointer {
        volatile long x;
        long p1, p2, p3, p4, p5, p6, p7;
        volatile long y;
    }
    ```
    &emsp; 再次运行程序，会发现输出时间神奇的缩短为了695ms。

2. <font color = "red">重新创建自己的long类型，而不是java自带的long</font>  
    &emsp; 修改Pointer如下：

    ```java
    class Pointer {
        MyLong x = new MyLong();
        MyLong y = new MyLong();
    }

    class MyLong {
        volatile long value;
        long p1, p2, p3, p4, p5, p6, p7;
    }
    ```
    &emsp; 同时把 pointer.x++; 修改为 pointer.x.value++;，把 pointer.y++; 修改为 pointer.y.value++;，再次运行程序发现时间是724ms。  
3. <font color = "red">使用@sun.misc.Contended注解（java8）</font>  
    &emsp; 修改MyLong如下：

    ```java
    @sun.misc.Contended
    class MyLong {
        volatile long value;
    }
    ```
    &emsp; 默认使用这个注解是无效的，需要在JVM启动参数加上-XX:-RestrictContended才会生效，，再次运行程序发现时间是718ms。  
    &emsp; 注意，以上三种方式中的前两种是通过加字段的形式实现的，加的字段又没有地方使用，可能会被jvm优化掉，所以建议使用第三种方式。  

#### 1.7.1.5. 总结  
1. CPU具有多级缓存，越接近CPU的缓存越小也越快；  
2. CPU缓存中的数据是以缓存行为单位处理的；  
3. CPU缓存行能带来免费加载数据的好处，所以处理数组性能非常高；  
4. CPU缓存行也带来了弊端，多线程处理不相干的变量时会相互影响，也就是伪共享；  
5. 避免伪共享的主要思路就是让不相干的变量不要出现在同一个缓存行中；  
6. 一是每两个变量之间加七个 long 类型；  
7. 二是创建自己的 long 类型，而不是用原生的；  
8. 三是使用 java8 提供的注解；  



## 1.8. java并发原语
&emsp; Java内存模型，除了定义了一套规范，还提供了一系列原语，封装了底层实现后，供开发者直接使用。  

* 原子性可以通过synchronized和Lock来实现。  
* 可见性可以通过Volatile、synchronized、final来实现。  
* 有序性可以通过synchronized或者Lock、volatile来实现。  


