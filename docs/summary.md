
<!-- TOC -->

- [1. 总结](#1-总结)
    - [1.1. Java](#11-java)
        - [1.1.1. Java基础](#111-java基础)
        - [1.1.2. Java基础数据类型](#112-java基础数据类型)
            - [1.1.2.1. String](#1121-string)
            - [1.1.2.2. Java基本数据类型](#1122-java基本数据类型)
            - [1.1.2.3. java对象大小](#1123-java对象大小)
        - [1.1.3. Java集合框架](#113-java集合框架)
            - [1.1.3.1. Java集合框架](#1131-java集合框架)
            - [1.1.3.2. HashMap](#1132-hashmap)
                - [1.1.3.2.1. HashMap源码](#11321-hashmap源码)
                - [1.1.3.2.2. HashMap安全](#11322-hashmap安全)
            - [1.1.3.3. Collection](#1133-collection)
        - [1.1.4. JDK1.8](#114-jdk18)
            - [1.1.4.1. 接口的默认方法与静态方法](#1141-接口的默认方法与静态方法)
            - [1.1.4.2. Lambda表达式](#1142-lambda表达式)
            - [1.1.4.3. Stream](#1143-stream)
            - [1.1.4.4. Optional](#1144-optional)
            - [1.1.4.5. DateTime](#1145-datetime)
        - [1.1.5. Java异常](#115-java异常)
        - [1.1.6. Java范型](#116-java范型)
        - [1.1.7. 自定义注解](#117-自定义注解)
        - [1.1.8. 反射](#118-反射)
        - [1.1.9. IO](#119-io)
        - [1.1.10. SPI](#1110-spi)
    - [1.2. 设计模式](#12-设计模式)
        - [1.2.1. 七大设计原则](#121-七大设计原则)
        - [1.2.2. 继承和组合/复用规则](#122-继承和组合复用规则)
        - [1.2.3. 设计模式详解](#123-设计模式详解)
            - [1.2.3.1. 5种创建型设计模式](#1231-5种创建型设计模式)
            - [1.2.3.2. 7种结构型设计模式](#1232-7种结构型设计模式)
            - [1.2.3.3. 11种行为型设计模式](#1233-11种行为型设计模式)
            - [1.2.3.4. 设计模式大讨论](#1234-设计模式大讨论)
            - [1.2.3.5. 2种动态代理](#1235-2种动态代理)
            - [1.2.3.6. 常使用的设计模式](#1236-常使用的设计模式)
    - [1.3. JVM](#13-jvm)
        - [1.3.1. JDK、JRE、JVM](#131-jdkjrejvm)
        - [1.3.2. 编译成Class字节码文件](#132-编译成class字节码文件)
        - [1.3.3. 类加载](#133-类加载)
            - [1.3.3.1. JVM类的加载](#1331-jvm类的加载)
            - [1.3.3.2. JVM类加载器](#1332-jvm类加载器)
        - [1.3.4. 内存结构](#134-内存结构)
            - [1.3.4.1. JVM内存结构](#1341-jvm内存结构)
                - [1.3.4.1.1. JVM内存结构](#13411-jvm内存结构)
                - [1.3.4.1.2. 常量池详解](#13412-常量池详解)
                - [1.3.4.1.3. 逃逸分析](#13413-逃逸分析)
            - [1.3.4.2. 内存中的对象](#1342-内存中的对象)
                - [1.3.4.2.1. 创建对象](#13421-创建对象)
                - [1.3.4.2.2. 对象生命周期](#13422-对象生命周期)
                - [1.3.4.2.3. 对象大小](#13423-对象大小)
            - [1.3.4.3. 内存泄露](#1343-内存泄露)
        - [1.3.5. JVM执行](#135-jvm执行)
        - [1.3.6. GC](#136-gc)
            - [1.3.6.1. GC-回收对象](#1361-gc-回收对象)
                - [1.3.6.1.1. 堆中对象的存活](#13611-堆中对象的存活)
                - [1.3.6.1.2. 方法区(类和常量)回收/类的卸载阶段](#13612-方法区类和常量回收类的卸载阶段)
                - [1.3.6.1.3. null与GC](#13613-null与gc)
            - [1.3.6.2. GC-回收位置/安全点](#1362-gc-回收位置安全点)
            - [1.3.6.3. 回收算法与分代回收](#1363-回收算法与分代回收)
            - [1.3.6.4. GC-垃圾回收器](#1364-gc-垃圾回收器)
                - [1.3.6.4.1. 垃圾回收器](#13641-垃圾回收器)
                - [1.3.6.4.2. CMS回收器](#13642-cms回收器)
                - [1.3.6.4.3. G1回收器](#13643-g1回收器)
                - [1.3.6.4.4. 三色标记](#13644-三色标记)
        - [1.3.7. JVM调优](#137-jvm调优)
            - [1.3.7.1. JVM调优-基础](#1371-jvm调优-基础)
            - [1.3.7.2. JVM调优](#1372-jvm调优)
            - [1.3.7.3. JVM问题排查](#1373-jvm问题排查)
            - [1.3.7.4. Arthas工具](#1374-arthas工具)
    - [1.4. 并发编程](#14-并发编程)
        - [1.4.1. 线程Thread](#141-线程thread)
            - [1.4.1.1. 线程状态详解](#1411-线程状态详解)
        - [1.4.2. 并发编程](#142-并发编程)
            - [1.4.2.1. 并发编程原理](#1421-并发编程原理)
                - [1.4.2.1.1. CPU缓存及JMM](#14211-cpu缓存及jmm)
                - [1.4.2.1.2. 并发安全问题产生原因](#14212-并发安全问题产生原因)
                - [1.4.2.1.3. 并发安全解决底层](#14213-并发安全解决底层)
                - [1.4.2.1.4. 伪共享问题](#14214-伪共享问题)
            - [1.4.2.2. 线程安全解决](#1422-线程安全解决)
                - [1.4.2.2.1. 线程安全解决方案](#14221-线程安全解决方案)
                - [1.4.2.2.2. Synchronized](#14222-synchronized)
                    - [1.4.2.2.2.1. Synchronized介绍](#142221-synchronized介绍)
                    - [1.4.2.2.2.2. Synchronized使用](#142222-synchronized使用)
                - [1.4.2.2.3. Synchronized使用是否安全](#14223-synchronized使用是否安全)
                    - [1.4.2.2.3.1. Synchronized底层原理](#142231-synchronized底层原理)
                    - [1.4.2.2.3.2. Synchronized优化](#142232-synchronized优化)
                - [1.4.2.2.4. Volatile](#14224-volatile)
                - [1.4.2.2.5. ThreadLocal](#14225-threadlocal)
                    - [1.4.2.2.5.1. ThreadLocal原理](#142251-threadlocal原理)
                    - [1.4.2.2.5.2. ThreadLocal应用](#142252-threadlocal应用)
            - [1.4.2.3. 线程通信(生产者消费者问题)](#1423-线程通信生产者消费者问题)
            - [1.4.2.4. 线程活跃性](#1424-线程活跃性)
        - [1.4.3. 线程池](#143-线程池)
            - [1.4.3.1. 线程池框架](#1431-线程池框架)
            - [1.4.3.2. ThreadPoolExecutor详解](#1432-threadpoolexecutor详解)
            - [1.4.3.3. 线程池的正确使用](#1433-线程池的正确使用)
            - [1.4.3.4. ForkJoinPool详解](#1434-forkjoinpool详解)
            - [1.4.3.5. Future相关](#1435-future相关)
            - [1.4.3.6. ~~CompletionService~~](#1436-completionservice)
            - [1.4.3.7. ~~CompletableFuture~~](#1437-completablefuture)
        - [1.4.4. JUC](#144-juc)
            - [1.4.4.1. CAS](#1441-cas)
            - [1.4.4.2. AQS](#1442-aqs)
                - [1.4.4.2.1. LockSupport类](#14421-locksupport类)
            - [1.4.4.3. LOCK](#1443-lock)
                - [1.4.4.3.1. ReentrantLock，重入锁](#14431-reentrantlock重入锁)
                    - [1.4.4.3.1.1. 读写锁](#144311-读写锁)
            - [1.4.4.4. Atomic](#1444-atomic)
                - [1.4.4.4.1. AtomicStampedReference与AtomicMarkableReference](#14441-atomicstampedreference与atomicmarkablereference)
                - [1.4.4.4.2. LongAdder](#14442-longadder)
            - [1.4.4.5. Collections](#1445-collections)
                - [1.4.4.5.1. CopyOnWriteArrayList](#14451-copyonwritearraylist)
                - [1.4.4.5.2. ConcurrentHashMap](#14452-concurrenthashmap)
                - [1.4.4.5.3. BlockingQueue](#14453-blockingqueue)
            - [1.4.4.6. tools](#1446-tools)
                - [1.4.4.6.1. CountDownLatch](#14461-countdownlatch)
                - [1.4.4.6.2. CyclicBarrier](#14462-cyclicbarrier)
                - [1.4.4.6.3. Semaphore](#14463-semaphore)
    - [1.5. 数据库](#15-数据库)
        - [1.5.1. SQL语句](#151-sql语句)
            - [1.5.1.1. 基本查询语句](#1511-基本查询语句)
            - [1.5.1.2. 连接查询](#1512-连接查询)
            - [1.5.1.3. ~~高级查询~~](#1513-高级查询)
        - [1.5.2. MySql函数](#152-mysql函数)
        - [1.5.3. MySql优化](#153-mysql优化)
            - [1.5.3.1. SQL分析](#1531-sql分析)
                - [1.5.3.1.1. Expain](#15311-expain)
            - [1.5.3.2. SQL优化](#1532-sql优化)
            - [1.5.3.3. 索引优化](#1533-索引优化)
            - [1.5.3.4. 碎片优化](#1534-碎片优化)
        - [1.5.4. 数据库分布式](#154-数据库分布式)
            - [1.5.4.1. 大数据量操作](#1541-大数据量操作)
            - [1.5.4.2. MySql瓶颈](#1542-mysql瓶颈)
            - [1.5.4.3. 数据库分布式](#1543-数据库分布式)
            - [1.5.4.4. 主从复制](#1544-主从复制)
                - [1.5.4.4.1. 主从复制原理](#15441-主从复制原理)
                - [1.5.4.4.2. 主从复制实现](#15442-主从复制实现)
                - [1.5.4.4.3. 主从复制问题](#15443-主从复制问题)
                - [1.5.4.4.4. 高可用实现](#15444-高可用实现)
                - [1.5.4.4.5. 读写分离实现](#15445-读写分离实现)
            - [1.5.4.5. 分区](#1545-分区)
            - [1.5.4.6. 分库分表](#1546-分库分表)
                - [1.5.4.6.1. 分库分表](#15461-分库分表)
                - [1.5.4.6.2. 分库分表查询](#15462-分库分表查询)
                - [1.5.4.6.3. 跨分片的排序分页](#15463-跨分片的排序分页)
            - [1.5.4.7. 数据迁移](#1547-数据迁移)
        - [1.5.5. 索引事物锁](#155-索引事物锁)
            - [1.5.5.1. 索引底层原理](#1551-索引底层原理)
            - [1.5.5.2. ~~各种索引~~（还需要总结）](#1552-各种索引还需要总结)
            - [1.5.5.3. MySql事务（还需要总结）](#1553-mysql事务还需要总结)
            - [1.5.5.4. MVCC](#1554-mvcc)
            - [1.5.5.5. MySql锁](#1555-mysql锁)
            - [1.5.5.6. MySql死锁和锁表](#1556-mysql死锁和锁表)
        - [1.5.6. MySql架构原理](#156-mysql架构原理)
            - [1.5.6.1. MySql架构](#1561-mysql架构)
            - [1.5.6.2. binLog日志](#1562-binlog日志)
            - [1.5.6.3. MySql存储引擎](#1563-mysql存储引擎)
            - [1.5.6.4. InnoDB体系结构](#1564-innodb体系结构)
                - [1.5.6.4.1. InnoDB内存结构-性能](#15641-innodb内存结构-性能)
                    - [1.5.6.4.1.1. BufferPool](#156411-bufferpool)
                    - [1.5.6.4.1.2. 写缓冲ChangeBuffer](#156412-写缓冲changebuffer)
                    - [1.5.6.4.1.3. AdaptiveHashIndex](#156413-adaptivehashindex)
                - [1.5.6.4.2. InnoDB磁盘结构-可靠性](#15642-innodb磁盘结构-可靠性)
                    - [1.5.6.4.2.1. BufferPool落盘表空间](#156421-bufferpool落盘表空间)
                    - [1.5.6.4.2.2. undoLog](#156422-undolog)
                    - [1.5.6.4.2.3. redoLog](#156423-redolog)
                    - [1.5.6.4.2.4. DoubleWrite](#156424-doublewrite)
                - [1.5.6.4.3. ~~两阶段提交和崩溃恢复~~](#15643-两阶段提交和崩溃恢复)
    - [1.6. 项目构建](#16-项目构建)
        - [1.6.1. 接口幂等](#161-接口幂等)
        - [1.6.2. 接口响应时间](#162-接口响应时间)
        - [1.6.3. 接口预警](#163-接口预警)
    - [1.7. 架构设计](#17-架构设计)
        - [1.7.1. 架构质量属性](#171-架构质量属性)
        - [1.7.2. 系统瓶颈](#172-系统瓶颈)
    - [1.8. Spring](#18-spring)
        - [1.8.1. Spring基础](#181-spring基础)
        - [1.8.2. Spring IOC](#182-spring-ioc)
        - [1.8.3. Spring DI](#183-spring-di)
            - [1.8.3.1. 循环依赖](#1831-循环依赖)
        - [1.8.4. Bean的生命周期](#184-bean的生命周期)
        - [1.8.5. 容器相关特性](#185-容器相关特性)
            - [1.8.5.1. FactoryBean](#1851-factorybean)
            - [1.8.5.2. Spring可二次开发常用接口（扩展性）](#1852-spring可二次开发常用接口扩展性)
                - [1.8.5.2.1. 事件](#18521-事件)
                - [1.8.5.2.2. Aware接口](#18522-aware接口)
                - [1.8.5.2.3. 后置处理器](#18523-后置处理器)
                - [1.8.5.2.4. InitializingBean](#18524-initializingbean)
        - [1.8.6. SpringAOP教程](#186-springaop教程)
        - [1.8.7. SpringAOP解析](#187-springaop解析)
        - [1.8.8. Spring事务](#188-spring事务)
            - [1.8.8.1. Spring事务使用](#1881-spring事务使用)
            - [1.8.8.2. Spring事务失效](#1882-spring事务失效)
        - [1.8.9. SpringMVC解析](#189-springmvc解析)
        - [1.8.10. 过滤器、拦截器、监听器](#1810-过滤器拦截器监听器)
    - [1.9. MyBatis](#19-mybatis)
        - [1.9.1. MyBatis大数据量查询](#191-mybatis大数据量查询)
        - [1.9.2. MyBatis架构](#192-mybatis架构)
        - [1.9.3. MyBatis SQL执行解析](#193-mybatis-sql执行解析)
        - [1.9.4. MyBatis缓存](#194-mybatis缓存)
        - [1.9.5. MyBatis插件解析](#195-mybatis插件解析)
    - [1.10. SpringBoot](#110-springboot)
        - [1.10.1. SpringBoot基础知识](#1101-springboot基础知识)
        - [1.10.2. SpringBoot启动过程](#1102-springboot启动过程)
            - [1.10.2.1. SpringApplication初始化](#11021-springapplication初始化)
            - [1.10.2.2. run()方法运行过程](#11022-run方法运行过程)
            - [1.10.2.3. SpringBoot事件监听机制](#11023-springboot事件监听机制)
                - [1.10.2.3.1. 事件监听步骤](#110231-事件监听步骤)
                - [1.10.2.3.2. 内置生命周期事件](#110232-内置生命周期事件)
            - [1.10.2.4. SpringBoot事件回调](#11024-springboot事件回调)
        - [1.10.3. SpringBoot自动配置](#1103-springboot自动配置)
            - [1.10.3.1. 注解@SpringBootApplication（启动对象）](#11031-注解springbootapplication启动对象)
            - [1.10.3.2. 加载自动配置流程](#11032-加载自动配置流程)
            - [1.10.3.3. 内置Tomcat](#11033-内置tomcat)
        - [1.10.4. 自定义strater](#1104-自定义strater)
    - [1.11. SpringCloud](#111-springcloud)
        - [1.11.1. Eureka](#1111-eureka)
        - [1.11.2. Ribbon](#1112-ribbon)
        - [1.11.3. Feign](#1113-feign)
        - [1.11.4. Zuul](#1114-zuul)
        - [1.11.5. Hytrix](#1115-hytrix)
        - [1.11.6. Sleuth](#1116-sleuth)
        - [1.11.7. Admin](#1117-admin)
    - [1.12. Dubbo](#112-dubbo)
        - [1.12.1. 分布式服务治理](#1121-分布式服务治理)
            - [1.12.1.1. Dubbo和Spring Cloud](#11211-dubbo和spring-cloud)
            - [1.12.1.2. Spring Cloud Alibaba介绍](#11212-spring-cloud-alibaba介绍)
        - [1.12.2. RPC介绍](#1122-rpc介绍)
        - [1.12.3. Dubbo介绍](#1123-dubbo介绍)
        - [1.12.4. Dubbo框架设计](#1124-dubbo框架设计)
        - [1.12.5. 暴露和引用服务](#1125-暴露和引用服务)
        - [1.12.6. 服务调用](#1126-服务调用)
            - [1.12.6.1. 服务调用介绍](#11261-服务调用介绍)
            - [1.12.6.2. Dubbo序列化和协议](#11262-dubbo序列化和协议)
                - [1.12.6.2.1. Dubbo协议长连接](#112621-dubbo协议长连接)
        - [1.12.7. Dubbo集群容错](#1127-dubbo集群容错)
        - [1.12.8. 扩展点加载(SPI)](#1128-扩展点加载spi)
    - [1.13. Zookeeper](#113-zookeeper)
        - [1.13.1. ZK服务端](#1131-zk服务端)
        - [1.13.2. ZK客户端](#1132-zk客户端)
        - [1.13.3. ZK弊端和应用场景](#1133-zk弊端和应用场景)
    - [1.14. 分布式](#114-分布式)
        - [1.14.1. 分布式理论CAP](#1141-分布式理论cap)
        - [1.14.2. 分布式ID](#1142-分布式id)
        - [1.14.3. 分布式事务](#1143-分布式事务)
            - [1.14.3.1. 事务模型DTP及XA](#11431-事务模型dtp及xa)
            - [1.14.3.2. TCC](#11432-tcc)
                - [1.14.3.2.1. TCC流程](#114321-tcc流程)
                - [1.14.3.2.2. TCC问题](#114322-tcc问题)
            - [1.14.3.3. Saga](#11433-saga)
            - [1.14.3.4. 消息模式](#11434-消息模式)
            - [1.14.3.5. 分布式事务的选型](#11435-分布式事务的选型)
            - [1.14.3.6. 分布式事务框架Seata](#11436-分布式事务框架seata)
                - [1.14.3.6.1. AT模式详解](#114361-at模式详解)
                - [1.14.3.6.2. 四种模式的区别](#114362-四种模式的区别)
        - [1.14.4. 分布式锁](#1144-分布式锁)
            - [1.14.4.1. 分布式锁实现方案](#11441-分布式锁实现方案)
            - [1.14.4.2. RedisLock](#11442-redislock)
            - [1.14.4.3. 使用redis分布式锁的注意点](#11443-使用redis分布式锁的注意点)
            - [1.14.4.4. Redisson](#11444-redisson)
            - [1.14.4.5. ZK分布式锁](#11445-zk分布式锁)
            - [1.14.4.6. MySql分布式锁](#11446-mysql分布式锁)
    - [1.15. 高并发](#115-高并发)
        - [1.15.1. 分布式和集群](#1151-分布式和集群)
        - [1.15.2. 系统性能指标](#1152-系统性能指标)
        - [1.15.3. 并发系统三高](#1153-并发系统三高)
            - [1.15.3.1. 高可用建设](#11531-高可用建设)
            - [1.15.3.2. 秒杀系统设计](#11532-秒杀系统设计)
        - [1.15.4. 资源限制](#1154-资源限制)
    - [1.16. 缓存](#116-缓存)
        - [1.16.1. ~~分布式缓存问题~~](#1161-分布式缓存问题)
        - [1.16.2. Redis](#1162-redis)
            - [1.16.2.1. Redis数据类型](#11621-redis数据类型)
                - [1.16.2.1.1. Redis基本数据类型](#116211-redis基本数据类型)
                - [1.16.2.1.2. Redis扩展数据类型](#116212-redis扩展数据类型)
                - [1.16.2.1.3. ~~Redis底层实现~~](#116213-redis底层实现)
                    - [1.16.2.1.3.1. 数据结构](#1162131-数据结构)
                    - [1.16.2.1.3.2. SDS详解](#1162132-sds详解)
                    - [1.16.2.1.3.3. Dictht](#1162133-dictht)
                    - [1.16.2.1.3.4. 数据类型](#1162134-数据类型)
            - [1.16.2.2. Redis原理](#11622-redis原理)
                - [1.16.2.2.1. Redis为什么那么快？](#116221-redis为什么那么快)
                - [1.16.2.2.2. Redis虚拟内存机制](#116222-redis虚拟内存机制)
                - [1.16.2.2.3. Redis事件/Reactor](#116223-redis事件reactor)
                - [1.16.2.2.4. Redis多线程模型](#116224-redis多线程模型)
                - [1.16.2.2.5. Redis协议](#116225-redis协议)
            - [1.16.2.3. Redis内置功能](#11623-redis内置功能)
                - [1.16.2.3.1. Redis事务](#116231-redis事务)
                - [1.16.2.3.2. RedisPipeline/批处理](#116232-redispipeline批处理)
                - [1.16.2.3.3. Redis和Lua](#116233-redis和lua)
                - [1.16.2.3.4. Redis持久化](#116234-redis持久化)
                    - [1.16.2.3.4.1. AOF重写阻塞](#1162341-aof重写阻塞)
                - [1.16.2.3.5. Redis过期键删除](#116235-redis过期键删除)
                - [1.16.2.3.6. Redis内存淘汰](#116236-redis内存淘汰)
                - [1.16.2.3.7. Redis实现消息队列](#116237-redis实现消息队列)
            - [1.16.2.4. Redis高可用](#11624-redis高可用)
                - [1.16.2.4.1. Redis高可用方案](#116241-redis高可用方案)
                - [1.16.2.4.2. Redis主从复制](#116242-redis主从复制)
                - [1.16.2.4.3. Redis读写分离](#116243-redis读写分离)
                - [1.16.2.4.4. Redis哨兵模式](#116244-redis哨兵模式)
                - [1.16.2.4.5. Redis集群模式](#116245-redis集群模式)
            - [1.16.2.5. Redis常见问题与优化](#11625-redis常见问题与优化)
        - [1.16.3. 分布式限流](#1163-分布式限流)
        - [1.16.4. 服务降级](#1164-服务降级)
    - [1.17. 分布式消息队列](#117-分布式消息队列)
        - [1.17.1. mq](#1171-mq)
        - [1.17.2. Kafka](#1172-kafka)
            - [1.17.2.1. kafka基本概念](#11721-kafka基本概念)
                - [1.17.2.1.1. kafka生产者](#117211-kafka生产者)
                - [1.17.2.1.2. 消息分区](#117212-消息分区)
                - [1.17.2.1.3. kafka消费者](#117213-kafka消费者)
                - [1.17.2.1.4. kafka服务端](#117214-kafka服务端)
            - [1.17.2.2. kafka特性](#11722-kafka特性)
                - [1.17.2.2.1. 【1】高性能(读写机制) ，Kafka为什么吞吐量大、速度快？](#117221-1高性能读写机制-kafka为什么吞吐量大速度快)
                    - [1.17.2.2.1.1. 网络IO优化](#1172211-网络io优化)
                    - [1.17.2.2.1.2. 内存](#1172212-内存)
                    - [1.17.2.2.1.3. 持久化/磁盘I/O-顺序读写](#1172213-持久化磁盘io-顺序读写)
                - [1.17.2.2.2. 【2】高可用与数据一致性(副本机制)](#117222-2高可用与数据一致性副本机制)
                - [1.17.2.2.3. ~~可靠性~~](#117223-可靠性)
                    - [1.17.2.2.3.1. 如何保证消息队列不丢失?](#1172231-如何保证消息队列不丢失)
                    - [1.17.2.2.3.2. 分区保证消费顺序](#1172232-分区保证消费顺序)
                    - [1.17.2.2.3.3. 消费语义介绍](#1172233-消费语义介绍)
                    - [1.17.2.2.3.4. 幂等（重复消费）](#1172234-幂等重复消费)
                    - [1.17.2.2.3.5. 事务](#1172235-事务)
    - [1.18. 分布式通信](#118-分布式通信)
        - [1.18.1. 通信基础](#1181-通信基础)
        - [1.18.2. 网络IO](#1182-网络io)
            - [1.18.2.1. 五种I/O模型](#11821-五种io模型)
            - [1.18.2.2. I/O多路复用详解](#11822-io多路复用详解)
            - [1.18.2.3. 多路复用之Reactor模式](#11823-多路复用之reactor模式)
            - [1.18.2.4. IO性能优化之零拷贝](#11824-io性能优化之零拷贝)
        - [1.18.3. Socket编程](#1183-socket编程)
        - [1.18.4. NIO](#1184-nio)
        - [1.18.5. Netty](#1185-netty)
            - [1.18.5.1. Netty简介](#11851-netty简介)
            - [1.18.5.2. Netty运行流程](#11852-netty运行流程)
            - [1.18.5.3. Netty核心组件](#11853-netty核心组件)
            - [1.18.5.4. Netty逻辑架构](#11854-netty逻辑架构)
            - [1.18.5.5. Netty高性能](#11855-netty高性能)
                - [1.18.5.5.1. Netty的Reactor线程模型](#118551-netty的reactor线程模型)
            - [1.18.5.6. Netty开发](#11856-netty开发)
                - [1.18.5.6.1. Netty应用场景，](#118561-netty应用场景)
                - [1.18.5.6.2. TCP粘拆包与Netty编解码](#118562-tcp粘拆包与netty编解码)
                - [1.18.5.6.3. Netty实战](#118563-netty实战)
                - [1.18.5.6.4. Netty多协议开发](#118564-netty多协议开发)
            - [1.18.5.7. Netty源码](#11857-netty源码)
    - [1.19. 计算机网络](#119-计算机网络)
        - [1.19.1. OSI七层网络模型](#1191-osi七层网络模型)
        - [1.19.2. 应用层](#1192-应用层)
            - [1.19.2.1. DNS](#11921-dns)
            - [1.19.2.2. HTTP](#11922-http)
            - [1.19.2.3. HTTPS](#11923-https)
        - [1.19.3. 传输层](#1193-传输层)
            - [1.19.3.1. TCP](#11931-tcp)
                - [1.19.3.1.1. 连接建立阶段](#119311-连接建立阶段)
                    - [1.19.3.1.1.1. 连接建立](#1193111-连接建立)
                    - [1.19.3.1.1.2. Http长短链接](#1193112-http长短链接)
                    - [1.19.3.1.1.3. TCP粘包](#1193113-tcp粘包)
                - [1.19.3.1.2. 数据传输阶段](#119312-数据传输阶段)
        - [1.19.4. 网络的性能指标](#1194-网络的性能指标)
    - [1.20. 负载均衡](#120-负载均衡)
        - [1.20.1. 负载均衡解决方案](#1201-负载均衡解决方案)
        - [1.20.2. Nginx](#1202-nginx)
            - [1.20.2.1. Nginx介绍](#12021-nginx介绍)
            - [1.20.2.2. Nginx使用](#12022-nginx使用)
    - [1.21. Devops](#121-devops)
        - [1.21.1. CI/CD](#1211-cicd)
        - [1.21.2. DevOps](#1212-devops)
        - [1.21.3. 从上往下学Docker](#1213-从上往下学docker)
            - [1.21.3.1. Docker使用教程](#12131-docker使用教程)
            - [1.21.3.2. 镜像详解](#12132-镜像详解)
            - [1.21.3.3. 容器详解](#12133-容器详解)
        - [1.21.4. Kubernetes](#1214-kubernetes)
            - [1.21.4.1. k8s架构](#12141-k8s架构)

<!-- /TOC -->


# 1. 总结  

## 1.1. Java
### 1.1.1. Java基础
1. static关键字：  
    1. 方便在没有创建对象的情况下来进行调用（方法/变量）。  
    2. static使用： 1). static修饰变量、 2). 修饰方法、 3). static 可以修饰代码块，主要分为两种，一种直接定义在类中，使用static{}，这种被称为静态代码块，一种是在类中定义静态内部类，使用static class xxx来进行定义、 4). static可以和单例模式一起使用，通过双重检查锁来实现线程安全的单例模式、 5).静态导包。     
    3. 静态方法可以调用成员变量吗？ `注⚠️：static静态方法引用类变量，变量需要static修饰。`  

### 1.1.2. Java基础数据类型
#### 1.1.2.1. String
1. String 类是用final关键字修饰的，所以认为其是不可变对象。反射可以改变String对象。  
&emsp; **<font color = "clime">为什么Java字符串是不可变的？</font>** 原因大致有以下三个：  
    * 为了实现字符串常量池。字符串常量池可以节省大量的内存空间。  
    * 为了线程安全。  
    * 为了 HashCode 的不可变性。String类经常被用作HashMap的key。  
2. String创建了几个对象？  
&emsp; `String str1 = "java";`创建一个对象放在常量池中。  
&emsp; `String str2 = new String("java");`创建两个对象，字面量"java"创建一个对象放在常量池中，new String()又创建一个对象放在堆中。如果常量池中已经存在，则是创建了一个对象。  
&emsp; `String str3 = "hello "+"java";`创建了一个对象。  
&emsp; `String str5 = str3 + "java";`创建了三个对象。
3. String不可变，安全；StringBuilder可变，线程不安全；StringBuffer可变，线程安全。  

#### 1.1.2.2. Java基本数据类型

|数据类型|字节|位数|默认值|取值范围|
|---|---|---|---|---|
|byte	|1	|8|0	|-128-127|
|short	|2	|16|0	|-32768-32767|
|int	|4	|32|0	|-2147483648-2147483647|
|long	|8	|64|0| |	
|float	|4	|32|0.0f| |	
|double	|8	|64|0.0d| |	
|char	|2	|16|'\u0000'| |	
|boolean	|4|32	|false	| |

&emsp; char的包装类型是Character。  

#### 1.1.2.3. java对象大小


### 1.1.3. Java集合框架
#### 1.1.3.1. Java集合框架
1. <font color = "clime">List：有序，可重复。Set：无序，不可重复(唯一)。Map：存储键值对。</font>  
&emsp; <font color = "clime">List有ArrayList、Vector、LinkedList。Map有HashMap、LinkedHashMap、TreeMap、Hashtable。Set有HashSet、LinkedHashSet、TreeSet。</font>    
2. 快速失败机制：单线程迭代器中直接删除元素或多线程使用非安全的容器都会抛出ConcurrentModificationException异常。  
&emsp; **<font color = "clime">采用安全失败(fail-safe)机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，再在拷贝的集合上进行遍历。</font>**  
3. 排序：  
    * Comparable，自然排序（自身属性，整数(大小排序)，字符串(字典序)）。  
    * Comparator，定制排序。  

#### 1.1.3.2. HashMap
##### 1.1.3.2.1. HashMap源码
1. HashMap数据结构：  
    1. Hash表数据结构：  
    &emsp; 初始容量为16；  
    &emsp; loadFactor加载因子0.75f；  
    &emsp; HashMap在发生hash冲突的时候用的是链地址法。JDK1.7中使用头插法，JDK1.8使用尾插法。  
    2. 树形化结构：  
    &emsp; 树形化：把链表转换成红黑树，树化需要满足以下两个条件：链表长度大于等于8；table数组长度大于等于64。  
    &emsp; 解除树形化：阈值6。
2. HashMap成员方法：  
    1. hash()函数/扰动函数：  
    &emsp; hash函数会根据传递的key值进行计算， 1)首先计算key的hashCode值， 2)然后再对hashcode进行无符号右移操作， 3)最后再和hashCode进行异或 ^ 操作。（即让hashcode的高16位和低16位进行异或操作。）   
    &emsp; **<font color = "clime">这样做的好处是增加了随机性，减少了碰撞冲突的可能性。</font>**    
    2. put()函数：  
        1. 在put的时候，首先对key做hash运算，计算出该key所在的index。
        2. 如果没碰撞，直接放到数组中；
        3. 如果碰撞了，如果key是相同的，则替换掉原来的值；
        4. 如果key不同，需要判断目前数据结构是链表还是红黑树，根据不同的情况来进行插入。
        5. 最后判断哈希表是否满了(当前哈希表大小*负载因子)，如果满了，则扩容。  
    2. 扩容机制：JDK 1.8扩容条件是数组长度大于阈值或链表转为红黑树且数组元素小于64时。  
        * 单节点迁移。  
        * 如果节点是红黑树类型的话则需要进行红黑树的拆分：`拆分成高低位链表，如果链表长度大于6，需要把链表升级成红黑树。`
        * 对链表进行迁移。会对链表中的节点进行分组，进行迁移后，一类的节点位置在原索引，一类在原索引+旧数组长度。 ~~通过 hash & oldCap(原数组大小)的值来判断，若为0则索引位置不变，不为0则新索引=原索引+旧数组长度~~

##### 1.1.3.2.2. HashMap安全
&emsp; HashMap的线程不安全体现在会造成死循环、数据丢失、数据覆盖这些问题。其中死循环和数据丢失是在JDK1.7中出现的问题，在JDK1.8中已经得到解决，然而1.8中仍会有数据覆盖这样的问题。  
1. 在jdk1.8中，在多线程环境下，会发生数据覆盖的情况。  
&emsp; 假设两个线程A、B都在进行put操作，并且hash函数计算出的插入下标是相同的，当线程A执行完第六行代码后由于时间片耗尽导致被挂起，而线程B得到时间片后在该下标处插入了元素，完成了正常的插入，`然后线程A获得时间片，由于之前已经进行了hash碰撞的判断，所以此时不会再进行判断，而是直接进行插入，这就导致了线程B插入的数据被线程A覆盖了，从而线程不安全。`  
2. `HashMap导致CPU100% 的原因是因为 HashMap 死循环导致的。`  
&emsp; 导致死循环的根本原因是JDK 1.7扩容采用的是“头插法”，会导致同一索引位置的节点在扩容后顺序反掉。而JDK 1.8之后采用的是“尾插法”，扩容后节点顺序不会反掉，不存在死循环问题。  
&emsp; 导致死循环示例：线程1、2同时扩容。线程1指向节点和下一节点，线程挂起。线程2完成扩容，此时线程1唤醒。线程1继续完成头节点插入，形成闭环。   
&emsp; 发生死循环后，剩余元素无法搬运，并且线程不会停止，因此会造成CPU100%。  
3. 线程安全的hashMap：Hashtable、Collections.synchronizedMap、[ConcurrentHashMap](/docs/java/concurrent/ConcurrentHashMap.md)。 

#### 1.1.3.3. Collection
1. HashSet基于HashMap实现： **<font color = "clime">存储在HashSet中的数据作为Map的key，而Map的value统一为PRESENT。</font>**  
    &emsp; 添加元素，如何保证值不重复？  
    &emsp; HashSet#add通过 map.put() 方法来添加元素。HashSet的add(E e)方法，会将e作为key，PRESENT作为value插入到map集合中。  
    * 如果e(新插入的key)存在，HashMap#put返回原key对应的value值（注意新插入的value会覆盖原value值），Hashset#add返回false，表示插入值重复，插入失败。  
    * 如果e(新插入的key)不存在，HashMap#put返回null值，Hashset#add返回true，表示插入值不重复，插入成功。  


### 1.1.4. JDK1.8
#### 1.1.4.1. 接口的默认方法与静态方法
1. 接口的默认方法与静态方法  
    * <font color = "clime">接口中的default方法会被子接口继承，也可以被其实现类所调用。default方法被继承时，可以被子接口覆写。</font>  
    * <font color = "clime">接口中的`static方法`不能被继承，也不能被实现类调用，`只能被自身调用`。即不能通过接口实现类的方法调用静态方法，直接通过接口名称调用。但是静态变量会被继承。</font>  


#### 1.1.4.2. Lambda表达式
1. **<font color = "clime">函数式接口的实例创建三种方式：lambda表达式；方法引用；构造方法引用。</font>**   
2. Lambda表达式作用域，访问外层作用域定义的局部变量、类的属性：  
    * <font color = "clime">访问局部变量：lambda表达式若访问了局部变量，则局部变量必须是final的。若局部变量没有加final关键字，系统会自动添加，此后再修改该局部变量，会编译错误。</font>  
    * <font color = "clime">访问类的属性：lambda内部使用this关键字（或不使用）访问或修改全局变量、实例方法。</font>    

#### 1.1.4.3. Stream
&emsp; **<font color = "clime">使用并行流parallelStream()有线程安全问题。例如：parallelStream().forEach()内部修改集合会有问题。解决方案：1.使用锁； 2.使用collect和reduce操作(Collections框架提供了同步的包装)。</font>**  

#### 1.1.4.4. Optional
&emsp; 使用Optional时尽量不直接调用Optional.get()方法，Optional.isPresent()更应该被视为一个私有方法，应依赖于其他像Optional.orElse()，Optional.orElseGet()，Optional.map()等这样的方法。  

#### 1.1.4.5. DateTime


### 1.1.5. Java异常
1. throws和throw：throws用在函数上，后面跟的是异常类，可以跟多个；`而throw用在函数内，后面跟的是异常对象。`  
2. 异常捕获后再次抛出。
    * 捕获后抛出原来的异常，希望保留最新的异常抛出点。 
    * 捕获后抛出新的异常，希望抛出完整的异常链。  
3. 自定义异常
4. 统一异常处理

### 1.1.6. Java范型
1. 范型擦除：Java会在编译Class文件时，将范型擦除成原始类型Object。  
2. 利用反射越过泛型检查  
&emsp; 反射是获取类Class文件进行操作。通过反射获取对象后可以获得相应的add方法，并向方法里面传入任何对象。  


### 1.1.7. 自定义注解


### 1.1.8. 反射
1. 运行时动态加载类、`破坏：可以访问任意一个对象的任意一个方法和属性，包括获取、修改私有属性。`   
2. **<font color = "clime">平常开发中使用反射的实际场景有：动态代理、JDBC中的加载数据库驱动程序、Spring框架中加载bean对象。</font>**  
3. 调用反射的总体流程如下：  
	* 准备阶段：编译期装载所有的类，将每个类的元信息保存至Class类对象中，每一个类对应一个Class对象。  
	* 获取Class对象：调用x.class/x.getClass()/Class.forName() 获取x的Class对象clz（这些方法的底层都是native方法，是在JVM底层编写好的，涉及到了JVM底层，就先不进行探究了）。  
	* 进行实际反射操作：通过clz对象获取Field/Method/Constructor对象进行进一步操作。  
4. 自定义 注解+反射 实际应用。    

### 1.1.9. IO
1. **<font color = "clime">将大文件数据全部读取到内存中，可能会发生OOM异常。</font>** I/O读写大文件解决方案：  
    * 使用BufferedInputStream进行包装。
    * 逐行读取。
    * 并发读取：1)逐行批次打包；2)大文件拆分成小文件。
    * 零拷贝方案：
        * FileChannel，分配读取到已分配固定长度的 java.nio.ByteBuffer。
        * 内存文件映射，MappedByteBuffer。采用内存文件映射不能读取超过2GB的文件。文件超过2GB，会报异常。


### 1.1.10. SPI
&emsp; **<font color = "clime">JDK提供的SPI机制：</font>**  
1. 提供一个接口；  
2. 服务提供方实现接口，并在META-INF/services/中暴露实现类地址；  
3. 服务调用方依赖接口，使用java.util.ServiceLoader类调用。  


-----

&emsp; 个人的简单理解：  
&emsp; SPI（Service Provider Interface），服务提供发现接口。热插拔、动态替换。  
&emsp; 多态，一个接口在一个包中有多个实现；而SPI提供的接口的实现一般在多个包中，例如JDBC的实现mysql、oracle，web容器有tomcat、jetty等。  
&emsp; 一个接口在b、c包中有实现，在a包中可替换所依赖的包（b或c），动态实现某一个功能。  


## 1.2. 设计模式
### 1.2.1. 七大设计原则
* 针对单个类的设计原则：  
    * 单一职责原则。   
    * 开闭原则（ **<font color = "clime">对已经使用的类的改动是通过增加代码进行的，而不是修改现有代码，实现一个热插拔的效果</font>** ）；
* 要依赖抽象或接口：  
    * 依赖倒置原则（ **<font color = "clime">为了实现这一原则，就要求在编程的时候针对抽象类或者接口编程，而不是针对具体实现编程</font>** ）； 
    * 接口隔离原则；     
    * 里氏替换原则（ **<font color = "clime">子类可以扩展父类的功能，但不能改变父类原有的功能</font>** ）。  
* 类与类：  
    * 合成复用原则（ **<font color = "red">尽量使用对象[组合(has-a)/聚合(contanis-a)](/docs/java/Design/compose.md)，而不是继承关系达到软件复用的目的</font>** ）；
    * 迪米特法则（一个对象应当对其他对象尽可能少的了解）。  

### 1.2.2. 继承和组合/复用规则
1. 类和类之间的关系有三种：is-a（继承或泛化）、has-a（关联或聚合）和use-a（依赖）。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/design/design-27.png)  
2. 组合的含义更像是一个对象(类)由各方面构成，这些方面并非来自于继承，但有时候却是必不可少的。`如果说继承是垂直结构，那么组合是横向结构。`  
3. `对于委托，类与类之间或对象与对象之间可以没有任何逻辑上的关系(比如继承关系和组合关系)，仅仅只是委托方和被委托方的关系。`不过，继承而来的方法本就会自动查找，所以这些方法不需要委托。`而组合经常会结合委托一起使用，或者说组合的过程中本就依赖于委托，`比如对于房子.煮饭()这个方法调用请求，应该委托或转发给厨房.煮饭()。  
&emsp; ~~委托是将一部分功能分割出去完成，即委托者（delegator）将自己委托给受托者（delegatee），`受托者方法中参数为委托者对象`；然后委托者调用受托者类对象。~~  

### 1.2.3. 设计模式详解
1. 常用设计模式有23种（不包含简单工厂模式）。 **<font color = "red">这23种设计模式的本质是面向对象设计原则的实际运用，是对类的封装性、继承性和多态性，以及类的关联关系和组合关系的充分理解。</font>**  
2.  **<font color = "red">结构型：多个类协同完成一个功能；行为型，算法模式。</font>**  

#### 1.2.3.1. 5种创建型设计模式
1. 单例模式
    1. `单例模式与static静态类`：静态使用于一些非状态Bean，单例使用于状态Bean。  
    2. ~~单例模式适用场景~~：全局只有一个示例，例如：数据库连接池、spring单例bean、全局熟悉...  
    3. 编码
    ★★★双重校验锁的形式：DCL详解参考[Volatile](/docs/java/concurrent/Volatile.md)。`注⚠️：static、volicate、双重校验+锁synchronized。`  

    ```java
    public class LazyDoubleCheckSingleton {
        
        private static volatile LazyDoubleCheckSingleton lazy = null;

        private LazyDoubleCheckSingleton(){
            
        }
        
        public static LazyDoubleCheckSingleton getInstance(){
            // 第一重检测
            if(lazy == null){
                // 锁定代码块
                synchronized (LazyDoubleCheckSingleton.class){
                    // 第二重检测
                    if(lazy == null){
                        // 实例化对象
                        lazy = new LazyDoubleCheckSingleton();
                        //1.分配内存给这个对象
                        //2.初始化对象
                        //3.设置 lazy 指向刚分配的内存地址
                    }
                }
            } 
            return lazy;
        }
        
        /**
        * 逻辑操作
        **/
        public void showMessage(){
            System.out.println("Hello World!");
        }
        
    }
    ```

    ```java
    public static void main(String[] args){
        // 
        LazyDoubleCheckSingleton instance = LazyDoubleCheckSingleton.getInstance();
        //
        instance.methodOne();
    }
    ```
    &emsp; <font color = "red">只有在singleton == null的情况下再进行加锁创建对象，如果singleton!=null，就直接返回就行了，并没有进行并发控制。大大的提升了效率。</font>   
    &emsp; <font color = "clime">从上面的代码中可以看到，其实整个过程中进行了两次singleton == null的判断，所以这种方法被称之为"双重校验锁"。</font>   
    &emsp; <font color = "clime">还有值得注意的是，双重校验锁的实现方式中，静态成员变量singleton必须通过volatile来修饰，保证其初始化不被重排，否则可能被引用到一个未初始化完成的对象。</font>   
2. 简单工厂模式和抽象工厂模式
3. 建造者模式： **<font color = "red">建造者模式适用于创建对象需要很多步骤，但是步骤的顺序不一定固定。如果一个对象有非常复杂的内部结构(很多属性)，可以将复杂对象的创建和使用进行分离。</font>**  
4. 原型模式：
    克隆的结果有2种，一种是浅复制，另一种是深复制。  
    * 浅复制: 对值类型的成员变量进行值的复制，对引用类型的成员变量只复制引用，不复制引用的对象。  
    * 深复制:  **<font color = "clime">对值类型的成员变量进行值的复制，对引用类型的成员变量也进行引用对象的复制。</font>**  

#### 1.2.3.2. 7种结构型设计模式
1. 外观模式/门面模式：**提供了一个统一的接口，用来访问子系统中的一群接口。**  
2. 适配器模式
    1. 平时开发中，面向接口编程，注入其他类，从而进行调用。  
    &emsp; 适配器(Adapter)模式中，Adapter，适配器类，即实现目标接口Target，又继承Adaptee类。适配器模式的核心角色，其他两个角色都是已经存在的角色，而适配器角色是需要新建立的，它的职责非常简单：把源角色转换为目标角色。`转换的方式有：即能通过继承，又能通过类关联的方式。`  
    2. **适配器模式有3种形式：类适配器、对象适配器、接口适配器。**  
        * 类适配器：Adapter类继承Adaptee（被适配类），同时实现Target接口（因为Java不支持多继承，所以只能通过接口的方法来实现多继承），在Client类中可以根据需要选择并创建任一种符合需求的子类，来实现具体功能。 
        * 对象适配器：不使用多继承或继承的方式，而是使用直接关联，或者称为委托的方式。  
        * 接口适配器：通过抽象类来实现适配。即适配器类是一个抽象类。  
    3. 适配的思想。  
3. 代理模式：<font color = "red">提供了对目标对象另外的访问方式，即通过代理访问目标对象。</font>  
4. 装饰器模式：Decorator，装饰角色，一般是一个抽象类，继承自或实现Component（抽象构件），在它的属性里面有一个变量指向Component抽象构件，这是装饰器最关键的地方。  
&emsp; 实际开发中，大多数用于对老项目的某些功能进行扩展。新项目中一般不怎么用此模式。  
&emsp; 此设计模式重点在于对已有的功能进行扩展。  
&emsp; 在Mybatis中，Cache的实现类LruCache、FifoCache等都是装饰一个类PerpetualCache。常见代码格式，就是装饰类中会有个被装饰类的属性，并且这个属性还是构造方法的参数。  
5. 桥接模式（if/else）
6. 组合模式
7. 享元模式（池化技术）  
    &emsp; 享元模式：①将对象的公共部分抽取出来成为内部状态(实现共享)，②将随时间改变、不可共享的部分作为外部状态(通过更换外部状态实现对象复用)，从而减少创建对象的数量，以减少内存开销和提高性能。  
    &emsp; 核心：共享和复用，共享(内部状态 - intrinsicState)，复用(外部状态 - extrinsicState)  
    &emsp; 使用场景：  

    * 共享：当只存在内部状态时，可以在多线程中共享使用(String常量池)  
    * 复用：通过改变外部状态，可以更好实现对象的复用(线程池)  

    &emsp; PS：外部状态在线程间需考虑并发问题，因此不适合共享，但当对象被使用完成后，通过修改外部状态，使其可以复用于下一次的访问需求。  


#### 1.2.3.3. 11种行为型设计模式
1. 模板方法模式
2. 策略模式(if/else)
3. 责任链模式(if/else)
4. 观察者模式

#### 1.2.3.4. 设计模式大讨论


#### 1.2.3.5. 2种动态代理
1. JDK动态代理
    1. Java动态代理类位于java.lang.reflect包下，一般主要涉及到以下两个重要的类或接口，`一个是InvocationHandler接口、另一个则是Proxy类。`  
        * Proxy类。该类即为动态代理类。Proxy.newProxyInstance()生成代理对象；  
        * InvocationHandler接口。 **<font color = "clime">在使用动态代理时，需要定义一个位于代理类与委托类之间的中介类，中介类被要求实现InvocationHandler接口。</font>** 通过代理对象调用一个方法的时候，这个方法的调用会被转发为由InvocationHandler这个接口的invoke方法来进行调用。  
    2. <font color = "clime">JDK动态代理的实现，大致流程：</font>  
        1. <font color = "red">为接口创建代理类的字节码文件。</font> 使用`反射`来创建代理类。  
        2. <font color = "red">使用ClassLoader将字节码文件加载到JVM。</font>  
        3. <font color = "red">创建代理类实例对象，执行对象的目标方法。</font>  
    3. `JDK动态代理为什么只能使用接口？`  
    &emsp; JDK动态代理是为接口生成代理对象，该代理对象继承了JAVA标准类库Proxy.java类并且实现了目标对象。由于JAVA遵循单继承多实现原则，所以JDK无法利用继承来为目标对象生产代理对象。   
2. CGLIB代理
    1. 依赖ASM字节码工具，通过动态生成`实现接口或继承类`的类字节码，实现动态代理。  
    &emsp; `针对接口，生成实现接口的类，即implements方式；针对类，生成继承父类的类，即extends方式。`  
    2. **<font color = "clime">CGLIB基于继承类生成动态代理需要注意：</font>**  
        1. final声明的类是不能被代理的；
        2. 类中的private,final方法不能被代理，static方法不生成代理方法。

#### 1.2.3.6. 常使用的设计模式
&emsp; 面试题：你使用过哪些设计模式？ 根据实际使用，设计模式分3类：  

* 框架：SpringAOP、池化（享元模式）、 mq
* 不自觉使用的设计模式，如外观/门面模式、 **<font color = "clime">对象适配器模式（Service层调用）</font>** 。  
* 需要编码：单例模式与static静态类、工厂模式、模板方法、3个if/else的优化：桥接模式、策略模式、观察者模式...  



## 1.3. JVM
### 1.3.1. JDK、JRE、JVM
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/JVM/JVM-4.png)  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/JVM/JVM-145.png)  
1. <font color = "red">JVM由4大部分组成：类加载器ClassLoader，运行时数据区Runtime Data Area，执行引擎Execution Engine，本地方法调用Native Interface。</font>  
2. **<font color = "clime">JVM各组件的作用（JVM执行程序的过程）：</font>**   
    1. 首先通过类加载器（ClassLoader）把Java代码转换成字节码；  
    2. 运行时数据区（Runtime Data Area）再把字节码加载到内存中；  
    3. <font color = "red">而字节码文件只是JVM的一套指令集规范，并不能直接交给底层操作系统去执行，因此`需要特定的命令解析器执行引擎（Execution Engine），将字节码翻译成底层系统指令，再交由CPU去执行；`</font>  
    4. 而这个过程中需要调用其他语言的本地库接口（Native Interface）来实现整个程序的功能。  

### 1.3.2. 编译成Class字节码文件

### 1.3.3. 类加载
#### 1.3.3.1. JVM类的加载
1. 类加载流程：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/JVM/JVM-5.png)  
2. 加载：查找并加载类的二进制数据。加载主要做三件事：找到类文件 -> 放入方法区 -> 开个入口（最后生成一个代表此类的java.lang.Class对象，作为访问方法区这些数据结构的入口）。  
&emsp; **<font color = "red">一句话概括：把代码数据加载到内存中，加载完成后，在方法区实例化一个对应的Class对象。</font>**  
3. 验证：确保被加载的类的正确性。验证阶段大致会完成4个阶段的检验动作：1. 文件格式验证、2. 元数据验证、3. 字节码验证、4. 符号引用验证。  
4. 准备(Preparation)  
&emsp; <font color = "red">为类的静态变量分配内存，并将其初始化为默认值，这些内存都将在方法区中分配。</font>对于该阶段有以下几点需要注意：  
    1. <font color = "red">这时候进行内存分配的仅包括类变量(static)，而不包括实例变量，实例变量会在对象实例化时随着对象一块分配在Java堆中。</font>  
    2. <font color = "red">这里所设置的初始值"通常情况"下是数据类型默认的零值(如0、0L、null、false等)，比如定义了public static int value=111 ，那么 value 变量在准备阶段的初始值就是 0 而不是111(初始化阶段才会复制)。</font>  
    * <font color = "red">特殊情况：比如给value变量加上了fianl关键字public static final int value=111，那么准备阶段value的值就被赋值为 111。</font>  
5. 解析(Resolution)： **<font color = "red">将常量池内的符号引用转换为直接引用</font>** ，得到类或者字段、方法在内存中的指针或者偏移量，确保类与类之间相互引用正确性，完成内存结构布局，以便直接调用该方法。  
&emsp; `为什么要用符号引用呢？` **<font color = "blue">这是因为类加载之前，javac会将源代码编译成.class文件，这个时候javac是不知道被编译的类中所引用的类、方法或者变量它们的引用地址在哪里，所以只能用符号引用来表示。</font>**  
&emsp; **<font color = "clime">解析过程在某些情况下可以在初始化阶段之后再开始，这是为了支持Java的动态绑定。</font>**   
6. 初始化：执行static代码块(cinit)进行初始化，如果存在父类，先对父类进行初始化。  


#### 1.3.3.2. JVM类加载器
1. JVM默认提供三个类加载器：启动类加载器、扩展类加载器、应用类加载器。  
&emsp; 自定义类加载器：需要继承自ClassLoader，重写方法findClass()。      
2. 双亲委派模型，一个类加载器首先将类加载请求转发到父类加载器，只有当父类加载器无法完成时才尝试自己加载。  
&emsp; 双亲委派模型中，类加载器之间的父子关系一般不会以继承（Inheritance）的关系来实现，而是使用组合（Composition）关系来复用父加载器的代码的。  
&emsp; 好处：避免类的重复加载；防止核心API被随意篡改。   
3. 破坏双亲委派模型：  
    1. 破坏双亲委派模型：继承ClassLoader，重写loadClass()方法。  
    1. `双亲委派模型有一个问题：顶层ClassLoader无法加载底层ClassLoader的类，典型例子JNDI、JDBC。`
        * **<font color = "clime">JDBC是启动类加载器加载，但 mysql 驱动是应用类加载器，而 JDBC 运行时又需要去访问子类加载器加载的驱动，就破坏了该模型。所以加入了`线程上下文类加载器(Thread Context ClassLoader)`，</font>** 可以通过Thread.setContextClassLoaser()设置该类加载器，然后顶层ClassLoader再使用Thread.getContextClassLoader()获得底层的ClassLoader进行加载。  
    2. Tomcat中使用了自定义ClassLoader，使得一个Tomcat中可以加载多个应用。一个Tomcat可以部署N个web应用，但是每个web应用都有自己的classloader，互不干扰。比如web1里面有com.test.A.class，web2里面也有com.test.A.class，如果没打破双亲委派模型的话，那么web1加载完后，web2再加载的话会冲突。    
    3. ......  

### 1.3.4. 内存结构
#### 1.3.4.1. JVM内存结构
##### 1.3.4.1.1. JVM内存结构
1. 运行时数据区。线程独享：程序计数器、JVM栈、本地方法栈；线程共享区：堆、方法区（元空间）。  
2. 程序计数器看作是当前线程所执行的字节码的行号指示器。  
3. <font color = "red">JVM栈描述Java方法执行的内存模型。</font>Java虚拟机栈中出栈入栈的元素称为“栈帧”，栈对应线程，栈帧对应方法。每个方法被执行的时候，都会创建一个栈帧，把栈帧压入栈，当方法正常返回或者抛出未捕获的异常时，栈帧就会出栈。    
&emsp; Java虚拟机栈是由一个个栈帧组成，每个栈帧中都拥有：局部变量表、操作数栈、动态链接、方法出口信息。局部变量表存储八大原始类型、对象引用、returnAddress。  
&emsp; `为什么不把基本类型放堆中呢？`   
&emsp; 因为其占用的空间一般是 1~8 个字节——需要空间比较少，而且因为是基本类型，所以不会出现动态增长的情况——长度固定，因此栈中存储就够了。  
4. 堆  
    1. 堆分为新生代、老年代，默认比例1: 2。 新生代又按照8: 1: 1划分为Eden区和两个Survivor区。  
    2. **<font color = "blue">在Eden区中，JVM为每个线程分配了一个私有缓存区域[TLAB(Thread Local Allocation Buffer)](/docs/java/JVM/MemoryObject.md)。</font>**    
    3. 堆是分配对象存储的唯一选择吗？[逃逸分析](/docs/java/JVM/escape.md)  
5. 方法区：
    1. 在类加载阶段，在Java堆中生成一个代表这个类的java.lang.Class对象，作为对方法区中这些数据的访问入口。  
    2. <font color = "clime">方法区的演进：</font>  
        1. 为什么JDK1.8移除元空间  
            1. 由于PermGen内存经常会溢出，引发java.lang.OutOfMemoryError: PermGen，因此JVM的开发者希望这一块内存可以更灵活地被管理，不要再经常出现这样的OOM。  
            2. 移除PermGen可以促进HotSpot JVM与JRockit VM的融合，因为JRockit没有永久代。  
        2. 演进历程：  
            * jdk1.6及之前：有永久代(permanent generation)。静态变量存放在永久代上。  
            * jdk1.7：有永久代，但已经逐步“去永久代”。[字符串常量池](/docs/java/JVM/ConstantPool.md) <font color = "red">、静态变量</font>移除，保存在堆中。  
            * jdk1.8及之后：无永久代。类型信息、字段、方法、<font color = "red">常量</font>保存在本地内存的元空间，<font color = "clime">但字符串常量池、静态变量仍在堆。</font>  
6. MetaSpace存储类的元数据信息。  
&emsp; 元空间与永久代之间最大的区别在于：元数据空间并不在虚拟机中，而是使用本地内存。元空间的内存大小受本地内存限制。  
7. 静态方法和实例方法  
&emsp; 静态方法会在程序运行的时候直接装载进入方法区。而实例方法会在new的时候以对象的方法装载进入堆中。  
&emsp; 最大的区别在于内存的区别，由于main函数为static静态方法，会直接在运行的时候装载进入内存区，实例方法必须new，在堆中创建内存区域。再进行引用。  

##### 1.3.4.1.2. 常量池详解
&emsp; **<font color = "clime">常量池分为以下三种：class文件常量池、运行时常量池、全局字符串常量池。</font>**   

##### 1.3.4.1.3. 逃逸分析
1. <font color = "red">通过逃逸分析算法可以分析出某一个方法中的某个对象是否会被其它方法或者线程访问到。</font>如果分析结果显示某对象并不会被其他方法引用或被其它线程访问，则有可能在编译期间做一些深层次的优化。   
2. 对于NoEscape（ **<font color = "clime">没有逃逸</font>** ）状态的对象不一定分配在堆中，具体会有这种优化情况：   
    1. 对象可能分配在栈上。  
    2. `分离对象或标量替换。`  
    &emsp; **<font color = "clime">在HotSpot中并没有真正的实现"栈"中分配对象的功能，取而代之的是一个叫做"标量替换"的折中办法。</font>**  
    &emsp; 什么是标量？标量，不可再分，基本数据类型；相对的是聚合量，可再分，引用类型。  
    &emsp; **当JVM通过逃逸分析，确定要将对象分配到栈上时，即时编译可以将对象打散，将对象替换为一个个很小的局部变量，将这个打散的过程叫做标量替换。** 
    3. 消除同步锁

#### 1.3.4.2. 内存中的对象
##### 1.3.4.2.1. 创建对象
1. **<font color = "clime">对象创建过程：1. 检测类是否被加载；2. 为对象分配内存；3. 将分配内存空间的对象初始化零值；4. 对对象进行其他设置；5.执行init方法。</font>**   
2. 步骤二：对象分配内存流程详解：
    * 分配内存两种方式：指针碰撞（内存空间绝对规整）；空闲列表（内存空间是不连续的）。
        * 标记-整理或复制 ---> 空间规整 ---> 指针碰撞； 
        * 标记-清除 ---> 空间不规整 ---> 空闲列表。       
    * 线程安全问题：1).采用CAS； **<font color = "clime">2).线程本地分配缓冲（TLAB）。</font>**  
    * **<font color = "blue">TLAB详解：</font>**  
        * 线程本地分配缓存，这是一个线程专用的内存分配区域。可以加速对象的分配。TLAB是在堆中开辟的内存区域。默认情况下，TLAB空间的内存非常小，仅占有整个Eden空间的1%。  
        * **<font color = "blue">TLAB通常很小，所以放不下大对象。`JVM设置了最大浪费空间`。</font>**  
        &emsp; 当大对象申请内存时，当剩余的空间小于最大浪费空间，那该TLAB属于的线程在重新向Eden区申请一个TLAB空间。进行对象创建，还是空间不够，那这个对象太大了，去Eden区直接创建吧！  
        &emsp; 当剩余的空间大于最大浪费空间，那这个大对象直接去Eden区创建。剩余空间还需要使用。
    * **<font color = "blue">`内存分配全流程：`逃逸分析 ---> 没有逃逸，尝试栈上分配 ---> 是否满足直接进入老年代的条件 ---> `尝试TLAB分配` ---> `新生代Eden区分配`。</font>**  
    * 堆内存分配策略：  
    &emsp; 分配策略有：对象优先在Eden分配、大对象直接进入老年代、长期存活的对象将进入老年代、动态对象年龄判定、空间分配担保。  
    &emsp; `空间分配担保：` **<font color = "clime">JVM在发生Minor GC之前，虚拟机会检查老年代最大可用的`连续空间`是否大于新生代所有对象的`总空间`。</font>**   

##### 1.3.4.2.2. 对象生命周期

##### 1.3.4.2.3. 对象大小
1. 在JVM中，对象在内存中的布局分为三块区域：对象头、实例数据和对齐填充。  
    * 实例数据：存放类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐。    
    * 对齐填充：JVM要求对象起始地址必须是8字节的整数倍(8字节对齐)。填充数据不是必须存在的，仅仅是为了字节对齐。   
2. JVM中对象头的方式有以下两种(以32位JVM为例)  
    * 普通对象：  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-60.png)   
    * 数组对象：  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-61.png)   

    对象头：包含Mark Word、class pointer、array length共3部分。  
    1. Mark Word：  
    &emsp; **<font color = "red">由于对象头信息是与对象自身定义的数据无关的额外存储成本，考虑到Java虚拟机的空间使用效率，</font>** **<font color = "clime">Mark Word被设计成一个非固定的动态数据结构，</font>** 以便在极小的空间内存储尽量多的信息。它会根据对象的状态复用自己的存储空间。  
    &emsp; 这部分主要用来存储对象自身的运行时数据，如hashcode、gc分代年龄等。mark word的位长度为JVM的一个Word大小，也就是说32位JVM的Mark word为32位，64位JVM为64位。
    为了让一个字大小存储更多的信息，JVM将字的最低两个位设置为标记位，
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-67.png)   

    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-68.png)   
    2. class pointer：  
    &emsp; 这一部分用于存储对象的类型指针，该指针指向它的类元数据，JVM通过这个指针确定对象是哪个类的实例。该指针的位长度为JVM的一个字大小，即32位的JVM为32位，64位的JVM为64位。 
    3. array length：  
    &emsp; 如果对象是一个数组，那么对象头还需要有额外的空间用于存储数组的长度，这部分数据的长度也随着JVM架构的不同而不同：32位的JVM上，长度为32位；64位JVM则为64位。64位JVM如果开启+UseCompressedOops选项，该区域长度也将由64位压缩至32位。  

#### 1.3.4.3. 内存泄露
1. 内存溢出与内存泄露  
&emsp; **<font color = "red">内存溢出out of memory</font>** ，是指<font color = "red">程序在申请内存时，`没有足够的内存空间供其使用`</font>，出现out of memory。  
&emsp; **<font color = "blue">内存泄露memory leak</font>** ，是指<font color = "red">程序在申请内存后，`无法释放已申请的内存空间`</font>。一次内存泄露危害可以忽略，但内存泄露堆积后果很严重，无论多少内存，迟早会被占光。内存泄露，会导致频繁的Full GC。  
&emsp; 所以内存泄漏可能会导致内存溢出，但内存溢出并不完全都是因为内存泄漏，也有可能使用了太多的大对象导致。  
2. 内存溢出影响  
&emsp; **<font color = "clime">问题：`JVM堆内存溢出后，其他线程是否可继续工作？`</font>**  
&emsp; 当一个线程抛出OOM异常后，它所占据的内存资源会全部被释放掉，从而不会影响其他线程的运行！  
&emsp; **<font color = "red">其实发生OOM的线程一般情况下会死亡，也就是会被终结掉，该线程持有的对象占用的heap都会被gc了，释放内存。</font><font color = "clime">因为发生OOM之前要进行gc，就算其他线程能够正常工作，也会因为频繁gc产生较大的影响。</font>**  

### 1.3.5. JVM执行
&emsp; ...

### 1.3.6. GC
#### 1.3.6.1. GC-回收对象

##### 1.3.6.1.1. 堆中对象的存活
1. 存活标准
    1. 引用计数法、根可达性分析法  
        1. **<font color = "clime">不可回收对象包含 1). 方法区中，类静态属性(static)引用的对象； 2). 方法区中，常量(final static)引用的对象；</font>** 
        2. `由以上可得java 全局变量 不可被回收。`  
    2. 四种引用  
        * **<font color = "red">软引用：SoftReference object=new  SoftReference(new Object()); 。当堆使用率临近阈值时，才会去回收软引用的对象。</font>**  
        * **<font color = "red">弱引用：WeakReference object=new  WeakReference (new Object();，ThreadLocal中有使用。只要发现弱引用，不管系统堆空间是否足够，都会将对象进行回收。</font>**  

                软引用和弱引用的使用：
                软引用，弱引用都非常适合来保存那些可有可无的缓存数据，如果这么做，当系统内存不足时，这些缓存数据会被回收，不会导致内存溢出。而当内存资源充足时，这些缓存数据又可以存在相当长的时间，从而起到加速系统的作用。  
                假如⼀个应⽤需要读取⼤量的本地图⽚，如果每次读取图⽚都从硬盘读取会严重影响性能，如果⼀次性全部加载到内存⼜可能造成内存溢出，这时可以⽤软引⽤解决这个问题。  

        * 虚引用：PhantomReference。虚引用是所有类型中最弱的一个。 **<font color = "red">一个持有虚引用的对象，和没有引用几乎是一样的，随时可能被垃圾回收器回收。</font>**    
2. 对象生存还是死亡？  
&emsp; **<font color = "clime">如果有必要执行父类`Object#finalize()`方法，放入F-Queue队列；收集器将对F-Queue队列中的对象进行第二次小规模的标记；如果对象在执行finalize()方法时重新与引用链上的任何一个对象建立关联则逃脱死亡，否则执行死亡。</font>**  

##### 1.3.6.1.2. 方法区(类和常量)回收/类的卸载阶段
1. Java虚拟机规范对方法区是否实现垃圾回收没有做出强制的规定。存在未实现或未能完整实现方法区类型卸载的垃圾回收器（例如JDK 11的zGC收集器）。    
&emsp; 方法区的回收效果比较难令人满意，条件很苛刻，但是回收又是很有必要的。在大量使用反射、动态代理、CGLib等字节码框架，动态生成JSP以及OSGi这类频繁自定义类加载器的场景中，通常都需要Java虚拟机具备类型卸载的能力，以保证不会对方法区造成过大的内存压力。  
2. 方法区的垃圾收集主要回收两部分：废弃的常量和不再使用的类型。  
3. 类的卸载
    1. 类需要同时满足下面3个条件才能算是 “无用的类” ：  
        * 该类所有的实例都已经被回收，也就是 Java 堆中不存在该类的任何实例。
        * 加载该类的 ClassLoader 已经被回收。
        * 该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。
    2. `一个类何时结束生命周期，取决于代表它的Class对象何时结束生命周期。`   
    &emsp; 注：`由java虚拟机自带的三种类加载加载的类在虚拟机的整个生命周期中是不会被卸载的，`由用户自定义的类加载器所加载的类才可以被卸载。     
    3. `方法区是在Full GC时回收。`  
    &emsp; Full GC: 收集整个堆，包括新生代，老年代，永久代(在 JDK 1.8 及以后，永久代被移除，换为 metaspace 元空间)等所有部分的模式。  

##### 1.3.6.1.3. null与GC  
&emsp; 《深入理解Java虚拟机》作者的观点：在需要“不使用的对象应手动赋值为null”时大胆去用，但不应当对其有过多依赖，更不能当作是一个普遍规则来推广。  
&emsp; **<font color = "red">虽然代码片段已经离开了变量xxx的`作用域`，但在此之后，没有任何对运行时栈的读写，placeHolder所在的索引还没有被其他变量重用，所以GC判断其为存活。</font>**    
&emsp; 加上`int replacer = 1;`和将placeHolder赋值为null起到了同样的作用：断开堆中placeHolder和栈的联系，让GC判断placeHolder已经死亡。    
&emsp; “不使用的对象应手动赋值为null”的原理，一切根源都是来自于JVM的一个“bug”：代码离开变量作用域时，并不会自动切断其与堆的联系。    

#### 1.3.6.2. GC-回收位置/安全点
1. 安全点  
&emsp; **<font color = "clime">可达性分析算法必须是在一个确保一致性的内存快照中进行。</font>**   
&emsp; **<font color = "clime">安全点意味着在这个点时，所有工作线程的状态是确定的，JVM可以安全地执行GC。</font>**  
2. `安全区域和线程中断`  
&emsp; `在安全点上中断的是活跃运行的用户线程，对于已经挂起的线程该怎么处理呢？`**<font color = "blue">已经挂起的线程会被认定为处在安全区域内，中断的时候不需要考虑安全区域中的线程。</font>**  
&emsp; 当前安全区域的线程要被唤醒离开安全区域时，先检查能否离开，如果GC完成了，那么线程可以离开，否则它必须等待直到收到安全离开的信号为止。  

#### 1.3.6.3. 回收算法与分代回收
1. GC算法  
    * **<font color = "clime">标记-清除算法分为两个阶段：标记阶段和清除阶段。</font>** 不足：清除过程中，扫描两次，效率不高；清除后，产生空间碎片。  
    * `复制：1).（非标记-复制）只扫描一次；` 2). 没有碎片，空间连续； 3). 50%的内存空间始终空闲浪费。  
    * 标记-整理：1). 没有碎片，空间连续； 2). 不会产生内存减半； 3). 扫描两次，指针需要调整(移动对象)，效率偏低。  
    &emsp; **<font color = "clime">标记-清除和标记-整理都需要扫描两次。</font>**   
2. 新生代采用复制算法；老年代采用标记-整理算法。 **<font color = "clime">注意：CMS回收老年代，但采用标记-清除算法；CMS收集器也会在内存空间的碎片化程度已经大到影响对象分配时，采用标记-整理算法收集一次（晋升失败(promotion failed) 或 并发模式失败(concurrent mode failure)），以获得规整的内存空间。</font>**    
    * `新生代采用复制算法。新生代存活率低，存活对象少。标记-清除算法效率高，搬运对象也比较少。`  
3. 分代回收流程  
4. 跨代引用假说（跨代引用相对于同代引用仅占少数）  
&emsp; **既然跨代引用只是少数，那么就没必要去扫描整个老年代，也不必专门记录每一个对象是否存在哪些跨代引用，只需在新生代上建立一个全局的数据结构，称为记忆集(Remembered Set)，这个结构把老年代划分为若干个小块，标识出老年代的哪一块内存会存在跨代引用。此后当发生Minor GC时，只有包含了跨代引用的小块内存里的对象才会被加入GC Roots进行扫描。**  
&emsp; `卡表是记忆集的一种实现方式。`  
5. 各种GC：  
    * `Partial GC(局部 GC)：并不收集整个 GC 堆的模式。`  
        * Young GC：只收集 Young Gen 的 GC，Young GC 还有种说法就叫做 Minor GC。  
        * Old GC：只收集 old gen 的 GC，只有垃圾收集器 CMS 的 concurrent collection 是这个模式。  
        * Mixed GC：收集整个 Young Gen 以及部分 old gen 的 GC，只有垃圾收集器 G1 有这个模式。  
    * `Full GC：收集整个堆，包括新生代，老年代，永久代(在 JDK 1.8 及以后，永久代被移除，换为 metaspace 元空间)等所有部分的模式。`  
6. YGC触发时机：eden区快要被占满的时候；在full gc前会让先执行以下young gc。  
7. Full GC   
&emsp; **<font color = "red">Full GC的触发时机：（老年代或永久代不足 ---> 老年代不满足年轻代晋升 ---> 回收器(例如CMS)---> 系统调用 ）</font>**   
    1. 老年代或永久的不足
        1. 老年代空间不足(92%)  
        &emsp; 老年代空间不足的常见场景为大对象直接进入老年代、长期存活的对象进入老年代等。  
        &emsp; 为了避免以上原因引起的Full GC，应当尽量不要创建过大的对象以及数组。除此之外，可以通过-Xmn虚拟机参数调大新生代的大小，让对象尽量在新生代被回收掉，不进入老年代。还可以通过 -XX:MaxTenuringThreshold调大对象进入老年代的年龄，让对象在新生代多存活一段时间。  
        2. JDK 1.7及以前的永久代空间不足  
        &emsp; 为避免以上原因引起的Full GC，可采用的方法为增大永久代空间或转为使用CMS GC。  
    2. 老年代不满足年轻代晋升  
        1. 统计得到的Minor GC晋升到旧生代的`平均大小`大于旧生代的剩余空间  
        &emsp; Hotspot为了避免由于新生代对象晋升到旧生代导致旧生代空间不足的现象，在进行Minor GC时，做了一个判断，如果之前统计所得到的Minor GC晋升到旧生代的平均大小大于旧生代的剩余空间，那么就直接触发Full GC。  
        2. 空间分配担保失败  
        &emsp; **<font color = "clime">JVM在发生Minor GC之前，虚拟机会检查老年代最大可用的`连续空间`是否大于新生代所有对象的`总空间`，</font>** 如果大于，则此次Minor GC是安全的；如果小于，则虚拟机会查看HandlePromotionFailure设置项的值是否允许担保失败。如果HandlePromotionFailure=true，那么会继续检查老年代最大可用连续空间是否大于历次晋升到老年代的对象的平均大小，如果大于则尝试进行一次Minor GC，但这次Minor GC依然是有风险的；如果小于或者HandlePromotionFailure=false，则改为进行一次Full GC。   
    3. CMS GC时出现promotion failed（晋升失败）和concurrent mode failure（并发模式失败）  
    &emsp; 执行CMS GC的过程中同时有对象要放入老年代，而此时老年代空间不足（可能是GC过程中浮动垃圾过多导致暂时性的空间不足），便会报Concurrent Mode Failure错误，并触发Full GC。  
    4. <font color = "red">系统调用System.gc()</font>  
    &emsp; 只是建议虚拟机执行Full GC，但是虚拟机不一定真正去执行。不建议使用这种方式，而是让虚拟机管理内存。  

#### 1.3.6.4. GC-垃圾回收器
##### 1.3.6.4.1. 垃圾回收器
1. 根据收集器的指标（性能考虑因素）分类（`两个关键指标，停顿时间和吞吐量`）：  
    * **<font color = "clime">吞吐量：运行用户代码时间/(运行用户代码时间+垃圾收集时间)。</font>**  
    * 停顿时间：执行垃圾收集时，程序的工作线程被暂停的时间。  
    * 内存占有（堆空间）：Java堆区所占的内存大小。  
    * 垃圾收集开销：吞吐量的补数，垃圾收集器所占时间与总时间的比例。  
    * 收集频率：相对于应用程序的执行，收集操作发生的频率。  
    * 快速：一个对象从诞生到被回收所经历的时间。  

    &emsp; <font color  = "red">其中内存占用、吞吐量和停顿时间，三者共同构成了一个“不可能三角”。</font>    
    &emsp; 停顿时间越短就越适合需要和用户交互的程序，良好的响应速度能提升用户体验；  
    &emsp; 高吞吐量则可以高效地利用CPU时间，尽快完成程序的运算任务，主要适合在后台运算而不需要太多交互的任务。  
2. 根据运行时，线程执行方式分类：  
    * 串行收集器 -> Serial和Serial Old  
    &emsp; **<font color = "red">只能有一个垃圾回收线程执行，用户线程暂停。</font>** 适用于内存比较小的嵌入式设备 。  
    * 并行收集器【吞吐量优先】 -> Parallel Scanvenge、Parallel Old  
    &emsp; **<font color = "red">多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。</font>** 适用于科学计算、后台处理等交互场景 。  
    * 并发收集器【停顿时间优先】 -> CMS、G1  
    &emsp; **<font color = "red">用户线程和垃圾收集线程同时执行</font><font color = "blue">（但并不一定是并行的，可能是交替执行的），</font><font color = "red">垃圾收集线程在执行的时候不会停顿用户线程的运行。</font>** 适用于相对时间有要求的场景，比如Web。  
3. `JDK 7u4后的7和JDK8默认使用的都是ParallelScavenge+ParallelOld。`  

##### 1.3.6.4.2. CMS回收器
1. **<font color = "clime">CMS在某些阶段是并发，即CMS GC时并不是全部并发执行。大部分并发，但也有停顿(STW)，只是停顿时间更少。因为CMS是并发收集器，为了不影响用户线程使用，所以采用标记-清除算法。</font>**   
2. CMS GC执行流程：(**<font color = "clime">3次标记、2次清除</font>**)  
    1. 初始标记：标记GCRoots能直接关联到的对象。   
    2. 并发标记：进行GCRoots Tracing（可达性分析）过程，GC与用户线程并发执行。
    3. 预清理：（`三色标记法的漏标问题处理`） **<font color = "red">这个阶段是用来</font><font color = "blue">处理</font><font color = "clime">前一个并发标记阶段因为引用关系改变导致没有标记到的存活对象的。如果发现对象的引用发生变化，则JVM会标记堆的这个区域为Dirty Card。那些能够从Dirty Card到达的对象也被标记（标记为存活），当标记做完后，这个Dirty Card区域就会消失。</font>**  
    4. 可终止的预处理。这个阶段尝试着去承担下一个阶段Final Remark阶段足够多的工作。  
    5. 重新标记（remark）：修正并发标记期间，因用户程序继续运作而导致标记产生变动的那一部分对象的标记记录。
    6. 并发清除：并发、标记-清除，GC与用户线程并发执行。   
    7. 并发重置。
3. `CMS的特点：`  
    1. 划时代的并发收集器。`关注停顿时间。`    
    2. `吞吐量低。`并发执行，线程切换。  
    3. **<font color = "blue">并发执行，`产生浮动垃圾（参考三色标记法中“错标”）`。</font>**  
    4. 使用"标记-清除"算法，产生空间碎片。CMS GC在老生代回收时产生的内存碎片会导致老生代的利用率变低；或者可能在老生代总内存大小足够的情况下，却不能容纳新生代的晋升行为（由于没有连续的内存空间可用），导致触发FullGC。  
        &emsp; 针对这个问题，`Sun官方给出了以下解决内存碎片问题的方法：`  
        * 增大Xmx或者减少Xmn  
        * `在应用访问量最低的时候，在程序中主动调用System.gc()，比如每天凌晨。`  
        * 在应用启动并完成所有初始化工作后，主动调用System.gc()，它可以将初始化的数据压缩到一个单独的chunk中，以腾出更多的连续内存空间给新生代晋升使用。  
        * `降低-XX:CMSInitiatingOccupancyFraction参数（内存占用率，默认70%）以提早执行CMS GC动作，`虽然CMSGC不会进行内存碎片的压缩整理，但它会合并老生代中相邻的free空间。这样就可以容纳更多的新生代晋升行为。 
        * CMS收集器提供了一个-XX：+UseCMS-CompactAtFullCollection开关参数（默认是开启的，此参数从JDK 9开始废弃），用于在CMS收集器不得不进行Full GC时开启内存碎片的合并整理过程。`还提供了另外一个参数-XX：CMSFullGCsBefore-Compaction（此参数从JDK 9开始废弃），这个参数的作用是要求CMS收集器在执行过若干次（数量由参数值决定）不整理空间的Full GC之后，下一次进入Full GC前会先进行碎片整理（默认值为0，表示每次进入Full GC时都进行碎片整理）。`  
    5. `晋升失败（新生代垃圾回收）与并发模式失败（CMS垃圾回收）`：都会退化成单线程的Full GC。  
        * 晋升失败(promotion failed)：`当新生代发生垃圾回收`， **老年代有足够的空间可以容纳晋升的对象，但是由于空闲空间的碎片化，导致晋升失败。** ~此时会触发单线程且带压缩动作的Full GC。~  
        * 并发模式失败(concurrent mode failure)：`当CMS在执行回收时`，新生代发生垃圾回收，同时老年代又没有足够的空间容纳晋升的对象时。CMS垃圾回收会退化成单线程的Full GC。所有的应用线程都会被暂停，老年代中所有的无效对象都被回收。  
    6. 减少remark阶段停顿：在执行并发操作之前先做一次Young GC。  


##### 1.3.6.4.3. G1回收器
1. G1是一种服务端应用使用的垃圾收集器，目标是用在`多核、大内存`的机器上， **<font color = "clime">G1在大多数情况下可以`实现指定的GC暂停时间，同时还能保持较高的吞吐量`。</font>**   
2. G1特点（为什么要选择G1？）  
    1. 并行和并发
    2. 分代收集：G1逻辑分代但物理不分代，将整个Java堆划分为多个大小相等的独立区域(Region)。E区、S区、H区、O区。  
    3. **<font color = "clime">`空间整合（不产生内存碎片）：`</font>** 与CMS的“标记--清理”算法不同，<font color = "red">G1从整体来看是基于“标记整理”算法实现的收集器；从局部上来看是基于“复制”算法实现的。</font>这两种算法都意味着<font color = "clime">G1运作期不会产生内存空间碎片</font>，收集后能提供规整的可用内存。这种特性有利于程序长时间运行，分配大对象吋不会因为无法找到连续内存空而提前触发下一次GC。  
    4. **<font color = "clime">`可预测的停顿：`</font>** 这是G1相对于CMS的另一个大优势，<font color = "red">降低停顿时间是G1和CMS共同的关注点，但G1除了追求低停顿外，还能建立可预测的停顿时间模型，</font>能让使用者明确指定在一个长度为M毫秒的时间片段内，消耗在垃圾收集上的时间不得超过N毫秒。  
3. 回收流程：G1的收集过程可能有4个阶段：新生代GC、老年队并发标记周期、混合回收、如果需要可能会进行Full GC。   
    1. 老年队并发标记周期  
    &emsp; **<font color = "clime">当整个堆内存（包括老年代和新生代）被占满一定大小的时候（默认是45%，可以通过-XX:InitiatingHeapOccupancyPercent进行设置），老年代回收过程会被启动。</font>**  
    &emsp; **<font color = "clime">老年队并发标记周期，回收百分之百为垃圾的内存分段，</font>** H区（本质是o区）Humongous对象会独占整个内存分段。  
    2. 混合回收MixGC  
    &emsp; 老年代并发标记过程结束以后，紧跟着就会开始混合回收过程。混合回收的意思是年轻代和老年代会同时被回收。  
    &emsp; **<font color = "blue">步骤分2步：全局并发标记（global concurrent marking）、拷贝存活对象（evacuation）。</font>**  
        1. 全局并发标记  
            1. 初始标记
            2. 根区域扫描
            3. 并发标记
            4. 最终标记： **<font color = "blue">去处理剩下的SATB（开始快照）日志缓冲区和所有更新，找出所有未被访问的存活对象，同时安全完成存活数据计算。</font>**   
            5. 清除垃圾


##### 1.3.6.4.4. 三色标记
1. 三色：  
    * 黑色：本对象已访问过，而且本对象 引用到 的其他对象 也全部访问过了。  
    * 灰色：本对象已访问过，但是本对象 引用到 的其他对象 尚未全部访问完。全部访问后，会转换为黑色。  
    * 白色：尚未访问过。  
2. 三色标记流程： 1).根对象黑色... **<font color = "clime">如果标记结束后对象仍为白色，意味着已经“找不到”该对象在哪了，不可能会再被重新引用。</font>**  
3. **<font color = "clime">`多标/错标`，本应该回收 但是 没有回收掉的内存，被称之为“浮动垃圾”</font>** ，并不会影响垃圾回收的正确性，只是需要等到下一轮垃圾回收才被清除。  
4. **<font color = "clime">漏标：把本来应该存活的垃圾，标记为了死亡。这就会导致非常严重的错误。</font>**   
	1. 两个必要条件：1). 灰色指向白色的引用消失。2). 黑色重新指向白色；  
  &emsp; 新增对象不算漏标。  
	2. CMS采用增量更新（针对新增的引用，将其记录下来等待遍历）， **<font color = "clime">关注引用的增加（黑色重新指向白色），`把黑色重写标记为灰色`，下次重新扫描属性。</font>** 破坏了条件“黑指向白”。    
    &emsp; CMS预清理：（`三色标记法的漏标问题处理`） **<font color = "red">这个阶段是用来</font><font color = "blue">处理</font><font color = "clime">前一个并发标记阶段因为引用关系改变导致没有标记到的存活对象的。如果发现对象的引用发生变化，则JVM会标记堆的这个区域为Dirty Card。那些能够从Dirty Card到达的对象也被标记（标记为存活），当标记做完后，这个Dirty Card区域就会消失。</font>**  
	3. G1采用开始时快照技术SATB， **<font color = "clime">关注引用的删除（灰色指向白色的引用消失），当B->D消失时，要把这个引用推到GC的堆栈，保证D还能被GC扫描到。破坏了条件“灰指向白的引用消失”。</font>** 保存在GC堆栈中的删除引用，会在最终标记remark阶段处理。    
	4. 使用SATB会大大减少扫描对象。  


### 1.3.7. JVM调优
#### 1.3.7.1. JVM调优-基础
1. JVM参数：

    |参数|描述|
    |---|---|
    |-Xms|用于在JVM启动时设置初始堆大小|
    |-Xmx|用于设置最大堆大小|
    |-Xmn|设置新生区的大小，剩下的空间用于老年区|
    |-XX：PermGen|用于设置永久区存初始大小|
    |-XX：MaxPermGen|用于设置Perm Gen的最大尺寸|
    |-XX：SurvivorRatio|提供Eden区域的比例|
    |-XX：NewRatio|用于提供老年代/新生代大小的比例，默认值为2|
2. JVM命令行调优工具：  
    * Jps：虚拟机进程状况工具。  
    * Jstack：java线程堆栈跟踪工具。  
    &emsp; **<font color = "clime">生成线程快照的主要目的是定位线程出现长时间停顿的原因，如线程间死锁、死循环、请求外部资源导致的长时间等待等都是导致线程长时间停顿的常见原因。</font>**  
    &emsp; **`线程出现停顿的时候，通过jstack来查看各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么。`**  
    * Jmap：java内存映像工具。  
    &emsp; <font color = "red">jmap（JVM Memory Map）命令用于生成heap dump文件。如果不使用这个命令，</font> **<font color = "red">还可以使用-XX:+HeapDumpOnOutOfMemoryError参数来让虚拟机出现OOM的时候自动生成dump文件。</font>**   
    &emsp; jmap -dump:live,format=b,file=path pid。 **<font color = "blue">参数lime表示需要抓取目前在生命周期内的内存对象。</font>**   
    * Jhat：虚拟机堆转储快照分析工具。  
    * Jstat：虚拟机统计信息监视工具。  
    * Jinfo：java配置信息工具。  

#### 1.3.7.2. JVM调优
1. 内存设置  
&emsp; 如何将各分区调整到合适的大小，分析活跃数据的大小是很好的切入点。  
&emsp; **活跃数据的大小是指，应用程序稳定运行时长期存活对象在堆中占用的空间大小，也就是Full GC后堆中老年代占用空间的大小。** 
2. GC调优
    1. <font color = "clime">`GC的优化主要有2个维度，一是频率，二是时长。`</font> **<font color = "clime">如果满足下面的指标，则一般不需要进行GC调优：</font>**    
        * Minor GC执行时间不到50ms;
        * Minor GC执行不频繁，约10秒一次；
        * Full GC执行时间不到1s;
        * Full GC执行频率不算频繁，不低于10分钟1次。
    2. Young GC、Full GC优化策略 参考 1.2.3节。


#### 1.3.7.3. JVM问题排查
1. 快速恢复业务：隔离故障服务器。  
2. FGC过高  
&emsp; **<font color = "clime">`FGC过高可能是内存参数设置不合理，也有可能是代码中某个位置读取数据量较大导致系统内存耗尽。`FGC过高可能导致CPU飚高。</font>**  
&emsp; **<font color = "clime">解决思路（`FGC过高参考CPU飚高`）：FGC过高一般会导致CPU过高，打印线程堆栈信息。查看线程堆栈是用户线程，还是GC线程。如果是GC线程，打印内存快照进行分析（`查看内存溢出`），`进行Full GC优化`。</font>**  
3. CPU飚高  
&emsp; **<font color = "red">CPU过高可能是系统频繁的进行Full GC，导致系统缓慢。</font><font color = "clime">而平常也可能遇到比较耗时的计算，导致CPU过高的情况。</font>**  
&emsp; **<font color = "clime">怎么区分导致CPU过高的原因具体是Full GC次数过多还是代码中有比较耗时的计算？</font>** `如果是Full GC次数过多，那么通过jstack得到的线程信息会是类似于VM Thread之类的线程`；而`如果是代码中有比较耗时的计算，那么得到的就是一个线程的具体堆栈信息。` 

        1. 通过top命令找到CPU消耗最高的进程，并记住进程ID。  
        2. 再次通过top -Hp [进程 ID]找到CPU消耗最高的线程ID，并记住线程ID。  
        3. 通过JDK提供的jstack工具dump线程堆栈信息到指定文件中。具体命令：jstack -l [进程 ID] >jstack.log。  
        4. 由于刚刚的线程ID是十进制的，而堆栈信息中的线程ID是16进制的，因此需要将10进制的转换成16进制的，并用这个线程ID在堆栈中查找。使用printf "%x\n" [十进制数字] ，可以将10进制转换成16进制。  
        5. 通过刚刚转换的16进制数字从堆栈信息里找到对应的线程堆栈。就可以从该堆栈中看出端倪。      
4. **<font color = "blue">★★★CPU高，查看所有进程占用率要远小于100。</font>**
    1. 可能多个线程执行同一方法，每个线程占有不高，但总和比较大。  
    2. 可以使用arthas工具的thread -n -i分析。
5. 内存溢出OOM  
	1. 解决方案：
		1. 修改JVM启动参数，直接增加内存。  
		2. `检查错误日志，查看“OutOfMemory”错误前是否有其它异常或错误。`  
		3. `对代码进行走查和分析，找出可能发生内存溢出的位置。` 
		4. `使用内存查看工具动态查看内存快照。` 
    2. 保存内存快照（两种方法）： 
        1. 添加JVM参数，(-XX:+HeapDumpOnOutOfMemoryError)，让JVM遇到OOM异常时能输出堆内信息，可以通过（-XX:+HeapDumpPath）参数设置堆内存溢出快照输出的文件地址。  
        2. jmap命令。`注：线上环境不能直接使用jmap命令。找到未进行GC的一个节点，从线上环境摘除。然后再使用jmap命令。`  
	3. 使用内存查看工具分析堆dump文件
    4. jvm内存快照dump文件太大： 
	    * **<font color = "clime">live参数表示需要抓取目前在生命周期内的内存对象，也就是说GC收不走的对象，然后绝大部分情况下，需要的看的就是这些内存。</font>**   
		* 如果Dump文件太大，可能需要加上-J-Xmx512m这种参数指定最大堆内存，即jhat -J-Xmx512m -port 9998 /tmp/dump.dat。
		* 如果dump文件太大，使用linux下的mat，既Memory Analyzer Tools。   


#### 1.3.7.4. Arthas工具


## 1.4. 并发编程
### 1.4.1. 线程Thread
1. 创建线程的方式：Thread、Runnable、Callable、线程池相关（Future, ThreadPOOL, `@Async`）...  
2. 线程状态 
3. yield()，线程让步。 yield会使当前线程让出CPU执行时间片，与其他线程一起重新竞争CPU时间片。  
4. thread.join()把指定的线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行的线程。比如在线程B中调用了线程A的Join()方法，直到线程A执行完毕后，才会继续执行线程B。  
5. 中断Thread.interrupt()  
    &emsp; **<font color = "red">线程在不同状态下对于中断所产生的反应：</font>**    
    * NEW和TERMINATED对于中断操作几乎是屏蔽的；  
    * RUNNABLE和BLOCKED类似， **<font color = "cclime">对于中断操作只是设置中断标志位并没有强制终止线程，对于线程的终止权利依然在程序手中；</font>**  
    * WAITING/TIMED_WAITING状态下的线程对于中断操作是敏感的，它们会抛出异常并清空中断标志位。  

#### 1.4.1.1. 线程状态详解
1. 通用的线程周期。操作系统层面有5个状态，分别是:New（新建）、Runnable（就绪）、Running（运行）、Blocked（阻塞）、Dead（死亡）。  
2. Java线程状态均来自Thread类下的State这一内部枚举类中所定义的状态：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/thread-2.png)  
1. 新建状态（NEW）：一个尚未启动的线程处于这一状态。用new语句创建的线程处于新建状态，此时它和其他Java对象一样，仅仅在堆区中被分配了内存，并初始化其成员变量的值。
    * new Thread()
2. 就绪状态(Runnable)：当一个线程对象创建后，其他线程调用它的start()方法，该线程就进入就绪状态，Java虚拟机会为它创建方法调用栈和程序计数器。处于这个状态的线程位于可运行池中，等待获得CPU的使用权。<!-- Runnable (可运行/运行状态，等待CPU的调度)(要注意：即使是正在运行的线程，状态也是Runnable，而不是Running) -->  
    * 调用了thread.start()启动线程。
    * 被synchronized标记的代码，获取到同步监视器。
    * obj.notify()唤醒线程。
    * obj.notifyAll()唤醒线程。
    * obj.wait(time), thread.join(time)等待时间time耗尽。
3. **<font color = "red">阻塞状态（BLOCKED）</font>：** **<font color = "clime">阻塞状态是指线程因为某些原因`放弃CPU`，暂时停止运行。</font>** 当线程处于阻塞状态时，Java虚拟机不会给线程分配CPU。直到线程重新进入就绪状态(获取监视器锁)，它才有机会转到运行状态。可分为以下3种：
    * **等待阻塞(o.wait->等待对列)：运行的线程执行wait()方法，JVM会把该线程放入等待池中。(wait会释放持有的锁)**
    * **同步阻塞(lock->锁池)：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入锁池(lock pool)中。**
    * **其他阻塞状态(sleep/join)：当前线程执行了sleep()方法，或者调用了其他线程的join()方法，或者发出了I/O请求时，就会进入这个状态。**
4. **<font color = "red">等待状态（WAITING）：</font>** **<font color = "clime">一个正在无限期等待另一个线程执行一个特别的动作的线程处于这一状态。</font>**
    * threadA中调用threadB.join()，threadA将Waiting，直到threadB终止。
    * obj.wait() 释放同步监视器obj，并进入阻塞状态。
5. <font color = "red">计时等待（TIMED_WAITING）：</font>一个正在限时等待另一个线程执行一个动作的线程处于这一状态。
    * threadA中调用threadB.join(time)。
    * obj.wait(time)
    * sleep(time)。
6. 终止状态（TERMINATED）：一个已经退出的线程处于这一状态。线程会以下面三种方式结束，结束后就是死亡状态。
    * 正常结束：run()或 call()方法执行完成，线程正常结束。
    * 异常结束：线程抛出一个未捕获的Exception或Error。
    * 调用stop：直接调用该线程的stop()方法来结束该线程—该方法通常容易导致死锁，不推荐使用。
7. 注意：由于wait()/wait(time)导致线程处于Waiting/TimedWaiting状态，当线程被notify()/notifyAll()/wait等待时间到之后，如果没有获取到同步监视器。会直接进入Blocked阻塞状态。  
8. 线程状态切换图示：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/thread-5.png) 

### 1.4.2. 并发编程
#### 1.4.2.1. 并发编程原理
##### 1.4.2.1.1. CPU缓存及JMM
1. JMM
    1. JMM内存划分：线程对变量的所有操作都必须在工作内存进行，而不能直接读写主内存中的变量。    
    2. 单个线程操作时，8种内存间交换操作指令。  
    3. 线程之间的通信和同步。线程之间的通信过程：线程对变量的操作（读取赋值等）必须在工作内存中进行，首先要将变量从主内存拷贝到自己的工作内存空间，然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，</font>各个线程中的工作内存中存储着主内存中的变量副本拷贝，<font color = "red">因此不同的线程间无法访问对方的工作内存，线程间的通信（传值）必须通过主内存来完成。</font>    


##### 1.4.2.1.2. 并发安全问题产生原因
1. **并发安全的3个问题：**  

    * 原子性：线程切换带来的原子性问题；（[Volatile](/docs/java/concurrent/Volatile.md)不保证原子性）
    * 可见性：缓存不能及时刷新导致的可见性问题；
    * 有序性：编译优化带来的有序性问题  

    &emsp; **<font color = "clime">`【缓存不能及时刷新】/可见性 (【内存系统重排序】)` 和`【编译器优化】/有序性` 都是`重排序`的一种。</font>**   
2. **~~重排序：~~**  
    * **<font color = "blue">重排序分类：1). 编译器优化；2). 指令重排序(CPU优化行为)；3). 内存系统重排序：内存系统没有重排序，但是由于有缓存的存在，使得程序整体上会表现出乱序的行为。</font>**     
        * 对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。  
        * 对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障指令， **<font color = "clime">通过内存屏障指令来禁止特定类型的处理器重排序</font>** （不是所有的处理器重排序都要禁止）。 

    * 重排序遵守的规则：重排序遵守数据依赖性、重排序遵守as-if-serial语义。  
    * 重排序对多线程的影响

##### 1.4.2.1.3. 并发安全解决底层
1. 缓存一致性协议  
    1. 怎么解决缓存一致性问题呢？使用总线锁或缓存锁。  
        * 总线锁：cpu从主内存读取数据到高速缓存，会在总线对这个数据加锁，这样其他cpu无法去读或写这个数据，直到这个cpu使用完数据释放锁之后其他cpu才能读取该数据。  
        * 缓存锁：只要保证多个CPU缓存的同一份数据是一致的就可以了，基于缓存一致性协议来实现。  
    2. MESI缓存一致性协议  
        1. 缓存一致性协议有很多种，MESI(Modified-Exclusive-Shared-Invalid)协议其实是目前使用很广泛的缓存一致性协议，x86处理器所使用的缓存一致性协议就是基于MESI的。  
        2. 其他cpu通过 总线嗅探机制 可以感知到数据的变化从而将自己缓存里的数据失效。  
        &emsp; 总线嗅探， **<font color = "red">每个CPU不断嗅探总线上传播的数据来检查自己缓存值是否过期了，如果处理器发现自己的缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置为无效状态，当处理器对这个数据进行修改操作的时候，会重新从内存中把数据读取到处理器缓存中。</font>**    
        2. 总线嗅探会带来总线风暴。  
2. 内存屏障：    
    &emsp; Java中如何保证底层操作的有序性和可见性？可以通过内存屏障。内存屏障，禁止处理器重排序，保障缓存一致性。  
    &emsp; `内存屏障的作用：（~~原子性~~、可见性、有序性）`  
    1. `（保障可见性）它会强制将对缓存的修改操作立即写入主存；` 如果是写操作，会触发总线嗅探机制(MESI)，会导致其他CPU中对应的缓存行无效，也有 [伪共享问题](/docs/java/concurrent/PseudoSharing.md)。   
    2. `（保障有序性）阻止屏障两侧的指令重排序。`   
3. JMM中的happens-before原则：  
    &emsp; JSR-133内存模型 **<font color = "red">使用`happens-before`的概念来阐述操作之间的`内存可见性`。在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。</font>** 这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。  
    &emsp; happens-before关系的定义如下：

    * 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。  
    * 两个操作之间存在happens-before关系，并不意味着Java平台的具体实现必须要按照happens-before关系指定的顺序来执行。如果重排序之后的执行结果，与按happens-before关系来执行的结果一致，那么JMM也允许这样的重排序。  

    **<font color = "clime">happens-before原则有管理锁定（lock）规则、volatile变量规则、线程启动规则（Thread.start()）、线程终止规则（Thread.join()）、线程中断规则（Thread.interrupt()）...</font>**  
    volatile变量规则就是使用内存屏障保证线程可见性。  

##### 1.4.2.1.4. 伪共享问题
1. CPU具有多级缓存，越接近CPU的缓存越小也越快；CPU缓存中的数据是以缓存行为单位处理的；CPU缓存行（通常是64字节）能带来免费加载数据的好处，所以处理数组性能非常高。  
2. **CPU缓存行也带来了弊端，多线程处理不相干的变量时会相互影响，也就是伪共享。**  
&emsp; 设想如果有个long类型的变量a，它不是数组的一部分，而是一个单独的变量，并且还有另外一个long类型的变量b紧挨着它，那么当加载a的时候将免费加载b。  
&emsp; 看起来似乎没有什么毛病，但是如果一个CPU核心的线程在对a进行修改，另一个CPU核心的线程却在对b进行读取。  
3. 避免伪共享的主要思路就是让不相干的变量不要出现在同一个缓存行中；一是在两个long类型的变量之间再加7个long类型(字节填充)；二是创建自己的long类型，而不是用原生的；三是使用java8提供的注解。  
&emsp; 高性能原子类[LongAdder](/docs/java/concurrent/LongAdder.md)可以解决类伪共享问题。   

#### 1.4.2.2. 线程安全解决
##### 1.4.2.2.1. 线程安全解决方案
1. 线程安全解决方案
	1. 阻塞/互斥同步（悲观锁）
	2. 非阻塞同步（乐观锁，CAS） 
	3. 无同步方案（线程封闭）
		* 栈封闭（类变量变局部变量）
		* 线程本地存储（Thread Local Storage）
	4. 不可变对象
2. Java并发原语
	Java内存模型，除了定义了一套规范，还提供了一系列原语，封装了底层实现后，供开发者直接使用。  
	* 原子性可以通过synchronized和Lock来实现。  
	* 可见性可以通过Volatile、synchronized、final来实现。  
	* 有序性可以通过synchronized或者Lock、volatile来实现。  

##### 1.4.2.2.2. Synchronized
###### 1.4.2.2.2.1. Synchronized介绍


###### 1.4.2.2.2.2. Synchronized使用
1. synchronized可以修饰代码块或者方法：  
    ```java
    synchronized (lock){
        //被保护的代码块
    }
    public synchronized void method() {
        被保护的方法
    }
    ```
2. 类锁和对象锁  
    1. `类锁：当Synchronized修饰静态方法或Synchronized修饰代码块传入某个class对象（Synchronized (XXXX.class)）时被称为类锁。`
    2. `对象锁：当Synchronized修饰非静态方法或Synchronized修饰代码块时传入非class对象（Synchronized this）时被称为对象锁。`
3. String锁：由于在JVM中具有String常量池缓存的功能，因此相同字面量是同一个锁。  


##### 1.4.2.2.3. Synchronized使用是否安全
&emsp; 共有 `类锁 + 对象锁 + 类锁 * 对象锁`种情况。    
1. 类锁
2. 对象锁
3. 类锁和对象锁
4. 不安全场景

###### 1.4.2.2.3.1. Synchronized底层原理
1. Synchronized底层实现：`查看Synchronized的字节码。`  
    * Synchronized方法同步：依靠的是方法修饰符上的ACC_Synchronized实现。  
    * Synchronized代码块同步：使用monitorenter和monitorexit指令实现。   
每一个对象都会和一个监视器monitor关联。监视器被占用时会被锁住，其他线程无法来获取该monitor。   
线程执行monitorenter指令时尝试获取对象的monitor的所有权，当monitor被占用时就会处于锁定状态。  
2. **<font color = "clime">Java对象头的MarkWord中除了存储锁状态标记外，还存有ptr_to_heavyweight_monitor（也称为管程或监视器锁）的起始地址，每个对象都存在着一个monitor与之关联。</font>**  
3. **<font color = "clime">在Java虚拟机（HotSpot）中，Monitor是基于C++实现的，在虚拟机的ObjectMonitor.hpp文件中。</font><font color = "blue">monitor运行的机制过程如下：(_EntryList队列、_Owner区域、_WaitSet队列)</font>**  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-55.png)  
    * `想要获取monitor的线程，首先会进入_EntryList队列。`  
    * `当某个线程获取到对象的monitor后，进入Owner区域，设置为当前线程，`同时计数器count加1。  
    * **如果线程调用了wait()方法，则会进入WaitSet队列。** 它会释放monitor锁，即将owner赋值为null，count自减1，进入WaitSet队列阻塞等待。  
    * 如果其他线程调用 notify() / notifyAll()，会唤醒WaitSet中的某个线程，该线程再次尝试获取monitor锁，成功即进入Owner区域。  
    * 同步方法执行完毕了，线程退出临界区，会将monitor的owner设为null，并释放监视锁。  
4. linux互斥锁nutex（内核态）  
&emsp; <font color = "clime">重量级锁是依赖对象内部的monitor锁来实现的，而monitor又依赖操作系统的MutexLock(互斥锁)来实现的，所以重量级锁也称为互斥锁。</font>  
&emsp; **<font color = "clime">为什么说重量级线程开销很大？</font>**  
&emsp; 当系统检查到锁是重量级锁之后，会把等待想要获得锁的线程进行阻塞，`被阻塞的线程不会消耗cpu`。 **<font color = "clime">`但是阻塞或者唤醒一个线程时，都需要操作系统来帮忙，这就需要从用户态转换到内核态(向内核申请)，而转换状态是需要消耗很多时间的，有可能比用户执行代码的时间还要长。`</font>**  


###### 1.4.2.2.3.2. Synchronized优化
1. **<font color = "clime">锁降级：</font>** <font color = "red">Hotspot在1.8开始有了锁降级。在STW期间JVM进入安全点时，如果发现有闲置的monitor（重量级锁对象），会进行锁降级。</font>   
2. 锁升级  
    &emsp; 锁主要存在四种状态，依次是：无锁状态（普通对象）、偏向锁状态、轻量级锁状态、重量级锁状态，它们会随着竞争的激烈而逐渐升级。锁升级流程如下：   
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-79.png)   
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-80.png)   
	1. 偏向锁：  
        1.  **<font color = "bule">偏向锁状态</font>**  
            * **<font color = "clime">匿名偏向(Anonymously biased)</font>** 。在此状态下thread pointer为NULL(0)，意味着还没有线程偏向于这个锁对象。第一个试图获取该锁的线程将会面临这个情况，使用原子CAS指令可将该锁对象绑定于当前线程。这是允许偏向锁的类对象的初始状态。
            * **<font color = "clime">可重偏向(Rebiasable)</font>** 。在此状态下，偏向锁的epoch字段是无效的（与锁对象对应的class的mark_prototype的epoch值不匹配）。下一个试图获取锁对象的线程将会面临这个情况，使用原子CAS指令可将该锁对象绑定于当前线程。**在批量重偏向的操作中，未被持有的锁对象都被置于这个状态，以便允许被快速重偏向。**
            * **<font color = "clime">已偏向(Biased)</font>** 。这种状态下，thread pointer非空，且epoch为有效值——意味着其他线程正在持有这个锁对象。
        2. 偏向锁获取： 
            1. 判断是偏向锁时，检查对象头Mark Word中记录的`Thread Id`是否是当前线程ID。  
            2. 如果对象头Mark Word中Thread Id不是当前线程ID，则`进行CAS操作，企图将当前线程ID替换进Mark Word`。如果当前对象锁状态处于匿名偏向锁状态（可偏向未锁定），则会替换成功（ **<font color = "clime">将Mark Word中的Thread id由匿名0改成当前线程ID，</font>** 在当前线程栈中找到内存地址最高的可用Lock Record，将线程ID存入）。  
            3. 如果对象锁已经被其他线程占用，则会替换失败，开始进行偏向锁撤销，这也是偏向锁的特点，一旦出现线程竞争，就会撤销偏向锁； 
        3. 偏向锁撤销： 
            1. 等到安全点，检查持有偏向锁的`线程是否还存活`。如果线程还存活，则检查线程是否在执行同步代码块中的代码，如果是，则升级为轻量级锁，进行CAS竞争锁； 
            2. `如果持有偏向锁的线程未存活，或者持有偏向锁的线程未在执行同步代码块中的代码`， **<font color = "red">则进行校验`是否允许重偏向`。</font>**   
                1. **<font color = "clime">如果不允许重偏向，则撤销偏向锁，将Mark Word设置为无锁状态（未锁定不可偏向状态），然后升级为轻量级锁，进行CAS竞争锁；</font><font color = "blue">(偏向锁被重置为无锁状态，这种策略是为了提高获得锁和释放锁的效率。)</font>**     
                2. 如果允许重偏向，设置为匿名偏向锁状态，CAS将偏向锁重新指向线程A（在对象头和线程栈帧的锁记录中存储当前线程ID）； 
            3. 唤醒暂停的线程，从安全点继续执行代码。 
	2. 轻量级锁：
		1. 偏向锁升级为轻量级锁之后，对象的Markword也会进行相应的的变化。   
            1. 线程在自己的栈桢中创建锁记录LockRecord。
            2. 将锁对象的对象头中的MarkWord复制到线程刚刚创建的锁记录中。
            3. 将锁记录中的Owner指针指向锁对象。
            4. 将锁对象的对象头的MarkWord替换为指向锁记录的指针。
		2. 自旋锁：轻量级锁在加锁过程中，用到了自旋锁。自旋锁分为固定次数自旋锁（在JDK 1.6之前，自旋次数默认是10次）和自适应自旋锁。
		3. 新线程获取轻量级锁
			1. 获取轻量锁过程当中会在当前线程的虚拟机栈中创建一个Lock Record的内存区域去存储获取锁的记录DisplacedMarkWord。
			2. 然后使用CAS操作将锁对象的Mark Word更新成指向刚刚创建的Lock Record的内存区域DisplacedMarkWord的地址。  
		4. 已经获取轻量级锁的线程的解锁： **<font color = "red">轻量级锁的锁释放逻辑其实就是获得锁的逆向逻辑，通过CAS操作把线程栈帧中的LockRecord替换回到锁对象的MarkWord中。</font>** 
    3. 重量级锁  
    &emsp; **<font color = "clime">为什么有了自旋锁还需要重量级锁？</font>**  
    &emsp; 自旋是消耗CPU资源的，如果锁的时间长，或者自旋线程多，CPU会被大量消耗；重量级锁有等待队列，所有拿不到锁的线程进入等待队列，不需要消耗CPU资源。  
    &emsp; 偏向锁、自旋锁都是用户空间完成。重量级锁是需要向内核申请。  

##### 1.4.2.2.4. Volatile
1. **<font color = "clime">Volatile的特性：</font>**  
    1. 不支持原子性。<font color = "red">它只对Volatile变量的单次读/写具有原子性；</font><font color = "clime">但是对于类似i++这样的复合操作不能保证原子性。</font>    
    2. 实现了可见性。 **Volatile提供happens-before的保证，使变量在多个线程间可见。**  
    3. <font color = "red">实现了有序性，禁止进行指令重排序。</font>  
2. `查看Volatile的汇编代码。`Volatile底层原理：  
    * **<font color = "clime">在Volatile写前插入写-写[屏障](/docs/java/concurrent/ConcurrencySolve.md)（禁止上面的普通写与下面的Volatile写重排序），在Volatile写后插入写-读屏障（禁止上面的Volatile写与下面可能有的Volatile读/写重排序）。</font>**  
    * **<font color = "clime">在Volatile读后插入读-读屏障（禁止下面的普通读操作与上面的Volatile读重排序）、读-写屏障（禁止下面所有的普通写操作和上面Volatile读重排序）。</font>**  
3. Volatile为什么不安全（不保证原子性，线程切换）？  
&emsp; 两个线程执行i++（i++的过程可以分为三步，首先获取i的值，其次对i的值进行加1，最后将得到的新值写回到缓存中），线程1获取i值后被挂起，线程2执行...  
4. volatile使用场景：  
    &emsp; 关键字Volatile用于多线程环境下的单次操作（单次读或者单次写）。即Volatile主要使用的场合是在多个线程中可以感知实例变量被更改了，并且可以获得最新的值使用，也就是用多线程读取共享变量时可以获得最新值使用。  
    1. 全局状态标志。
    2. DCL详解：  
        1. 为什么两次判断？ 线程1调用第一个if(singleton==null)，可能会被挂起。  
        2. 为什么要加volatile关键字？  
        &emsp; singleton = new Singleton()非原子性操作，包含3个步骤：分配内存 ---> 初始化对象 ---> 将singleton对象指向分配的内存空间(这步一旦执行了，那singleton对象就不等于null了)。  
        &emsp; **<font color = "clime">因为指令重排序，可能编程1->3->2。如果是这种顺序，会导致别的线程拿到半成品的实例。</font>**  


##### 1.4.2.2.5. ThreadLocal
&emsp; ThreadLocal的作用是每一个线程创建一个副本。  

1. 在进行对象跨层次传递的时候，使用ThreadLocal可以避免多次传递，打破层次间的束缚。   
2. 线程间层次隔离。  
3. 进行事务操作，用于存储线程事务信息。  
4. 数据库连接，Session会话管理。  

###### 1.4.2.2.5.1. ThreadLocal原理
1. ThreadLocal源码/内存模型：  
    1. **<font color = "red">ThreadLocal#set()#getMap()方法：线程调用threadLocal对象的set(Object value)方法时，数据并不是存储在ThreadLocal对象中，</font><font color = "clime">而是将值存储在每个Thread实例的threadLocals属性中。</font>** 即，当前线程调用ThreadLocal类的set或get方法时，实际上调用的是ThreadLocalMap类对应的 get()、set()方法。  
    &emsp; ~~Thread ---> ThreadLocal.ThreadLocalMap~~
    2. **<font color = "clime">ThreadLocal.ThreadLocalMap，</font>Map结构中Entry继承WeakReference，所以Entry对应key的引用(ThreadLocal实例)是一个弱引用，Entry对Value的引用是强引用。<font color = "clime">`Key是一个ThreadLocal实例，Value是设置的值。`Entry的作用即是：为其属主线程建立起一个ThreadLocal实例与一个线程持有对象之间的对应关系。</font>**   
2. ThreadLocal是如何实现线程隔离的？   
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-85.png)  
    &emsp; ThreadLocal之所以能达到变量的线程隔离，其实就是每个线程都有一个自己的ThreadLocalMap对象来存储同一个threadLocal实例set的值，而取值的时候也是根据同一个threadLocal实例去自己的ThreadLocalMap里面找，自然就互不影响了，从而达到线程隔离的目的！  
3. **ThreadLocal内存泄露：**  
    &emsp; ThreadLocalMap使用ThreadLocal的弱引用作为key，<font color = "red">如果一个ThreadLocal不存在外部强引用时，Key(ThreadLocal实例)会被GC回收，这样就会导致ThreadLocalMap中key为null，而value还存在着强引用，只有thead线程退出以后，value的强引用链条才会断掉。</font>  
    &emsp; **<font color = "clime">但如果当前线程迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：Thread Ref -> Thread -> ThreaLocalMap -> Entry -> value。永远无法回收，造成内存泄漏。</font>**  
    &emsp; 解决方案：`调用remove()方法`
4. **ThreadLocalMap的key被回收后，如何获取值？**  
    &emsp; ThreadLocal#get() ---> setInitialValue() ---> ThreadLocalMap.set(this, value); 。  
    &emsp; 通过nextIndex()不断获取table上的槽位，直到遇到第一个为null的地方，此处也将是存放具体entry的位置，在线性探测法的不断冲突中，如果遇到非空entry中的key为null，可以表明key的弱引用已经被回收，但是由于线程仍未结束生命周期被回收，而导致该entry仍未从table中被回收，那么则会在这里尝试通过replaceStaleEntry()方法，将null key的entry回收掉并set相应的值。  

###### 1.4.2.2.5.2. ThreadLocal应用
1. ThreadLocal使用场景：  
    1. 线程安全问题。
    2. 业务中变量传递。1)ThreadLocal实现同一线程下多个类之间的数据传递；2)ThreadLocal实现线程内的缓存，避免重复调用。
    3. ThreadLocal+MDC实现链路日志增强。
    4. ThreadLocal 实现数据库读写分离下强制读主库。
2. ~~ThreadLocal三大坑~~
    1. 内存泄露
    2. ThreadLocal无法在`父子线程（new Thread()）`之间传递。使用类InheritableThreadLocal可以在子线程中取得父线程继承下来的值。   
    3. 线程池中线程上下文丢失。TransmittableThreadLocal是阿里巴巴开源的专门解决InheritableThreadLocal的局限性，实现线程本地变量在线程池的执行过程中，能正常的访问父线程设置的线程变量。  
    4. 并行流中线程上下文丢失。问题同线程池中线程上下文丢失。  
3. ThreadLocal优化：FastThreadLocal

#### 1.4.2.3. 线程通信(生产者消费者问题)

#### 1.4.2.4. 线程活跃性


### 1.4.3. 线程池
#### 1.4.3.1. 线程池框架
1. **线程池通过线程复用机制，并对线程进行统一管理，** 具有以下优点：  
    * 降低系统资源消耗。通过复用已存在的线程，降低线程创建和销毁造成的消耗；  
    * 提高响应速度。当有任务到达时，无需等待新线程的创建便能立即执行；  
    * 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗大量系统资源，还会降低系统的稳定性，使用线程池可以进行对线程进行统一的分配、调优和监控。  
2. 线程池框架Executor：  
&emsp; Executor：所有线程池的接口。  
&emsp; ExecutorService：扩展了Executor接口。添加了一些用来管理执行器生命周期和任务生命周期的方法。  
&emsp; ThreadPoolExecutor（创建线程池方式一）：线程池的具体实现类。  
&emsp; Executors（创建线程池方式二）：提供了一系列静态的工厂方法用于创建线程池，返回的线程池都实现了ExecutorService 接口。  
3. 根据返回的对象类型，创建线程池可以分为几类：ThreadPoolExecutor、ScheduleThreadPoolExecutor（任务调度线程池）、ForkJoinPool。  
4. **<font color = "clime">Executors返回线程池对象的弊端如下：</font>**  
	* SingleThreadExecutor（单线程）和FixedThreadPool（定长线程池，可控制线程最大并发数）：允许请求的队列长度为Integer.MAX_VALUE，可能堆积大量的请求，从而导致OOM。
	* CachedThreadPool和ScheduledThreadPool：允许创建的线程数量为Integer.MAX_VALUE，可能会创建大量线程，从而导致OOM。
5. 线程池执行，ExecutorService的API：execute()，提交不需要返回值的任务；`submit()，提交需要返回值的任务，返回值类型是Future`。    

#### 1.4.3.2. ThreadPoolExecutor详解
1. 理解构造函数中参数：核心线程数大小、最大线程数大小、空闲线程（超出corePoolSize的线程）的生存时间、参数keepAliveTime的单位、任务阻塞队列、创建线程的工厂（可以通过这个工厂来创建有业务意义的线程名字）。  
    * [阻塞队列](/docs/java/concurrent/BlockingQueue.md)，线程池所使用的缓冲队列，常用的是：SynchronousQueue、ArrayBlockingQueue、LinkedBlockingQueue。   
    * 拒绝策略，默认AbortPolicy（拒绝任务，抛异常）， **<font color = "clime">可以选用CallerRunsPolicy（任务队列满时，不进入线程池，由主线程执行）。</font>**  
2. 线程池中核心方法调用链路：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/threadPool-17.png)  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/threadPool-14.png)  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/threadPool-20.png)  
2. 线程运行流程：查看execute方法。  
    &emsp; <font color = "clime">线程池创建时`没有设置成预启动加载`，首发线程数为0。</font><font color = "red">任务队列是作为参数传进来的。即使队列里面有任务，线程池也不会马上执行它们，而是创建线程。</font>当一个线程完成任务时，它会从队列中取下一个任务来执行。当调用execute()方法添加一个任务时，线程池会做如下判断：  
    1. 如果当前工作线程总数小于corePoolSize，则直接创建核心线程执行任务（任务实例会传入直接用于构造工作线程实例）。  
    2. 如果当前工作线程总数大于等于corePoolSize，判断线程池是否处于运行中状态，同时尝试用非阻塞方法向任务队列放入任务，这里会二次检查线程池运行状态，如果当前工作线程数量为0，则创建一个非核心线程并且传入的任务对象为null。  
    3. 如果向任务队列投放任务失败（任务队列已经满了），则会尝试创建非核心线程传入任务实例执行。  
    4. 如果创建非核心线程失败，此时需要拒绝执行任务，调用拒绝策略处理任务。  
3. 线程复用机制：    
&emsp; **线程池将线程和任务进行解耦，线程是线程，任务是任务，摆脱了之前通过Thread创建线程时的一个线程必须对应一个任务的限制。**  
&emsp; **<font color = "red">在线程池中，同一个线程可以从阻塞队列中不断获取新任务来执行，其核心原理在于线程池对Thread进行了封装（内部类Worker），并不是每次执行任务都会调用Thread.start() 来创建新线程，而是让每个线程去执行一个“循环任务”，在这个“循环任务”中不停的检查是否有任务需要被执行。</font>** 如果有则直接执行，也就是调用任务中的run方法，将run方法当成一个普通的方法执行，通过这种方式将只使用固定的线程就将所有任务的run方法串联起来。  
&emsp; 源码解析：`runWorker()方法中，有任务时，while (task != null || (task = getTask()) != null) 循环获取；没有任务时，清除空闲线程。`  
4. 线程池保证核心线程不被销毁？  
    &emsp; `ThreadPoolExecutor回收线程都是等while死循环里getTask()获取不到任务，返回null时，调用processWorkerExit方法从Set集合中remove掉线程。`  
    1. getTask()返回null又分为2两种场景：  
        1. 线程正常执行完任务，`并且已经等到超过keepAliveTime时间，大于核心线程数，那么会返回null`，结束外层的runWorker中的while循环。
        2. 当调用shutdown()方法，会将线程池状态置为shutdown，并且需要等待正在执行的任务执行完，阻塞队列中的任务执行完才能返回null。
    2. `getTask()不返回null的情况有获取到任务，或获取不到任务，但线程数小于等于核心线程数。`  

#### 1.4.3.3. 线程池的正确使用
1. **<font color = "clime">线程池设置：</font>**   
    1. `使用自定义的线程池。`共享的问题在于会干扰，如果有一些异步操作的平均耗时是1秒，另外一些是100秒，这些操作放在一起共享一个线程池很可能会出现相互影响甚至饿死的问题。`建议根据异步业务类型，合理设置隔离的线程池。`  
    2. `确定线程池的大小（CPU可同时处理线程数量大部分是CPU核数的两倍）`  
        1. 线程数设置，`建议核心线程数core与最大线程数max一致`
            * 如果是CPU密集型应用（多线程处理复杂算法），则线程池大小设置为N+1。
            * 如果是IO密集型应用（多线程用于数据库数据交互、文件上传下载、网络数据传输等），则线程池大小设置为2N。
            * 如果是混合型，将任务分为CPU密集型和IO密集型，然后分别使用不同的线程池去处理，从而使每个线程池可以根据各自的工作负载来调整。  
        2. 阻塞队列设置  
        &emsp; `线程池的任务队列本来起缓冲作用，`但是如果设置的不合理会导致线程池无法扩容至max，这样无法发挥多线程的能力，导致一些服务响应变慢。队列长度要看具体使用场景，取决服务端处理能力以及客户端能容忍的超时时间等。队列长度要根据使用场景设置一个上限值，如果响应时间要求较高的系统可以设置为0。  
        &emsp; `队列大小200或500-1000。`  
    3. `线程池的优雅关闭：`处于SHUTDOWN的状态下的线程池依旧可以调用shutdownNow。所以可以结合shutdown，shutdownNow，awaitTermination，更加优雅关闭线程池。  
2. **<font color = "clime">线程池使用：</font>**    
    1. `线程池未处理异常：`
        1. 线程遇到未处理的异常就结束了。ThreadPoolExecutor中将异常传递给afterExecute()方法，而afterExecute()没有做任何处理。这种处理方式能够保证提交的任务抛出了异常不会影响其他任务的执行，同时也不会对用来执行该任务的线程产生任何影响。然而afterExecute()没有做任何处理，所以如果任务抛出了异常，也无法立刻感知到。即使感知到了，也无法查看异常信息。    
        2. `当线程池中线程频繁出现未捕获的异常，那线程的复用率就大大降低了，需要不断地创建新线程。`  
    2. `线程池中线程中异常尽量手动捕获。`  
3. **<font color = "clime">线程池的监控：</font>**  
&emsp; 通过重写线程池的beforeExecute、afterExecute和shutdown等方式就可以实现对线程的监控。  
4. @Async方法没有执行的问题分析：  
&emsp; @Async异步方法默认使用Spring创建ThreadPoolTaskExecutor(参考TaskExecutionAutoConfiguration)，其中默认核心线程数为8，默认最大队列和默认最大线程数都是Integer.MAX_VALUE，队列使用LinkedBlockingQueue，容量是：Integet.MAX_VALUE，空闲线程保留时间：60s，线程池拒绝策略：AbortPolicy。创建新线程的条件是队列填满时，而这样的配置队列永远不会填满，如果有@Async注解标注的方法长期占用线程(比如HTTP长连接等待获取结果)，在核心8个线程数占用满了之后，新的调用就会进入队列，外部表现为没有执行。  


#### 1.4.3.4. ForkJoinPool详解
1. <font color = "clime">ForkJoinPool的两大核心是 分而治之和工作窃取 算法。</font>  
2. 分而治之：<font color = "red">ForkJoinPool的计算方式是大任务拆中任务，中任务拆小任务，最后再汇总。</font>  
3. 工作窃取算法  
&emsp; <font color = "clime">每个工作线程都有自己的工作队列WorkQueue。这是一个双端队列，它是线程私有的。</font>双端队列的操作：push、pop、poll。push/pop只能被队列的所有者线程调用，而poll是由其它线程窃取任务时调用的。  
    1. ForkJoinTask中fork的子任务，将放入运行该任务的工作线程的队头，工作线程将以LIFO的顺序来处理工作队列中的任务；  
    2. **<font color = "clime">`为了最大化地利用CPU，空闲的线程将随机从其它线程的队列中“窃取”任务来执行。从工作队列的尾部窃取任务，以减少竞争；`</font>**  
    3. **<font color = "clime">`当只剩下最后一个任务时，还是会存在竞争，是通过CAS来实现的；`</font>**    


#### 1.4.3.5. Future相关
1. **Future是一个接口，它可以对具体的Runnable或者Callable任务进行取消、判断任务是否已取消、查询任务是否完成、获取任务结果。**  
2. JDK1.5为Future接口提供了一个实现类FutureTask，表示一个可以取消的异步运算。它有启动和取消运算、查询运算是否完成和取回运算结果等方法。  


#### 1.4.3.6. ~~CompletionService~~
&emsp; CompletionService 提供了异步任务的执行与结果的封装，轻松实现多线程任务， **<font color = "clime">并方便的集中处理上述任务的结果(且任务最先完成的先返回)。</font>**  
&emsp; 内部通过阻塞队列+FutureTask，实现了任务先完成可优先获取到，即结果按照完成先后顺序排序。  

#### 1.4.3.7. ~~CompletableFuture~~
&emsp; CompletableFuture 可以很方便的实现异步任务的封装 **<font color = "clime">并实现结果的联合等一系列操作，</font>** 轻松实现 任务的并行。  

* thenCombine：结合两个CompletionStage的结果，进行转化后返回。  
* applyToEither：两个CompletionStage，谁计算的快，就用那个CompletionStage的结果进行下一步的处理。  
* ...

### 1.4.4. JUC
#### 1.4.4.1. CAS
1. **<font color = "clime">CAS，Compare And Swap，即比较并交换。一种无锁原子算法，CAS是一种乐观锁。</font>**  
2. CAS函数  
&emsp; **<font color = "clime">在函数CAS(V,E,N)中有3个参数：从内存中读取的值E，计算的结果值V，内存中的当前值N（可能已经被其他线程改变）。</font>**  
&emsp; **<font color = "clime">函数流程：</font>** 1. 读取当前值E；2. 计算结果值V；<font color = "clime">3. 将读取的当前值E和当前新值N作比较，如果相等，更新为V；</font>4. 如果不相等，再次读取当前值E计算结果V，将E再和新的当前值N比较，直到相等。 
3. **`CAS缺点：`**  
    * 循环时间长开销大。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。  
    * **<font color = "red">只能保证一个共享变量的原子操作。</font> <font color = "clime">从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。</font>**  
    * ABA问题。  
4. ABA问题详解
    1. 什么是ABA问题？  
    &emsp; ABA示例：  
    &emsp; 1).在多线程的环境中，线程a从共享的地址X中读取到了对象A。  
    &emsp; 2).在线程a准备对地址X进行更新之前， **<font color = "clime">线程a挂起</font>** 。线程b将地址X中的值修改为了B。  
    &emsp; 3).接着线程b或者线程c将地址X中的值又修改回了A。  
    &emsp; 4).线程a恢复，接着对地址X执行CAS，发现X中存储的还是对象A，对象匹配，CAS成功。  
    2. ABA问题需不需要解决？   
    &emsp; ~~如果依赖中间变化的状态，需要解决。如果不是依赖中间变化的状态，对业务结果无影响。~~  
    3. 解决ABA问题  
    &emsp; **<font color = "red">ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A。</font>**   
    &emsp; **<font color = "clime">从Java1.5开始JDK的atomic包里提供了[AtomicStampedReference](/docs/java/concurrent/6.AtomicStampedReference.md)和AtomicMarkableReference类来解决ABA问题。</font>**  

#### 1.4.4.2. AQS
1. 属性
    1. 同步状态，通过state控制同步状态。  
    2. 同步队列，`双向链表`，每个节点代表一个线程，节点有5个状态。
        * 入列addWaiter()：未获取到锁的线程会创建节点，`线程安全（CAS算法设置尾节点+死循环自旋）`的加入队列尾部。  
        * 出列unparkSuccessor()：首节点的线程释放同步状态后，`将会唤醒(LockSupport.unpark)它的后继节点(next)`，而后继节点将会在获取同步状态成功时将自己设置为首节点。
        * 入列或出列都会使用到[LockSupport](/docs/java/concurrent/LockSupport.md)工具类来阻塞、唤醒线程。    
2. 方法
    1. 独占模式：  
        * **<font color = "blue">获取同步状态</font>**   
            1. 调用使用者重写的tryAcquire方法， **<font color = "blue">tryAcquire()尝试直接去获取资源，</font>** 如果成功则直接返回；
            2. tryAcquire()获取资源失败，则调用addWaiter()将该线程加入等待队列的尾部，并标记为独占模式；
            3. acquireQueued()使线程阻塞在等待队列中获取资源，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。
            4. 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。
        * 释放同步状态  
    2. 共享模式下，获取同步状态、释放同步状态。  

##### 1.4.4.2.1. LockSupport类
&emsp; LockSupport是一个线程阻塞工具类，所有的方法都是静态方法，可以让线程在任意位置阻塞，当然阻塞之后肯定得有唤醒的方法。  
&emsp; LockSupport主要有两类方法：park和unpark。 

#### 1.4.4.3. LOCK
##### 1.4.4.3.1. ReentrantLock，重入锁
1. ReentrantLock与synchronized比较
    1. （支持非公平）ReenTrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。所谓的公平锁就是先等待的线程先获得锁。  
    2. Lock接口可以尝试非阻塞地获取锁，当前线程尝试获取锁。如果这一时刻锁没有被其他线程获取到，则成功获取并持有锁。  
    3. （可被中断）Lock接口能被中断地获取锁，与synchronized不同，获取到锁的线程能够响应中断，当获取到的锁的线程被中断时，中断异常将会被抛出，同时锁会被释放。可以使线程在等待锁的时候响应中断；  
    4. （支持超时/限时等待）Lock接口可以在指定的截止时间之前获取锁，如果截止时间到了依旧无法获取锁，则返回。可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间；  
    5. （可实现选择性通知，锁可以绑定多个条件）ReenTrantLock提供了一个Condition(条件)类，用来实现分组唤醒需要唤醒的一些线程，而不是像synchronized要么随机唤醒一个线程要么唤醒全部线程。  
2. **<font color = "red">lock()方法描述：</font>**  
    1. 在初始化ReentrantLock的时候，如果不传参数是否公平，那么默认使用非公平锁，也就是NonfairSync。  
    2. 1). <font color = "clime">调用ReentrantLock的lock方法的时候，实际上是调用了NonfairSync的lock方法，这个方法①先用CAS操作`compareAndSetState(0, 1)`，去尝试抢占该锁。如果成功，就把当前线程设置在这个锁上，表示抢占成功。</font>         
    &emsp; `“非公平”体现在，如果占用锁的线程刚释放锁，state置为0，而排队等待锁的线程还未唤醒时，新来的线程就直接抢占了该锁，那么就“插队”了。`   
    2). ②如果失败，则`调用acquire()模板方法`，等待抢占。   
    3. `AQS的acquire模板方法：`  
        1. AQS#acquire()调用子类NonfairSync#tryAcquire()#nonfairTryAcquire()。 **<font color = "blue">如果锁状态是0，再次CAS抢占锁。</font>** 如果锁状态不是0，判断是否当前线程。    
        2. acquireQueued(addWaiter(Node.EXCLUSIVE), arg) )，其中addWaiter(Node.EXCLUSIVE)入等待队列。  
        3. acquireQueued(final Node node, int arg)，使线程阻塞在等待队列中获取资源，一直获取到资源后才返回。如果在整个等待过程中被中断过，则返回true，否则返回false。
        4. 如果线程在等待过程中被中断过，它是不响应的。只是获取资源后才再进行自我中断selfInterrupt()，将中断补上。  

    &emsp; 用一张流程图总结一下非公平锁的获取锁的过程。  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-75.png)  

###### 1.4.4.3.1.1. 读写锁
1. ReentrantReadWriteLock  
    1. 读写锁ReentrantReadWriteLock：读读共享，`读写互斥`，写写互斥。  
    2. **<font color = "red">ReentrantReadWriteLock缺点：`读写锁互斥`，只有当前没有线程持有读锁或者写锁时，才能获取到写锁，</font><font color = "clime">这`可能会导致写线程发生饥饿现象`，</font><font color = "red">即读线程太多导致写线程迟迟竞争不到锁而一直处于等待状态。StampedLock()可以解决这个问题。</font>**  
2. StampedLock  
    1. StampedLock有3种模式：写锁writeLock、悲观读锁readLock、乐观读锁tryOptimisticRead。  
    2. StampedLock通过乐观读锁tryOptimisticRead解决ReentrantReadWriteLock的写锁饥饿问题。乐观读锁模式下，一个线程获取的乐观读锁之后，不会阻塞其他线程获取写锁。    
    3. **<font color = "clime">同时允许多个乐观读和一个写线程同时进入临界资源操作，那读取的数据可能是错的怎么办？</font>**    
    &emsp; **<font color = "clime">通过版本号控制。</font>** 乐观读不能保证读取到的数据是最新的，所以将数据读取到局部变量的时候需要通过 lock.validate(stamp) 校验是否被写线程修改过，若是修改过则需要上悲观读锁，再重新读取数据到局部变量。`即乐观读失败后，再次使用悲观读锁。`    

#### 1.4.4.4. Atomic
##### 1.4.4.4.1. AtomicStampedReference与AtomicMarkableReference
1. AtomicStampedReference每次修改都会让stamp值加1，类似于版本控制号。 
2. **<font color = "clime">AtomicStampedReference可以知道引用变量中途被更改了几次。有时候，并不关心引用变量更改了几次，只是单纯的关心是否更改过，所以就有了AtomicMarkableReference。</font>**  

##### 1.4.4.4.2. LongAdder
1. LongAdder重要属性：有一个全局变量`volatile long base`值、父类Striped64中存在一个`volatile Cell[] cells;`数组，其长度是2的幂次方。  
2. LongAdder原理：  
    1. CAS操作：当并发不高的情况下都是通过CAS来直接操作base值，如果CAS失败，则针对LongAdder中的Cell[]数组中的Cell进行CAS操作，减少失败的概率。
    2. 解决伪共享：每个Cell都使用@Contended注解进行修饰，而@Contended注解可以进行缓存行填充，从而解决伪共享问题。  

#### 1.4.4.5. Collections
##### 1.4.4.5.1. CopyOnWriteArrayList
1. CopyOnWriteArrayList  
&emsp; CopyOnWrite，写时复制。`读操作时不加锁以保证性能不受影响。`  
&emsp; **<font color = "clime">`写操作时加锁，复制资源的一份副本，在副本上执行写操作，写操作完成后将资源的引用指向副本。`</font>** CopyOnWriteArrayList源码中，`基于ReentrantLock保证了增加元素和删除元素动作的互斥。`   
&emsp; **优点：** 可以对CopyOnWrite容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素。`所以CopyOnWrite容器也是一种读写分离的思想，读和写不同的容器。`  
&emsp; **<font color = "clime">缺点：** **1.占内存(写时复制，new两个对象)；2.不能保证数据实时一致性。</font>**  
&emsp; **使用场景：** <font color = "clime">CopyOnWrite并发容器用于读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景。</font>

##### 1.4.4.5.2. ConcurrentHashMap
1. ConcurrentHashMap，JDK1.8  
    &emsp; **<font color = "red">从jdk1.8开始，ConcurrentHashMap类取消了Segment分段锁，采用`Node + CAS + Synchronized`来保证并发安全。</font>**  
    &emsp; **<font color = "clime">jdk1.8中的ConcurrentHashMap中synchronized只锁定当前链表或红黑树的首节点，只要节点hash不冲突，就不会产生并发，相比JDK1.7的ConcurrentHashMap效率又提升了许多。</font>**  
    1. **<font color = "clime">put()流程：</font>**
        1. 根据 key 计算出 hashcode 。  
        2. 整个过程自旋添加节点。  
        2. 判断是否需要进行初始化数组。  
        3. <font color = "red">为当前key定位出Node，如果为空表示此数组下无节点，当前位置可以直接写入数据，利用CAS尝试写入，失败则进入下一次循环。</font>  
        4. **<font color = "blue">如果当前位置的hashcode == MOVED == -1，表示其他线程插入成功正在进行扩容，则当前线程`帮助进行扩容`。</font>**  
        5. <font color = "red">如果都不满足，则利用synchronized锁写入数据。</font>  
        6. 如果数量大于TREEIFY_THRESHOLD则要转换为红黑树。 
        7. 最后通过addCount来增加ConcurrentHashMap的长度，并且还可能触发扩容操作。  
    2. **<font color = "clime">get()流程：为什么ConcurrentHashMap的读操作不需要加锁？</font>**  
        1. 在1.8中ConcurrentHashMap的get操作全程不需要加锁，这也是它比其他并发集合（比如hashtable、用Collections.synchronizedMap()包装的hashmap）安全效率高的原因之一。  
        2. `get操作全程不需要加锁是因为Node的成员val是用volatile修饰的，`和数组用volatile修饰没有关系。  
        3. 数组用volatile修饰主要是保证在数组扩容的时候保证可见性。  
2. ConcurrentHashMap，JDK1.7  
    1. 在JDK1.7中，ConcurrentHashMap类采用了分段锁的思想，Segment(段) + HashEntry(哈希条目) + ReentrantLock。  
    2. Segment继承ReentrantLock(可重入锁)，从而实现并发控制。Segment的个数一旦初始化就不能改变，默认Segment的个数是16个，也可以认为ConcurrentHashMap默认支持最多16个线程并发。  

##### 1.4.4.5.3. BlockingQueue
1. 阻塞队列：当队列是空的时候，从队列中获取元素的操作将会被阻塞，或者当队列是满时，往队列里添加元素的操作会被阻塞。  
2. `线程池所使用的缓冲队列，常用的是：SynchronousQueue（无缓冲等待队列）、ArrayBlockingQueue（有界缓冲等待队列）、LinkedBlockingQueue（无界缓冲等待队列）。`   
3. SynchronousQueue，没有容量，是无缓冲等待队列，是一个不存储元素的阻塞队列，会直接将任务交给消费者，必须等队列中的元素被消费后才能继续添加新的元素。  
4. LinkedBlockingQueue不同于ArrayBlockingQueue，它如果不指定容量，默认为Integer.MAX_VALUE，也就是无界队列。所以为了避免队列过大造成机器负载或者内存爆满的情况出现，在使用的时候建议手动传一个队列的大小。  
5. <font color = "red">ArrayBlockingQueue与LinkedBlockingQueue：</font> ArrayBlockingQueue预先分配好一段连续内存，更稳定；LinkedBlockingQueue读写锁分离，吞吐量更大。  

#### 1.4.4.6. tools
##### 1.4.4.6.1. CountDownLatch
1.  **<font color = "red">java.util.concurrent.CountDownLatch类，`能够使一个线程等待其他线程完成各自的工作后再执行。`</font>** <font color = "red">利用它可以实现类似计数器的功能。</font><font color = "blue">比如有一个任务A，它要等待其他4个任务执行完毕之后才能执行，此时就可以利用CountDownLatch来实现这种功能了。</font>  
2. **<font color = "clime">countDown()方法是将count-1，如果发现count=0了，就唤醒</font><font color = "blue">阻塞的主线程。</font>**  
&emsp; ⚠️注：特别注意主线程会被阻塞。  
3. <font color = "red">CountDownLatch对象不能被重复利用，也就是不能修改计数器的值。</font>CountDownLatch是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当CountDownLatch使用完毕后，它不能再次被使用。    
4. <font color = "clime">CountDownLatch是由AQS实现的，创建CountDownLatch时设置计数器count其实就是设置AQS.state=count，也就是重入次数。  
    * await()方法调用获取锁的方法，由于AQS.state=count表示锁被占用且重入次数为count，所以获取不到锁线程被阻塞并进入AQS队列。  
    * countDown()方法调用释放锁的方法，每释放一次AQS.state减1，当AQS.state变为0时表示处于无锁状态了，就依次唤醒AQS队列中阻塞的线程来获取锁，继续执行逻辑代码。</font>  

##### 1.4.4.6.2. CyclicBarrier
&emsp; CyclicBarrier字面意思是回环栅栏， **<font color = "blue">允许一组线程互相等待，直到到达某个公共屏障点 (common barrier point)之后，再全部同时执行。</font>** 叫做回环是因为当所有等待线程都被释放以后，CyclicBarrier可以被重用。  

&emsp; **<font color = "clime">CyclicBarrier用途有两个：</font>**   

* 让一组线程等待至某个状态后再同时执行。
* 让一组线程等待至某个状态后，执行指定的任务。

##### 1.4.4.6.3. Semaphore
&emsp; Semaphore类，一个计数信号量。从概念上讲，信号量维护了一个许可集合。如有必要，在许可可用前会阻塞每一个acquire()，然后再获取该许可。每个 release()添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore只对可用许可的号码进行计数，并采取相应的行动。  
&emsp; 使用场景： **<font color = "red">Semaphore通常用于限制可以访问某些资源（物理或逻辑的）的线程数目。Semaphore可以用来构建一些对象池，资源池之类的，比如数据库连接池。</font>**   


## 1.5. 数据库
### 1.5.1. SQL语句  
#### 1.5.1.1. 基本查询语句
1. 基本查询SQL执行顺序：from -> on -> join -> where -> group by ->  avg,sum.... ->having -> select -> distinct -> order by -> top,limit。 
2. distinct关键字：Distinct与Count(聚合函数)，COUNT()会过滤掉为NULL的项。  
3. 分组函数  
&emsp; **<font color = "clime">查询结果集中有统计数据时，就需要使用分组函数。</font>**  
&emsp; **<font color = "red">Group By分组函数中，查询只能得到组相关的信息。组相关的信息(统计信息)：count,sum,max,min,avg。</font> 在select指定的字段要么包含在Group By语句的后面，作为分组的依据；要么被包含在聚合函数中。group by是对结果集分组，而不是查询字段分组。**  
&emsp; **<font color = "red">Group By含有去重效果。</font>**  
1. 普通Limit语句需要全表扫描。  
&emsp; 建立主键或唯一索引，利用索引：`SELECT * FROM 表名称 WHERE id_pk > (pageNum*10) LIMIT M`  
&emsp; 基于索引再排序：`SELECT * FROM 表名称 WHERE id_pk > (pageNum*10) ORDER BY id_pk ASC LIMIT M`
2. **<font color = "blue">ORDER BY与limit（分页再加排序）</font>**  
&emsp; ORDER BY排序后，用LIMIT取前几条，发现返回的结果集的顺序与预期的不一样。    
&emsp; 如果order by的列有相同的值时，MySQL会随机选取这些行，`为了保证每次都返回的顺序一致可以额外增加一个排序字段（比如：id），用两个字段来尽可能减少重复的概率。`  

#### 1.5.1.2. 连接查询
1. **关键字in：**  
&emsp; **<font color = "clime">in查询里面的数量最大只能1000。</font>**  
&emsp; **<font color = "red">确定给定的值是否与子查询或列表中的值相匹配。in在查询的时候，首先查询子查询的表，然后将内表和外表做一个笛卡尔积，然后按照条件进行筛选。所以</font><font color = "clime">相对内表比较小的时候，in的速度较快。</font>**  
2. exists指定一个子查询，检测行的存在。<font color = "clime">遍历循环外表，然后看外表中的记录有没有和内表的数据一样的。匹配上就将结果放入结果集中。</font><font color = "red">exists内层查询语句不返回查询的记录，而是返回一个真假值。</font>  
&emsp; **<font color = "clime">in和exists的区别：</font><font color = "red">如果子查询得出的结果集记录较少，主查询中的表较大且又有索引时应该用in，反之如果外层的主查询记录较少，子查询中的表大，又有索引时使用exists。</font>**  
3. **UNION与UNION ALL：** 默认地，UNION 操作符选取不同的值。如果允许重复的值，请使用UNION ALL。  

#### 1.5.1.3. ~~高级查询~~


### 1.5.2. MySql函数
&emsp; **<font color = "red">控制流程函数、字符串函数、数学函数、日期时间函数、聚合函数</font>**  

### 1.5.3. MySql优化
&emsp; <font color = "red">MySql性能由综合因素决定，抛开业务复杂度，影响程度依次是硬件配置、MySQL配置、数据表设计、索引优化。</font>  
1. SQL语句的优化。  
    &emsp; `对查询语句的监控、分析、优化是SQL优化的一般步骤。`常规调优思路：  
    1. 查看慢查询日志slowlog，分析slowlog，分析出查询慢的语句。  
    2. 按照一定优先级，进行一个一个的排查所有慢语句。  
    3. 分析top sql，进行explain调试，查看语句执行时间。  
    4. 调整[索引](/docs/SQL/7.index.md)或语句本身。 
2. 表结构设计： **<font color = "red">单库单表无法满足时，可以拆分表结构（主从复制、分库分表），或者使用ES搜索引擎。</font>**  
3. 服务器的优化。  

#### 1.5.3.1. SQL分析
1. **<font color = "clime">SQL分析语句有EXPLAIN与explain extended、show warnings、proceduer analyse、profiling、trace。</font>**  
2. <font color = "red">用explain extended查看执行计划会比explain多一列filtered。filtered列给出了一个百分比的值，这个百分比值和rows列的值一起使用，可以估计出那些将要和explain中的前一个表进行连接的行的数目。前一个表就是指explain的id列的值比当前表的id小的表。</font>  
&emsp; mysql中有一个explain 命令可以用来分析select 语句的运行效果，例如explain可以获得select语句使用的索引情况、排序的情况等等。除此以外，explain 的extended 扩展能够在原本explain的基础上额外的提供一些查询优化的信息，这些信息可以通过mysql的show warnings命令得到。  
3. profiling  
&emsp; 使用profiling命令可以了解SQL语句消耗资源的详细信息（每个执行步骤的开销）。可以清楚了解到SQL到底慢在哪个环节。   
4. trace  
&emsp; 查看优化器如何选择执行计划，获取每个可能的索引选择的代价。  

##### 1.5.3.1.1. Expain
&emsp; expain信息列分别是id、select_type、table、partitions、`type`、possible_keys、`key`、`key_len`、ref、`rows`、filtered、 `Extra`。  
* **<font color = "clime">`type，单表的访问方法。`单表查询类型要达到range级别（只检索给定范围的行，使用一个索引来选择行，非全表扫描）。</font>**  
* key_len表示使用的索引长度，key_len可以衡量索引的好坏，key_len越小 索引效果越好。 **<font color = "blue">可以根据key_len来判断联合索引是否生效。</font>**  
* **<font color = "red">extra：额外的信息，该列包含MySQL解决查询的详细信息。注意，常见的不太友好的值，如Using filesort（额外排序）、Using temporary（使用了临时表），意思MYSQL根本不能使用索引，常出现在使用order by。</font>**  

#### 1.5.3.2. SQL优化
1. 基本查询优化：  
2. 子查询优化：
2. 关联查询优化：使用索引、 **<font color = "bllue">驱动表选择、`条件谓词下推`</font>** ......  
&emsp; 谓词下推，就是在将过滤条件下推到离数据源更近的地方，最好就是在table_scan时就能过滤掉不需要的数据。  

#### 1.5.3.3. 索引优化
1. 创建索引：为了使索引的使用效率更高，在创建索引时，需要考虑在哪些字段上创建索引和创建什么类型的索引。  
    * 多表连接的字段、where条件字段、分组字段、排序字段、联合UNION字段、去重distinct字段上建立索引。  
    * 尽量选择区分度高的列作为索引。  
    * ...  
2. 索引失效：进行null值运算、进行运算、隐式转换、对索引列使用函数 导致索引失效，进行模糊查询like时可能使索引失效(以%开头)，不满足联合索引最左前缀匹配原则。   
3. 索引条件下推：  
&emsp; 索引下推简而言之就是在复合索引由于某些条件（比如 like %aa）失效的情况下，当存在失效的过滤字段在索引覆盖范围内，使用比较的方式在不回表的情况下进一步缩小查询的范围。其实就是对索引失效的进一步修复。  
&emsp; **<font color = "clime">~~MySQL 5.6 引入了「索引下推优化」，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。~~</font>**  
    * 关闭ICP：索引 ---> 回表 ---> 条件过滤。  
    * 开启ICP：索引 ---> 条件过滤 ---> 回表。</font>在支持ICP后，`MySQL在取出索引数据的同时，判断是否可以进行where条件过滤，`<font color = "blue">将where的部分过滤操作放在存储引擎层提前过滤掉不必要的数据，</font>减少了不必要数据被扫描带来的IO开销。  

#### 1.5.3.4. 碎片优化


### 1.5.4. 数据库分布式
#### 1.5.4.1. 大数据量操作

#### 1.5.4.2. MySql瓶颈
1. MySql性能
	* 最大并发数：并发数是指同一时刻数据库能处理多少个请求，由max_connections和max_user_connections决定。max_connections是指MySQL实例的最大连接数，上限值是16384，max_user_connections是指每个数据库用户的最大连接数。  
	* 查询耗时0.5秒，0.5秒是个经验值。  
	* 最大数据量：《阿里巴巴Java开发手册》提出单表行数超过500万行或者单表容量超过2GB，才推荐分库分表。  
2. 数据库瓶颈  
	&emsp; <font color = "clime">`不管是IO瓶颈，还是CPU瓶颈，最终都会导致数据库的活跃连接数增加，进而逼近甚至达到数据库可承载活跃连接数的阈值。在业务Service来看就是，可用数据库连接少甚至无连接可用。`</font>   
	1. IO瓶颈：  
	&emsp; 第一种：磁盘读IO瓶颈，热点数据太多，数据库缓存放不下，每次查询时会产生大量的IO，降低查询速度。 解决方案：分库和垂直分表。  
	&emsp; 第二种：网络IO瓶颈，请求的数据太多（MySql一般并发数200～5000），网络带宽不够。 解决方案：分库。  
	2. CPU瓶颈：  
	&emsp; 第一种：SQL问题，如SQL中包含join，group by，order by，非索引字段条件查询等，增加CPU运算的操作。 解决方案：SQL优化，建立合适的索引，在业务Service层进行业务计算。  
	&emsp; 第二种：单表数据量太大（达到1000W或100G以后），查询时扫描的行太多，SQL效率低，CPU率先出现瓶颈。 解决方案：水平分表。  

#### 1.5.4.3. 数据库分布式
&emsp; **数据库拆分过程基本遵循的顺序是：1).垂直拆分(业务拆分) ---> 2).读写分离 ---> 3).分库分表(水平拆分)。每个拆分过程都能解决业务上的一些问题，但同时也面临了一些挑战。**  
1.  **分表和分区的区别：**  
    1. 实现方式上：
        * mysql的分表是真正的分表，一张表分成很多表后，每一个小表都是完整的一张表，都对应三个文件，一个.MYD数据文件，.MYI索引文件，.frm表结构文件。  
        * 分区不一样，一张大表进行分区后，还是一张表，不会变成多张表，但是存放数据的区块变多了。  
    2. 数据处理上： 
        * 分表后，数据都是存放在分表里，总表只是一个外壳，存取数据发生在一个一个的分表里面。  
        * 分区不存在分表的概念，分区只不过把存放数据的文件分成了许多小块，分区后的表还是一张表。数据处理还是由自己来完成。  
2. **分表和分区的联系：**  
    1. 都能提高mysql的性能，在高并发状态下都有一个良好的表面。 
    2. **<font color = "clime">分表和分区不矛盾，可以相互配合。</font>**  
        * 对于那些大访问量，并且表数据比较多的表，可以`采取分表和分区结合的方式`（如果merge这种分表方式，不能和分区配合的话，可以用其他的分表试）。  
        * `访问量不大，但是表数据很多的表，可以采取分区的方式等。`  
3. **分库分表与读写分离：** `读写分离实现了数据库读能力的水平扩展，分库分表实现了写能力的水平扩展。`  
    1. 存储能力的水平扩展：在读写分离的情况下，每个集群中的master和slave基本上数据是完全一致的，从存储能力来说，存在海量数据的情况下，可能由于磁盘空间的限制，无法存储所有的数据。而在分库分表的情况下，可以搭建多个mysql主从复制集群，每个集群只存储部分分片的数据，实现存储能力的水平扩展。  
    2. 写能力的水平扩展：在读写分离的情况下，由于每个集群只有一个master，所有的写操作压力都集中在这一个节点上，在写入并发非常高的情况下，这里会成为整个系统的瓶颈。  

&emsp; ~~而在分库分表的情况下，每个分片所属的集群都有一个master节点，都可以执行写入操作，实现写能力的水平扩展。此外减小建立索引开销，降低写操作的锁操作耗时等，都会带来很多显然的好处。~~  

#### 1.5.4.4. 主从复制
##### 1.5.4.4.1. 主从复制原理  
1. 对于每一个主从复制的连接，都有三个线程。  
    * 拥有多个从库的主库为每一个连接到主库的从库创建一个binlog输出线程。  
    * 每一个从库都有它自己的I/O线程和SQL线程。  
        * `I/O线程与主库进行连接，请求主库的binlog。接收到binlog后，会存储到relay log中（中继日志）。`  
        * SQL线程会解析中继日志，并在从库上进行应用。  
2. 同步方式可以划分为：异步、半同步和同步。`在MySQL5.7中，带来了全新的多线程复制技术。`  
3. 复制类型有三种：基于行的复制、基于语句的复制、混合模式复制。  
    * 并非所有修改数据的语句都可以使用基于语句的复制进行复制。使用基于语句的复制时，任何非确定性行为都难以复制。  
    * 基于行的复制会产生大量的日志。  
    * MySQL5.1及其以后的版本推荐使用混合模式的复制，它是<font color = "clime">根据事件的类型实时的改变binlog的格式。当设置为混合模式时，默认为基于语句的格式，但在特定的情况下它会自动转变为基于行的模式。</font>  

##### 1.5.4.4.2. 主从复制实现


##### 1.5.4.4.3. 主从复制问题
1. 复制过程
	1. 大对象blog,text传输： **<font color = "clime">解决的办法就是在主从库上增加max_allowed_packet参数的大小。</font>**  
2. 错误
	1. 主从不一致后锁表 
	2. 跳过错误
	3. 数据损坏或丢失  
		1. 主库意外关闭  
		2. 备库意外关闭
		3. 主库二进制日志损坏
		4. 备库中继日志损坏
		5. 二进制日志与InnoDB事务日志不同步
	4. 未定义的服务器ID
3. 性能
	1. 如何查看主从延迟？  
	2. 产生延迟的两种方式：
		1. `突然产生延迟，然后再跟上。可以通过备库上的慢查询日志来进行优化。`在备库上开启log_slow_slave_statement选项，可以在慢查询日志中记录复制线程执行的语句。
		2. 稳定的延迟增大
	3. 并行复制  
4. <font color = "red">复制问题要分清楚是master的问题，还是slave的问题。master问题找二进制日志binlog，slave问题找中继日志relaylog。</font>  

##### 1.5.4.4.4. 高可用实现


##### 1.5.4.4.5. 读写分离实现
&emsp; 读写分离的实现，可以在应用层解决，也可以通过中间件实现。  
1. 应用层解决方案：  
    1. 驱动实现
        * com.mysql.jdbc.ReplicationDriver
        * Sharding-jdbc
    2. MyBatis plugin(sqlType: select,update,insert)  
    3. SpringAOP + mybatis plugin + 注解
    4. Spring动态数据源 + mybatis plugin
2. 常见代理中间件有MyCat...  

#### 1.5.4.5. 分区



#### 1.5.4.6. 分库分表
##### 1.5.4.6.1. 分库分表
1. 数据切分方式：  
    * 垂直分库，一般根据业务维度拆分，分布式项目中单项目单库。  
    * **<font color = "clime">`水平分库主要根据用户属性（如地市）拆分物理数据库。`一种常见的方式是将全省划分为多个大区。`可以复合分片字段拆分，即按照用户属性（如地市）拆分后，再按照时间拆分。`</font>**  
    * 垂直分表，基于列字段进行的。一般是表中的字段较多，将不常用的，数据较大，长度较长（比如text类型字段）的拆分到“扩展表”。  
    * ~~水平分表：针对数据量比较大的单张表。~~ **<font color = "red">MySql水平分表必须使用MyISAM引擎。</font>**  
2. 水平分库无论怎么分，只要能通过拆分字段和分片策略，找到具体的库就可以。  

##### 1.5.4.6.2. 分库分表查询
1. `非partition key的查询 / 分库分表多维度查询`  
	* 冗余法
	* 基因法  
    &emsp; 如果拆分成16张表，则需要截取二进制订单id的最后LOG(16,2)=4位，作为分库/分表基因，订单id的最后4位采用从用户id那边获取的4位基因。这样就满足按照订单号和用户（买家、卖家）id查询。   
	* 映射法
	* NoSQL法：ES、Hbase等。  
    
    <font color = "blue">B2B模式（有买家、卖家），订单表采用`冗余法（买家库和卖家库）和基因法`结合。</font>  
2. `跨分片的分组group by以及聚合count等函数`  
&emsp; 这些是一类问题，因为它们<font color = "red">都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作，部分支持聚合函数MAX、MIN、COUNT、SUM。</font>  
&emsp; **<font color = "red">解决方案：分别在各个节点上执行相应的函数处理得到结果后，在应用程序端进行合并。</font>** 每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。  
3. `跨分片的排序分页`  
&emsp; <font color = "red">一般来讲，分页时需要按照指定字段进行排序。`当排序字段是分片字段时，通过分片规则可以比较容易定位到指定的分片；`而当排序字段非分片字段时，情况就会变得比较复杂了。</font>为了最终结果的准确性，需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。  
4. `跨节点Join的问题`  
    tddl、MyCAT等都支持跨分片join。如果中间不支持，跨库Join的几种解决思路：  
	* `在程序中进行拼装。`  
	* 全局表
	* 字段冗余 
5. ~~**<font color = "blue">小结：分库分表分片键设计</font>**~~  
&emsp; ~~分库分表的分片键设计多数参考查询场景。因此分库分表时设计拆分字段考虑因素：1). 是否有必要按照地区、时间拆分表；2)参考B2B模式（有买家、卖家），订单表采用`冗余法（买家库和卖家库）和基因法`结合。~~  

##### 1.5.4.6.3. 跨分片的排序分页
&emsp; **<font color = "red">总结：</font>**  
&emsp; “跨库分页”的四种方案。  
1. 分库分表对分页的影响：  
	常见的分片策略有随机分片和连续分片这两种。  
2. 全局视野法
	1. 流程
		1. 如果要获取第N页的数据(每页S条数据)，则将每一个子库的前N页(offset 0,limit N*S)的所有数据都先查出来(有筛选条件或排序规则的话都包含)。  
		2. 然后将各个子库的结果合并起来之后，再做一次分页查询（可不用带上相同的筛选条件，但还要带上排序规则)即可得出最终结果，这种方式类似es分页的逻辑。
	2. 优点: 数据准确，可以跳页  
	3. 缺点： 
	（1）每个分库需要返回更多的数据，增大了网络传输量（耗网络）；  
	（2）服务层还需要进行二次排序，增大了服务层的计算量（耗CPU）；   	（3）最致命的，这个算法随着页码的增大，性能会急剧下降，这是因为SQL改写后每个分库要返回X+Y行数据：返回第3页，offset中的X=200；假如要返回第100页，offset中的X=9900，即每个分库要返回100页数据，数据量和排序量都将大增，性能平方级下降。  
3. 方法二：业务折衷法-禁止跳页查询(对应es中的scroll方法)   
	1. 流程：  
		1. 如果要获取第N页的数据，第一页时，是和全局视野法一致。  
		2. 但第二页开始后，需要在每一个子库查询时，加上可以排除上一页的过滤条件(如按时间排序时，获取上一页的最大时间后，需要加上time > ${maxTime_lastPage}的条件，然后再limit S。即可获取各个子库的结果。  
		3. 之后再合并后top S即可得到最终结果。  
	2. 优点: 数据准确，性能良好  
	3. 缺点: 不能跳页  
4. 方法三：业务折衷法-允许模糊数据  
	1. 前提：数据库分库-数据均衡原理  
	使用patition key进行分库，在数据量较大，数据分布足够随机的情况下，各分库所有非patition key属性，在各个分库上的数据分布，统计概率情况是一致的。  
	2. 流程：将order by time offset X limit Y，改写成order by time offset X/N limit Y/N    
	3. 优点: 性能良好，可以跳页
	4. 缺点: 数据不准确
5. 终极武器-二次查询法  



#### 1.5.4.7. 数据迁移
1. 现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表**动态切换**到分库分表上？
    * 停机迁移方案
    * 双写迁移方案 

### 1.5.5. 索引事物锁
#### 1.5.5.1. 索引底层原理 
1. **<font color = "clime">评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中`磁盘I/O`操作次数的渐进复杂度。</font>**  
2. InnoDB使用的数据结构：  
    * B树：
        1. B树中每个节点中不仅包含数据的key值，还有data值。 **<font color = "red">而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小。当存储的数据量很大时同样会导致B树的深度较大，</font>** 增大查询时的磁盘I/O次数进而影响查询效率。  
        2. `范围查询，磁盘I/O高。`
    * B+树  
        1. B+Tree中间节点不存储数据，因此B+Tree能够在同样大小的节点中，存储更多的key。
        2. `叶子节点之间会有个指针指向，这个也是B+树的核心点，可以大大提升范围查询效率，也方便遍历整个树。`  
        3. `B+tree的查询效率更加稳定。`  
3. **<font color = "red">联合索引底层还是使用B+树索引，并且还是只有一棵树，只是此时的排序：首先按照第一个索引排序，在第一个索引相同的情况下，再按第二个索引排序，依此类推。</font>**  
4. 无索引时的数据查询：查询数据时从磁盘中依次加载数据页到InnoDB的缓冲池中，然后对缓冲池中缓存页的每行数据，通过数据页的单向链表一个一个去遍历查找，如果没有找到，那么就会顺着数据页的双向链表数据结构，依次遍历加载磁盘中的其他数据页到缓冲池中遍历查询。 

#### 1.5.5.2. ~~各种索引~~（还需要总结）
&emsp; <font color = "red">InnoDB索引类型可以分为主键索引（聚簇索引）和辅助索引（非聚簇索引/非主键索引）。</font>  

#### 1.5.5.3. MySql事务（还需要总结）  
1. 事务的四大特性（ACID）：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。  
2. 并发事务处理带来的问题：脏读、丢失修改、不可重复读、幻读。  
    * 脏`读`：一个事务读了另一个事务未提交的数据。
    * 丢失`修改`：一个事务覆盖了另一个事务的数据。  
    * 不可重复读：一个事务多次读，另一事务中间修改了数据。  
    * 幻读：一个事务多次读，另一事务中间新增了数据。  
3. SQL标准定义了四个隔离级别（隔离性）：读取未提交、读取已提交、可重复读（可以阻止脏读和不可重复读，幻读仍有可能发生，但MySql的可重复读解决了幻读）、可串行化。  
4. Innodb事务实现原理
    * 原子性的实现：采用回滚日志[undo log](/docs/SQL/undoLog.md)实现。  
    * 持久性的实现：采用重做日志[redo log](/docs/SQL/redoLog.md)实现。  
    * 隔离性（事务的隔离级别）的实现
        在MySQL中，默认的隔离级别是REPEATABLE-READ（可重复读），阻止脏读和不可重复读，并且解决了幻读问题。  
        &emsp; 隔离性（事务的隔离级别）的实现，利用的是锁和MVCC机制。 
        * **<font color = "blue">快照读：生成一个事务快照（ReadView），之后都从这个快照获取数据。</font>** 普通select语句就是快照读。  
        &emsp; <font color = "blue">对于快照读，MVCC因为从ReadView读取，所以必然不会看到新插入的行，所以天然就解决了幻读的问题。</font>  
        * **<font color = "clime">当前读：读取数据的最新版本。</font>** 常见的update/insert/delete、还有 select ... for update、select ... lock in share mode都是当前读。  
        &emsp; 对于当前读的幻读，MVCC是无法解决的。需要使用Gap Lock或Next-Key Lock（Gap Lock + Record Lock）来解决。  
    * 一致性的实现  
        &emsp; Mysql怎么保证一致性的？这个问题分为两个层面来说。  
        1. 从数据库层面，数据库通过原子性、隔离性、持久性来保证一致性。也就是说ACID四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。数据库必须要实现AID三大特性，才有可能实现一致性。例如，原子性无法保证，显然一致性也无法保证。  
        2. 从应用层面，通过代码判断数据库数据是否有效，然后决定回滚还是提交数据！如果在事务里故意写出违反约束的代码，一致性还是无法保证的。

#### 1.5.5.4. MVCC
1. **<font color = "clime">多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制。</font>**  
&emsp; <font color = "clime">`MVCC与锁：MVCC主要解决读写问题，锁解决写写问题。`两者结合才能更好的控制数据库隔离性，保证事务正确提交。</font>  
2. **<font color = "clime">InnoDB有两个非常重要的模块来实现MVCC。</font>**   
    * 一个是undo log，用于记录数据的变化轨迹（版本链），用于数据回滚。  
    &emsp; 版本链的生成：在数据库中的每一条记录实际都会存在三个隐藏列：事务ID、行ID、回滚指针，指向undo log记录。  
    *  另外一个是Read View，用于判断一个session对哪些数据可见，哪些不可见。  
    &emsp; **<font color = "red">Read View是用来判断每一个读取语句有资格读取版本链中的哪个记录。所以在读取之前，都会生成一个Read View。然后根据生成的Read View再去读取记录。</font>**  
3. ~~Read View判断：~~  
    &emsp; 如果被访问版本的trx_id小于ReadView中的up_limit_id值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。  
    &emsp; <font color = "red">如果被访问版本的trx_id属性值在ReadView的up_limit_id和low_limit_id之间，那就需要判断一下trx_id属性值是不是在trx_ids列表中。</font>如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；<font color = "clime">如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。</font>  

    &emsp; Read View是如何保证可见性判断的呢？我们先看看Read view 的几个重要属性   

    * m_ids:当前系统中那些活跃(未提交)的读写事务ID, 它数据结构为一个List。  
    * min_limit_id:表示在生成Read View时，当前系统中活跃的读写事务中最小的事务id，即m_ids中的最小值。  
    * max_limit_id:表示生成Read View时，系统中应该分配给下一个事务的id值。  
    * creator_trx_id: 创建当前Read View的事务ID  

    &emsp; Read view 匹配条件规则如下：

    * 如果数据事务ID trx_id < min_limit_id，表明生成该版本的事务在生成Read View前，已经提交(因为事务ID是递增的)，所以该版本可以被当前事务访问。  
    * 如果trx_id>= max_limit_id，表明生成该版本的事务在生成ReadView后才生成，所以该版本不可以被当前事务访问。  
    * 如果 min_limit_id =<trx_id< max_limit_id，需要分3种情况讨论  
        * （1）.如果m_ids包含trx_id,则代表Read View生成时刻，这个事务还未提交，但是如果数据的trx_id等于creator_trx_id的话，表明数据是自己生成的，因此是可见的。  
        * （2）如果m_ids包含trx_id，并且trx_id不等于creator_trx_id，则Read   View生成时，事务未提交，并且不是自己生产的，所以当前事务也是看不见的；
        * （3）.如果m_ids不包含trx_id，则说明你这个事务在Read View生成之前就已经提交了，修改的结果，当前事务是能看见的。
4. 在读取已提交、可重复读两种隔离级别下会使用MVCC。  
    * 读取已提交READ COMMITTED是在`每次执行select操作时`都会生成一次Read View。所以解决不了幻读问题。 
    * 可重复读REPEATABLE READ只有在第一次执行select操作时才会生成Read View，后续的select操作都将使用第一次生成的Read View。
5. MVCC解决了幻读没有？  
        当前读:select...lock in share mode; select...for update;
        当前读:update、insert、delete
    &emsp; 对于当前读的幻读，MVCC是无法解决的。需要使用 Gap Lock 或 Next-Key Lock（Gap Lock + Record Lock）来解决。</font>其实原理也很简单，用上面的例子稍微修改下以触发当前读：select * from user where id < 10 for update。`若只有MVCC，当事务1执行第二次查询时，操作的数据集已经发生变化，所以结果也会错误；`当使用了Gap Lock时，Gap锁会锁住id < 10的整个范围，因此其他事务无法插入id < 10的数据，从而防止了幻读。  


#### 1.5.5.5. MySql锁
1. InnoDB共有七种类型的锁：共享/排它锁、意向锁、记录锁（Record lock）、间隙锁（Gap lock）、临键锁（Next-key lock）、插入意向锁、自增锁。  
2. **<font color = "red">InnoDB存储引擎的锁的算法有三种：</font>**  
    1. Record lock：单个行记录上的锁。  
    2. Gap lock：间隙锁，锁定一个范围，不包括记录本身。  
    &emsp; **<font color = "red">当使用范围条件（> 、< 、between...）检索数据，InnoDB会给符合条件的已有数据记录的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP）”，InnoDB也会对这个“间隙”加锁，这就是间隙锁。</font>**  
    &emsp; **<font color = "red">InnoDB除了通过范围条件加锁时使用间隙锁外，如果使用相等条件请求给一个不存在的记录加锁，InnoDB 也会使用间隙锁。</font>**  
    3. Next-key lock：record+gap锁定一个范围，包含记录本身。  
    &emsp; 临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。  
    &emsp; <font color = "red">默认情况下，innodb使用next-key locks来锁定记录。</font><font color = "clime">但当查询的索引含有唯一属性的时候，Next-Key Lock会进行优化，将其降级为Record Lock，即仅锁住索引本身，不是范围。</font>  

#### 1.5.5.6. MySql死锁和锁表
&emsp; ~~胡扯，死锁，mysql检测后，回滚一条事务，抛出异常。~~  
1. 服务器报错：`Deadlock found when trying to get to lock; try restarting transaction`。  
2. **<font color = "clime"> 死锁发生了如何解决，MySQL有没有提供什么机制去解决死锁？</font>**  
    1. 发起死锁检测，主动回滚其中一条事务，让其他事务继续执行。  
    2. 设置超时时间，超时后自动释放。  
    &emsp; `在涉及外部锁，或涉及表锁的情况下，InnoDB并不能完全自动检测到死锁，`这需要通过设置锁等待超时参数 innodb_lock_wait_timeout来解决。</font>   
3. **<font color = "clime">如果出现死锁</font>** ，<font color = "clime">可以用`show engine innodb status;`命令来确定最后一个死锁产生的原因。</font>  


### 1.5.6. MySql架构原理
#### 1.5.6.1. MySql架构
1. MySQL整个查询执行过程，总的来说分为5个步骤：  
    1. 客户端请求 ---> 连接器（验证用户身份，给予权限）  
    2. 查询缓存（存在缓存则直接返回，不存在则执行后续操作）
    3. 分析器（对SQL进行词法分析和语法分析操作）  ---> 优化器（主要对执行的sql优化选择最优的执行方案方法）  
    4. 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口）  
    5. 去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果）。   
2. **<font color = "clime">MySQL服务器主要分为Server层和存储引擎层。</font>**  
	1. <font color = "red">Server层包括连接器、查询缓存、分析器、优化器、执行器等。</font>涵盖MySQL的大多数核心服务功能，以及所有的内置函数(如日期、时间、数学和加密函数等)，所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等，还有 **<font color = "clime">一个通用的日志模块binglog日志模块。</font>**     
	2. `存储引擎：主要负责数据的存储和读取，`采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory等多个存储引擎，其中InnoDB引擎有自有的日志模块redolog模块。  
3. MySQL更新路程：  
    1. 事务提交前 --- 内存操作：  
        1. 数据加载到缓冲池buffer poll；  
        2. `写回滚日志undo log；`  
        3. 更新缓冲池数据；  
        4. 写redo log buffer。  
    2. 事务提交：`redo log与bin log两阶段提交。`  
    3. 事务提交后：后台线程将buffer poll中数据落盘。  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-174.png)  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-183.png)  

#### 1.5.6.2. binLog日志  
1. **<font color = "clime">binlog是mysql的逻辑日志，并且由Server层进行记录，使用任何存储引擎的mysql数据库都会记录binlog日志。</font>**  
2. 在实际应用中，主要用在两个场景：主从复制和数据恢复。  
3. 写入流程：SQL修改语句先写Binlog Buffer，事务提交时，按照一定的格式刷到磁盘中。  
&emsp; binlog刷盘时机：对于InnoDB存储引擎而言，mysql通过sync_binlog参数控制binlog的刷盘时机。  

#### 1.5.6.3. MySql存储引擎
1. **<font color = "red">InnoDB的特性：</font>**    
    * [支持事务](/docs/SQL/transaction.md)  
    * [支持行锁](/docs/SQL/lock.md)，采用[MVCC](/docs/SQL/MVCC.md)来支持高并发  
    * 支持外键  
    * 支持崩溃后的安全恢复  
    * 不支持全文索引  
    * InnoDB 不保存表的具体行数，执行`select count(*) from table`时需要全表扫描。  

#### 1.5.6.4. InnoDB体系结构
&emsp; Innodb体系结构包含后台线程、内存池和磁盘上的结构。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-147.png)  
1. `如果从内存上来看，Change Buffer和Adaptive Hash Index占用的内存都属于Buffer Pool；redo Log Buffer占用的内存与Buffer Pool独立。即InnoDB内存主要有两大部分：缓冲池、重做日志缓冲。`  
2. `Buffer Pool有Changer Buffer；Redo Log有Double Write。`  


##### 1.5.6.4.1. InnoDB内存结构-性能
&emsp; 内存中的结构主要包括Buffer Pool，Change Buffer、Adaptive Hash Index以及redo Log Buffer四部分。 **<font color = "blue">如果从内存上来看，[Change Buffer](/docs/SQL/ChangeBuffer.md)和[Adaptive Hash Index](/docs/SQL/AdaptiveHashIndex.md)占用的内存都属于Buffer Pool，redo Log Buffer占用的内存与 [Buffer Pool](/docs/SQL/bufferPoolNew.md)独立。</font>** `即InnoDB内存主要有两大部分：缓冲池、重做日志缓冲。`  

&emsp; 内存数据落盘整体思路分析：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-173.png)  
&emsp; `InnoDB内存缓冲池中的数据page要完成持久化的话，是通过两个流程来完成的，一个是脏页落盘；一个是预写redo log日志。`  

###### 1.5.6.4.1.1. BufferPool
1. 缓冲池是主内存中的一个区域，在InnoDB访问表和索引数据时会在其中进行高速缓存。**在专用服务器上，通常将多达80％的物理内存分配给缓冲池。**  
1. **预读：**   
&emsp; 数据访问，通常都遵循“集中读写”的原则，使用一些数据，大概率会使用附近的数据，这就是所谓的“局部性原理”，它表明提前加载是有效的，确实能够减少磁盘IO。  
&emsp; **<font color = "clime">预读机制能把一些“可能要访问”的页提前加入缓冲池，避免未来的磁盘IO操作；</font>**  
2. **预读失效与缓存污染：**    
&emsp; 预读失效：读取连续的缓存页，将lru链表尾部经常被访问的页清除了。缓存污染：当执行一条 SQL 语句时，如果扫描了大量数据或是进行了全表扫描，从而将缓冲池中已存在的所有页替换出去。  
3. **读操作：改进的lru算法：**    
&emsp; **<font color = "clime">为了提高缓存命中率，InnoDB 在传统 Lru 算法的基础上做了优化，解决了两个问题：1、预读失效 2、缓存池污染。</font>**   
&emsp; `将LRU链表分为两部分，一部分为热数据区域，一部分为冷数据区域。`当数据页第一次被加载到缓冲池中的时候，先将其放到冷数据区域的链表头部，1s（由 innodb_old_blocks_time 参数控制） 后该缓存页被访问了再将其移至热数据区域的链表头部。  
5. **写操作：**    
&emsp; **Buffer pool 另一个主要的功能是「加速写」，即当需要修改一个页面的时候，先将这个页面在缓冲池中进行修改，记下相关的重做日志，这个页面的修改就算已经完成了。**  


###### 1.5.6.4.1.2. 写缓冲ChangeBuffer
1. 在「非唯一」「普通」索引页（即非聚集索引）不在缓冲池中，对页进行了写操作， 1). 并不会立刻将磁盘页加载到缓冲池，而仅仅记录缓冲变更， 2).`等未来数据被读取时，再将数据合并(merge)恢复到缓冲池中`的技术。  
2. **~~<font color = "red">如果辅助索引页已经在缓冲区了，则直接修改即可；如果不在，则先将修改保存到 Change Buffer。</font><font color = "blue">Change Buffer的数据在对应辅助索引页读取到缓冲区时合并到真正的辅助索引页中。Change Buffer 内部实现也是使用的 B+ 树。</font>~~**  

###### 1.5.6.4.1.3. AdaptiveHashIndex
&emsp;对于InnoDB的哈希索引，确切的应该这么说：  
&emsp;(1)InnoDB用户无法手动创建哈希索引，这一层上说，InnoDB确实不支持哈希索引；  
&emsp;(2)InnoDB会自调优(self-tuning)，如果判定建立自适应哈希索引(Adaptive Hash Index, AHI)，能够提升查询效率，InnoDB自己会建立相关哈希索引，这一层上说，InnoDB又是支持哈希索引的。  

##### 1.5.6.4.2. InnoDB磁盘结构-可靠性
###### 1.5.6.4.2.1. BufferPool落盘表空间
1. 从InnoDb存储引擎的逻辑存储结构看，所有数据都被逻辑地存放在一个空间中，称之为表空间tablespace。表空间又由段segment，区extent，页page组成。  
2. **<font color = "clime">相比较之下，使用独占表空间的效率以及性能会更高一点。</font>**  
3. **<font color = "clime">在InnoDB存储引擎中，默认每个页的大小为16KB（在操作系统中默认页大小是4KB）。</font>**  

###### 1.5.6.4.2.2. undoLog
1. **<font color = "clime">Undo log，回滚日志，是逻辑日记。undo log解决了事务原子性。</font>** 主要有两个作用，事务回滚和MVCC（Mutil-Version Concurrency Control）。      
2. undo log主要记录了数据的逻辑变化，比如一条INSERT语句，对应一条DELETE的undo log，对于每个UPDATE语句，对应一条相反的UPDATE的undo log，这样在发生错误时，就能回滚到事务之前的数据状态。
3. 事务开始之前，将当前的版本生成undo log。

###### 1.5.6.4.2.3. redoLog
1. redo log，物理格式的日志，记录的是物理数据页面的修改的信息。 **<font color = "red">`redo log实际上记录数据页的变更，而这种变更记录是没必要全部保存，`因此redo log实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。</font>**    
2. 解决事务的一致性，持久化数据。  
3. 写入流程：`(Write-Ahead Logging，‘日志’先行)  
&emsp; 在计算机体系中，CPU处理速度和硬盘的速度，是不在同一个数量级上的，为了让它们速度匹配，从而催生了我们的内存模块，但是内存有一个特点，就是掉电之后，数据就会丢失，不是持久的，我们需要持久化的数据，最后都需要存储到硬盘上。InnoDB引擎设计者也利用了类似的设计思想。   
&emsp; 当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log(redolog buffer)里面，并更新内存(buffer pool)，这个时候更新就算完成了。`同时，InnoDB引擎会在适当的时候，`将这个redoLog操作记录更新到磁盘里面（刷脏页）`。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-184.png)  
4. 刷盘时机：重做日志的写盘，并不一定是随着事务的提交才写入重做日志文件的，而是随着事务的开始，逐步开始的。先写入redo log buffer。  

###### 1.5.6.4.2.4. DoubleWrite
&emsp; double write：<font color = "blue">如果说写缓冲change buffer带给InnoDB存储引擎的是性能，那么两次写Double Write带给InnoDB存储引擎的是数据的可靠性。</font>  
1. MySQL将buffer中一页数据刷入磁盘，要写4个文件系统里的页。  
2. 在应用(apply)重做日志(redo log)前，需要一个页的副本，当写入失效发生时，先通过页的副本来还原该页，再进行重做，这就是doublewrite。即doublewrite是页的副本。  
    1. 在异常崩溃时，如果不出现“页数据损坏”，能够通过redo恢复数据；
    2. 在出现“页数据损坏”时，能够通过double write buffer恢复页数据； 
3. doublewrite分为内存和磁盘的两层架构。当有页数据要刷盘时：  
    1. 第一步：页数据先memcopy到doublewrite buffer的内存里；
    2. 第二步：doublewrite buffe的内存里，会先刷到doublewrite buffe的磁盘上；
    3. 第三步：doublewrite buffe的内存里，再刷到数据磁盘存储上； 

##### 1.5.6.4.3. ~~两阶段提交和崩溃恢复~~
1. 两阶段提交
    1. **<font color = "clime">redo log和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。两阶段提交保证解决binlog和redo log的数据一致性。</font>**    
    2. `两阶段提交是很典型的分布式事务场景，因为redolog和binlog两者本身就是两个独立的个体，`要想保持一致，就必须使用分布式事务的解决方案来处理。 **<font color = "blue">而将redolog分成了两步，其实就是使用了两阶段提交协议(Two-phaseCommit，2PC)。</font>**  
    &emsp; 事务的提交过程有两个阶段，就是将redolog的写入拆成了两个步骤：prepare和commit，中间再穿插写入binlog。  
        1. 记录redolog，InnoDB事务进入prepare状态；
        2. 写入binlog；
        3. 将redolog这个事务相关的记录状态设置为commit状态。
2. 崩溃恢复： **<font color = "red">当重启数据库实例的时候，数据库做2个阶段性操作：redo log处理，undo log及binlog 处理。在崩溃恢复中还需要回滚没有提交的事务，提交没有提交成功的事务。由于回滚操作需要undo日志的支持，undo日志的完整性和可靠性需要redo日志来保证，所以崩溃恢复先做redo前滚，然后做undo回滚。</font>**    


## 1.6. 项目构建
### 1.6.1. 接口幂等
&emsp; 接口幂等常用解决方案：  
* 分布式锁
* DB锁
    * 1).select+insert，insert前先select，该方案可能不适用于并发场景，在并发场景中，要配合其他方案一起使用，否则同样会产生重复数据 
    * 2). 状态机
    * 3). 乐观锁（新增version字段）） 

&emsp; **<font color = "blue">小结：</font>**  
&emsp; 一般场景直接使用redis分布式锁解决。可是redis分布式锁可能因编码、部署等，出现一些问题。    
&emsp; 对数据要求高的场景，使用分布式锁 + db锁，db锁一般采用状态机幂等。  
&emsp; 对于将商品数量放在redis中，扣减库存采用lua脚本，支付时反查订单系统，防止超卖问题。    


### 1.6.2. 接口响应时间
1. `链路追踪，查询耗时情况。`  
2. 接口的响应时间过长，你会怎么办？（此处只针对最简单的场景，抛开STW那些复杂的问题。）以下是我目前想到的：  
    1. 异步化（Runnable、Future）  
    2. 缓存  
    3. 并行（ForkJoinPool、CyclicBarrier）  
    4. 干掉锁（空间换时间）  

### 1.6.3. 接口预警
1. 应用主动发送：
    1. 钉钉应用开放平台
    2. logback添加error预警
2. 中间件：  
    1. Filebeat+Logstash发送Email告警日志


## 1.7. 架构设计
&emsp; ~~架构的方方面面： 1).架构模式、2).性能/系统瓶颈。~~   

1. 功能、流程
2. 性能/系统瓶颈：CPU、磁盘IO、内存、网络IO


&emsp; 应用型框架，Spring、Mybatis
&emsp; 功能性框架，redis、mq，一般都是分布式、高并发系统。  

* 分布式带来的问题：  
* 高并发系统的三高：  


### 1.7.1. 架构质量属性
&emsp; 高性能、可靠性、可定制性、可扩展性...  
&emsp; 架构属性一般包括如下方面：性能，伸缩性，可用性，安全性，容错性，灾难恢复，可访问性，可运维，管理，灵活性，可扩展性，可维护性，国际化，本地化。还有法律法规，成本，人员等对上面架构属性的影响。 

--------

1. 架构自身：
2. 架构延伸：
3. 架构对外：


### 1.7.2. 系统瓶颈
1. 网络I/O
2. 磁盘I/O
3. 内存
4. CPU

## 1.8. Spring
### 1.8.1. Spring基础
1. **@Autowired和@Resource之间的区别：**  
    1. @Autowired默认是按照类型装配注入的，默认情况下它要求依赖对象必须存在(可以设置它的required属性为false)。
    2. @Resource默认是按照名称来装配注入的，只有当找不到与名称匹配的bean才会按照类型来装配注入。  

### 1.8.2. Spring IOC
1. BeanFactory与ApplicationContext
    * BeanFactory作为最顶层的一个接口类，定义了IOC容器的基本功能规范。
    * <font color = "clime">ApplicationContext接口是BeanFactory的扩展，它除了具备BeanFactory接口所拥有的全部功能外，还有应用程序上下文的一层含义</font>，主要包括：  
        1. 继承自ListableBeanFactory接口，<font color = "clime">可以访问Bean工厂上下文的组件；</font>  
        2. 继承自ResourceLoader接口，以通用的方式加载文件资源；  
        3. 继承自ApplicationContextPublisher接口，<font color = "clime">拥有发布事件注册监听的能力；</font>  
        4. 继承自 MessageSource 接口，解析消息支持国际化。  
2. BeanDefinition： **<font color = "red">BeanDefinition中保存了Bean信息，比如这个Bean指向的是哪个类、是否是单例的、是否懒加载、这个Bean依赖了哪些Bean等。</font>**  
3. Spring bean容器刷新的核心 12个步骤完成IoC容器的创建及初始化工作：  
    
    **<font color = "blue">（⚠`利用工厂和反射创建Bean。主要包含3部分：1).容器本身--创建容器、2).容器扩展--后置处理器、3).事件，子容器，实例化Bean。`）</font>**     
    1. 刷新前的准备工作。  
    2. **<font color = "red">创建IoC容器(DefaultListableBeanFactory)，加载和注册BeanDefinition对象。</font>** <font color = "blue">`个人理解：此处仅仅相当于创建Spring Bean的类，实例化是在Spring DI里。`</font>   
        &emsp; **<font color = "clime">DefaultListableBeanFactory中使用一个HashMap的集合对象存放IOC容器中注册解析的BeanDefinition。</font>**  
        ```java
        private final Map<String, BeanDefinition> beanDefinitionMap = new ConcurrentHashMap<>(256);
        ```
    -----------
    3. **<font color = "red">对IoC容器进行一些预处理。</font>** 为BeanFactory配置容器特性，`例如设置BeanFactory的类加载器，`配置了BeanPostProcessor，注册了三个默认bean实例，分别是“environment”、“systemProperties”、“systemEnvironment”。  
    4. 允许在上下文子类中对bean工厂进行后处理。 本方法没有具体实现，是一个扩展点，开发人员可以根据自己的情况做具体的实现。  
    5. **<font color = "red">调用BeanFactoryPostProcessor后置处理器对BeanDefinition处理（修改BeanDefinition对象）。</font>**  
    6. **<font color = "red">注册BeanPostProcessor后置处理器。</font>**  
    7. 初始化一些消息源（比如处理国际化的i18n等消息源）。 
    ------------ 
    8. **<font color = "red">初始化应用[事件多播器](/docs/SSM/Spring/feature/EventMulticaster.md)。</font>**     
    9. **<font color = "red">`onRefresh()，典型的模板方法(钩子方法)。不同的Spring容器做不同的事情。`比如web程序的容器ServletWebServerApplicationContext中会调用createWebServer方法去创建内置的Servlet容器。</font>**  
    10. **<font color = "red">注册一些监听器到事件多播器上。</font>**  
    11. **<font color = "red">`实例化剩余的单例bean(非懒加载方式)。`</font><font color = "blue">`注意事项：Bean的IoC、DI和AOP都是发生在此步骤。`</font>**  
    12. **<font color = "red">完成刷新时，发布对应的事件。</font>**  


### 1.8.3. Spring DI
1. 加载时机：SpringBean默认单例，非懒加载，即容器启动时就加载。  
2. 加载流程：  
    1. doCreateBean()创建Bean有三个关键步骤：2.createBeanInstance()实例化、5.populateBean()属性填充、6.initializeBean()初始化。  

#### 1.8.3.1. 循环依赖
1. Spring循环依赖的场景：均采用setter方法（属性注入）注入方式，可被解决；采用构造器和setter方法（属性注入）混合注入方式可能被解决。
2. **<font color = "red">Spring通过3级缓存解决：</font>**  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/SSM/Spring/spring-20.png)  
    * 三级缓存: Map<String,ObjectFactory<?>> singletonFactories，早期曝光对象工厂，用于保存bean创建工厂，以便于后面扩展有机会创建代理对象。  
    * 二级缓存: Map<String,Object> earlySingletonObjects， **<font color = "blue">早期曝光对象</font>** ，`二级缓存，用于存放已经被创建，但是尚未初始化完成的Bean。`尚未经历了完整的Spring Bean初始化生命周期。
    * 一级缓存: Map<String,Object> singletonObjects，单例对象池，用于保存实例化、注入、初始化完成的bean实例。经历了完整的Spring Bean初始化生命周期。  
3. 未发生依赖
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/SSM/Spring/spring-21.png)  
4. **<font color = "clime">单例模式下Spring解决循环依赖的流程：</font>**  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/SSM/Spring/spring-22.png)  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/SSM/Spring/spring-17.png)  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/SSM/Spring/spring-16.png)  
    1. Spring创建bean主要分为两个步骤，创建原始bean对象，接着去填充对象属性和初始化。  
    2. 每次创建bean之前，都会从缓存中查下有没有该bean，因为是单例，只能有一个。  
    3. 当创建beanA的原始对象后，并把它放到三级缓存中，接下来就该填充对象属性了，这时候发现依赖了beanB，接着就又去创建 beanB，同样的流程，创建完beanB填充属性时又发现它依赖了beanA，又是同样的流程，不同的是，这时候可以在三级缓存中查到刚放进去的原始对象beanA，所以不需要继续创建，用它注入beanB，完成beanB的创建。此时会将beanA从三级缓存删除，放到二级缓存。   
    4. 既然 beanB 创建好了，所以 beanA 就可以完成填充属性的步骤了，接着执行剩下的逻辑，闭环完成。  
    ---
    &emsp; 当A、B两个类发生循环引用时，在A完成实例化后，就使用实例化后的对象去创建一个对象工厂，并添加到三级缓存中。 **<font color = "blue">`如果A被AOP代理，那么通过这个工厂获取到的就是A代理后的对象，如果A没有被AOP代理，那么这个工厂获取到的就是A实例化的对象。`</font>** 当A进行属性注入时，会去创建B，同时B又依赖了A，所以创建B的同时又会去调用getBean(a)来获取需要的依赖，此时的getBean(a)会从缓存中获取：  

    * 第一步，先获取到三级缓存中的工厂。  
    * 第二步，调用对象工厂的getObject方法来获取到对应的对象，得到这个对象后将其注入到B中。紧接着B会走完它的生命周期流程，包括初始化、后置处理器等。  

    当B创建完后，会将B再注入到A中，此时A再完成它的整个生命周期。  
5. 常见问题
    1. 二级缓存能解决循环依赖嘛？  
    &emsp; 二级缓存可以解决循环依赖。  
    &emsp; 如果创建的Bean有对应的代理，那其他对象注入时，注入的应该是对应的代理对象；但是Spring无法提前知道这个对象是不是有循环依赖的情况，而正常情况下（没有循环依赖情况），Spring都是在创建好完成品Bean之后才创建对应的代理。这时候Spring有两个选择：

        * 方案一：不管有没有循环依赖，都提前创建好代理对象，并将代理对象放入缓存，出现循环依赖时，其他对象直接就可以取到代理对象并注入。
        * 方案二：不提前创建好代理对象，在出现循环依赖被其他对象注入时，才实时生成代理对象。这样在没有循环依赖的情况下，Bean就可以按着Spring设计原则的步骤来创建。  

    &emsp; 如果使用二级缓存解决循环依赖，即采用方案一，意味着所有Bean在实例化后就要完成AOP代理，这样违背了Spring设计的原则，Spring在设计之初就是通过AnnotationAwareAspectJAutoProxyCreator这个后置处理器来在Bean生命周期的最后一步来完成AOP代理，而不是在实例化后就立马进行AOP代理。   
    &emsp; **怎么做到提前曝光对象而又不生成代理呢？**   
    &emsp; Spring就是在对象外面包一层ObjectFactory（三级缓存存放），提前曝光的是ObjectFactory对象，在被注入时才在ObjectFactory.getObject方式内实时生成代理对象，并将生成好的代理对象放入到第二级缓存Map\<String, Object> earlySingletonObjects。  


### 1.8.4. Bean的生命周期
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SSM/Spring/spring-10.png)  
&emsp; SpringBean的生命周期主要有4个阶段：  
1. 实例化（Instantiation），可以理解为new一个对象；
2. 属性赋值（Populate），可以理解为调用setter方法完成属性注入；
3. 初始化（Initialization），包含：  
    * 激活Aware方法  
    * 前置处理  
    * 激活自定义的init方法 
    * 后置处理 
4. 销毁（Destruction）---注册Destruction回调函数。  

### 1.8.5. 容器相关特性
#### 1.8.5.1. FactoryBean
&emsp; BeanFactory是个Factory，也就是IOC容器或对象工厂；FactoryBean是个Bean，也由BeanFactory管理。  
&emsp; 一般情况下，Spring通过`反射机制`利用\<bean\>的class属性指定实现类实例化Bean。 **<font color = "red">在某些情况下，实例化Bean过程比较复杂，</font>** 如果按照传统的方式，则需要在\<bean>中提供大量的配置信息。配置方式的灵活性是受限的，这时采用编码的方式可能会得到一个简单的方案。 **<font color = "red">Spring为此提供了一个org.springframework.bean.factory.FactoryBean的`工厂类接口`，用户可以通过实现该接口定制实例化Bean的逻辑。</font>**  
&emsp; **<font color = "red">FactoryBean接口的一些实现类，如Spring自身提供的ProxyFactoryBean、JndiObjectFactoryBean，还有Mybatis中的SqlSessionFactoryBean，</font>** 用于生产一些复杂的Bean。  

&emsp; `⚠️FactoryBean，工厂Bean，首先是个Bean，其次再加上工厂模式。`  


#### 1.8.5.2. Spring可二次开发常用接口（扩展性）
&emsp; Spring为了用户的开发方便和特性支持，开放了一些特殊接口和类，用户可进行实现或者继承，常见的有：  

&emsp; **Spring IOC阶段：**  
&emsp; [事件多播器](/docs/SSM/Spring/feature/EventMulticaster.md)  
&emsp; [事件](/docs/SSM/Spring/feature/Event.md)  

&emsp; **Spring DI阶段：**  
&emsp; [Aware接口](/docs/SSM/Spring/feature/Aware.md)  
&emsp; [后置处理器](/docs/SSM/Spring/feature/BeanFactoryPostProcessor.md)  
&emsp; [InitializingBean](/docs/SSM/Spring/feature/InitializingBean.md)  

##### 1.8.5.2.1. 事件
&emsp; **<font color = "clime">★★★Spring事件机制的流程：</font>**   
1. **<font color = "clime">事件机制的核心是事件。</font>** Spring中的事件是ApplicationEvent。Spring提供了5个标准事件，此外还可以自定义事件(继承ApplicationEvent)。  
2. **<font color = "clime">确定事件后，要把事件发布出去。</font>** 在事件发布类的业务代码中调用ApplicationEventPublisher#publishEvent方法（或调用ApplicationEventPublisher的子类，例如调用ApplicationContext#publishEvent）。  
3. **<font color = "blue">`发布完成之后，启动监听器，自动监听。`</font>** 在监听器类中覆盖ApplicationListener#onApplicationEvent方法。  
4. 最后，就是实际场景中触发事件发布，完成一系列任务。  


&emsp; **<font color = "clime">5个标准事件：</font>**   

* 上下文更新事件（ContextRefreshedEvent）：在调用ConfigurableApplicationContext接口中的refresh()方法时被触发。  
* 上下文开始事件（ContextStartedEvent）：当容器调用ConfigurableApplicationContext的Start()方法开始/重新开始容器时触发该事件。  
* 上下文停止事件（ContextStoppedEvent）：当容器调用ConfigurableApplicationContext的Stop()方法停止容器时触发该事件。  
* 上下文关闭事件（ContextClosedEvent）：当ApplicationContext被关闭时触发该事件。容器被关闭时，其管理的所有单例Bean都被销毁。  
* 请求处理事件（RequestHandledEvent）：在Web应用中，当一个http请求（request）结束触发该事件。如果一个bean实现了ApplicationListener接口，当一个ApplicationEvent被发布以后，bean会自动被通知。  

##### 1.8.5.2.2. Aware接口
&emsp; **<font color = "clime">容器管理的Bean一般不需要了解容器的状态和直接使用容器，但在某些情况下，是需要在Bean中直接对IOC容器进行操作的，这时候，就需要在Bean中设定对容器的感知。Spring IOC容器也提供了该功能，它是通过特定的aware接口来完成的。</font>** <font color = "red">aware接口有以下这些：

* BeanNameAware，可以在Bean中得到它在IOC容器中的Bean实例名称。  
* BeanFactoryAware，可以在Bean中得到Bean所在的IOC容器，从而直接在Bean中使用IOC容器的服务。  
* ApplicationContextAware，可以在Bean中得到Bean所在的应用上下文，从而直接在 Bean中使用应用上下文的服务。  
* MessageSourceAware，在Bean中可以得到消息源。  
* ApplicationEventPublisherAware，在Bean中可以得到应用上下文的事件发布器，从而可以在Bean中发布应用上下文的事件。  
* ResourceLoaderAware，在Bean中可以得到ResourceLoader，从而在Bean中使用ResourceLoader加载外部对应的Resource资源。</font>  

&emsp; 在设置Bean的属性之后，调用初始化回调方法之前，Spring会调用aware接口中的setter方法。  


##### 1.8.5.2.3. 后置处理器
1. <font color = "clime">实现BeanFactoryPostProcessor接口，可以`在spring的bean创建之前，修改bean的定义属性（BeanDefinition）`。</font>  
2. <font color = "red">实现BeanPostProcessor接口，</font><font color = "blue">可以在spring容器实例化bean之后，`在执行bean的初始化方法前后，`添加一些自己的处理逻辑。</font>  


##### 1.8.5.2.4. InitializingBean
&emsp; ......  


### 1.8.6. SpringAOP教程
1. SpringAOP的主要功能是：日志记录，性能统计，安全控制，事务处理，异常处理等。 
    * 慢请求记录  
    * 使用aop + redis + Lua接口限流
2. `SpringAOP失效：`  
&emsp; 参考[Spring事务失效](/docs/SSM/Spring/SpringTransactionInvalid.md)  
&emsp; <font color = "red">同一对象内部方法嵌套调用，慎用this来调用被@Async、@Transactional、@Cacheable等注解标注的方法，this下注解可能不生效。</font>async方法中的this不是动态代理的子类对象，而是原始的对象，故this调用无法通过动态代理来增强。 
3. **<font color = "red">过滤器，拦截器和aop的区别：</font>** 过滤器拦截的是URL；拦截器拦截的是URL；Spring AOP只能拦截Spring管理Bean的访问（业务层Service）。  


### 1.8.7. SpringAOP解析
1. **<font color = "blue">自动代理触发的时机：AspectJAnnotationAutoProxyCreator是一个后置处理器BeanPostProcessor，</font>** 因此Spring AOP是在这一步，进行代理增强！  
2. **<font color = "clime">代理类的生成流程：1). `获取当前的Spring Bean适配的advisors；`2). `创建代理类`。</font>**   
    1. Spring AOP获取对应Bean适配的Advisors链的核心逻辑：
        1. 获取当前IoC容器中所有的Aspect类。
        2. 给每个Aspect类的advice方法创建一个Spring Advisor，这一步又能细分为： 
            1. 遍历所有 advice 方法。
            2. 解析方法的注解和pointcut。
            3. 实例化 Advisor 对象。
        3. 获取到候选的 Advisors，并且`缓存`起来，方便下一次直接获取。
        4. 从候选的Advisors中筛选出与目标类适配的Advisor。 
            1. 获取到Advisor的切入点pointcut。
            2. 获取到当前target类所有的public方法。
            3. 遍历方法，通过切入点的methodMatcher匹配当前方法，只要有一个匹配成功就相当于当前的Advisor适配。
        5. 对筛选之后的Advisor链进行排序。  
    2. 创建代理类
        1. 创建AopProxy。根据ProxyConfig 获取到了对应的AopProxy的实现类，分别是JdkDynamicAopProxy和ObjenesisCglibAopProxy。 
        2. 获取代理类。


### 1.8.8. Spring事务
#### 1.8.8.1. Spring事务使用  
1. `@Transactional(rollbackFor = Exception.class) `，Transactional`默认只回滚RuntimeException，`但是可以指定要回滚的异常类型。    
2. **<font color = "red">Spring事务属性通常由事务的传播行为、事务的隔离级别、事务的超时值、事务只读标志组成。</font>**  
    * 事务的传播行为主要分为支持当前事务和不支持当前事务。  
    &emsp; <font color = "red">PROPAGATION_REQUIRED：如果当前存在事务，则加入该事务，合并成一个事务；如果当前没有事务，则创建一个新的事务。这是默认值。</font>  
    * 事务的隔离级别，默认使用底层数据库的默认隔离级别。  
    * 事务只读，相当于将数据库设置成只读数据库，此时若要进行写的操作，会出现错误。  


#### 1.8.8.2. Spring事务失效
1. <font color = "red">同一个类中方法调用。</font>  
&emsp; 因为spring声明式事务是基于AOP实现的，是使用动态代理来达到事务管理的目的，当前类调用的方法上面加@Transactional 这个是没有任何作用的，因为 **<font color = "clime">调用这个方法的是this，没有经过 Spring 的代理类。</font>**  
2. 方法不是public的。    
&emsp; @Transactional 只能用于 public 的方法上，否则事务不会失效，如果要用在非 public 方法上，可以开启 AspectJ 代理模式。  
3. 抛出的异常不支持回滚。捕获了异常，未再抛出。  


### 1.8.9. SpringMVC解析
1. **SpringMVC的工作流程：**  
    1. 找到处理器：前端控制器DispatcherServlet ---> **<font color = "red">处理器映射器HandlerMapping</font>** ---> 找到处理器Handler；  
    2. 处理器处理：前端控制器DispatcherServlet ---> **<font color = "red">处理器适配器HandlerAdapter</font>** ---> 处理器Handler ---> 执行具体的处理器Controller（也叫后端控制器） ---> Controller执行完成返回ModelAndView；  
    &emsp; 1. 处理器映射器HandlerMapping：根据请求的url查找HandlerHandler即处理器（Controller）。  
    &emsp; 2. **<font color = "blue">处理器适配器HandlAdapter：按照特定规则（HandlerAdapter要求的规则）去执行Handler。通过HandlerAdapter对处理器进行执行，这是适配器模式的应用，通过扩展适配器可以对更多类型的处理器进行执行。</font>**  
    &emsp; 3. 处理器Handler和controller区别：
    3. 返回前端控制器DispatcherServlet ---> 视图解析器ViewReslover。  
2. **SpringMVC解析：**  
    1. 在SpringMVC.xml中定义一个DispatcherServlet和一个监听器ContextLoaderListener。  
    2. 上下文在web容器中的启动：<font color = "red">由ContextLoaderListener启动的上下文为根上下文。在根上下文的基础上，还有一个与Web MVC相关的上下文用来保存控制器（DispatcherServlet）需要的MVC对象，作为根上下文的子上下文，构成一个层次化的上下文体系。</font>  
    3. **<font color = "red">`DispatcherServlet初始化和使用：`</font>**     
        1. 初始化阶段。DispatcherServlet的初始化在HttpServletBean#init()方法中。 **<font color = "red">`完成Spring MVC的组件的初始化。`</font>**    
        2. 调用阶段。这一步是由请求触发的。入口为DispatcherServlet#doService() ---> DispatcherServlet#doDispatch()。 **<font color = "blue">`逻辑即为SpringMVC处理流程。`</font>**   


### 1.8.10. 过滤器、拦截器、监听器
&emsp; ......  

## 1.9. MyBatis

### 1.9.1. MyBatis大数据量查询
1. `流式查询（针对查询结果集比较大）`  
&emsp; 流式查询指的是查询成功后不是返回一个集合而是返回一个迭代器，应用每次从迭代器取一条查询结果。流式查询的好处是能够降低内存使用。  
&emsp; **<font color = "clime">如果没有流式查询，想要从数据库取 1000 万条记录而又没有足够的内存时，就不得不分页查询，而分页查询效率取决于表设计，如果设计的不好，就无法执行高效的分页查询。因此流式查询是一个数据库访问框架必须具备的功能。</font>**  
&emsp; 流式查询的过程当中，数据库连接是保持打开状态的，因此要注意的是： **<font color = "clime">执行一个流式查询后，数据库访问框架就不负责关闭数据库连接了，需要应用在取完数据后自己关闭。</font>**  

### 1.9.2. MyBatis架构
&emsp; **<font color = "red">Mybatis的功能架构分为三层：</font>**  

* API接口层：提供给外部使用的接口API，开发人员通过这些本地API来操纵数据库。接口层一接收到调用请求就会调用核心处理层来完成具体的数据处理。  
* 核心处理层：负责具体的SQL查找、SQL解析、SQL执行和执行结果映射处理等。它主要的目的是根据调用的请求完成一次数据库操作。  
* 基础支持层：负责最基础的功能支撑，包括连接管理、事务管理、配置加载和缓存处理，这些都是共用的东西，将它们抽取出来作为最基础的组件。为上层的数据处理层提供最基础的支撑。  


### 1.9.3. MyBatis SQL执行解析
1. Mybatis Sql执行流程：   
    1. 读取核心配置文件并返回InputStream流对象。
    2. 根据InputStream流对象解析出Configuration对象，然后创建SqlSessionFactory工厂对象。
    3. 根据一系列属性从SqlSessionFactory工厂中创建SqlSession。
    4. 从SqlSession中调用Executor执行数据库操作和生成具体SQL指令。
    5. 对执行结果进行二次封装。
    6. 提交与事务。      
2. **<font color = "clime">Mapper接口动态代理类的生成：</font>** 
    * **<font color = "blue">解析配置文件生成sqlSessionFactory时，</font>** 会调用bindMapperForNamespace() ---> addMapper方法， **<font color = "blue">根据mapper文件中的namespace属性值，将接口生成动态代理类的`工厂`，存储在MapperRegistry对象中。</font>** MapperRegistry内部维护一个映射关系，每个接口对应一个`MapperProxyFactory（生成动态代理工厂类）`。      
    * 在调用getMapper，根据type类型，从MapperRegistry对象中的knownMappers获取到当前类型对应的代理工厂类，然后通过代理工厂类使用`jdk自带的动态代理`生成对应Mapper的代理类。  
    ```java
    //这里可以看到每次调用都会创建一个新的代理对象返回
    return mapperProxyFactory.newInstance(sqlSession);
    ```

    ```java
    public T newInstance(SqlSession sqlSession) {
        //首先会调用这个newInstance方法
        //动态代理逻辑在MapperProxy里面
        final MapperProxy<T> mapperProxy = new MapperProxy<>(sqlSession, mapperInterface, methodCache);
        //通过这里调用下面的newInstance方法
        return newInstance(mapperProxy);
    }
    @SuppressWarnings("unchecked")
    protected T newInstance(MapperProxy<T> mapperProxy) {
        //jdk自带的动态代理
        return (T) Proxy.newProxyInstance(mapperInterface.getClassLoader(), new Class[] { mapperInterface }, mapperProxy);
    }
    ```


### 1.9.4. MyBatis缓存
&emsp; ......  


### 1.9.5. MyBatis插件解析
1. **<font color="clime">Mybaits插件的实现主要用了拦截器、责任链和动态代理。</font>** 动态代理可以对SQL语句执行过程中的某一点进行拦截，当配置多个插件时，责任链模式可以进行多次拦截。  
2. **<font color = "clime">mybatis扩展性很强，基于插件机制，基本上可以控制SQL执行的各个阶段，如执行器阶段，参数处理阶段，语法构建阶段，结果集处理阶段，具体可以根据项目业务来实现对应业务逻辑。</font>**   
    * 执行器Executor（update、query、commit、rollback等方法）；  
    * 参数处理器ParameterHandler（getParameterObject、setParameters方法）；  
    * 结果集处理器ResultSetHandler（handleResultSets、handleOutputParameters等方法）；  
    * SQL语法构建器StatementHandler（prepare、parameterize、batch、update、query等方法）；    


## 1.10. SpringBoot

### 1.10.1. SpringBoot基础知识
&emsp; SpringBoot基本上是Spring框架的扩展，它消除了设置Spring应用程序所需的XML配置，为更快，更高效的开发生态系统铺平了道路。  

* SpringBoot简化了Spring的配置；
* SpringBoot提供了起步依赖、自动配置；
* SpringBoot内嵌了Tomcat、 Jetty、 Undertow容器（无需部署war文件）；
* 提供生产指标，例如指标、健壮检查和外部化配置。  

### 1.10.2. SpringBoot启动过程
&emsp; SpringApplication.run()中首先new SpringApplication对象，然后调用该对象的run方法。<font color = "red">`即run()方法主要包括两大步骤：`</font>  
1. 创建SpringApplication对象；  
2. 运行run()方法。  

#### 1.10.2.1. SpringApplication初始化
1. **<font color = "blue">构造过程一般是对构造函数的一些成员属性赋值，做一些初始化工作。</font><font color = "blue">SpringApplication有6个属性：`资源加载器`、资源类集合、应用类型、`初始化器`、`监听器`、`包含main函数的主类`。</font>**  
	1. 给resourceLoader属性赋值，resourceLoader属性，资源加载器，此时传入的resourceLoader参数为null；  
	2. **<font color = "clime">初始化资源类集合并去重。</font>** 给primarySources属性赋值，primarySources属性即`SpringApplication.run(MainApplication.class,args);`中传入的MainApplication.class，该类为SpringBoot项目的启动类，主要通过该类来扫描Configuration类加载bean；
	3. **<font color = "clime">判断当前是否是一个 Web 应用。</font>** 给webApplicationType属性赋值，webApplicationType属性，代表应用类型，根据classpath存在的相应Application类来判断。因为后面要根据webApplicationType来确定创建哪种Environment对象和创建哪种ApplicationContext；
	4. **<font color = "blue">设置应用上下文初始化器。</font>** 给initializers属性赋值，initializers属性为List<ApplicationContextInitializer<?\>>集合，利用SpringBoot的SPI机制从spring.factories配置文件中加载，后面在初始化容器的时候会应用这些初始化器来执行一些初始化工作。因为SpringBoot自己实现的SPI机制比较重要；  
	5. **<font color = "blue">设置监听器。</font>** 给listeners属性赋值，listeners属性为List<ApplicationListener<?\>>集合，同样利用SpringBoot的SPI机制从spring.factories配置文件中加载。因为SpringBoot启动过程中会在不同的阶段发射一些事件，所以这些加载的监听器们就是来监听SpringBoot启动过程中的一些生命周期事件的；
	6. **<font color = "clime">推断主入口应用类。</font>** 给mainApplicationClass属性赋值，mainApplicationClass属性表示包含main函数的类，即这里要推断哪个类调用了main函数，然后把这个类的全限定名赋值给mainApplicationClass属性，用于后面启动流程中打印一些日志。

2. **<font color = "clime">SpringApplication初始化中第4步和第5步都是利用SpringBoot的[SPI机制](/docs/java/basis/SPI.md)来加载扩展实现类。SpringBoot通过以下步骤实现自己的SPI机制：</font>**  
	1. 首先获取线程上下文类加载器;  
	2. 然后利用上下文类加载器从spring.factories配置文件中加载所有的SPI扩展实现类并放入缓存中；  
	3. 根据SPI接口从缓存中取出相应的SPI扩展实现类；  
	4. 实例化从缓存中取出的SPI扩展实现类并返回。  

#### 1.10.2.2. run()方法运行过程
1. **<font color = "clime">运行流程，分3步：</font>**  
	1. 创建所有Spring运行监听器并发布应用启动事件、准备环境变量、创建容器。 
	2. 容器准备（为刚创建的容器对象做一些初始化工作，准备一些容器属性值等）、刷新容器。 
	3. 执行刷新容器后的后置处理逻辑、调用ApplicationRunner和CommandLineRunner的run方法。  

    ```java
    // SpringApplication.java
    public ConfigurableApplicationContext run(String... args) {
        // 创建并启动计时监控类。new 一个StopWatch用于统计run启动过程花了多少时间
        StopWatch stopWatch = new StopWatch();
        // 开始计时，首先记录了当前任务的名称，默认为空字符串，然后记录当前 Spring Boot 应用启动的开始时间
        stopWatch.start();
        ConfigurableApplicationContext context = null;
        // exceptionReporters集合用来存储异常报告器，用来报告SpringBoot启动过程的异常
        Collection<SpringBootExceptionReporter> exceptionReporters = new ArrayList<>();
        // 配置系统属性headless，即“java.awt.headless”属性，默认为ture
        // 其实是想设置该应用程序,即使没有检测到显示器,也允许其启动.对于服务器来说,是不需要显示器的,所以要这样设置.
        configureHeadlessProperty();
        // 【1】创建所有 Spring 运行监听器并发布应用启动事件
        //从spring.factories配置文件中加载到EventPublishingRunListener对象并赋值给SpringApplicationRunListeners
        // EventPublishingRunListener对象主要用来发布SpringBoot启动过程中内置的一些生命周期事件，标志每个不同启动阶段
        SpringApplicationRunListeners listeners = getRunListeners(args);
        // 启动SpringApplicationRunListener的监听，表示SpringApplication开始启动。
        // 》》》》》发布【ApplicationStartingEvent】事件
        listeners.starting();
        try {
            // 初始化默认应用参数类，封装命令行参数
            // 创建ApplicationArguments对象，封装了args参数
            ApplicationArguments applicationArguments = new DefaultApplicationArguments(args);
            // 【2】准备环境变量，包括系统变量，环境变量，命令行参数，默认变量，servlet相关配置变量，随机值，
            // JNDI属性值，以及配置文件（比如application.properties）等，注意这些环境变量是有优先级的
            // 》》》》》发布【ApplicationEnvironmentPreparedEvent】事件
            ConfigurableEnvironment environment = prepareEnvironment(listeners,applicationArguments);
            // 配置spring.beaninfo.ignore属性，默认为true，即跳过搜索BeanInfo classes.
            configureIgnoreBeanInfo(environment);
            // 【3】控制台打印SpringBoot的bannner标志
            Banner printedBanner = printBanner(environment);
            // 【4】创建容器
            // 根据不同类型创建不同类型的spring applicationcontext容器
            // 因为这里是servlet环境，所以创建的是AnnotationConfigServletWebServerApplicationContext容器对象
            context = createApplicationContext();
            // 【5】准备异常报告器
            // 从spring.factories配置文件中加载异常报告期实例，这里加载的是FailureAnalyzers
            // 注意FailureAnalyzers的构造器要传入ConfigurableApplicationContext，因为要从context中获取beanFactory和environment
            exceptionReporters = getSpringFactoriesInstances(
                    SpringBootExceptionReporter.class,
                    new Class[] { ConfigurableApplicationContext.class }, context); // ConfigurableApplicationContext是AnnotationConfigServletWebServerApplicationContext的父接口
            // 【6】容器准备
            //为刚创建的AnnotationConfigServletWebServerApplicationContext容器对象做一些初始化工作，准备一些容器属性值等
            // 1）为AnnotationConfigServletWebServerApplicationContext的属性AnnotatedBeanDefinitionReader和ClassPathBeanDefinitionScanner设置environgment属性
            // 2）根据情况对ApplicationContext应用一些相关的后置处理，比如设置resourceLoader属性等
            // 3）在容器刷新前调用各个ApplicationContextInitializer的初始化方法，ApplicationContextInitializer是在构建SpringApplication对象时从spring.factories中加载的
            // 4）》》》》》发布【ApplicationContextInitializedEvent】事件，标志context容器被创建且已准备好
            // 5）从context容器中获取beanFactory，并向beanFactory中注册一些单例bean，比如applicationArguments，printedBanner
            // 6）TODO 加载bean到application context，注意这里只是加载了部分bean比如mainApplication这个bean，大部分bean应该是在AbstractApplicationContext.refresh方法中被加载？这里留个疑问先
            // 7）》》》》》发布【ApplicationPreparedEvent】事件，标志Context容器已经准备完成
            prepareContext(context, environment, listeners, applicationArguments,printedBanner);
            // 【7】刷新容器，IOC 容器初始化（如果是 Web 应用还会创建嵌入式的 Tomcat），扫描、创建、加载所有组件
            // 1）在context刷新前做一些准备工作，比如初始化一些属性设置，属性合法性校验和保存容器中的一些早期事件等；
            // 2）让子类刷新其内部bean factory,注意SpringBoot和Spring启动的情况执行逻辑不一样
            // 3）对bean factory进行配置，比如配置bean factory的类加载器，后置处理器等
            // 4）完成bean factory的准备工作后，此时执行一些后置处理逻辑，子类通过重写这个方法来在BeanFactory创建并预准备完成以后做进一步的设置
            // 在这一步，所有的bean definitions将会被加载，但此时bean还不会被实例化
            // 5）执行BeanFactoryPostProcessor的方法即调用bean factory的后置处理器：
            // BeanDefinitionRegistryPostProcessor（触发时机：bean定义注册之前）和BeanFactoryPostProcessor（触发时机：bean定义注册之后bean实例化之前）
            // 6）注册bean的后置处理器BeanPostProcessor，注意不同接口类型的BeanPostProcessor；在Bean创建前后的执行时机是不一样的
            // 7）初始化国际化MessageSource相关的组件，比如消息绑定，消息解析等
            // 8）初始化事件广播器，如果bean factory没有包含事件广播器，那么new一个SimpleApplicationEventMulticaster广播器对象并注册到bean factory中
            // 9）AbstractApplicationContext定义了一个模板方法onRefresh，留给子类覆写，比如ServletWebServerApplicationContext覆写了该方法来创建内嵌的tomcat容器
            // 10）注册实现了ApplicationListener接口的监听器，之前已经有了事件广播器，此时就可以派发一些early application events
            // 11）完成容器bean factory的初始化，并初始化所有剩余的单例bean。这一步非常重要，一些bean postprocessor会在这里调用。
            // 12）完成容器的刷新工作，并且调用生命周期处理器的onRefresh()方法，并且发布ContextRefreshedEvent事件
            refreshContext(context);
            // 【8】应用上下文刷新后置处理，从 IOC 容器中获取所有的 ApplicationRunner 和 CommandLineRunner 进行回调
            afterRefresh(context, applicationArguments);
            // 停止stopWatch计时
            stopWatch.stop();
            // 输出日志记录执行主类名、时间信息
            if (this.logStartupInfo) {
                new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch);
            }
            // 》》》》》发布【ApplicationStartedEvent】事件，标志spring容器已经刷新，此时所有的bean实例都已经加载完毕
            listeners.started(context);
            // 【9】调用ApplicationRunner和CommandLineRunner的run方法，实现spring容器启动后需要做的一些东西比如加载一些业务数据等
            callRunners(context, applicationArguments);
        }
        // 【10】若启动过程中抛出异常，此时用FailureAnalyzers来报告异常
        // 并》》》》》发布【ApplicationFailedEvent】事件，标志SpringBoot启动失败
        catch (Throwable ex) {
            handleRunFailure(context, ex, exceptionReporters, listeners);
            throw new IllegalStateException(ex);
        }

        try {
            // 发布应用上下文就绪事件，触发所有SpringApplicationRunListener 监听器的running事件方法。
            // 》》》》》发布【ApplicationReadyEvent】事件，标志SpringApplication已经正在运行即已经成功启动，可以接收服务请求了。
            listeners.running(context);
        }
        // 若出现异常，此时仅仅报告异常，而不会发布任何事件
        catch (Throwable ex) {
            handleRunFailure(context, ex, exceptionReporters, null);
            throw new IllegalStateException(ex);
        }
        // 【11】最终返回容器
        return context;
    }
    ```
2. **<font color = "clime">`内置生命周期事件：`</font>** <font color = "red">在SpringBoot启动过程中，每个不同的启动阶段会分别发布不同的内置生命周期事件。</font>  
3. **<font color = "clime">`事件回调机制：`</font>** <font color = "red">run()阶段涉及了比较重要的[事件回调机制](/docs/microService/SpringBoot/eventCallback.md)，回调4个监听器（ApplicationContextInitializer、ApplicationRunner、CommandLineRunner、SpringApplicationRunListener）中的方法与加载项目中组件到IOC容器中。</font>  

#### 1.10.2.3. SpringBoot事件监听机制
##### 1.10.2.3.1. 事件监听步骤
&emsp; **<font color = "clime">SpringBoot启动时广播生命周期事件步骤：</font>**    
1. 为广播SpringBoot内置生命周期事件做前期准备：    
    1. 首先加载ApplicationListener监听器实现类；  
    2. 其次加载SPI扩展类EventPublishingRunListener。  
2. SpringBoot启动时利用EventPublishingRunListener广播生命周期事件，然后ApplicationListener监听器实现类监听相应的生命周期事件执行一些初始化逻辑的工作。  
    1. 构建SpringApplication对象时<font color = "red">根据ApplicationListener接口去spring.factories配置文件中加载并实例化监听器。</font>  
    2. 在SpringBoot的启动过程中首先从spring.factories配置文件中加载并实例化EventPublishingRunListener对象。  
    3. 在SpringBoot的启动过程中会发布一系列SpringBoot内置的生命周期事件。  

##### 1.10.2.3.2. 内置生命周期事件
&emsp; **<font color = "clime">SpringBoot内置的7种生命周期事件</font>**  

|发布顺序|事件|用途|
|---|---|---|
|1|ApplicationStartingEvent|在SpringApplication`启动时`但在环境变量Environment或容器ApplicationContext创建前触发，标志SpringApplication开始启动。|
|2|ApplicationEnvironmentPreparedEvent|在SpringApplication`已经开始启动`且环境变量Environment已经准备好时触发，标志环境变量已经准备好。|
|3|ApplicationContextInitializedEvent|ApplicationContextInitilizers的初始化方法已经被调用即从spring.factories中加载的initializers已经执行ApplicationContext初始化逻辑但在bean定义加载前触发，标志Application已经初始化完毕。|
|4|ApplicationPreparedEvent|在Spring容器`刷新refresh前`触发。|
|5|ApplicationStaredEvent|在Spring`容器刷新后`触发，但在调用ApplicationRunner和CommandLineRunner的run方法调用前触发，标志Spring容器已经刷新，此时所有的bean实例等都已经加载了。|
|6|ApplicationReadyEvent|只要SpringApplication可以接收服务请求时即调用完ApplicationRunner和CommandLineRunner的run方法后触发，此时标志SpringApplication已经正在运行，即成功启动。|
|7|ApplicationFailedEvent|若SpringApplicaton`未能成功启动时`则会catch住异常发布ApplicationFailedEvent事件，标志ApplicationFailedEvent启动失败。|


#### 1.10.2.4. SpringBoot事件回调
&emsp; **<font color = "clime">SpringBoot事件回调：</font>**  

* **<font color = "red">ApplicationContextInitializer，IOC容器初始化时被回调；</font>**  
* **<font color = "red">SpringApplicationRunListener，SpringBoot启动过程中多次被回调；</font>**  
* **<font color = "red">ApplicationRunner，容器启动完成后被回调；</font>**  
* **<font color = "red">CommandLineRunner，ApplicationRunner之后被回调。</font>**  

### 1.10.3. SpringBoot自动配置
&emsp; 包含两部分：1. 注解@SpringBootApplication；2. 加载自动配置流程。


#### 1.10.3.1. 注解@SpringBootApplication（启动对象）
1. @SpringBootApplication  
    * @ComponentScan  
    * @SpringBootConfiguration  
    * @EnableAutoConfiguration  
2. @EnableAutoConfiguration使用@Import将所有符合自动配置条件的bean定义加载到IOC容器。   
    1. @Import({AutoConfigurationImportSelector.class})，开启自动配置，导入了AutoConfigurationImportSelector类。  
    2. AutoConfigurationImportSelector#getCandidateConfigurations()方法获取配置文件spring.factories所有候选的配置，剔除重复部分，再剔除@SpringbootApplication注解里exclude的配置，才得到最终的配置类名集合。  


#### 1.10.3.2. 加载自动配置流程
1. `启动对象的注入`：在SpringBoot启动流程的`容器准备阶段`prepareContext()会将@SpringBootApplication--->@Component对象注册到容器中。  
2. `自动装配入口`，从SpringBoot启动流程的`刷新容器阶段`refresh()开始。 

#### 1.10.3.3. 内置Tomcat
1. SpringBoot内置Tomcat，可以对比SpringBoot自动配置运行流程了解。  
2. Tomcat的自动装配：自动装配过程中，Web容器所对应的自动配置类为ServletWebServerFactoryAutoConfiguration，该类导入了EmbeddedTomcat，EmbeddedJetty，EmbeddedUndertow三个类，可以根据用户的需求去选择使用哪一个web服务器，默认情况下使用的是tomcat。  
3. Tomcat的启动：在容器刷新refreshContext(context)步骤完成。  

### 1.10.4. 自定义strater
1. 第一步，创建maven项目  
	1. 命名潜规则  
	&emsp; spring-boot-starter-XX是springboot官方的starter；XX-spring-boot-starter是第三方扩展的starter。
	2. 项目pom文件
2. `第二步，写自动配置逻辑`
	1. 编写业务逻辑  
	2. 定义配置文件对应类  
    	* @ConfigurationProperties 配置属性文件，需要指定前缀 prefix。
    	* @EnableConfigurationProperties 启用配置，需要指定启用的配置类。
    	* @NestedConfigurationProperty 当一个类中引用了外部类，需要在该属性上加该注解。
	3. 定义自动配置类，自动暴露功能接口。  
3. 第三步，应用加载starter的配置，有两种方式：主动加载、被动加载。  


## 1.11. SpringCloud
&emsp; **<font color = "clime">Spring Cloud各组件运行流程：</font>**  
1. 外部或者内部的非Spring Cloud项目都统一通过微服务网关(Zuul)来访问内部服务。客户端的请求首先经过负载均衡(Ngnix)，再到达服务网关(Zuul集群)；  
2. 网关接收到请求后，从注册中心(Eureka)获取可用服务；  
3. 由Ribbon进行负载均衡后，分发到后端的具体实例；  
4. 微服务之间也可通过Feign进行通信处理业务；  
5. Hystrix负责处理服务超时熔断；Hystrix dashboard，Turbine负责监控Hystrix的熔断情况，并给予图形化的展示；  
6. 服务的所有的配置文件由配置服务管理，配置服务的配置文件放在git仓库，方便开发人员随时改配置。  

### 1.11.1. Eureka
1. 服务治理框架和产品都围绕着服务注册与服务发现机制来完成对微服务应用实例的自动化管理。  
2. Spring Cloud Eureka，使用Netflix Eureka来实现服务注册与发现，它既包含了服务端组件，也包含了客户端组件。  
3. Eureka服务治理体系包含三个核心角色：服务注册中心、服务提供者以及服务消费者。  
    * 服务提供者  
    &emsp; 服务同步、服务续约。
    * 服务消费者    
    &emsp; 荻取服务、服务调用、服务下线。
    * 服务注册中心  
        * 失效剔除  
        * 自我保护：  
        &emsp; 开启自我保护后，Eureka Server在运行期间，会统计心跳失败的比例在15分钟之内是否低于85%，如果出现低于的情况（在单机调试的时候很容易满足，实际在生产环境上通常是由于网络不稳定导致），Eureka Server会将当前的实例注册信息保护起来，让这些实例不会过期，尽可能保护这些注册信息。  
        &emsp; Eureka Server进入自我保护状态后，客户端很容易拿到实际已经不存在的服务实例，会出现调用失败的清况。  
4. <font color = "red">高可用注册中心/AP模型：EurekaServer的高可用实际上就是将自己作为服务向其他服务注册中心注册自己，这样就可以形成一组互相注册的服务注册中心，以实现服务清单的互相同步，达到高可用的效果。</font>  


### 1.11.2. Ribbon
&emsp; 负载均衡大体可以分为两类：集中式、进程内。前者也被称为服务端负载均衡，其一般位于服务集群的前端，统一接收、处理、转发客户端的请求。典型地包括F5硬件、LVS、Nginx等技术方案；而后者也被称为客户端负载均衡，其是在客户端侧根据某种策略选择合适的服务实例直接进行请求，其典型代表有Ribbon。  

### 1.11.3. Feign



### 1.11.4. Zuul
1. Spring Cloud Zuul，微服务网关，包含hystrix、ribbon、actuator。主要有路由转发、请求过滤功能。  
2. **<font color = "red">Zuul提供了四种过滤器的API，分别为前置（Pre）、路由（Route）、后置（Post）和错误（Error）四种处理方式。</font>**  
3. 动态加载：  
&emsp; 作为最外部的网关，它必须具备动态更新内部逻辑的能力，比如动态修改路由规则、动态添加／删除过滤器等。  
&emsp; 通过Zuul实现的API网关服务具备了动态路由和动态过滤器能力，可以在不重启API网关服务的前提下为其动态修改路由规则和添加或删除过滤器。   


### 1.11.5. Hytrix
1. 服务雪崩：在微服务架构中，存在着那么多的服务单元，若一个单元出现故障，就很容易因依赖关系而引发故障的蔓延，最终导致整个系统的瘫痪。  
2. Hystrix工作流程：1. 包装请求 ---> 2. 发起请求 ---> 3. 缓存处理 ---> 4. 判断断路器是否打开（熔断） ---> 5. 判断是否进行业务请求（请求是否需要隔离或降级） ---> 6. 执行业务请求 ---> 7. 健康监测 ---> 8. fallback处理或返回成功的响应。  
3. 熔断是一种[降级](/docs/microService/thinking/Demotion.md)策略。Hystrix中的降级方案：熔断触发降级、请求超时触发降级、资源（信号量、线程池）隔离触发降级 / 依赖隔离。  
  1. <font color = "clime">熔断的对象是服务之间的请求；`熔断策略有根据请求的数量分为信号量和线程池，还有请求的时间（即超时熔断），请求错误率（即熔断触发降级）。`</font>  
  2. 线程池隔离与信号量隔离  
    1. 线程池隔离：请求线程和每个服务单独用线程池。
      &emsp; 比如现在有3个业务调用分别是查询订单、查询商品、查询用户，且这三个业务请求都是依赖第三方服务-订单服务、商品服务、用户服务。`为每一个服务接口单独开辟一个线程池，`保持与其他服务接口线程的隔离，提高该服务接口的独立性和高可用。    
      2. 优点：  
        1. 使用线程池隔离可以完全隔离依赖的服务，请求线程可以快速放回。  
        2. 当线程池出现问题时，线程池隔离是独立的，不会影响其他服务和接口。  
        3. 当失败的服务再次变得可用时，线程池将清理并可立即恢复，而不需要一个长时间的恢复。  
        4. 独立的线程池提高了并发性。    
      3. 缺点：  
        1. 线程池隔离的主要缺点是它们增加计算开销（CPU）。每个命令的执行涉及到排队、调度和上下文切换都是在一个单独的线程上运行的。    
    1. ~~线程池隔离：~~  
      1. 调用线程和hystrixCommand线程不是同一个线程，并发请求数受到线程池（不是容器tomcat的线程池，而是hystrixCommand所属于线程组的线程池）中的线程数限制，默认是10。
      2. 这个是默认的隔离机制
      3. hystrixCommand线程无法获取到调用线程中的ThreadLocal中的值
    2. 信号量隔离：
      1. 调用线程和hystrixCommand线程是同一个线程，默认最大并发请求数是10  
      2. 调用数度快，开销小，由于和调用线程是处于同一个线程，所以必须确保调用的微服务可用性足够高并且返回快才用  
    3. 什么情况下使用线程池隔离/信号量隔离？  
      * 请求并发量大，并且耗时长（请求耗时长一般是计算量大，或读数据库）：采用线程池隔离策略，这样的话，可以保证大量的容器（tomcat）线程可用，不会由于服务原因，一直处于阻塞或等待状态，快速失败返回。  
      * 请求并发量大，并且耗时短（请求耗时长一般是计算量大，或读缓存）：采用信号量隔离策略，因为这类服务的返回通常会非常的快，不会占用容器线程太长时间，而且也减少了线程切换的一些开销，提高了缓存服务的效率。  
4. <font color = "clime">微服务集群中，Hystrix的度量信息通过`Turbine`来汇集监控信息，并将聚合后的信息提供给Hystrix Dashboard来集中展示和监控。</font> 


### 1.11.6. Sleuth
1. 分布式调用链追踪系统，可以解决的问题：  
    **<font color = "red">(1) 如何快速定位请求异常；</font>**    
    **<font color = "red">(2) 如何快速定位性能瓶颈；</font>**  
    **<font color = "red">(3) 如何快速定位不合理调用；</font>**  
2. **<font color = "red">埋点日志通常包含：traceId、spanId、调用的开始时间，协议类型、调用方ip和端口，请求的服务名、调用耗时，调用结果，异常信息等，同时预留可扩展字段，为下一步扩展做准备；</font>**  
3. spring-cloud-starter-sleuth功能点：
    1. 有关traceId：获取当前traceId、日志获取traceId、传递traceId到异步线程池、子线程或线程池中获取Zipkin traceId并打印。  
    2. sleuth自定义信息。增加自定义属性、添加自定义Tag标签。  
    3. 监控本地方法：异步执行和远程调用都会新开启一个Span，如果想监控本地的方法耗时时间，可以采用埋点的方式监控本地方法，也就是开启一个新的Span。  
    4. ...  


### 1.11.7. Admin
1. spring-boot-starter-actuator依赖中已经实现的一些原生端点。根据端点的作用，<font color = "clime">可以将原生端点分为以下三大类：</font>  
    * 应用配置类：获取应用程序中加载的应用配置、环境变量、自动化配置报告等与Spring Boot应用密切相关的配置类信息。  
    * 度量指标类：获取应用程序运行过程中用于监控的度量指标，比如内存信息、线程池信息、HTTP请求统计等。  
    * 操作控制类：提供了对应用的关闭等操作类功能。  
2. 监控通知
3. 集成spring security


## 1.12. Dubbo
### 1.12.1. 分布式服务治理
#### 1.12.1.1. Dubbo和Spring Cloud
1. 两个框架在开始目标就不一致：<font color = "red">Dubbo定位服务治理；Spirng Cloud是一个生态。</font>  
    * Dubbo是SOA时代的产物，它的关注点主要在于服务的调用，流量分发、流量监控和熔断。  
    * Spring Cloud诞生于微服务架构时代，考虑的是微服务治理的方方面面，另外由于依托了Spirng、Spirng Boot的优势之上。  
2. <font color = "red">Dubbo底层是使用Netty这样的NIO框架，是基于TCP协议传输的，配合以Hession序列化完成RPC通信。</font><font color = "clime">而SpringCloud是基于Http协议+Rest接口调用远程过程的通信，</font>相对来说，Http请求会有更大的报文，占的带宽也会更多。但是REST相比RPC更为灵活，服务提供方和调用方的依赖只依靠一纸契约，不存在代码级别的强依赖，这在强调快速演化的微服务环境下，显得更为合适，至于注重通信速度还是方便灵活性，具体情况具体考虑。  

#### 1.12.1.2. Spring Cloud Alibaba介绍  
1. Spring Cloud与Dubbo的比较本身是不公平的，主要前者是一套较为完整的架构方案，而Dubbo只是服务治理与RPC实现方案。Spring Cloud Alibaba是阿里巴巴提供的微服务开发一站式解决方案，是阿里巴巴开源中间件与 Spring Cloud体系的融合。   
2. 集成 Spring Cloud 组件： **<font color = "clime">Spring Cloud Alibaba作为整套的微服务解决组件，只依靠目前阿里的开源组件是不够的，更多的是集成当前的社区组件，所以 Spring Cloud Alibaba 可以集成 Zuul，OpenFeign等网关，也支持 Spring Cloud Stream消息组件。</font>**  
3. **<font color = "clime">使用@DubboTransported 注解可将底层的 Rest 协议无缝切换成 Dubbo RPC 协议，进行 RPC 调用。</font>**  
4. Spring Cloud Alibaba 基于 Nacos 提供 spring-cloud-alibaba-starter-nacos-discovery & spring-cloud-alibaba-starter-nacos-config 实现了服务注册 & 配置管理功能。  
&emsp; 使用 Seata 解决微服务场景下面临的分布式事务问题。  

### 1.12.2. RPC介绍
&emsp; ......  


### 1.12.3. Dubbo介绍
1. Dubbo的工作原理：  
    1. 服务启动的时候，provider和consumer根据配置信息，连接到注册中心register，分别向注册中心注册和订阅服务。  
    2. register根据服务订阅关系，返回provider信息到consumer，同时consumer会把provider信息缓存到本地。如果信息有变更，consumer会收到来自register的推送。  
    3. consumer生成代理对象，同时根据负载均衡策略，选择一台provider，同时定时向monitor记录接口的调用次数和时间信息。  
    4. **<font color = "clime">拿到代理对象之后，consumer通过`代理对象`发起接口调用。</font>**  
    5. provider收到请求后对数据进行反序列化，然后通过代理调用具体的接口实现。  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/Dubbo/dubbo-52.png)   
2. **<font color = "red">为什么要通过代理对象通信？</font>**    
    &emsp; dubbo实现接口的透明代理，封装调用细节，让用户可以像调用本地方法一样调用远程方法，同时还可以通过代理实现一些其他的策略，比如：负载、降级等。让用户可以像调用本地方法一样调用远程方法，同时还可以通过代理实现一些其他的策略，比如：  
    1. 调用的负载均衡策略  
    2. 调用失败、超时、降级和容错机制  
    3. 做一些过滤操作，比如加入缓存、mock数据  
    4. 接口调用数据统计  

### 1.12.4. Dubbo框架设计
1. 分层架构设计  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/Dubbo/dubbo-51.png)  
    1. 从大的范围来说，dubbo分为三层：
        * business业务逻辑层由开发人员来提供接口和实现，还有一些配置信息。
        * `RPC层就是真正的RPC调用的核心层，封装整个RPC的调用过程、负载均衡、集群容错、代理。`
        * remoting则是对网络传输协议和数据转换的封装。  
    2. RPC层包含配置层config、代理层proxy、服务注册层register、路由层cluster、监控层monitor、远程调用层protocol。    
        1. **<font color = "red">`服务代理层proxy`：服务接口透明代理，生成服务的客户端Stub和服务器端Skeleton，以ServiceProxy为中心，扩展接口为ProxyFactory。</font>**  
        &emsp; **<font color = "red">Proxy层封装了所有接口的透明化代理，而在其它层都以Invoker为中心，</font><font color = "blue">只有到了暴露给用户使用时，才用Proxy将Invoker转成接口，或将接口实现转成 Invoker，也就是去掉Proxy层RPC是可以Run的，只是不那么透明，不那么看起来像调本地服务一样调远程服务。</font>**  
        &emsp; dubbo实现接口的透明代理，封装调用细节，让用户可以像调用本地方法一样调用远程方法，同时还可以通过代理实现一些其他的策略，比如：负载、降级......  
        2. **<font color = "red">`远程调用层protocol`：封装RPC调用，以Invocation, Result为中心，扩展接口为Protocol, Invoker, Exporter。</font>**  
    3. remoting层：  
        1. 网络传输层：抽象mina和netty为统一接口，以Message为中心，扩展接口为Channel, Transporter, Client, Server, Codec。  
        2. 数据序列化层：可复用的一些工具，扩展接口为Serialization, ObjectInput, ObjectOutput, ThreadPool。  
2. ~~总体调用过程~~  


### 1.12.5. 暴露和引用服务
1. 解析服务：  
&emsp; **<font color = "clime">基于dubbo.jar内的META-INF/spring.handlers配置，Spring在遇到dubbo名称空间时，会回调DubboNamespaceHandler。所有dubbo的标签，都统一用DubboBeanDefinitionParser进行解析，基于一对一属性映射，将XML标签解析为Bean对象。</font>**  
&emsp; ⚠️注：`在暴露服务ServiceConfig.export()或引用服务ReferenceConfig.get()时，会将Bean对象转换URL格式，所有Bean属性转成URL的参数。`然后将URL传给协议扩展点，基于扩展点的扩展点自适应机制，根据URL的协议头，进行不同协议的服务暴露或引用。  
2. **服务提供者暴露服务的主过程：** `参考dubbo架构分层`，`主要分4步`。    
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/Dubbo/dubbo-29.png)   
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/Dubbo/dubbo-53.png)   
    1. ServiceConfig将Bean对象解析成URL格式。  
    2. 通过ProxyFactory类的getInvoker方法使用ref(实际类)生成一个AbstractProxyInvoker实例。`ProxyFactory #getInvoker(T proxy, Class<T> type, URL url)`  
    3. 通过Protocol(协议)类的export方法暴露服务。`DubboProtocol #export(Invoker<T> invoker)`  
        1. 本地各种协议暴露。  
        2. 注册中心暴露。  
    4. 如果通过注册中心暴露服务，RegistryProtocol保存URL地址和invoker的映射关系，同时注册到服务中心。  
3. **服务消费者引用服务的主过程：** `与服务暴露相反` 
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/Dubbo/dubbo-30.png)   
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/Dubbo/dubbo-54.png)   
    1. ReferenceConfig解析引用的服务。  
    2. ReferenceConfig类的init方法调用Protocol的refer方法生成Invoker实例。  
    3. 把Invoker转换为客户端需要的接口。  

### 1.12.6. 服务调用
#### 1.12.6.1. 服务调用介绍


#### 1.12.6.2. Dubbo序列化和协议
1. 不同服务在性能上适用不同协议进行传输，比如`大数据用短连接协议`，`小数据大并发用长连接协议`。  
2. 默认使用Hessian序列化，还有Duddo、FastJson、Java自带序列化。   

##### 1.12.6.2.1. Dubbo协议长连接
&emsp; Dubbo缺省协议采用单一长连接和NIO异步通讯，适合于小数据量大并发的服务调用，以及服务消费者机器数远大于服务提供者机器数的情况。  
&emsp; 注意：Dubbo缺省协议不适合传送大数据量的服务，比如传文件，传视频等，除非请求量很低。  
&emsp; Dubbo协议采用长连接，还可以防止注册中心宕机风险。  


### 1.12.7. Dubbo集群容错
1. 负载均衡
2. 集群容错策略
3. 服务降级

### 1.12.8. 扩展点加载(SPI)
1. **<font color = "clime">Dubbo改进了JDK标准的SPI的以下问题：</font>**  
    * JDK标准的SPI会一次性实例化扩展点所有实现。  
    * 如果扩展点加载失败，连扩展点的名称都拿不到了。  
    * 增加了对扩展点IoC和AOP的支持，一个扩展点可以直接setter注入其它扩展点。  
2. 扩展点特性
    * 扩展点自动包装，Wrapper机制
    * 扩展点自动装配
    * 扩展点自适应
    * 扩展点自动激活

## 1.13. Zookeeper
&emsp; **<font color = "clime">Zookeeper是一个分布式协调服务的开源框架。主要用来解决分布式集群中应用系统的一致性问题。</font>**  

### 1.13.1. ZK服务端
1. `ZK服务端`通过`ZAB协议`保证`数据顺序一致性`。  
    1. ZAB协议：
        1. Zookeeper集群角色：  
            * 领导者Leader：同一时间，集群只允许有一个Leader，提供对客户端的读写功能，负责将数据同步至各个节点；  
            * 跟随者Follower：提供对客户端读功能，写请求则转发给Leader处理，当Leader崩溃失联之后参与Leader选举；  
            * 观察者Observer：与Follower不同的是但不参与Leader选举。  
        2. **<font color = "clime">崩溃恢复</font>**  
            * 服务器启动时的leader选举：每个server发出投票，投票信息包含(myid, ZXID,epoch)；接受投票；处理投票(epoch>ZXID>myid)；统计投票；改变服务器状态。</font>  
            * 运行过程中的leader选举：变更状态 ---> 发出投票 ---> 处理投票 ---> 统计投票 ---> 改变服务器的状态。
        3. **<font color = "clime">`消息广播（数据读写流程，读写流程）：`</font>**  
            &emsp; 在zookeeper中，客户端会随机连接到zookeeper集群中的一个节点。    
            * 如果是读请求，就直接从当前节点中读取数据。  
            * 如果是写请求，那么请求会被转发给 leader 提交事务，然后leader会广播事务，只要有超过半数节点写入成功，那么写请求就会被提交。   
            &emsp; ⚠️注：leader向follower写数据详细流程：类2pc(两阶段提交)。  
    2. 数据一致性  
        &emsp; **<font color = "red">Zookeeper保证的是CP，即一致性(Consistency)和分区容错性(Partition-Tolerance)，而牺牲了部分可用性(Available)。</font>**  
        * 为什么不满足AP模型？<font color = "red">zookeeper在选举leader时，会停止服务，直到选举成功之后才会再次对外提供服务。</font>
        * Zookeeper的CP模型：非强一致性， **<font color = "clime">而是单调一致性/顺序一致性。</font>**  
            1. <font color = "clime">假设有2n+1个server，在同步流程中，leader向follower同步数据，当同步完成的follower数量大于n+1时同步流程结束，系统可接受client的连接请求。</font><font color = "red">如果client连接的并非同步完成的follower，那么得到的并非最新数据，但可以保证单调性。</font> 未同步数据的情况，Zookeeper提供了同步机制（可选型），类似回调。   
            2. follower接收写请求后，转发给leader处理；leader完成两阶段提交的机制。向所有server发起提案，当提案获得超过半数(n+1)的server认同后，将对整个集群进行同步，超过半数(n+1)的server同步完成后，该写请求完成。如果client连接的并非同步完成follower，那么得到的并非最新数据，但可以保证单调性。  
2. 服务端脑裂：过半机制，要求集群内的节点数量为2N+1。  

### 1.13.2. ZK客户端
&emsp; zookeeper引入了`watcher机制`来实现`客户端和服务端`的发布/订阅功能。  
1. ~~Watcher机制运行流程：Zookeeper客户端向服务端的某个Znode注册一个Watcher监听，当服务端的一些指定事件触发了这个Watcher，服务端会向指定客户端发送一个事件通知来实现分布式的通知功能，然后客户端根据Watcher通知状态和事件类型做出业务上的改变。  
&emsp; 触发watch事件种类很多，如：节点创建，节点删除，节点改变，子节点改变等。~~  
&emsp; 概括可以分为三个过程：1. 客户端注册 Watcher；2. 服务端处理 Watcher；3. 客户端回调 Watcher。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/zookeeper/zk-5.png)  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/zookeeper/zk-6.png)  
&emsp; 大致流程就是 Client 向ZK中注册 Watcher，如果注册成功的话，会将对应的 Watcher 存储在本地。当ZK服务器端触发 Watcher 事件之后，会向客户端发送通知，客户端会从 ClientWatchManager 中取出对应的 Watcher 进行回调。  
2.  **watch的重要特性：**  
    * 异步发送
    * 一次性触发：  
    &emsp; Watcher通知是一次性的， **<font color = "clime">即一旦触发一次通知后，该Watcher就失效了，因此客户端需要反复注册Watcher。</font>** 但是在获取watch事件和设置新的watch事件之间有延迟。延迟为毫秒级别，理论上会出现不能观察到节点的每一次变化。  
    &emsp; `不支持用持久Watcher的原因：如果Watcher的注册是持久的，那么必然导致服务端的每次数据更新都会通知到客户端。这在数据变更非常频繁且监听客户端特别多的场景下，ZooKeeper无法保证性能。`  
    * 有序性：  
    &emsp; 客户端先得到watch通知才可查看节点变化结果。  
3. 客户端过多，会引发网络风暴。  

### 1.13.3. ZK弊端和应用场景
5. ZK的弊端：
	1. 服务端从节点多，主从同步慢。  
	2. 客户端多，`网络风暴`。~~watcher机制中，回调流程，只有主节点参与？~~  
6. Zookeeper应用场景：统一命名服务，生成分布式ID、分布式锁、队列管理、元数据/配置信息管理，数据发布/订阅、分布式协调、集群管理，HA高可用性。  


## 1.14. 分布式
### 1.14.1. 分布式理论CAP
1. CAP：一致性(Consistency)、可用性(Availability)、分区容错性(Partition tolerance)。  
&emsp; 一致性模型：强一致性、弱一致性、最终一致性、单调一致性/顺序一致性、会话一致性。  
2. BASE：**是Basically Available(基本可用)、Soft state(软状态)和Eventually consistent(最终一致性)三个短语的缩写。<font color = "red">`BASE是对CAP中AP的一个扩展`，是对CAP中一致性和可用性权衡的结果。</font>**  
3. **<font color = "blue">无处不在的CAP的C</font>**  
&emsp; 只要是分布式或集群，甚至一个接口中处在不同事务的调用，都会有数据一致性的问题。 例如Mysql主从复制、binlog和redolog的两阶段提交......  

### 1.14.2. 分布式ID
1. 分布式ID的基本生成方式有：UUID，数据库方式（主键自增、序列号、<font color = "clime">号段模式</font>），<font color = "red">redis、ZK等中间件，雪花算法。</font>  
    * 数据库Oracle中有序列SEQUENCE；在Mysql中可以建一张伪序列号表。  
    * 号段模式可以理解为从数据库批量的获取自增ID，每次从数据库取出一个号段范围。  
2. snowflake算法：  
    1. snowflake算法所生成的ID结构：正数位(占1比特)+ 时间戳(占41比特)+ 机器ID(占5比特)+ 数据中心(占5比特)+ `自增值(占12比特)`，总共64比特组成的一个Long类型。可以根据自身业务特性分配bit位，非常灵活。
    2. ID呈趋势递增。  
    3. **snowflake算法缺点：** <font color="red">依赖于系统时钟的一致性。如果某台机器的系统时钟回拨，有可能造成ID冲突，或者ID乱序。</font>  
    &emsp; 百度UidGenerator如果时间有任何的回拨，那么直接抛出异常。此外UidGenerator通过消费未来时间克服了雪花算法的并发限制。   
    4. **<font color = "clime">时钟回拨问题解决方案：</font>**    
    &emsp; **<font color = "red">雪花算法中，第53-64的bit位：这12位表示序列号，也就是单节点1毫秒内可以生成2^12=4096个不同的ID。发生时钟回拨：</font>**  
        1. 抛异常。  
        2. `可以对给定的基础序列号稍加修改，后面每发生一次时钟回拨就将基础序列号加上指定的步长，`例如开始时是从0递增，发生一次时钟回拨后从1024开始递增，再发生一次时钟回拨则从2048递增，这样还能够满足3次的时钟回拨到同一时间点（发生这种操作就有点扯了）。  
        3. 当业务不是很繁忙，可以将12位序列号预留两位。2位的扩展位允许有3次大的时钟回拨，如果其超过三次可以打印异常。  


### 1.14.3. 分布式事务
#### 1.14.3.1. 事务模型DTP及XA
1. X/Open DTP中的角色：应用程序、事务管理器（能够提供单数据源的事务能力，它们通过XA接口，将本数据库的提交、回滚等能力提供给事务管理器调用）、资源管理器、XA接口。   
2. **2PC：**  
   &emsp; <font color = "clime">二阶段提交将分布式事务的提交拆分为2个阶段：准备阶段prepare和提交阶段commit/rollback。</font>  
   &emsp; 尽量(不能100%)保证了数据的强一致，适合对数据强一致要求很高的关键领域。  
   &emsp; **XA二阶段问题：** 
   1. 单点故障问题。  
   2. 同步阻塞问题。执行过程中，所有参与节点都是事务阻塞型的。`当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。` 
   3. 丢失消息导致的数据不一致问题。在二阶段提交的阶段二中，<font color = "clime">当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送commit请求过程中协调者发生了故障，这会导致只有一部分参与者接受到了commit请求。</font>  
   4. 二阶段无法解决的问题：协调者和参与者同时宕机。  
3. **3PC：解决2PC的问题。**  
    1. 3PC也就是多了一个阶段(一个询问的阶段)，分别是准备、预提交和提交这三个阶段。  
        1. 准备阶段单纯就是协调者去访问参与者，类似于“你还好吗？能接请求不”。  
        2. 预提交其实就是2PC的准备阶段，除了事务的提交啥都干了。  
        3. 提交阶段和2PC的提交一致。
    2. **XA三阶段特点：<font color = "clime">3PC的引入降低了参与者的阻塞范围，解决协调者和参与者同时挂掉的问题，减少了数据不一致的情况。</font>**  
        1. `解决单点故障问题，引入超时机制。` **<font color = "red">同时在协调者和参与者中都引入超时机制。一旦事物参与者迟迟没有接到协调者的commit请求，`会自动进行本地commit`。3PC追求的是最终一致性。这样也有效解决了协调者单点故障的问题。</font>**  
        2. <font color = "clime">超时机制也降低了参与者的阻塞范围，因为参与者不会一直持有事务资源并处于阻塞状态。</font>  
        3. <font color = "red">数据不一致问题依然存在。</font>当参与者收到preCommit请求后等待do commite指令时，此时如果协调者请求`中断事务`，而协调者无法与参与者正常通信，会导致参与者继续提交事务，造成数据不一致。  

#### 1.14.3.2. TCC
##### 1.14.3.2.1. TCC流程
1. **<font color = "red">TCC是一种`业务层面或者是应用层`的`两阶段、补偿型`的事务。</font>**  
2. TCC是`Try（检测及资源锁定或者预留）`、Commit（确认）、Cancel（取消）的缩写，业务层面需要写对应的三个方法。  
    一个支付订单的场景  
    * Try
        * 订单服务，订单状态修改为 UPDATING，也就是修改中的意思
        * 库存服务，别直接扣减库存，可以冻结掉库存。
        * 积分服务，别直接给用户增加会员积分，可以先在积分表里的一个预增加积分字段加入积分。
    * Confirm/Cancel
        * 订单服务，
        * 库存服务，
        * 积分服务，
3. TCC与二阶段比较  
&emsp; 使用2PC机制时————以提交为例————一个完整的事务生命周期是：begin -> 业务逻辑 -> prepare -> commit。  
&emsp; 使用TCC机制时————以提交为例————一个完整的事务生命周期是：begin -> 业务逻辑(try业务) -> commit(comfirm业务)。  
&emsp; 综上，可以从执行的阶段上将二者一一对应起来：  
&emsp; 1、2PC机制的业务阶段 等价于 TCC机制的try业务阶段；  
&emsp; 2、2PC机制的提交阶段（prepare & commit） 等价于 TCC机制的提交阶段（confirm）；  
&emsp; 3、2PC机制的回滚阶段（rollback） 等价于 TCC机制的回滚阶段（cancel）。  
&emsp; 因此，可以看出，虽然TCC机制中有两个阶段都存在业务逻辑的执行，但其中 `try业务阶段其实是与全局事务处理无关的`。认清了这一点，当再比较TCC和2PC时，就会很容易地发现，`TCC不是两阶段提交，而只是它对事务的提交/回滚是通过执行一段confirm/cancel业务逻辑来实现，仅此而已。`  

##### 1.14.3.2.2. TCC问题
&emsp; 在微服务架构下，很有可能出现网络超时、重发，机器宕机等一系列的异常情况。一旦遇到这些情况，就会导致分布式事务执行过程出现异常。  

* 允许空回滚
	* 产生：注册分支事务是在调用 RPC 时，Seata 框架的切面会拦截到该次调用请求， **<font color = "red">先向 TC 注册一个分支事务，然后才去执行 RPC 调用逻辑。如果 RPC 调用逻辑有问题，`比如调用方机器宕机、网络异常，都会造成 RPC 调用失败，即未执行 Try 方法。但是分布式事务已经开启了，需要推进到终态，因此，TC 会回调参与者二阶段 Cancel 接口，从而形成空回滚。`</font>**  
	* 解决方案： **<font color = "clime">需要一张额外的事务控制表，其中有分布式事务 ID 和分支事务 ID，第一阶段 Try 方法里会插入一条记录，表示一阶段执行了。Cancel 接口里读取该记录，如果该记录存在，则正常回滚；如果该记录不存在，则是空回滚。</font>**  
* 接口幂等
	* 产生
	* 解决方案：在事务控制表上加一个状态字段，用来记录每个分支事务的执行状态。
* 防止资源悬挂
	* 产生： **<font color = "clime">因为允许空回滚的原因，Cancel 接口认为 Try 接口没执行，空回滚直接返回成功，对于 Seata 框架来说，认为分布式事务的二阶段接口已经执行成功，整个分布式事务就结束了。但是这之后 Try 方法才真正开始执行，预留业务资源，前面提到事务并发控制的业务加锁，对于一个 Try 方法预留的业务资源，只有该分布式事务才能使用，然而 Seata 框架认为该分布式事务已经结束，也就是说，当出现这种情况时，该分布式事务第一阶段预留的业务资源就再也没有人能够处理了，对于这种情况，我们就称为悬挂，即业务资源预留后没法继续处理。</font>**    
	&emsp; **<font color = "clime">什么样的情况会造成悬挂呢？按照前面所讲，在 RPC 调用时，先注册分支事务，再执行 RPC 调用，如果此时 RPC 调用的网络发生拥堵，通常 RPC 调用是有超时时间的，RPC 超时以后，发起方就会通知 TC 回滚该分布式事务，可能回滚完成后，RPC 请求才到达参与者，真正执行，从而造成悬挂。</font>**  
	* 解决方案：`可以在二阶段执行时插入一条事务控制记录，状态为已回滚，这样当一阶段执行时，先读取该记录，如果记录存在，就认为二阶段已经执行；否则二阶段没执行。`   

#### 1.14.3.3. Saga
1. Saga是一种解决长事务的分布式事务方案。Saga模型将一个分布式事务拆分为多个本地事务，也是一种二阶段补偿性事务（⚠️`注：二阶段提交和二阶段补偿的区别`）。  
2. Saga执行流程：  
    1. Saga有两种执行方式：  
        * 编排（Choreography）：每个服务产生并聆听其他服务的事件，并决定是否应采取行动。  
        &emsp; 该实现第一个服务执行一个事务，然后发布一个事件。该事件被一个或多个服务进行监听，这些服务再执行本地事务并发布(或不发布)新的事件，当最后一个服务执行本地事务并且不发布任何事件时，意味着分布式事务结束，或者它发布的事件没有被任何Saga参与者听到都意味着事务结束。  
        * 控制（Orchestration）：saga协调器orchestrator以命令/回复的方式与每项服务进行通信，告诉服务应该执行哪些操作。  
    2. 有两种恢复策略：  
        * <font color = "red">backward recovery，向后恢复，补偿所有已完成的事务。</font>  
        * <font color = "red">forward recovery，向前恢复，重试失败的事务，假设每个子事务最终都会成功。</font>  
3. **<font color = "blue">Saga和TCC比较：</font>**  
    1. **<font color = "red">Saga没有“预留”Try行为，（直接进入终态），每个子事务(本地事务)依次执行提交阶段，所以会留下原始事务操作的痕迹，</font>** Cancel属于不完美补偿，需要考虑对业务上的影响。  
    2. Saga和TCC一样需要注意3个问题：1)保持幂等性；2)允许空补偿；3)防止资源悬挂。

#### 1.14.3.4. 消息模式
1. **基于本地消息表：**  
&emsp; 基本思想：调用方存储业务表和消息表；调用其他服务，如果成功修改消息表状态， **<font color = "clime">如果失败发起重试（重试方式可以基于定时任务、mq等）。</font>**    
2. **基于事务消息：** ~~相比于最终一致性方案可靠性高，但也非强一致性。~~   
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/problems/problem-48.png)  
    1. 调用方开启消息事务；
    2. 发送消息；
    3. 调用方执行本地事务；  
    4. 调用方提交或回滚事务消息。
3. **最大努力通知方案和可靠消息最终一致性方案的区别：**  
&emsp; 可靠消息最终一致性方案可以保证的是只要系统A的事务完成，通过不停(无限次)重试来保证系统B的事务总会完成。但是最大努力方案就不同，如果系统B本地事务执行失败了，那么它会重试N次后就不再重试，系统B的本地事务可能就不会完成了。  

#### 1.14.3.5. 分布式事务的选型
&emsp; 分布式事务的选型：(`~~判断事务发起方与事务被调用方的关系、数据一致的要求、性能~~`)  
* **<font color = "clime">`事务被调用方跟随事务发起方，使用最终一致性的消息事务；`(基于消息实现的事务适用于分布式事务的提交或回滚只取决于事务发起方的业务需求)</font>** `例如消费长积分`  
* **<font color = "clime">`事务被调用方与事务发起方协助完成功能，使用补偿性事务；`</font>** `例如库存服务和支付服务` 
    * 事务被调用方与事务发起方`协助完成`功能，事务被调用方与事务发起方的数据保持一致性，使用强一致性的TCC；  
    * SAGA可以看做一个异步的、利用队列实现的补偿事务。<font color = "red">适用于不需要同步返回发起方执行最终结果、可以进行补偿、对性能要求较高、不介意额外编码的业务场景。</font>  
* **<font color = "clime">单体服务，多数据源，使用XA协议的服务；</font>**  

#### 1.14.3.6. 分布式事务框架Seata
##### 1.14.3.6.1. AT模式详解
&emsp; AT 模式分为两个阶段：

1. 一阶段：执行用户SQL。`业务数据和回滚日志记录在同一个本地事务中提交，`释放本地锁和连接资源。    
2. 二阶段：Seata框架自动生成。commit异步化快速完成；rollback通过一阶段的回滚日志进行反向补偿。    

![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/problems/problem-68.png)  
&emsp; 下面通过一个分支事务的执行过程来了解 Seata 的工作流程。  
&emsp; 例如有一个业务表 product(id,name)，分支事务的业务逻辑：  

```sql
update product set name = 'GTS' where name = 'TXC';
```

1. 一阶段  
    （1）解析 SQL  
    &emsp; 得到 SQL 的类型（UPDATE），表（product），条件（where name = 'TXC'）等相关的信息。  
    （2）查询前镜像  
    &emsp; 根据解析得到的条件信息，生成查询语句，定位数据。  

    ```sql
    select id, name from product where name = 'TXC';  
    ```
    &emsp; 得到前镜像：  

    |id|name|
    |---|---|
    |1|TXC|

    （3）执行业务 SQL  
    &emsp; 执行自己的业务逻辑：  
    ```sql  
    update product set name = 'GTS' where name = 'TXC';  
    ```
    &emsp; 把 name 改为了 GTS。  
    （4）查询后镜像  
    &emsp; 根据前镜像的结果，通过 主键 定位数据。  

    ```sql
    select id, name from product where id = 1;
    ```
    &emsp; 得到后镜像：

    |id|name|
    |---|---|
    |1|GTS|

    （5）插入回滚日志  
    &emsp; 把前后镜像数据以及业务 SQL 相关的信息组成一条回滚日志记录，插入到 UNDO_LOG 表中。  
    （6）提交前，向 TC 注册分支：申请 product 表中，主键值等于 1 的记录的 全局锁 。  
    （7）本地事务提交：业务数据的更新和前面步骤中生成的 UNDO LOG 一并提交。  
    （8）将本地事务提交的结果上报给 TC。  
2. 二阶段 - 提交  
（1）收到 TC 的分支提交请求，把请求放入一个异步任务的队列中，马上返回提交成功的结果给 TC。  
（2）异步任务阶段的分支提交请求，将异步和批量地删除相应 UNDO LOG 记录。  
3. 二阶段 - 回滚  
（1）收到 TC 的分支回滚请求，开启一个本地事务，执行如下操作。  
（2）通过 XID 和 Branch ID 查找到相应的 UNDO LOG 记录。  
（3）数据校验  
&emsp; 拿 UNDO LOG 中的后镜与当前数据进行比较，根据校验结果决定是否做回滚。  
（4）根据 UNDO LOG 中的前镜像和业务 SQL 的相关信息生成并执行回滚的语句：  
```sql
update product set name = 'TXC' where id = 1;
```
（5）提交本地事务  
&emsp; 并把本地事务的执行结果（即分支事务回滚的结果）上报给 TC。  

##### 1.14.3.6.2. 四种模式的区别
&emsp; 四种分布式事务模式，分别在不同的时间被提出，每种模式都有它的适用场景  

* AT 模式是无侵入的分布式事务解决方案，适用于不希望对业务进行改造的场景，几乎0学习成本。  
* TCC 模式是高性能分布式事务解决方案，适用于核心系统等对性能有很高要求的场景。  
* Saga 模式是长事务解决方案，适用于业务流程长且需要保证事务最终一致性的业务系统，Saga 模式一阶段就会提交本地事务，无锁，长流程情况下可以保证性能，多用于渠道层、集成层业务系统。事务参与者可能是其它公司的服务或者是遗留系统的服务，无法进行改造和提供 TCC 要求的接口，也可以使用 Saga 模式。  
* XA模式是分布式强一致性的解决方案，但性能低而使用较少。  

### 1.14.4. 分布式锁
#### 1.14.4.1. 分布式锁实现方案
1. 分布式锁使用场景
    1. 避免不同节点重复相同的工作，实现幂等。  
    2. 避免破坏数据的正确性：在分布式环境下解决多实例对数据的访问一致性。如果多个节点在同一条数据上同时进行操作，可能会造成数据错误或不一致的情况出现。  
2. 实现分布式锁的细节：  
    * **<font color = "blue">确保互斥：在同一时刻，必须保证锁至多只能被一个客户端持有。</font>**  
    * **<font color = "clime">`不能死锁：`在一个客户端在持有锁的期间崩溃而没有主动解锁情况下，`也能保证后续其他客户端能加锁`。</font>**    
    * **<font color = "clime">`避免活锁：`在获取锁失败的情况下，`反复进行重试操作，占用CPU资源，影响性能。`</font>**    
    * 实现更多锁特性：锁中断、锁重入、锁超时等。确保客户端只能解锁自己持有的锁。  
3. 分布式锁选型（各种锁的对比）：  
&emsp; ~~CAP只能满足其二、数据一致性、性能。~~  
&emsp; 分布式中间件的选型无非就是AP、CP模型（CAP原理）中的一种。针对常用的分布式锁，redis是AP模型、zookeeper是CP模型。  
&emsp; 具体选择哪一种看使用场景对数据一致性的要求。`解决幂等时一般情况下，使用redis分布式锁，但是分布式锁编码问题、中间件部署问题都有可能影响分布式锁的使用。所以数据一致性要求高的，要结合数据库乐观锁（状态控制）。`    

#### 1.14.4.2. RedisLock
1. 使用redis分布式锁要注意的问题：  
    1. 采用Master-Slave模式，加锁的时候只对一个节点加锁，即使通过Sentinel做了高可用，但是<font color="clime">如果Master节点故障了，发生主从切换，此时就会有可能出现`锁丢失`的问题，`可能导致多个客户端同时完成加锁`</font>。  
    &emsp; `在解决接口幂等问题中，采用redis分布式锁可以。但是如果涉及支付等对数据一致性要求严格的场景，需要结合数据库锁，建议使用基于状态机的乐观锁。`  
    2. 编码问题：  
        * key：释放别人的锁。唯一标识，例如UUID。  
        * 如何避免死锁？设置锁过期时间。  
        * `锁过期。 增大冗余时间。`  
2. redis实现分布式锁方案：  
    * 方案一：SETNX + EXPIRE  
    * 方案二：SETNX + value值是（系统时间+过时时间）  
    * `方案三：使用Lua脚本(包含SETNX + EXPIRE两条指令) ` 
    * 方案四：SET的扩展命令（SET EX PX NX）  
    * `方案五：SET EX PX NX + 校验惟一随机值，再删除释放`  
    * `方案六: 开源框架: Redisson`  
    * `方案七：多机实现的分布式锁Redlock`   
3. `方案五：SET EX PX NX + 校验惟一随机值，再删除释放（先查询再删除，非原子操作，需要使用lua脚本保证其原子性）。`  
&emsp; 在这里，判断是否是当前线程加的锁和释放锁不是一个原子操做。若是调用jedis.del()释放锁的时候，可能这把锁已经不属于当前客户端，会解除他人加的锁。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/problems/problem-61.png)  
&emsp; 为了更严谨，通常也是用lua脚本代替。lua脚本以下：  
    ```text
    if redis.call('get',KEYS[1]) == ARGV[1] then 
    return redis.call('del',KEYS[1]) 
    else
    return 0
    end;
    ```
4. RedLock红锁：  
    1. RedLock：当前线程尝试给每个Master节点`顺序`加锁。要在多数节点上加锁，并且加锁时间小于超时时间，则加锁成功；加锁失败时，依次删除节点上的锁。  
    2. ~~RedLock“顺序加锁”：确保互斥。在同一时刻，必须保证锁至多只能被一个客户端持有。~~   

#### 1.14.4.3. 使用redis分布式锁的注意点
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/problems/problem-69.png)  

&emsp; 使用redis分布式锁的注意点：  

1. 非原子操作  
2. 忘了释放锁  
3. 释放了别人的锁  
4. 大量失败请求  
&emsp; 如果有1万的请求同时去竞争那把锁，可能只有一个请求是成功的，其余的9999个请求都会失败。  
&emsp; 在秒杀场景下，会有什么问题？  
&emsp; 答：每1万个请求，有1个成功。再1万个请求，有1个成功。如此下去，直到库存不足。这就变成均匀分布的秒杀了，跟我们想象中的不一样。  
&emsp; `使用自旋锁。`  
5. 锁重入问题  
&emsp; 递归调用，使用可重入锁。 
6. 锁竞争问题  
&emsp; 如果有大量需要写入数据的业务场景，使用普通的redis分布式锁是没有问题的。  
&emsp; 但如果有些业务场景，写入的操作比较少，反而有大量读取的操作。这样直接使用普通的redis分布式锁，会不会有点浪费性能？  
&emsp; 我们都知道，锁的粒度越粗，多个线程抢锁时竞争就越激烈，造成多个线程锁等待的时间也就越长，性能也就越差。   
&emsp; 所以，提升redis分布式锁性能的第一步，就是要把锁的粒度变细。  
&emsp; 可以：1. `读写锁；`2. `锁分段`。
7. 锁超时问题  
&emsp; 自动续期  
8. 主从复制问题  
9. ~~正确使用分布式锁~~ 

#### 1.14.4.4. Redisson
1.  **<font color = "clime">RedissonLock解决客户端死锁问题（自动延期）：</font>**  
    1. 什么是死锁？因为业务不知道要执行多久才能结束，所以这个key一般不会设置过期时间。这样如果在执行业务的过程中，业务机器宕机，unlock操作不会执行，所以这个锁不会被释放，`其他机器拿不到锁，从而形成了死锁。`  
    2. ~~Redission解决死锁：(**要点：30s和10s**)~~
        1. `未设置加锁时间，自动设置加锁时间：`当业务方调用加锁操作的时候，`未设置加锁时间`，默认的leaseTime是-1，所以会取watch dog的时间作为锁的持有时间，默认是30s，这个时候即使发生了宕机现象，因为这个锁不是永不过期的，所以30s后就会释放，不会产生死锁。 
        2. `异步续租、递归调用：`另一方面，它还能解决当锁内逻辑超过30s的时候锁会失效的问题，因为当leaseTime是-1的时候，`客户端会启动一个异步任务（watch dog）`，会每隔10秒检查一下，如果客户端1还持有锁key，在业务方释放锁之前，会一直不停的增加这个锁的生命周期时间，保证在业务执行完毕之前，这个锁一直不会因为redis的超时而被释放。
2. Redisson实现了多种锁：重入锁、公平锁、联锁、红锁、读写锁、信号量Semaphore 和 CountDownLatch...  
3. **Redisson重入锁：**  
    1. Redisson重入锁加锁流程：  
        1. 执行lock.lock()代码时，<font color = "red">如果该客户端面对的是一个redis cluster集群，首先会根据hash节点选择一台机器。</font>  
        2. 然后发送一段lua脚本，带有三个参数：一个是锁的名字(在代码里指定的)、一个是锁的时常(默认30秒)、一个是加锁的客户端id(每个客户端对应一个id)。<font color = "red">然后脚本会判断是否有该名字的锁，如果没有就往数据结构中加入该锁的客户端id。</font>  

            * 锁不存在(exists)，则加锁(hset)，并设置(pexpire)锁的过期时间；  
            * 锁存在，检测(hexists)是当前线程持有锁，锁重入(hincrby)，并且重新设置(pexpire)该锁的有效时间；
            * 锁存在，但不是当前线程的，返回(pttl)锁的过期时间。 
    2. **<font color = "red">Redisson重入锁缺陷：</font>** 在哨兵模式或者主从模式下，如果master实例宕机的时候，可能导致多个客户端同时完成加锁。  


#### 1.14.4.5. ZK分布式锁
1. **<font color = "clime">对于ZK来说，实现分布式锁的核心是临时顺序节点和监听机制。</font>**  
2. **ZooKeeper分布式锁的缺点：** 1). 需要依赖zookeeper；2). 性能低。频繁地“写”zookeeper。集群节点数越多，同步越慢，获取锁的过程越慢。  
3. 基于ZooKeeper可以实现分布式的独占锁和读写锁。  
    1. **使用ZK实现分布式独占锁：**<font color="red">在某一节点下，建立临时顺序节点。最小节点获取到锁。非最小节点监听上一节点，上一节点释放锁，唤醒当前节点。</font>  
    2. **使用ZK实现分布式读写锁：<font color = "red">客户端从 Zookeeper 端获取 /share_lock下所有的子节点，并判断自己能否获取锁。</font>**  
        1. **<font color = "red">如果客户端创建的是读锁节点，获取锁的条件（满足其中一个即可）如下：</font>**  

            * 自己创建的节点序号排在所有其他子节点前面  
            * 自己创建的节点前面无写锁节点  
            
        2. **<font color = "red">如果客户端创建的是写锁节点，</font>** 由于写锁具有排他性，所以获取锁的条件要简单一些，只需确定自己创建的锁节点是否排在其他子节点前面即可。  

#### 1.14.4.6. MySql分布式锁
1. 基于表记录实现
2. 基于排他锁/悲观锁(for update)实现
3. 乐观锁实现
	* 一般是通过为数据库表添加一个version字段来实现读取出数据时，将此版本号一同读出。
	* 基于状态机的乐观锁


## 1.15. 高并发
### 1.15.1. 分布式和集群
&emsp; `分布式带来数据一致性的问题。`  

### 1.15.2. 系统性能指标
1. 吞吐量  
&emsp; 一般来说， **<font color = "clime">系统吞吐量指的是系统的抗压、负载能力，代表一个系统每秒钟能承受的最大用户访问量。</font>**   
&emsp; **<font color = "clime">`一个系统的吞吐量通常由qps(tps)、并发数来决定，`每个系统对这两个值都有一个相对极限值，只要某一项达到最大值，系统的吞吐量就上不去了。</font>**  
2. QPS  
&emsp; Queries Per Second，每秒查询数，即是每秒能够响应的查询次数，注意这里的查询是指用户发出请求到服务器做出响应成功的次数，简单理解可以认为查询=请求request。`qps=每秒钟request数量`  
3. TPS  
&emsp; Transactions Per Second 的缩写，每秒处理的事务数。一个事务是指一个客户机向服务器发送请求然后服务器做出反应的过程。客户机在发送请求时开始计时，收到服务器响应后结束计时，以此来计算使用的时间和完成的事务个数。  
&emsp; 针对单接口而言，TPS可以认为是等价于QPS的，比如访问一个页面/index.html，是一个TPS，而访问/index.html页面可能请求了3次服务器比如css、js、index接口，产生了3个QPS。  
4. 并发数  
&emsp; 简而言之，系统能同时处理的请求/事务数量。  
&emsp; 计算方式：QPS = 并发数 / RT 或者 并发数= QPS * RT  

### 1.15.3. 并发系统三高
&emsp; 高并发绝不意味着只追求高性能，这是很多人片面的理解。从宏观角度看，高并发系统设计的目标有三个：高性能、高可用，以及高可扩展。  
1. **<font color = "red">`高性能`：性能体现了系统的并行处理能力，在有限的硬件投入下，提高性能意味着节省成本。**</font> 同时，性能也反映了用户体验，响应时间分别是100毫秒和1秒，给用户的感受是完全不同的。  
2. **<font color = "clime">`高可用`：表示系统可以正常服务的时间。</font>** 一个全年不停机、无故障；另一个隔三差五出线上事故、宕机，用户肯定选择前者。另外，如果系统只能做到90%可用，也会大大拖累业务。  
3. **<font color = "clime">`高扩展`：表示系统的扩展能力，流量高峰时能否在短时间内完成扩容，更平稳地承接峰值流量，比如双11活动、明星离婚等热点事件。</font>**  

#### 1.15.3.1. 高可用建设


#### 1.15.3.2. 秒杀系统设计
1. 什么是秒杀系统？定时开始、库存有限...  
2. 秒杀应该考虑哪些问题？  
&emsp; 链接暴露、恶意请求（接口防刷）、突然增加的网络及服务器带宽、超卖问题、数据库设计...  
3. 秒杀系统设计思考：  
    &emsp; 从架构视角来看，<font color = "red">`秒杀系统本质是一个高性能、高可用、高一致的三高系统。`</font>  
	* 高性能。动静分离、热点优化以及服务端性能优化。  
        * **<font color = "clime">热点数据的处理三步走，一是热点识别，二是热点隔离，三是热点优化。</font>**   
            1. 热点隔离：1. 业务隔离；2. 部署隔离；3. 数据隔离。  
            2. 热点优化：缓存和限流。  
	* 高可用。流量削峰(答题、mq)、高可用建设。  
	* 高一致。从业界通用的几种减库存方案切入。减库存一般有以下几个方式：下单减库存、付款减库存、<font color = "clime">`预扣库存（买家下单后，库存为其保留一定的时间（如15 分钟），超过这段时间，库存自动释放，释放后其他买家可以购买）。业界最为常见的是预扣库存。`</font>    
4. 秒杀业务完整流程梳理：  
    * 后端service服务层。  
        * **<font color = "clime">使用缓存(Redis、Memchched)：将读多写少的业务数据放入缓存，如秒杀业务中可以将更新频繁的商品库存信息放入Redis缓存处理。</font>**  
            &emsp; 注：`库存信息放入Redis缓存的时候最好分为多份放入不同key的缓存中`，如库存为10万可以分为10份分别放入不同key的缓存中，这样将数据分散操作可以达到更高的读写性能。
        * 使用队列处理：将请求放入队列排队处理，以可控的速度来访问底层DB。
        * **<font color = "clime">异步处理：如将秒杀成功的订单通知信息通过消息队列(RabbitMQ、Kafka)来异步处理。</font>**    


### 1.15.4. 资源限制
&emsp; 并发高，但是服务器资源有限，可以采取哪些方案？具体案例可以参考[秒杀系统设计](/docs/system/seckill.md)。    
1. 高并发3大利器：[缓存](/docs/cache/Cache.md)、[限流](/docs/microService/thinking/CurrentLimiting.md)、[降级](/docs/microService/thinking/Demotion.md)；
2. 削峰：[mq消峰](/docs/microService/mq/mq.md)、流量削峰；
3. 将请求放入队列中（包括但不限于阻塞队列、高效队列、redis队列）；  
4. 使用服务器请求队列。例如tomcat的server.xml中增大acceptCount值。  
&emsp; acceptCount：当tomcat请求处理线程池中的所有线程都处于忙碌状态时，此时新建的链接将会被放入到pending队列，acceptCount即是此队列的容量，如果队列已满，此后所有的建立链接的请求(accept)，都将被拒绝。默认为100。在高并发/短链接较多的环境中，可以适当增大此值；当长链接较多的场景中，可以将此值设置为0。  
5. 池化技术。各种池化技术的使用和池大小的设置，包括HTTP请求池、线程池（考虑CPU密集型还是IO密集型设置核心参数）、数据库和Redis连接池等。    

## 1.16. 缓存
### 1.16.1. ~~分布式缓存问题~~
1. 对数据的操作：curd。  
2. 缓存预热/新增缓存
3. **查询缓存/（缓存穿透、缓存击穿和缓存雪崩）：**  
&emsp; <font color="red">缓存穿透、缓存击穿和缓存雪崩都是缓存失效导致大量请求直接访问数据库而出现的情况。</font>  
&emsp; <font color="red">不同的是缓存穿透是数据库和缓存都不存在相关数据；而缓存击穿和缓存雪崩是缓存和数据库都存在相应数据，</font><font color = "clime">只是缓存失效了而已。</font>  
4. 缓存穿透：  
&emsp; 缓存穿透是指，请求访问的数据在缓存中没有命中，到数据库中查询也没有，导致此次查询失败；当大量请求针对此类数据时，由于缓存不能命中，请求直接穿透缓存，直击数据库，给数据库造成巨大的访问压力。    
&emsp; 解决方案：空值缓存；`设置布隆过滤器`，若布隆过滤器中无，则直接返回，若存在，则查找缓存redis。  
5. 缓存`击穿`(`热点缓存`)：  
&emsp; 当缓存中不存在但是数据库中存在的数据（`一般来说指缓存失效`），在短时间内针对这种数据产生大量的请求，由于缓存不能命中，直击数据库，给数据库造成较大压力。  
&emsp; **<font color = "clime">解决方案：key永不过期，使用互斥锁或队列，双缓存。</font>**   
6. 缓存雪崩：  
&emsp; 缓存雪崩是指某一时间段内缓存中数据大批量过期失效，但是查询数据量巨大，引起数据库压力过大甚至宕机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，导致大量请求直达数据库。缓存雪崩有两种情况：  
    * 缓存批量过期：缓存批量过期这样的雪崩只是对数据库产生周期性的压力，数据还是扛得住的。解决方案：`key随机值，` **<font color = "clime">key永不过期，使用互斥锁或队列，双缓存。</font>**
    * 缓存服务器宕机：缓存服务器的某个节点宕机或断网，对数据库产生的压力是致命的。解决方案：服务器高可用。   
7. 更新缓存  
    1. 「先更新数据库，再删缓存」的策略，原因是这个策略即使在并发读写时，也能最大程度保证数据一致性。  
    2. `先删除缓存，再更新数据库，非原子操作。可以采用双删延迟策略，进行兜底。` **<font color = "clime">第二次删除前线程休眠冗余的读写时间，如果读从库，再加上延迟时间。</font>**  
    3. 先更新数据库，再删缓存，采用异步延时删除策略。  
    4. `采用`延时删除`策略中的问题：`  
        * **<font color = "clime">同步方式会降低吞吐量，可以采用异步。</font>**  
        * **<font color = "clime">第二次删除可能失败，提供一个保障的重试机制。</font>** 方案一：采用消息队列，缺点对业务线代码造成大量的侵入；方案二：订阅binlog，订阅程序提取出所需要的数据以及key，另起一段非业务代码，获得该信息，尝试删除缓存操作，发现删除失败，将这些信息发送至消息队列，重新从消息队列中获得该数据，重试操作。
6. 缓存预热

### 1.16.2. Redis
#### 1.16.2.1. Redis数据类型
##### 1.16.2.1.1. Redis基本数据类型
1. Key操作命令：expire，为给定key设置生存时间；TTL key，以秒为单位，返回给定key的剩余生存时间（TTL, time to live）。  
2.  **<font color = "clime">Redis各个数据类型的使用场景：分析存储类型和可用的操作。</font>**  
    * 有序列表list：  
    &emsp; `列表不但是有序的，同时支持按照索引范围获取元素。`  
    &emsp; 可以用作栈、文章列表。  
    * 无序集合set：
        * 集合内操作，可以用作标签、点赞、签到；
        * 集合间操作，可以用作社交需求； 
        * spop/srandmember命令生成随机数。   
    * 有序集合ZSet：  
    &emsp; 有序的集合，每个元素有个 score。  
    &emsp; 可以用作排行榜、延迟队列。  
3. **ZSet实现多维排序：**  
&emsp; <font color = "red">将涉及排序的多个维度的列通过一定的方式转换成一个特殊的列</font>，即result = function(x, y, z)，即x，y，z是三个排序因子，例如下载量、时间等，通过自定义函数function()计算得到result，将result作为ZSet中的score的值，就能实现任意维度的排序需求了。 

##### 1.16.2.1.2. Redis扩展数据类型
1. <font color = "clime">Bitmap、HyperLogLog都是作为Redis的Value值。</font>  
2. <font color = "clime">`Bitmap：二值状态统计。`Redis中的Bitmap，`key可以为某一天或某一ID，Bitmap中bit可以存储用户的任意信息，所以Redis Bitmap可以用作统计信息。`常用场景：用户签到、统计活跃用户、用户在线状态。</font>  
    1. 基于Redis BitMap实现用户签到功能： **<font color = "clime">考虑到每月初需要重置连续签到次数，最简单的方式是按用户每月存一条签到数据（也可以每年存一条数据）。`Key的格式为u :sign :uid :yyyyMM`，`Value则采用长度为4个字节（32位）的位图（最大月份只有31天）。位图的每一位代表一天的签到，1表示已签，0表示未签。`</font>**  
3. <font color = "clime">`HyperLogLog用于基数统计，例如UV（独立访客数）。`</font>  
    * `基数统计是指找出集合中不重复元素，用于去重。`  
    * 使用Redis统计集合的基数一般有三种方法，分别是使用Redis的Hash，BitMap和HyperLogLog。  
    * HyperLogLog内存空间消耗少，但存在误差0.81%。  
4. Streams消息队列：支持多播的可持久化的消息队列，用于实现发布订阅功能，借鉴了kafka的设计。 
5. [布隆过滤器](/docs/function/otherStructure.md)作为一个插件加载到Redis Server中，就会给Redis提供了强大的布隆去重功能。  


##### 1.16.2.1.3. ~~Redis底层实现~~
1. 很重要的思想：redis设计比较复杂的对象系统，都是为了缩减内存占有！！！  

###### 1.16.2.1.3.1. 数据结构
1. 很重要的思想：redis设计比较复杂的对象系统，都是为了缩减内存占有！！！  
2. redis底层8种数据结构：int、raw、embstr(SDS)、ziplist、hashtable、quicklist、intset、skiplist。  
3. 3种链表：  
    * 双端链表LinkedList  
        &emsp; Redis的链表在双向链表上扩展了头、尾节点、元素数等属性。Redis的链表结构如下：
        ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/Redis/redis-62.png)  
    * 压缩列表Ziplist  
        &emsp; 在双端链表中，如果在一个链表节点中存储一个小数据，比如一个字节。那么对应的就要保存头节点，前后指针等额外的数据。这样就浪费了空间，同时由于反复申请与释放也容易导致内存碎片化。这样内存的使用效率就太低了。  
        &emsp; Redis设计了压缩列表  
        ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/Redis/redis-110.png)  
        &emsp; ziplist是一组连续内存块组成的顺序的数据结构， **<font color = "red">是一个经过特殊编码的双向链表，它不存储指向上一个链表节点和指向下一个链表节点的指针，而是存储上一个节点长度和当前节点长度，通过牺牲部分读写性能，来换取高效的内存空间利用率，节省空间，是一种时间换空间的思想。</font>** 只用在字段个数少，字段值小的场景里。  
    * 快速列表Quicklist  
        QuickList其实就是结合了ZipList和LinkedList的优点设计出来的。quicklist存储了一个双向链表，每个节点都是一个ziplist。  
        ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/Redis/redis-63.png)  
4. 整数集合inset  
&emsp; inset的数据结构：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/Redis/redis-7.png)  
&emsp; inset也叫做整数集合，用于保存整数值的数据结构类型，它可以保存int16_t、int32_t 或者int64_t 的整数值。  
&emsp; 在整数集合中，有三个属性值encoding、length、contents[]，分别表示编码方式、整数集合的长度、以及元素内容，length就是记录contents里面的大小。  
5. 跳跃表SkipList  
&emsp; skiplist也叫做「跳跃表」，跳跃表是一种有序的数据结构，它通过每一个节点维持多个指向其它节点的指针，从而达到快速访问的目的。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/Redis/redis-85.png)  
&emsp; SkipList分为两部分，dict部分是由字典实现，Zset部分使用跳跃表实现，从图中可以看出，dict和跳跃表都存储了数据，实际上dict和跳跃表最终使用指针都指向了同一份数据，即数据是被两部分共享的，为了方便表达将同一份数据展示在两个地方。  


###### 1.16.2.1.3.2. SDS详解
1. **<font color = "clime">对于SDS中的定义在Redis的源码中有的三个属性int len、int free、char buf[]。</font>**  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/Redis/redis-77.png)  
    * len保存了字符串的长度；
    * free表示buf数组中未使用的字节数量；
    * buf数组则是保存字符串的每一个字符元素。  
2. Redis字符串追加会做以下三个操作：  
    1. 计算出大小是否足够；  
    2. 开辟空间至满足所需大小；  
    3. **<font color = "red">如果len < 1M，开辟与已使用大小len相同长度的空闲free空间；如果len >= 1M，开辟1M长度的空闲free空间。</font>**  
3. **Redis字符串的性能优势：**  
    * 动态扩展：拼接字符串时，计算出大小是否足够，开辟空间至满足所需大小。  
    * 避免缓冲区溢出。「c语言」中两个字符串拼接，若是没有分配足够长度的内存空间就「会出现缓冲区溢出的情况」。  
    * （内存分配优化）降低空间分配次数，提升内存使用效率。 **<font color = "blue">空间预分配和惰性空间回收。</font>** 
        * 空间预分配：对于追加操作来说，Redis不仅会开辟空间至够用，<font color = "red">而且还会预分配未使用的空间(free)来用于下一次操作。</font>  
        * 惰性空间回收：与上面情况相反，<font color = "red">惰性空间回收适用于字符串缩减操作。</font>比如有个字符串s1="hello world"，对s1进行sdstrim(s1," world")操作，<font color = "red">执行完该操作之后Redis不会立即回收减少的部分，而是会分配给下一个需要内存的程序。</font>  
    * 快速获取字符串长度。
    * 二进制安全。

###### 1.16.2.1.3.3. Dictht
1. **<font color = "red">rehash：</font>**  
&emsp; dictEntry有ht[0]和ht[1]两个对象。  
&emsp; 扩展操作：ht[1]扩展的大小是比当前 ht[0].used 值的二倍大的第一个2的整数幂；收缩操作：ht[0].used 的第一个大于等于的 2 的整数幂。  
&emsp; **<font color = "clime">当ht[0]上的所有的键值对都rehash到ht[1]中，会重新计算所有的数组下标值，当数据迁移完后，ht[0]就会被释放，然后将ht[1]改为ht[0]，并新创建ht[1]，为下一次的扩展和收缩做准备。</font>**  
2. **<font color = "red">渐进式rehash：</font>**  
&emsp; **<font color = "clime">Redis将所有的`rehash操作分成多步进行`，直到都rehash完成。</font>**  
&emsp; **<font color = "red">在渐进式rehash的过程「更新、删除、查询会在ht[0]和ht[1]中都进行」，比如更新一个值先更新ht[0]，然后再更新ht[1]。</font>**   
&emsp; **<font color = "clime">而新增操作直接就新增到ht[1]表中，ht[0]不会新增任何的数据，</font><font color = "red">这样保证「ht[0]只减不增，直到最后的某一个时刻变成空表」，这样rehash操作完成。</font>**  


###### 1.16.2.1.3.4. 数据类型  
&emsp; Redis会根据当前值的类型和长度决定使用哪种内部编码实现。 **<font color = "clime">Redis根据不同的使用场景和内容大小来判断对象使用哪种数据结构，从而优化对象在不同场景下的使用效率和内存占用。</font>**   
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/Redis/redis-106.png)  

* String字符串类型的内部编码有三种：
    1. int，存储8个字节的长整型(long，2^63-1)。当int数据不再是整数，或大小超过了long的范围(2^63-1=9223372036854775807)时，自动转化为embstr。  
    2. embstr，代表 embstr 格式的 SDS(Simple Dynamic String 简单动态字符串)，存储小于44个字节的字符串。  
    3. raw，存储大于 44 个字节的字符串(3.2 版本之前是 39 字节)。  
* Hash由ziplist(压缩列表)或者dictht(字典)组成；  
* List，「有序」「可重复」集合，由ziplist压缩列表和linkedlist双端链表的组成，在 3.2 之后采用QuickList；  
* Set，「无序」「不可重复」集合， **<font color = "clime">是特殊的Hash结构(value为null)，</font>** 由intset(整数集合)或者dictht(字典)组成；
* ZSet，「有序」「不可重复」集合，由skiplist(跳跃表)或者ziplist(压缩列表)组成。  


#### 1.16.2.2. Redis原理
##### 1.16.2.2.1. Redis为什么那么快？
&emsp; Redis的性能非常之高，每秒可以承受10W+的QPS，它如此优秀的性能主要取决于以下几个方面：  

1. 磁盘I/O：
    * 纯内存操作
    * [虚拟内存机制](/docs/microService/Redis/RedisVM.md)  
    * 合理的数据编码
2. 网络I/O：  
    * [使用IO多路复用技术](/docs/microService/Redis/RedisEvent.md)  
    * [合理的线程模型](/docs/microService/Redis/RedisMultiThread.md)   
    * [简单快速的Redis协议](/docs/microService/Redis/RESP.md)  
3. ......

##### 1.16.2.2.2. Redis虚拟内存机制
&emsp; **<font color = "clime">通过VM功能可以实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘。这样就可以避免因为内存不足而造成访问速度下降的问题。</font>**  
&emsp; 使用虚拟内存把那些不经常访问的数据交换到磁盘上。需要特别注意的是Redis并没有使用OS提供的Swap，而是自己实现。  
&emsp; **<font color = "clime">Redis为了保证查找的速度，只会将value交换出去，而在内存中保留所有的Key。</font>**  

##### 1.16.2.2.3. Redis事件/Reactor
&emsp; 参考[Redis事件/Reactor](/docs/microService/Redis/RedisEvent.md)  
&emsp; Redis基于Reactor模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）：文件事件处理器使用I/O多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。  
&emsp; 下图展示了文件事件处理器的四个组成部分，它们分别是套接字、I/O多路复用程序、文件事件分派器(dispatcher)，以及事件处理器。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/Redis/redis-56.png)    

##### 1.16.2.2.4. Redis多线程模型
1. 为什么Redis一开始使用单线程？  
&emsp; 基于内存而且使用多路复用技术，单线程速度很快，又保证了多线程的特点。因此没有必要使用多线程。  
2. 为什么引入多线程？  
&emsp; **<font color = "clime">因为读写网络的read/write系统调用（网络I/O）在Redis执行期间占用了大部分CPU时间，如果把网络读写做成多线程的方式对性能会有很大提升。</font>**  
&emsp; **<font color = "clime">Redis的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。</font>** 
3. 官方建议：4核的机器建议设置为2或3个线程，8核的建议设置为6个线程， **<font color = "clime">`线程数一定要小于机器核数，尽量不超过8个。`</font>**   

##### 1.16.2.2.5. Redis协议
&emsp; RESP是Redis Serialization Protocol的简称，也就是专门为redis设计的一套序列化协议。这个协议其实在redis的1.2版本时就已经出现了，但是到了redis2.0才最终成为redis通讯协议的标准。  
&emsp; 这个序列化协议听起来很高大上， 但实际上就是一个文本协议。根据官方的说法，这个协议是基于以下几点(而妥协)设计的：  
1. 实现简单。可以减低客户端出现bug的机率。  
2. `解析速度快。`由于RESP能知道返回数据的固定长度，所以不用像json那样扫描整个payload去解析，所以它的性能是能跟解析二进制数据的性能相媲美的。  
3. 可读性好。  

#### 1.16.2.3. Redis内置功能
##### 1.16.2.3.1. Redis事务
1. **<font color = "clime">Redis事务的三个阶段：</font>**  
    * 开始事务：以MULTI开启一个事务。   
    * **<font color = "clime">命令入队：将多个命令入队到事务中，接到这些命令不会立即执行，而是放到等待执行的事务队列里。</font>**    
    * 执行事务(exec)或取消事务(discard)：由EXEC/DISCARD命令触发事务。  
2. **使用Redis事务的时候，可能会遇上以下两种错误：**  
    * **<font color = "red">（类似于Java中的编译错误）事务在执行EXEC之前，入队的命令可能会出错。</font>** 比如说，命令可能会产生语法错误(参数数量错误，参数名错误等等)，或者其他更严重的错误，比如内存不足(如果服务器使用maxmemory设置了最大内存限制的话)。  
    * **<font color = "red">（类似于Java中的运行错误）命令可能在 EXEC 调用之后失败。</font>** 举个例子，事务中的命令可能处理了错误类型的键，比如将列表命令用在了字符串键上面，诸如此类。  

    1. Redis 针对如上两种错误采用了不同的处理策略，对于发生在 EXEC 执行之前的错误，服务器会对命令入队失败的情况进行记录，并在客户端调用 EXEC 命令时，拒绝执行并自动放弃这个事务（Redis 2.6.5 之前的做法是检查命令入队所得的返回值：如果命令入队时返回 QUEUED ，那么入队成功；否则，就是入队失败）  
    2. 对于那些在 EXEC 命令执行之后所产生的错误，并没有对它们进行特别处理：即使事务中有某个/某些命令在执行时产生了错误，事务中的其他命令仍然会继续执行。 
3. **带Watch的事务：**  
&emsp; WATCH命令用于在事务开始之前监视任意数量的键：当调用EXEC命令执行事务时，如果任意一个被监视的键已经被其他客户端修改了，那么整个事务将被打断，不再执行，直接返回失败。 

##### 1.16.2.3.2. RedisPipeline/批处理
&emsp; Redis主要提供了以下几种批量操作方式：  

* 批量get/set(multi get/set)。⚠️注意：Redis中有删除单个Key的指令DEL，但没有批量删除 Key 的指令。  
* 管道(pipelining)
* 事务(transaction)
* 基于事务的管道(transaction in pipelining)

##### 1.16.2.3.3. Redis和Lua

##### 1.16.2.3.4. Redis持久化
1. RDB，快照；保存某一时刻的全部数据；缺点是间隔长（配置文件中默认最少60s）。  
2. AOF，文件追加；记录所有操作命令；优点是默认间隔1s，丢失数据少；缺点是文件比较大，通过重写机制来压缩文件体积。  
    1. **<font color = "clime">重写后的AOF文件为什么可以变小？有如下原因：</font>**  
        1. <font color = "red">进程内已经超时的数据不再写入文件。</font>   
        2. <font color = "red">旧的AOF文件含有无效命令，</font>如del key1、hdel key2、srem keys、set a111、set a222等。重写使用进程内数据直接生成，这样新的AOF文件只保留最终数据的写入命令。  
        3. <font color = "red">多条写命令可以合并为一个，</font>如：lpush list a、lpush list b、lpush list c可以转化为：lpush list a b c。为了防止单条命令过大造成客户端缓冲区溢出，对于list、set、hash、zset等类型操作，以64个元素为界拆分为多条。  
    2. **<font color = "red">AOF重写降低了文件占用空间，除此之外，另一个目的是：更小的AOF 文件可以更快地被Redis加载。</font>**  
    3. 在写入AOF日志文件时，如果Redis服务器宕机，则AOF日志文件文件会出格式错误。在重启Redis服务器时，Redis服务器会拒绝载入这个AOF文件，可以修复AOF 并恢复数据。 
3. Redis4.0混合持久化，先RDB，后AOF。  
4. ~~**<font color = "clime">RDB方式bgsave指令中fork子进程、AOF方式重写bgrewriteaof都会造成阻塞。</font>**~~  

###### 1.16.2.3.4.1. AOF重写阻塞
1. **<font color = "clime">当Redis执行完一个写命令之后，它会同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区。</font>**  
2. AOF重写阻塞原因：
	1. **<font color = "clime">当子进程完成AOF重写工作之后，它会向父进程发送一个信号，父进程在接收到该信号之后，`会调用一个信号处理函数，并执行相应工作：将AOF重写缓冲区中的所有内容写入到新的AOF文件中。`</font>**  
	2. **<font color = "clime">在整个AOF后台重写过程中，`只有信号处理函数执行时会对Redis主进程造成阻塞，`在其他时候，AOF后台重写都不会阻塞主进程。</font>**  
&emsp; 如果信号处理函数执行时间较长，即造成AOF阻塞时间长，就会对性能有影响。  
3. 解决方案：  
	* **<font color = "red">将no-appendfsync-on-rewrite设置为yes。</font>** 
	* master节点关闭AOF。  
    
    可以采取比较折中的方式：  
        * 在master节点设置将no-appendfsync-on-rewrite设置为yes（`表示在日志重写时，不进行命令追加操作，而只是将命令放在重写缓冲区里，避免与命令的追加造成磁盘IO上的冲突`），同时auto-aof-rewrite-percentage参数设置为0关闭主动重写。  
        * 在重写时为了避免硬盘空间不足或者IO使用率高影响重写功能，还添加了硬盘空间报警和IO使用率报警保障重写的正常进行。
4. 虽然在everysec配置下aof的fsync是由子线程进行操作的，但是主线程会监控fsync的执行进度。  
&emsp; **<font color = "clime">主线程在执行时候如果发现上一次的fsync操作还没有返回，那么主线程就会阻塞。</font>**  


##### 1.16.2.3.5. Redis过期键删除
1. 过期键常见的删除策略有3种：定时删除(主动)、惰性删除(被动)、定期删除(主动)。<font color = "red">Redis服务器使用的是惰性删除策略和定期删除策略。</font>  
    * 定时删除策略，在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。  
    * <font color = "clime">惰性删除策略，只有当访问一个key时，才会判断该key是否已过期，过期则清除。</font>  
    * <font color = "red">`定期删除策略，每隔一段时间执行一次删除过期键操作`</font>，并通过<font color = "clime">`限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响`</font>，同时，通过定期删除过期键，也有效地减少了因为过期键而带来的内存浪费。  


##### 1.16.2.3.6. Redis内存淘汰
1. **Redis内存淘汰使用的算法有4种：**  
    * random，随机删除。  
    * TTL，删除过期时间最少的键。  
    * <font color = "clime">LRU，Least Recently Used：最近最少使用（访问时间）。</font>判断最近被使用的时间，离目前最远的数据优先被淘汰。  
    &emsp; **<font color = "red">`如果基于传统LRU算法实现，Redis LRU会有什么问题？需要额外的数据结构存储，消耗内存。`</font>**  
    &emsp; **<font color = "blue">Redis LRU对传统的LRU算法进行了改良，通过`随机采样`来调整算法的精度。</font>** 如果淘汰策略是LRU，则根据配置的采样值maxmemory_samples(默认是 5 个)，随机从数据库中选择m个key，淘汰其中热度最低的key对应的缓存数据。所以采样参数m配置的数值越大，就越能精确的查找到待淘汰的缓存数据，但是也消耗更多的CPU计算，执行效率降低。  
    * <font color = "clime">LFU，Least Frequently Used，最不常用（`访问频率`），4.0版本新增。</font>  
2. **~~内存淘汰策略选择：~~**  
&emsp; **<font color = "clime">volatile和allkeys规定了是对已设置过期时间的key淘汰数据还是从全部key淘汰数据。volatile-xxx策略只会针对带过期时间的key进行淘汰，allkeys-xxx策略会对所有的key进行淘汰。</font>**  
    * 如果只是拿Redis做缓存，那应该使用allkeys-xxx，客户端写缓存时不必携带过期时间。  
    * `如果还想同时使用Redis的持久化功能，那就使用volatile-xxx策略，这样可以保留没有设置过期时间的key，它们是永久的key不会被LRU算法淘汰。`  

    1. 如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，或者无法预测数据的使用频率时，则使用allkeys-lru/allkeys-lfu。  
    2. 如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random。
    3. 如果研发者需要通过设置不同的ttl来判断数据过期的先后顺序，此时可以选择volatile-ttl策略。
    4. `如果希望一些数据能长期被保存，而一些数据可以被淘汰掉，选择volatile-lru/volatile-lfu或volatile-random都是比较不错的。`
    5. 由于设置expire会消耗额外的内存，如果计划避免Redis内存在此项上的浪费，可以选用allkeys-lru/volatile-lfu策略，这样就可以不再设置过期时间，高效利用内存了。  

##### 1.16.2.3.7. Redis实现消息队列
&emsp; redis中实现消息队列的几种方案：  

* 基于List的 LPUSH+BRPOP 的实现
* PUB/SUB，订阅/发布模式
* 基于Sorted-Set的实现
* 基于Stream类型的实现


#### 1.16.2.4. Redis高可用
##### 1.16.2.4.1. Redis高可用方案
1. **<font color = "clime">考虑资源：</font>**    
&emsp; Redis集群最少6个节点，每个节点20G，总共120G。因此Redis集群比较耗资源。小型公司可以采用哨兵模式。    
2. **<font color = "clime">考虑QPS：</font>**  
&emsp; **单机的redis一般是支持上万甚至几万，具体的性能取决于数据操作的复杂性，如果仅仅是简单的kv操作的话，可以达到数万，如果是运行复杂的lua脚本的话，就可能只能到一万左右。**  
&emsp; 缓存一般是用来支撑读的高并发，一般比较少用来支撑读的操作，一般读的操作是比较频繁的，甚至达到几万几十万，但是写的操作每秒才几千，这就需要读写分离了。  

&emsp; `小型公司，可以采用哨兵，主从复制-单副本模式。`  


##### 1.16.2.4.2. Redis主从复制
1. **<font color = "red">Redis主从复制架构常见的是`单副本`、双副本模式。</font>**  
2. <font color = "red">主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段。</font>  
&emsp; 一、连接建立阶段：1. 保存主节点(master)信息。2. 从节点(slave)内部通过每秒运行的定时任务维护复制相关逻辑，当定时任务发现存在新的主节点后，会尝试与该节点建立网络连接。</font>3. 发送ping命令。  
&emsp; 二、数据同步阶段：5. 同步数据集。有两种复制方式：全量复制和部分复制。  
&emsp; 三、命令传播阶段：6. 命令持续复制。  
3. redis 2.8之前使用sync [runId] [offset]同步命令，redis2.8之后使用psync [runId] [offset]命令。两者不同在于，sync命令仅支持全量复制过程，psync支持全量和部分复制。    
4. **主从复制应用与问题：**
    * **<font color = "red">传输延迟，提供了repl-disable-tcp-nodelay参数用于控制是否关闭TCP_NODELAY，默认关闭。</font>**    
        * `当关闭时，主节点产生的命令数据无论大小都会及时地发送给从节点，这样主从之间延迟会变小，但增加了网络带宽的消耗。` **<font color = "blue">适用于主从之间的网络环境良好的场景，如同机架或同机房部署。</font>** 
        * **<font color = "blue">当开启时，主节点会合并较小的TCP数据包从而节省带宽。</font>** 默认发送时间间隔取决于Linux的内核，一般默认为40毫秒。这种配置节省了带宽但增大主从之间的延迟。 **<font color = "blue">适用于主从网络环境复杂或带宽紧张的场景，如跨机房部署。</font>**  
    * 规避全量复制
        * 节点运行ID不匹配。提供故障转移的功能；如果修改了主节点的配置，需要重启才能够生效，可以选择安全重启的方式(debug reload)。  
        * 复制偏移量offset不在复制积压缓冲区中。需要根据中断时长来调整复制积压缓冲区的大小。  

##### 1.16.2.4.3. Redis读写分离


##### 1.16.2.4.4. Redis哨兵模式
1. <font color="clime">监控和自动故障转移使得Sentinel能够完成主节点故障发现和自动转移，配置提供者和通知则是实现通知客户端主节点变更的关键。</font>  
2. <font color = "clime">Redis哨兵架构中主要包括两个部分：Redis Sentinel集群和Redis数据集群。</font>  
3. **<font color = "clime">哨兵原理：</font>**  
    * **<font color = "red">心跳检查：Sentinel通过三个定时任务来完成对各个节点的发现和监控，这是保证Redis高可用的重要机制。</font>**  
        * 每隔10秒，每个Sentinel节点会向主节点和从节点发送`info命令` **<font color = "clime">获取最新的拓扑结构。</font>**   
        * 每隔2秒，每个Sentinel节点会向Redis数据节点的`__sentinel__：hello频道`上发送该Sentinel节点对于主节点的判断以及当前Sentinel节点的信息，同时每个Sentinel节点也会订阅该频道， **<font color = "clime">了解其他Sentinel节点以及它们对主节点的判断。</font>**  
        * 每隔1秒，每个Sentinel节点会向主节点、从节点、其余Sentinel节点发送一条`ping命令` **<font color = "clime">做一次心跳检测。</font>**  
    * **<font color = "red">主观下线和客观下线：</font>** 首先单个Sentinel节点认为数据节点主观下线，询问其他Sentinel节点，Sentinel多数节点认为主节点存在问题，这时该 Sentinel节点会对主节点做客观下线的决定。
    * **<font color = "red">故障转移/主节点选举：</font>** Sentinel节点的领导者根据策略在从节点中选择主节点。    
    * **<font color = "red">Sentinel选举：</font>** Sentinel集群是集中式架构，基于raft算法。  


##### 1.16.2.4.5. Redis集群模式
1. **<font color = "red">根据执行分片的位置，可以分为三种分片方式：</font>** 客户端分片、代理分片、服务器分片：官方Redis Cluster。  
2. **<font color = "clime">Redis集群的服务端：</font>**  
    * 数据分布
        * Redis数据分区
        * 集群限制
            1. <font color = "red">key批量操作支持有限。</font>如mset、mget，目前只支持具有相同slot值的key执行批量操作。对于映射为不同slot值的key由于执行mset、mget等操作可能存在于多个节点上因此不被支持。   
            2. key事务操作支持有限。同理只支持多key在同一节点上的事务操作，当多个key分布在不同的节点上时无法使用事务功能。     
            5. 复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。  
    * 故障转移：
        * 故障发现：主观下线(pfail)和客观下线(fail)。  
        * 故障恢复：当从节点通过内部定时任务发现自身复制的主节点进入客观下线；从节点发起选举；其余主节点选举投票。  
3. **<font color = "clime">Redis集群的客户端：</font>**  
&emsp; Redis集群对客户端通信协议做了比较大的修改，为了追求性能最大化，并没有采用代理的方式，而是采用客户端直连节点的方式。    
    * 请求重定向：在集群模式下，Redis接收任何键相关命令时首先计算键对应的槽，再根据槽找出所对应的节点，如果节点是自身，则处理键命令；否则回复MOVED重定向错误，通知客户端请求正确的节点。这个过程称为MOVED重定向。  
    * ASK重定向：Redis集群支持在线迁移槽(slot)和数据来完成水平伸缩，当slot对应的数据从源节点到目标节点迁移过程中，客户端需要做到智能识别，保证键命令可正常执行。例如当一个slot数据从源节点迁移到目标节点时，期间可能出现一部分数据在源节点，而另一部分在目标节点。  
        1. 客户端根据本地slots缓存发送命令到源节点，如果存在键对象则直接执行并返回结果给客户端。  
        2. **<font color = "clime">`如果键对象不存在，则可能存在于目标节点，这时源节点会回复ASK重定向异常。格式如下：(error)ASK{slot}{targetIP}：{targetPort}。`</font>**   
        3. `客户端从ASK重定向异常提取出目标节点信息，`发送asking命令到目标节点打开客户端连接标识，再执行键命令。如果存在则执行，不存在则返回不存在信息。   

    &emsp; **<font color = "clime">ASK与MOVED虽然都是对客户端的重定向控制，但是有着本质区别。ASK重定向说明集群正在进行slot数据迁移，客户端无法知道什么时候迁移完成，因此只能是临时性的重定向，客户端不会更新slots缓存。但是MOVED重定向说明键对应的槽已经明确指定到新的节点，因此需要更新slots缓存。</font>**  

#### 1.16.2.5. Redis常见问题与优化


### 1.16.3. 分布式限流
&emsp; 限流的地方、怎么限流？  
1. **<font color = "clime">一个限流系统的设计要考虑限流对象、限流算法、限流方式、限流设计的要点。</font>**  
2. 限流的位置：网关、系统还是接口？  
3. `限流对象分类：基于请求限流、基于资源限流。` 阿里Sentinel是针对`qps和线程数`进行限流。   
4. 限流算法：  
    * 固定窗口算法，有时会让通过请求量允许为限制的两倍。  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/problems/problem-24.png)  
    * 滑动窗口算法， **<font color = "clime">`避免了固定窗口计数器带来的双倍突发请求。`</font>** 但时间区间的精度越高，算法所需的空间容量就越大。  
    * 漏桶算法，实现流量整形和流量控制。漏洞底部的设计大小固定，水流速度固定。漏桶算法的缺陷也很明显，当短时间内有大量的突发请求时，即便此时服务器没有任何负载，每个请求也都得在队列中等待一段时间才能被响应。  
    * 令牌桶算法，
        1. 漏桶算法和令牌桶算法在设计上的区别：`漏桶算法中“水滴”代表请求，令牌桶中“水滴”代表请求令牌。`   
        2. **<font color = "blue">只要令牌桶中存在令牌，那么就允许突发地传输数据直到达到用户配置的门限，所以它适合于具有突发特性的流量。</font>** 
5. 限流方式有服务降级、服务拒绝。 

### 1.16.4. 服务降级
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/problems/problem-36.png)  


## 1.17. 分布式消息队列
### 1.17.1. mq
1. 为什么使用mq？  
    * 优点：解耦（调用多个系统，非同步调用）、异步、削锋（削qps）  
2. 消息队列选型  
3. 消息队列使用事项
    1. 保障高可用  
    2. 消息队列丢失消息有3种情况：生产者丢失数据、mq客户端丢失数据、消费者丢失数据。提供两种方案解决。    
    2. 重复消费  
        消费接口幂等性。  
    3. 顺序消费  
        发送到单个queue或partition，单线程消费。  
    4. **<font color = "red">~~消息积压~~</font>**  
        `修复消费者问题` ---> ~~将原topic下的消息迁移到一个新的扩容的topic下（分区/队列扩容）~~ ---> 扩容消费者  
        &emsp; 一般这种比较着急的问题，`最好的办法就是临时扩容，用更快的速度来消费数据。`  

        1. 临时建立一个新的Topic，然后调整queue的数量为原来的10倍或者20倍，根据堆积情况来决定。  
        2. 然后写一个临时分发消息的consumer程序，这个程序部署上去消费积压的消息，消费的就是刚刚新建的Topic，消费之后不做耗时的处理，只需要直接均匀的轮询将这些消息轮询的写入到临时创建的queue里面即可。  
        3. 然后增加相应倍数的机器来部署真正的consumer消费，注意这里的Topic，然后让这些consumer去真正的消费这些临时的queue里面的消息。  
  
    &emsp; 一个topic堵住了，新建一个topic去进行分流，临时将queue资源和consumer资源扩大10倍，将消息平均分配到这些新增的queue资源和consumer资源上，以正常10倍的速度来消费消息，等到这些堆积的消息消费完了，便可以恢复到原来的部署架构。  
    &emsp; 这种只是用于临时解决一些异常情况导致的消息堆积的处理，如果消息经常出现堵塞的情况，那该考虑一下彻底增强系统的部署架构了。  
5. 消息的推拉机制  
    1. **<font color = "red">一般说的推拉模式指的是broker和consumer之间的，producer和broker之间的模式是推的模式，也就是每次producer每次生产了消息，会主动推给broker。</font>**  
    2. 推模式以及优缺点
        1. 优点
            1. **<font color = "clime">一个优点就是延迟小，实时性比较好，</font>** broker接收到消息之后就会立刻推送到Consumer，实时性相对来说是比较高的。  
            2. 还有一个优点其实就是简化了Consumer端的逻辑，消费端不需要自己去处理这个拉取的逻辑，只需要监听这个消息的topic，然后去专心的处理这个消息的业务逻辑即可。  
        2. 缺点
            1. 第二点简化了Consumer消费端的逻辑的同时，也就复杂化了broker端的逻辑，这其实也不算是优点或者缺点吧，算是这个模式的一个特点，需要根据场景来选择自己合适的模式。
            2. **<font color = "clime">最大的一个缺点就是推送的速率和消费的速率不好去匹配。</font>** 如果broker拿到消息就推给Consumer，不在乎Consumer的消费能力如何，就往Consumer直接扔，那Consumer有可能会崩溃。
            3. **<font color = "clime">还有一个缺点就是消息推出去之后，无法保证消息发送成功，</font>** push采用的是广播模式，也就是只有服务端和客户端都在同一个频道的时候，推模式才可以成功的将消息推到消费者。
    3. 拉模式以及优缺点  
        1. 优点
            1. **<font color = "clime">最大的优点就是主动权掌握在Consumer这边了，每个消费者的消费能力可能不一样，消费者可以根据自身的情况来拉取消息的请求，如果消费者真的出现那种忙不过来的情况下，可以根据一定的策略去暂停拉取。</font>** 
            2. **<font color = "clime">拉模式也更适合批量消息的发送，推模式是来一个消息就推一个，</font>** 当然也可以缓存一部分消息再推送，但是无法确定Consumer是否能够处理这批推送的消息，拉模式则是Consumer主动来告诉broker，这样broker也可以更好的决定缓存多少消息用于批量发送。
        2. 缺点  
            1. 拉模式需要Consumer对于服务端有一定的了解， **<font color = "clime">主要的缺点就是实时性较差，</font>** 针对于服务器端的实时更新的信息，客户端还是难以获取实时的信息。  
            &emsp; **<font color = "clime">不能频繁的去拉取，这样也耗费性能，因此就必须降低请求的频率，请求间隔时间也就意味着消息的延迟。</font>**   
    4. 常见MQ的选择  
    &emsp; RocketMQ最终决定的拉模式，kafka也是如此。  

### 1.17.2. Kafka

#### 1.17.2.1. kafka基本概念
&emsp; Apache Kafka是一个分布式流处理平台。支持百万及TPS。    

##### 1.17.2.1.1. kafka生产者
1. Producer发送消息的过程：需要经过拦截器，序列化器和分区器，最终由累加器批量发送至Broker。  
&emsp; Kafka分区策略查看[消息分区](/docs/microService/mq/kafka/topic.md)。  
2. **<font color = "clime">如何提升Producer的性能？异步，批量，压缩。</font>**  
3. 多线程处理：  
&emsp; 多线程单KafkaProducer实例（可以理解为单例模式）、多线程多KafkaProducer实例（可以理解为多例，原型模式）。  
&emsp; **<font color = "clime">如果是对分区数不多的Kafka集群而言，比较推荐使用第一种方法，即在多个producer用户线程中共享一个KafkaProducer实例。若是对那些拥有超多分区的集群而言，釆用第二种方法具有较高的可控性，方便producer的后续管理。</font>**   

##### 1.17.2.1.2. 消息分区
1. 分区说明  
&emsp; 分区(Partition)的作用就是提供负载均衡的能力，单个topic的不同分区可存储在相同或不同节点机上，为实现系统的高伸缩性（Scalability），`不同的分区被放置到不同节点的机器上，`各节点机独立地执行各自分区的读写任务，如果性能不足，可通过添加新的节点机器来增加整体系统的吞吐量。  
2. 服务端物理分区分配
    1. 分区策略  
    在所有broker上均匀地分配分区副本； **<font color = " red">确保分区的每个副本分布在不同的broker上。</font>**  
    2. ~~分区存储数据~~
3. 客户端怎么分区？
    1. 生产者
        1. 分区策略  
        &emsp; 如果没有指定分区，但是 `消息的key不为空，则基于key的哈希值来选择一个分区；`  
        &emsp; 如果既没有指定分区，且 `消息的key也是空，则用轮询的方式选择一个分区。`
    2. 消费者  
        1. 消费者`分组消费`。同一时刻，`一条消息只能被组中的一个消费者实例消费。`  
        2. 消费者消费分区策略
            1. 轮询。  
            2. range策略。 
4. 分区数设置
5. 分区后保持有序，查看顺序消费。    

##### 1.17.2.1.3. kafka消费者
1. 消费者/消费者组/消费者组重平衡  
    1. `消费者组：Kafka消费端确保一个Partition在一个消费者组内只能被一个消费者消费。`  
    2. **<font color = "red">消费者组重平衡：</font>**  
    &emsp; **什么是重平衡？ 假设组内某个实例挂掉了，Kafka能够自动检测到，然后把这个`Failed实例之前负责的分区转移给其他活着的消费者`，这个过程称之为重平衡(Rebalance)。**  
    &emsp; 重平衡触发条件：组成员发生变更、组订阅topic数发生变更、组订阅topic的分区数发生变更。
    3.  **重平衡流程：**  
    &emsp; 引入协调者（每一台Broker上都有一个协调者组件），由协调者为消费组服务，为消费者们做好协调工作。一个消费组只需一个协调者进行服务。  
    &emsp; 1. 当消费者收到协调者的再均衡开始通知时，需要立即提交偏移量；  
    &emsp; **2. 消费者在收到提交偏移量成功的响应后，再发送JoinGroup请求，重新申请加入组，请求中会含有订阅的主题信息；**  
    &emsp; **<font color = "red">3. 当协调者收到第一个JoinGroup请求时，会把发出请求的消费者指定为Leader消费者，</font>**  
    &emsp; **<font color = "red">4. Leader消费者收到JoinGroup响应后，根据消费者的订阅信息制定分配方案，把方案放在SyncGroup请求中，发送给协调者。</font>**  
    &emsp; **<font color = "red">5. 协调者收到分配方案后，再通过SyncGroup响应把分配方案发给所有消费组。</font>**  
    4. **如何避免重平衡？**  
    &emsp; **<font color = "clime">其实只需要避免实例减少的情况就行了。</font>** ~~消费时间过长~~  
2. 消费者位移管理  
    &emsp; **<font color = "red">位移提交有两种方式：</font><font color = "clime">自动提交、手动提交。</font>**  
3. 怎样消费  
    * 消费者分区分配策略：轮询RoundRobin、range策略。
    * 消费语义：至少一次、至多一次、正好一次。

##### 1.17.2.1.4. kafka服务端


#### 1.17.2.2. kafka特性
* 高并发：支持百万级TPS。    
    * 高性能：磁盘I/O-顺序读写、基于Sendfile实现零拷贝。  
    * 高可用：Kafka副本机制。  
* 分布式：  
    * 可靠性：副本的一致性保证、可以保证消息队列不丢失、幂等（重复消费）和事务。  
    * 如何让Kafka的消息有序？  


##### 1.17.2.2.1. 【1】高性能(读写机制) ，Kafka为什么吞吐量大、速度快？
&emsp; Kafka的消息是保存或缓存在磁盘上的，一般认为在磁盘上读写数据是会降低性能的，因为寻址会比较消耗时间，但是实际上，Kafka的特性之一就是高吞吐率。 **Kafka之所以能这么快，是因为：「顺序写磁盘、大量使用内存页、零拷贝技术的使用」..**  


###### 1.17.2.2.1.1. 网络IO优化
1. Kafka 的数据传输通过TransportLayer来完成，其子类 PlaintextTransportLayer 通过Java NIO的FileChannel的transferTo和transferFrom方法实现零拷贝。  
2. 批量读写、批量压缩。  

###### 1.17.2.2.1.2. 内存
&emsp; 为了优化读写性能，Kafka利用了操作系统本身的Page Cache，就是利用操作系统自身的内存而不是JVM空间内存。  

###### 1.17.2.2.1.3. 持久化/磁盘I/O-顺序读写
&emsp; kafka的消息是不断追加到文件中的，这个特性使kafka可以充分利用磁盘的顺序读写性能。  



##### 1.17.2.2.2. 【2】高可用与数据一致性(副本机制)
1. **<font color = "blue">`Kafka副本中只有Leader可以和客户端交互，进行读写，`其他副本是只能同步，不能分担读写压力。</font>**  
2. 服务端Leader的选举：从ISR（保持同步的副本）集合副本中选取。  
3. 服务端副本消息的同步：  
&emsp; LEO，低水位，记录了日志的下一条消息偏移量，即当前最新消息的偏移量加一；HW，高水位，界定了消费者可见的消息，是ISR队列中最小的LEO。  
    1. Follower副本更新LEO和HW：  
    &emsp; 更新LEO和HW的时机： **<font color = "clime">Follower向Leader拉取了消息之后。(⚠️注意：Follower副本只和Leader副本交互。)</font>**  
    &emsp; **<font color = "red">会用获取的偏移量加1来更新LEO，并且用Leader的HW值和当前LEO的最小值来更新HW。</font>**  
    2. Leader副本上LEO和HW的更新：  
        * 正常情况下Leader副本的更新时机有两个：一、收到生产者的消息；二、被Follower拉取消息。(⚠️注意：Leader副本即和Follower副本交互，也和生产者交互。)  
            * 当收到生产者消息时，会用当前偏移量加1来更新LEO，然后取LEO和远程ISR副本中LEO的最小值更新HW。 
            * 当Follower拉取消息时，会更新Leader上存储的Follower副本LEO，然后判断是否需要更新HW，更新的方式和上述相同。 
        * 除了这两种正常情况，当发生故障时，例如Leader宕机，Follower被选为新的Leader，会尝试更新HW。还有副本被踢出ISR时，也会尝试更新HW。 
4. 在服务端Leader切换时，会存在数据丢失和数据不一致的问题。  
    1. 主从切换，数据不一致的情况如下：  
    &emsp; A作为Leader，A已写入m0、m1两条消息，且HW为2，而B作为Follower，只有m0消息，且HW为1。若A、B同时宕机，且B重启时，A还未恢复，则B被选为Leader。  
    &emsp; 在B重启作为Leader之后，收到消息m2。A宕机重启后向成为Leader的B发送Fetch请求，发现自己的HW和B的HW一致，都是2，因此不会进行消息截断，而这也造成了数据不一致。  
    2. 引入Leader Epoch机制：  
    &emsp; **<font color = "blue">为了解决HW可能造成的数据丢失和数据不一致问题，Kafka引入了Leader Epoch机制。</font>** 在每个副本日志目录下都有一个leader-epoch-checkpoint文件，用于保存Leader Epoch信息。  
    &emsp; Leader Epoch，分为两部分，前者Epoch，表示Leader版本号，是一个单调递增的正整数，每当Leader变更时，都会加1；`后者StartOffset，为每一代Leader写入的第一条消息的位移。`   
5. 客户端数据请求：  
&emsp; 集群中的每个broker都会缓存所有主题的分区副本信息，客户端会定期发送元数据请求，然后将获取的集群元数据信息进行缓存。  

##### 1.17.2.2.3. ~~可靠性~~
&emsp; Kafka作为一个商业级消息中间件，消息可靠性的重要性可想而知。如何确保消息的精确传输？如何确保消息的准确存储？如何确保消息的正确消费？这些都是需要考虑的问题。  
&emsp; 可靠性保证：确保系统在各种不同的环境下能够发生一致的行为。  
&emsp; Kafka的保证：  

* 保证分区消息的顺序
	* 如果使用同一个生产者往同一个分区写入消息，而且消息B在消息A之后写入
	* 那么Kafka可以保证消息B的偏移量比消息A的偏移量大，而且消费者会先读取消息A再读取消息B
* 只有当消息被写入分区的所有同步副本时（文件系统缓存），它才被认为是已提交
	* 生产者可以选择接收不同类型的确认，控制参数acks
* 只要还有一个副本是活跃的，那么“已提交的消息就不会丢失”  
* 消费者只能读取已经提交的消息  



###### 1.17.2.2.3.1. 如何保证消息队列不丢失?  
1. 在Producer端、Broker端、Consumer端都有可能丢失消息。  
2. Producer端：  
&emsp; 为防止Producer端丢失消息， **<font color = "red">除了将ack设置为all，表明所有副本 Broker 都要接收到消息，才算“已提交”。</font>**  
&emsp; `还可以使用带有回调通知的发送API，即producer.send(msg, callback)`。  
3. Broker端:  
&emsp; Kafka没有提供同步刷盘的方式。要完全让kafka保证单个broker不丢失消息是做不到的，只能通过调整刷盘机制的参数缓解该情况。  
&emsp; 为了解决该问题，kafka通过producer和broker协同处理单个broker丢失参数的情况。 **<font color = "red">`一旦producer发现broker消息丢失，即可自动进行retry。`</font>** 除非retry次数超过阀值（可配置），消息才会丢失。此时需要生产者客户端手动处理该情况。  
4. ~~Consumer端：~~  
&emsp; 采用手动提交位移。  
5. `方案二：使用补偿机制`  
&emsp; 服务端丢失消息处理：建立消息表，发送消息前保存表记录，发送后更新表记录。  
&emsp; 客户端丢失消息处理：服务端提供查询接口。 

###### 1.17.2.2.3.2. 分区保证消费顺序  
1. Apache Kafka官方保证了partition内部的数据有效性（追加写、offset读）。为了提高Topic的并发吞吐能力，可以提高Topic的partition数，并通过设置partition的replica来保证数据高可靠。但是在多个Partition时，不能保证Topic级别的数据有序性。  
2. 顺序消费
    1. 前提：[消息分区](/docs/microService/mq/kafka/topic.md)  
    2. 针对消息有序的业务需求，还分为全局有序和局部有序：  
        * 全局有序：一个Topic下的所有消息都需要按照生产顺序消费。
        * 局部有序：一个Topic下的消息，只需要满足同一业务字段的要按照生产顺序消费。例如：Topic消息是订单的流水表，包含订单orderId，业务要求同一个orderId的消息需要按照生产顺序进行消费。
3. 全局有序：  
&emsp; 一个生产者、一个分区、一个消费者（或使用分布式锁），并严格到一个消费线程。   
4. 局部有序：    
&emsp; 多分区时，要满足局部有序，只需要在发消息的时候指定Partition Key，Kafka对其进行Hash计算，根据计算结果决定放入哪个Partition。这样Partition Key相同的消息会放在同一个Partition。此时，Partition的数量仍然可以设置多个，提升Topic的整体吞吐量。   
5. ~~注意事项：~~  
    1. 消息重试对顺序消息，无影响。   
6. `业务上实现有序消费（***着重看看）`
    &emsp; 除了消息队列自身的顺序消费机制，我们可以合理地对消息进行改造，从业务上实现有序的目的。具体的方式有以下几种。  

    1. 根据不同的业务场景，以发送端或者消费端时间戳为准  
    &emsp; 比如在电商大促的秒杀场景中，如果要对秒杀的请求进行排队，就可以使用秒杀提交时服务端的时间戳，虽然服务端不一定保证时钟一致，但是在这个场景下，我们不需要保证绝对的有序。  
    2. 每次消息发送时生成唯一递增的 ID  
    &emsp; 在每次写入消息时，可以考虑添加一个单调递增的序列 ID，在消费端进行消费时，缓存最大的序列 ID，只消费超过当前最大的序列 ID 的消息。这个方案和分布式算法中的 Paxos 很像，虽然无法实现绝对的有序，但是可以保证每次只处理最新的数据，避免一些业务上的不一致问题。  
    3. 通过缓存时间戳的方式  
    &emsp; 这种方式的机制和递增 ID 是一致的，即当生产者在发送消息时，添加一个时间戳，消费端在处理消息时，通过缓存时间戳的方式，判断消息产生的时间是否最新，如果不是则丢弃，否则执行下一步。  


###### 1.17.2.2.3.3. 消费语义介绍 
&emsp; 消息传递语义message delivery semantic，简单说就是消息传递过程中消息传递的保证性。主要分为三种：  

* at most once：最多一次。消息可能丢失也可能被处理，但最多只会被处理一次。  
* at least once：至少一次。消息不会丢失，但可能被处理多次。可能重复，不会丢失。  
* exactly once：精确传递一次。消息被处理且只会被处理一次。不丢失不重复就一次。  


&emsp; at most once，最多一次，可以理解为可能发生消息丢失；at least once，至少一次，可以理解为可能发生重复消费。kafka通过ack的配置来实现这两种。  
&emsp; 理想情况下肯定是希望系统的消息传递是严格exactly once，也就是保证不丢失、只会被处理一次，但是很难做到。 **exactly once也被称为幂等性。**  

![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/kafka/kafka-119.png)  

###### 1.17.2.2.3.4. 幂等（重复消费）
1. **幂等又称为exactly once（精确传递一次。消息被处理且只会被处理一次。不丢失不重复就一次）。**  
2. `Kafka幂等是针对生产者角度的特性。`kafka只保证producer单个会话中的单个分区幂等。  
3. **<font color = "red">Kafka幂等性实现机制：（`producer_id和序列号，进行比较`）</font>**  
    1. `每一个producer在初始化时会生成一个producer_id，并为每个目标partition维护一个"序列号"；`
    2. producer每发送一条消息，会将 \<producer_id,分区\> 对应的“序列号”加1；  
    3. broker端会为每一对 \<producer_id,分区\> 维护一个序列号，对于每收到的一条消息，会判断服务端的SN_old和接收到的消息中的SN_new进行对比：  

        * 如果SN_old < SN_new+1，说明是重复写入的数据，直接丢弃。    
        * 如果SN_old > SN_new+1，说明中间有数据尚未写入，或者是发生了乱序，或者是数据丢失，将抛出严重异常：OutOfOrderSeqenceException。 
4. Kafka消费者的幂等性（kafka怎样保证消息仅被消费一次？）  
    &emsp; 在使用kafka时，大多数场景对于数据少量的不一致(重复或者丢失)并不关注，比如日志，因为不会影响最终的使用或者分析，但是在某些应用场景(比如业务数据)，需要对任何一条消息都要做到精确一次的消费，才能保证系统的正确性，`kafka并不提供准确一致的消费API，需要在实际使用时借用外部的一些手段来保证消费的精确性。`    
    &emsp; 当消费者消费到了重复的数据的时候，消费者需要去过滤这部分的数据。主要有以下两种思路：  
    1. 将消息的offset存在消费者应用中或者第三方存储的地方  
    &emsp; 可以将这个数据存放在redis或者是内存中，消费消息时，如果有这条数据的话，就不会去做后续操作  
    2. 数据落库的时候，根据主键去过滤  
    &emsp; 在落库时，如果不不在这条数据，则去新增，如果存在则去修改  

###### 1.17.2.2.3.5. 事务


## 1.18. 分布式通信
### 1.18.1. 通信基础
&emsp; 1. 序列化。  

### 1.18.2. 网络IO
#### 1.18.2.1. 五种I/O模型
1. **<font color = "red">网络IO的本质就是socket流的读取，通常一次IO读操作会涉及到两个对象和两个阶段。**</font>  
    * **<font color = "clime">两个对象：用户进程（线程）、内核对象（内核态和用户态）。</font><font color = "blue">用户进程请求内核。</font>**   
    * **<font color = "clime">`内核中涉及两个阶段：1. 等待数据准备；2. 数据从内核空间拷贝到用户空间。`</font>**  
    &emsp; `⚠️基于以上两个阶段就产生了五种不同的IO模式，`分别是：阻塞I/O模型、非阻塞I/O模型、多路复用I/O模型、信号驱动I/O模型、异步I/O模型。其中，前四种被称为同步I/O。  
2. **<font color = "blue">同步（等待结果）和阻塞（线程）：</font>**  
    * 异步和同步：对于请求结果的获取是客户端主动获取结果，还是由服务端来通知结果。    
    * 阻塞和非阻塞：在等待这个函数返回结果之前，当前的线程是处于挂起状态还是运行状态。 
3. 同步阻塞I/O：  
    1. 流程：  
        ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/netty/netty-1.png)  
        1. 用户进程发起recvfrom系统调用内核。用户进程【同步】等待结果；
        2. 内核等待I/O数据返回，此时用户进程处于【阻塞】，一直等待内核返回；
        3. I/O数据返回后，内核将数据从内核空间拷贝到用户空间；  
        4. 内核将数据返回给用户进程。  
    特点：两阶段都阻塞。  
    2. BIO采用多线程时，`大量的线程占用很大的内存空间，并且线程切换会带来很大的开销，10000个线程真正发生读写事件的线程数不会超过20%，每次accept都开一个线程也是一种资源浪费。`  
4. 同步非阻塞I/O：  
    1. 流程：  
        ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/netty/netty-2.png)  
        1. 用户进程发起recvfrom系统调用内核。用户进程【同步】等待结果；
        2. 内核等待I/O数据返回。无I/O数据返回时，内核返回给用户进程ewouldblock结果。`【非阻塞】用户进程，立马返回结果。`但 **<font color = "clime">用户进程要主动轮询查询结果。</font>**  
        3. I/O数据返回后，内核将数据从内核空间拷贝到用户空间；  
        4. 内核将数据返回给用户进程。  
    特点：`第一阶段不阻塞但要轮询，`第二阶段阻塞。  
    2. NIO`每次轮询所有fd（包括没有发生读写事件的fd）会很浪费cpu。`  
5. 多路复用I/O：（~~同步阻塞，又基于回调通知~~）  
    1. 为什么有多路复用？  
    &emsp; 如果一个I/O流进来，就开启一个进程处理这个I/O流。那么假设现在有一百万个I/O流进来，那就需要开启一百万个进程一一对应处理这些I/O流（——这就是传统意义下的多进程并发处理）。思考一下，一百万个进程，CPU占有率会多高，这个实现方式及其的不合理。所以人们提出了I/O多路复用这个模型，一个线程，通过记录I/O流的状态来同时管理多个I/O，可以提高服务器的吞吐能力。  
    2. `多路是指多个socket套接字，复用是指复用同一个进程。`  
    3. 流程：  
        ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/netty/netty-3.png)  
        1. 用户多进程或多线程发起select系统调用，复用器Selector会监听注册进来的进程事件。用户进程【同步】等待结果；
        2. 内核等待I/O数据返回，无数据返回时，select进程【阻塞】，进程也受阻于select调用；
        2. I/O数据返回后，内核将数据从内核空间拷贝到用户空间， **<font color = "clime">Selector`通知`哪个进程哪个事件；</font>**  
        4. 进程发起recvfrom系统调用。
    多路复用I/O模型和阻塞I/O模型并没有太大的不同，事实上，还更差一些，因为它需要使用两个系统调用(select和recvfrom)，而阻塞I/O模型只有一次系统调用(recvfrom)。但是Selector的优势在于它可以同时处理多个连接。   
    4. 多路复用`能支持更多的并发连接请求。`  
6. 信号驱动IO  
7. 异步IO

#### 1.18.2.2. I/O多路复用详解
1. **<font color = "clime">`~~select,poll,epoll只是I/O多路复用模型中第一阶段，即获取网络数据、用户态和内核态之间的拷贝。~~`</font>** 此阶段会阻塞线程。  
2. **select()：**  
    1. **select运行流程：**  
        &emsp; **<font color = "red">select()运行时会将fd_set集合从用户态拷贝到内核态。</font>** 在内核态中线性扫描socket，即采用轮询。如果有事件返回，会将内核态的数组相应的FD置位。最后再将内核态的数据返回用户态。  
    2. **select机制的问题：（拷贝、两次轮询、FD置位）**  
        * 为了减少数据拷贝带来的性能损坏，内核对被监控的fd_set集合大小做了限制，并且这个是通过宏控制的，大小不可改变（限制为1024）。  
        * 每次调用select， **<font color = "red">1)需要把fd_set集合从用户态拷贝到内核态，</font>** **<font color = "clime">2)需要在内核遍历传递进来的所有fd_set（对socket进行扫描时是线性扫描，即采用轮询的方法，效率较低），</font>** **<font color = "red">3)如果有数据返回还需要从内核态拷贝到用户态。</font>** 如果fd_set集合很大时，开销比较大。 
        * 由于运行时，需要将FD置位，导致fd_set集合不可重用。  
        * **<font color = "clime">select()函数返回后，</font>** 调用函数并不知道是哪几个流（可能有一个，多个，甚至全部）， **<font color = "clime">还得再次遍历fd_set集合处理数据，即采用无差别轮询。</font>**   
        * ~~惊群~~   
3. **poll()：** 运行机制与select()相似。将fd_set数组改为采用链表方式pollfds，没有连接数的限制，并且pollfds可重用。   
4. **epoll()：**   
    1. **epoll的三个函数：**  
        ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/netty/netty-119.png)  
        * 调用epoll_create，会在内核cache里建个红黑树，同时也会再建立一个rdllist双向链表。 
        * epoll_ctl将被监听的描述符添加到红黑树或从红黑树中删除或者对监听事件进行修改。
        * 双向链表，用于存储准备就绪的事件，当epoll_wait调用时，仅查看这个rdllist双向链表数据即可。epoll_wait阻塞等待注册的事件发生，返回事件的数目，并将触发的事件写入events数组中。   

        -------------------
        1. 执行epoll_create()时，创建了红黑树和就绪链表；
        2. 执行epoll_ctl()时，如果增加socket句柄，则检查在红黑树中是否存在，存在立即返回，不存在则添加到树干上，然后向内核注册回调函数，用于当中断事件来临时向准备就绪链表中插入数据；
        3. 执行epoll_wait()时立刻返回准备就绪链表里的数据即可。
        
        -----------
        首先epoll_create创建一个epoll文件描述符，底层同时创建一个红黑树，和一个就绪链表；红黑树存储所监控的文件描述符的节点数据，就绪链表存储就绪的文件描述符的节点数据；epoll_ctl将会添加新的描述符，首先判断是红黑树上是否有此文件描述符节点，如果有，则立即返回。如果没有， 则在树干上插入新的节点，并且告知内核注册回调函数。当接收到某个文件描述符过来数据时，那么内核将该节点插入到就绪链表里面。epoll_wait将会接收到消息，并且将数据拷贝到用户空间，清空链表。对于LT模式epoll_wait清空就绪链表之后会检查该文件描述符是哪一种模式，如果为LT模式，且必须该节点确实有事件未处理，那么就会把该节点重新放入到刚刚删除掉的且刚准备好的就绪链表，epoll_wait马上返回。ＥＴ模式不会检查，只会调用一次
    2. **epoll机制的工作模式：**  
        * LT模式（默认，水平触发，level trigger）：当epoll_wait检测到某描述符事件就绪并通知应用程序时，应用程序可以不立即处理该事件；下次调用epoll_wait时，会再次响应应用程序并通知此事件。    
        * ET模式（边缘触发，edge trigger）：当epoll_wait检测到某描述符事件就绪并通知应用程序时，应用程序必须立即处理该事件。如果不处理，下次调用epoll_wait时，不会再次响应应用程序并通知此事件。（直到做了某些操作导致该描述符变成未就绪状态了，也就是说 **<font color = "clime">边缘触发只在状态由未就绪变为就绪时只通知一次。</font>** ）   

        &emsp; 由此可见：ET模式的效率比LT模式的效率要高很多。只是如果使用ET模式，就要保证每次进行数据处理时，要将其处理完，不能造成数据丢失，这样对编写代码的人要求就比较高。  
        &emsp; 注意：ET模式只支持非阻塞的读写：为了保证数据的完整性。  

    3. **epoll机制的优点：**  
        * 调用epoll_ctl时拷贝进内核并保存，之后每次epoll_wait不拷贝。  
        * epoll()函数返回后，调用函数以O(1)复杂度遍历。  
5. 两种IO多路复用模式：[Reactor和Proactor](/docs/microService/communication/Netty/Reactor.md)  

#### 1.18.2.3. 多路复用之Reactor模式
1. `Reactor，是网络编程中基于IO多路复用的一种设计模式，是event-driven architecture的一种实现方式，处理多个客户端并发的向服务端请求服务的场景。`    
2. **<font color = "red">Reactor模式核心组成部分包括Reactor线程和worker线程池，</font><font color = "blue">`其中Reactor负责监听和分发事件，线程池负责处理事件。`</font>** **<font color = "clime">而根据Reactor的数量和线程池的数量，又将Reactor分为三种模型。</font>**  
3. **单线程模型(单Reactor单线程)**  
&emsp; ~~这是最基本的单Reactor单线程模型。其中Reactor线程，负责多路分离套接字，有新连接到来触发connect事件之后，交由Acceptor进行处理，有IO读写事件之后交给hanlder处理。~~  
&emsp; ~~Acceptor主要任务就是构建handler，在获取到和client相关的SocketChannel之后，绑定到相应的hanlder上，对应的SocketChannel有读写事件之后，基于racotor分发,hanlder就可以处理了（所有的IO事件都绑定到selector上，有Reactor分发）。~~  
&emsp; **<font color = "red">Reactor单线程模型，指的是所有的IO操作都在同一个NIO线程上面完成。</font>** 单个NIO线程会成为系统瓶颈，并且会有节点故障问题。   
4. **多线程模型(单Reactor多线程)**  
&emsp; ~~相对于第一种单线程的模式来说，在处理业务逻辑，也就是获取到IO的读写事件之后，交由线程池来处理，这样可以减小主reactor的性能开销，从而更专注的做事件分发工作了，从而提升整个应用的吞吐。~~  
&emsp; Rector多线程模型与单线程模型最大的区别就是有一组NIO线程处理IO操作。在极个别特殊场景中，一个NIO线程(Acceptor线程)负责监听和处理所有的客户端连接可能会存在性能问题。    
5. **主从多线程模型(多Reactor多线程)**    
&emsp; 主从Reactor多线程模型中，Reactor线程拆分为mainReactor和subReactor两个部分， **<font color = "clime">`mainReactor只处理连接事件`，`读写事件交给subReactor来处理`。</font>** 业务逻辑还是由线程池来处理。  
&emsp; mainRactor只处理连接事件，用一个线程来处理就好。处理读写事件的subReactor个数一般和CPU数量相等，一个subReactor对应一个线程。  
&emsp; ~~第三种模型比起第二种模型，是将Reactor分成两部分：~~  
&emsp; ~~mainReactor负责监听server socket，用来处理新连接的建立，将建立的socketChannel指定注册给subReactor。~~  
&emsp; ~~subReactor维护自己的selector, 基于mainReactor 注册的socketChannel多路分离IO读写事件，读写网 络数据，对业务处理的功能，另其扔给worker线程池来完成。~~  
&emsp; Reactor主从多线程模型中，一个连接accept专门用一个线程处理。  
&emsp; 主从Reactor线程模型的特点是：服务端用于接收客户端连接的不再是个1个单独的NIO线程，而是一个独立的NIO线程池。Acceptor接收到客户端TCP连接请求处理完成后（可能包含接入认证等），将新创建的SocketChannel注册到IO线程池（sub reactor线程池）的某个IO线程上，由它负责SocketChannel的读写和编解码工作。Acceptor线程池仅仅只用于客户端的登陆、握手和安全认证，一旦链路建立成功，就将链路注册到后端subReactor线程池的IO线程上，由IO线程负责后续的IO操作。  
&emsp; 利用主从NIO线程模型，可以解决1个服务端监听线程无法有效处理所有客户端连接的性能不足问题。  


#### 1.18.2.4. IO性能优化之零拷贝
1. 比较常见的I/O流程是读取磁盘文件传输到网络中。  
2. **<font color = "clime">I/O传输中的一些基本概念：</font>**  
    * 状态切换：内核态和用户态之间的切换。  
    * CPU拷贝：内核态和用户态之间的复制。 **零拷贝："零"更多的是指在用户态和内核态之间的复制是0次。**   
    * DMA拷贝：设备（或网络）和内核态之间的复制。  
3. 仅CPU方式：  
	![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/netty/netty-66.png)  
	&emsp; **仅CPU方式读数据read流程：**  

	* 当应用程序需要读取磁盘数据时，调用read()从用户态陷入内核态，read()这个系统调用最终由CPU来完成；
	* CPU向磁盘发起I/O请求，磁盘收到之后开始准备数据；
	* 磁盘将数据放到磁盘缓冲区之后，向CPU发起I/O中断，报告CPU数据已经Ready了；
	* CPU收到磁盘控制器的I/O中断之后，开始拷贝数据，完成之后read()返回，再从内核态切换到用户态；  

    `仅CPU方式有4次状态切换，4次CPU拷贝。`    

4. CPU & DMA（Direct Memory Access，直接内存访问）方式   
	![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/netty/netty-68.png)    
	&emsp; **<font color = "red">最主要的变化是，CPU不再和磁盘直接交互，而是DMA和磁盘交互并且将数据从磁盘缓冲区拷贝到内核缓冲区，因此减少了2次CPU拷贝。共2次CPU拷贝，2次DMA拷贝，4次状态切换。之后的过程类似。</font>**  

	* 读过程涉及2次空间切换(需要CPU参与)、1次DMA拷贝、1次CPU拷贝；
	* 写过程涉及2次空间切换、1次DMA拷贝、1次CPU拷贝；  
5. `零拷贝技术的几个实现手段包括：mmap+write、sendfile、sendfile+DMA收集、splice等。`  
6. **<font color = "blue">mmap（内存映射）：</font>**   
    &emsp; **<font color = "clime">mmap是Linux提供的一种内存映射文件的机制，它实现了将内核中读缓冲区地址与用户空间缓冲区地址进行映射，从而实现内核缓冲区与用户缓冲区的共享，</font>** 又减少了一次cpu拷贝。总共包含1次cpu拷贝，2次DMA拷贝，4次状态切换。此流程中，cpu拷贝从4次减少到1次，但状态切换还是4次。   
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/netty/netty-100.png)  
7. sendfile（函数调用）：  
    1. 升级后的sendfile将内核空间缓冲区中对应的数据描述信息（文件描述符、地址偏移量等信息）记录到socket缓冲区中。  
    2. DMA控制器根据socket缓冲区中的地址和偏移量将数据从内核缓冲区拷贝到网卡中，从而省去了内核空间中仅剩的1次CPU拷贝。  

&emsp; `数据不经过用户缓冲区，这种方式又减少了1次CPU拷贝。`即有2次状态切换、0次CPU拷贝、2次DMA拷贝。  
&emsp; 但是`仍然无法对数据进行修改`，并且需要硬件层面DMA的支持， **并且sendfile只能将文件数据拷贝到socket描述符上，有一定的局限性。**   
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/netty/netty-32.png)  
8. sendfile+DMA收集
9. splice方式  
&emsp; splice系统调用是Linux在2.6版本引入的，其不需要硬件支持，并且不再限定于socket上，实现两个普通文件之间的数据零拷贝。  
&emsp; splice系统调用可以在内核缓冲区和socket缓冲区之间建立管道来传输数据，避免了两者之间的CPU拷贝操作。  
&emsp; **<font color = "clime">splice也有一些局限，它的两个文件描述符参数中有一个必须是管道设备。</font>**  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/netty/netty-35.png)  


### 1.18.3. Socket编程
&emsp; `Socket是对TCP/IP 协议的封装。`Socket 只是个接口不是协议，通过 Socket 才能使用 TCP/IP 协议，除了 TCP，也可以使用 UDP 协议来传递数据。  


### 1.18.4. NIO
&emsp; **BIO即Block I/O，同步并阻塞的IO。**  
&emsp; **<font color = "red">NIO，同步非阻塞I/O，基于io多路复用模型，即select，poll，epoll。</font>**  
&emsp; **<font color = "red">AIO即Async非阻塞，是异步非阻塞的IO。</font>**  

&emsp; BIO方式适用于连接数目比较小且固定的架构，这种方式对服务器资源要求比较高，并发局限于应用中，JDK1.4以前的唯一选择，但程序直观简单易理解。  
&emsp; NIO方式适用于连接数目多且连接比较短（轻操作）的架构，比如聊天服务器，并发局限于应用中，编程比较复杂，JDK1.4开始支持。  
&emsp; AIO方式适用于连接数目多且连接比较长（重操作）的架构，比如相册服务器，充分调用OS参与并发操作，编程比较复杂，JDK7开始支持。  

### 1.18.5. Netty
#### 1.18.5.1. Netty简介
&emsp; Netty是一个非阻塞I/O客户端-服务器框架，主要用于开发Java网络应用程序，如协议服务器和客户端。异步事件驱动的网络应用程序框架和工具用于简化网络编程，例如TCP和UDP套接字服务器。[2]Netty包括了反应器编程模式的实现。Netty最初由JBoss开发，现在由Netty项目社区开发和维护。  
&emsp; 除了作为异步网络应用程序框架，Netty还包括了对HTTP、HTTP2、DNS及其他协议的支持，涵盖了在Servlet容器内运行的能力、对WebSockets的支持、与Google Protocol Buffers的集成、对SSL/TLS的支持以及对用于SPDY协议和消息压缩的支持。自2004年以来，Netty一直在被积极开发。  

1. **Netty是由JBoss开发，基于Java NIO的一个高性能通信框架。**  
    1. Netty是一个基于NIO的client-server（客户端服务器）框架，使用它可以快速简单地开发网络应用程序。
    2. 它极大地简化并优化了TCP和UDP套接字服务器等网络编程，并且性能以及安全性等很多方面甚至都要更好。
    3. 支持多种协议，如FTP，SMTP，HTTP以及各种二进制和基于文本的传统协议。  

2. **<font color = "clime">为什么要用Netty？</font>**  
    &emsp; 在实际的网络开发中，其实很少使用Java NIO原生的API。主要有以下原因：  

    * NIO的类库和API繁杂，使用麻烦，需要熟练掌握Selector、ServerSocketChannek、SockctChannek、ByteBuffer等。  
    * **原生API使用单线程模型，不能很好利用多核优势；**  
    * 原生API是直接使用的IO数据，没有做任何封装处理，对数据的编解码、TCP的粘包和拆包、客户端断连、网络的可靠性和安全性方面没有做处理；  
    * **<font color = "red">JDK NIO的BUG，例如臭名昭著的epoll bug，它会导致Selector空轮询，最终导致CPU100%。</font>官方声称在JDK1.6版本的update18修复了该问题，但是直到JDK 1.7版本该问题仍旧存在，只不过该BUG发生概率降低了一些而已，它并没有得到根本性解决。该BUG以及与该BUG相关的问题单可以参见以下链接内容。** 
        * http://bugs.java.com/bugdatabase/viewbug.do?bug_id=6403933  
        * http://bugs.java.com/bugdalabase/viewbug.do?bug_id=21477l9  

#### 1.18.5.2. Netty运行流程
&emsp; [Netty运行流程](/docs/microService/communication/Netty/operation.md)   

&emsp; **<font color = "clime">一般来说，使用Bootstrap创建启动器的步骤可分为以下几步：</font>**  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/netty/netty-151.png)  
1. 创建服务器启动辅助类，服务端是ServerBootstrap。  
&emsp; 需要设置事件循环组EventLoopGroup，如果使用reactor主从模式，需要创建2个： **<font color = "clime">`创建boss线程组（EventLoopGroup bossGroup）`用于服务端接受客户端的连接；`创建worker线程组（EventLoopGroup workerGroup）`用于进行 SocketChannel的数据读写。</font>**  
2. 对ServerBootstrap进行配置，配置项有channel,handler,option。  
3. 绑定服务器端口并启动服务器，同步等待服务器启动完毕。  
4. 阻塞启动线程，并同步等待服务器关闭，因为如果不阻塞启动线程，则会在finally块中执行优雅关闭，导致服务器也会被关闭了。  

![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/netty/netty-150.png)  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/netty/netty-44.png)  

&emsp; Netty整体运行流程：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/netty/netty-87.png) 

#### 1.18.5.3. Netty核心组件
1. `由netty运行流程可以看出Netty核心组件有Bootstrap、channel相关、EventLoop、byteBuf...`  
2. Bootstrap和ServerBootstrap是针对于Client和Server端定义的引导类，主要用于配置各种参数，并启动整个Netty服务。  
3. `EventLoop线程模型`  
    1. **EventLoop定义了Netty的核心抽象，用于处理连接（一个channel）的生命周期中所发生的事件。<font color = "clime">EventLoop的主要作用实际就是负责监听网络事件并调用事件处理器进行相关I/O操作的处理。</font>**  
    2. **<font color = "red">Channel与EventLoop：</font>**  
    &emsp; 当一个连接到达时，Netty就会创建一个Channel，然后从EventLoopGroup中分配一个EventLoop来给这个Channel绑定上，在该Channel的整个生命周期中都是由这个绑定的EventLoop来服务的。  
    3. **<font color = "red">EventLoopGroup与EventLoop：</font>**  
    &emsp; EventLoopGroup是EventLoop的集合，一个EventLoopGroup包含一个或者多个EventLoop。可以将EventLoop看做EventLoopGroup线程池中的一个工作线程。  
4. Channel  
    1. **在Netty中，Channel是一个Socket连接的抽象，它为用户提供了关于底层Socket状态（是否是连接还是断开）以及对Socket的读写等操作。**  
    2. ChannelHandler  
    &emsp; **ChannelHandler主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。**  
    3. ChannelPipeline  
    &emsp; Netty的ChannelHandler为处理器提供了基本的抽象，目前可以认为每个ChannelHandler的实例都类似于一种为了响应特定事件而被执行的回调。从应用程序开发人员的角度来看，它充当了所有处理入站和出站数据的应用程序逻辑的拦截载体。ChannelPipeline提供了ChannelHandler链的容器，并定义了用于在该链上传播入站和出站事件流的API。当Channel被创建时，它会被自动地分配到它专属的ChannelPipeline。  
    4. ChannelHandlerContext  
    &emsp; 当ChannelHandler被添加到ChannelPipeline时，它将会被分配一个ChannelHandlerContext，它代表了ChannelHandler和ChannelPipeline之间的绑定。ChannelHandlerContext的主要功能是管理它所关联的ChannelHandler和在同一个ChannelPipeline中的其他ChannelHandler之间的交互。  


#### 1.18.5.4. Netty逻辑架构
&emsp; **<font color = "red">Netty采用了典型的三层网络架构进行设计和开发，逻辑架构如下图所示：</font>**  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/netty/netty-134.png)  
1. 业务逻辑编排层 Service ChannelHandler：  
&emsp; 业务逻辑编排层通常有两类，一类是纯粹的业务逻辑编排，一类是应用层协议插件，用于特定协议相关的会话和链路管理。由于应用层协议栈往往是开发一次到处运行，并且变动较小，故而将应用协议到 POJO 的转变和上层业务放到不同的 ChannelHandler 中，就可以实现协议层和业务逻辑层的隔离，实现架构层面的分层隔离。  
2. 职责链 ChannelPipeline：  
&emsp; 它负责事件在职责链中的有序传播，同时负责动态地编排职责链。职责链可以选择监听和处理自己关心的事件，它可以拦截处理和向后/向前传播事件。不同应用的Handler用于消息的编解码，它可以将外部的协议消息转换成内部的POJO对象，这样上层业务则只需要关心处理业务逻辑即可，不需要感知底层的协议差异和线程模型差异，实现了架构层面的分层隔离。  
3. 通信调度层 Reactor：  
&emsp; 由一系列辅助类组成，包括 Reactor 线程 NioEventLoop 及其父类，NioSocketChannel 和 NioServerSocketChannel 等等。该层的职责就是监听网络的读写和连接操作，负责将网络层的数据读到内存缓冲区，然后触发各自网络事件，例如连接创建、连接激活、读事件、写事件等。将这些事件触发到 pipeline 中，由 pipeline 管理的职责链来进行后续的处理。  

&emsp; 架构的不同层面，需要关心和处理的对象都不同，通常情况下，对于业务开发者，只需要关心职责链的拦截和业务Handler的编排。因为应用层协议栈往往是开发一次，到处运行，所以实际上对于业务开发者来说，只需要关心服务层的业务逻辑开发即可。各种应用协议以插件的形式提供，只有协议开发人员需要关注协议插件，对于其他业务开发人员来说，只需关心业务逻辑定制。这种分层的架构设计理念实现了NIO框架各层之间的解耦，便于上层业务协议栈的开发和业务逻辑的定制。  

#### 1.18.5.5. Netty高性能
&emsp; Netty高性能：    

1. 网络I/O  
    * IO 线程模型：异步非阻塞通信。  
    * [高效的Reactor线程模型](/docs/microService/communication/Netty/Reactor.md) 
    * [零拷贝](/docs/microService/communication/Netty/nettyZeroCopy.md)  
    * 高性能序列化协议：支持 protobuf 等高性能序列化协议。
2. 内存池设计：申请的内存可以重用，主要指直接内存。内部实现是用一颗二叉查找树管理内存分配情况。  
3. 串形化处理读写：避免使用锁带来的性能开销。以及高效的并发编程。  

##### 1.18.5.5.1. Netty的Reactor线程模型
1. Netty的线程模型并不是一成不变的，它实际取决于用户的启动参数配置。<font color = "red">通过设置不同的启动参数，Netty可以同时支持Reactor单线程模型、多线程模型和主从Reactor多线层模型。</font><font color = "clime">Netty主要靠NioEventLoopGroup线程池来实现具体的线程模型的。</font>  
2. Netty主从Reactor多线层模型，内部实现了两个线程池，boss线程池和work线程池，其中boss线程池的线程负责处理请求的accept事件，当接收到accept事件的请求时，把对应的socket封装到一个NioSocketChannel中，并交给work线程池，其中work线程池负责请求的read和write事件，由对应的Handler处理。

#### 1.18.5.6. Netty开发
##### 1.18.5.6.1. Netty应用场景，  
&emsp; Netty主要用来做网络通信：   

* 作为 RPC 框架的网络通信工具 ：我们在分布式系统中，不同服务节点之间经常需要相互调用，这个时候就需要 RPC 框架了。不同服务节点之间的通信是如何做的呢？可以使用 Netty 来做。比如我调用另外一个节点的方法的话，至少是要让对方知道我调用的是哪个类中的哪个方法以及相关参数吧！  
* 实现一个自己的 HTTP 服务器 ：通过 Netty 我们可以自己实现一个简单的 HTTP 服务器，这个大家应该不陌生。说到 HTTP 服务器的话，作为 Java 后端开发，我们一般使用 Tomcat 比较多。一个最基本的 HTTP 服务器可要以处理常见的 HTTP Method 的请求，比如 POST 请求、GET 请求等等。  
* 实现一个即时通讯系统 ：使用 Netty 可以实现一个可以聊天类似微信的即时通讯系统，这方面的开源项目还蛮多的，可以自行去 Github 找一找。  
* 实现消息推送系统 ：市面上有很多消息推送系统都是基于 Netty 来做的。......
* ...  

##### 1.18.5.6.2. TCP粘拆包与Netty编解码  
1. [TCP的粘包和拆包问题描述](/docs/network/TCPSticking.md)  
2. **<font color = "clime">Netty对半包或者粘包的处理：</font>** **每个Handler都是和Channel唯一绑定的，一个Handler只对应一个Channel，<font color = "red">所以Channel中的数据读取的时候经过解析，如果不是一个完整的数据包，则解析失败，将这个数据包进行保存，等下次解析时再和这个数据包进行组装解析，直到解析到完整的数据包，才会将数据包向下传递。</font>** 
3. Netty默认提供了多种解码器来解决，可以进行分包操作。  
    * 固定长度的拆包器 FixedLengthFrameDecoder
    * 行拆包器 LineBasedFrameDecoder
    * 分隔符拆包器 DelimiterBasedFrameDecoder
    * 基于数据包长度的拆包器 LengthFieldBasedFrameDecoder  

##### 1.18.5.6.3. Netty实战
&emsp; ...  

##### 1.18.5.6.4. Netty多协议开发

* Http协议开发应用
* WebSocket协议开发  
&emsp; WebSocket是基于TCP的应用层协议，用于在C/S架构的应用中实现双向通信，关于WebSocket协议的详细规范和定义参见rfc6455。  
* 私有协议栈开发  

#### 1.18.5.7. Netty源码


## 1.19. 计算机网络
### 1.19.1. OSI七层网络模型
![image](https://gitee.com/wt1814/pic-host/raw/master/images/network/osi-2.png)  

### 1.19.2. 应用层
#### 1.19.2.1. DNS
1. **<font color = "clime">DNS解析流程：</font>** ...  
2. DNS将域名解析成ip，网络通信也即 ip:端口 间的通信。  

#### 1.19.2.2. HTTP
&emsp; 在浏览器地址栏键入URL，按下回车之后经历的流程：URL解析 ---> DNS解析 ---> TCP连接 ---> 发送HTTP请求 ---> 服务器处理请求并返回HTTP报文 ---> 浏览器解析渲染页面 ---> 连接结束。  

#### 1.19.2.3. HTTPS
1. **<font color = "clime">HTTPS的整体过程分为证书验证、协商密钥、数据传输阶段。</font>**  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/network/https-5.png)  
    1. 证书验证阶段，一次交互，客户端发送请求，获取到服务端的证书，并进行校验。若不合法，进行警告。  
    2. 协商密钥阶段，采取非对称加密。`客户端用公钥对随机数进行加密和传输；`服务端用私钥解密随机数，获取到随机数，完成连接。 **<font color = "clime">~~注：非对称加密的目的就是让服务端得到这个随机值，以后客户端和服务端的通信就可以通过这个随机值来进行加密解密。~~</font>**  
    3. 完成连接后，采用对称加密进行数据传输。  
2. 本地随机数会被窃取嘛？  
&emsp; HTTPS并不包含对随机数的安全保证，HTTPS保证的只是传输过程安全，<font color = "red">而随机数存储于本地，本地的安全属于另一安全范畴。</font>  

### 1.19.3. 传输层
#### 1.19.3.1. TCP
##### 1.19.3.1.1. 连接建立阶段
###### 1.19.3.1.1.1. 连接建立
1. 连接建立
    1. 三次握手  
        1. 为什么只有三次握手才能确认双方的接受与发送能力是否正常，而两次却不可以？  
        &emsp; <font color = "clime">第三次握手中，客户端向服务器发送确认包ACK，防止了服务器端的一直等待而浪费资源。</font>例如：已失效的连接请求报文突然又传送到了服务器，从而会产生错误。  
    2. 四次挥手  
        1. **<font color = "clime">Client收到服务端F1N后，Client进入TIME_WAIT状态。</font>** 2MSL后自动关闭。 
        2. 为什么客户端最后还要等待2MSL？  
        &emsp; <font color = "red">保证客户端发送的最后一个`ACK报文`能够到达服务器，因为这个ACK报文可能丢失。</font>  
        &emsp; `站在服务器的角度看来，服务端已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是服务器发送的请求断开报文它没有收到，于是服务器又会重新发送一次。而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文， **<font color = "clime">并且会重启2MSL计时器。`</font>**  
    &emsp;如果客户端收到服务端的FIN+ACK报文后，发送一个ACK给服务端之后就“自私”地立马进入CLOSED状态，可能会导致服务端无法确认收到最后的ACK指令，也就无法进入CLOSED状态，这是客户端不负责任的表现。  
    3. **<font color = "blue">`如果已经建立了连接，但是客户端突然出现故障了怎么办？`</font>**   
    &emsp; 客户端如果出现故障，服务器不能一直等下去，白白浪费资源。`在TCP设有一个保活计时器。`<font color = "clime">服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75分钟发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。</font>  
2. TIME_WAIT问题
    1. TIME_WAIT状态，该socket所占用的本地端口号将一直无法释放。TIME_WAIT过多，可能出现做为客户端的程序无法向服务端建立新的socket连接的情况。  
    2. **大量的TIME_WAIT状态TCP连接存在，是因为大量的短连接存在。TIME_WAIT状态时socket还占用端口。** TIME_WAIT状态默认为2MSL。    
    3. 解决办法：
        1. 客户端  
        &emsp; **HTTP请求的头部，connection 设置为 keep-alive，** 保持存活一段时间：现在的浏览器，一般都这么进行了。     
        2. 服务器端  
            * **<font color = "red">允许time_wait状态的socket被重用。</font>**
            * 缩减time_wait时间，设置为 1 MSL（即2mins）。


###### 1.19.3.1.1.2. Http长短链接

###### 1.19.3.1.1.3. TCP粘包
1. **TCP是基于流传输的协议，请求数据在其传输的过程中是没有界限区分，所以在读取请求的时候，不一定能获取到一个完整的数据包。**  
2. **<font color = "red">TCP粘包/拆包常见解决方案：</font>** 
    * 每个包都固定长度。
    * 每个包的末尾使用固定的分隔符。
    * 将消息分为头部和消息体，在头部中保存有当前整个消息的长度。
    * 通过自定义协议进行粘包和拆包的处理。   

##### 1.19.3.1.2. 数据传输阶段

### 1.19.4. 网络的性能指标
&emsp; **<font color = "red">通常是以4个指标来衡量网络的性能，分别是`带宽、延时、吞吐率、PPS(Packet Per Second)`。</font>**  

## 1.20. 负载均衡
&emsp; 要想理解负载均衡，首先需要清楚OSI七层网络模型。  

### 1.20.1. 负载均衡解决方案
&emsp; **<font color = "clime">★★★负载均衡方案选择</font>**  
&emsp; 小于3000万pv的，DNS轮询+监控；  
&emsp; **3000万以上的，nginx+监控；**  
&emsp; 5000万PV的，HAProxy+Keepalived,nginx，HAPROXY负责TCP的负载均衡，nginx负责7层调度；  
&emsp; **1亿以上的，LVS-DR+keepalived,nginx，LVS-DR负责TCP的负载均衡，nginx负责7层调度。**  

### 1.20.2. Nginx
#### 1.20.2.1. Nginx介绍
1. Nginx是一个高性能的Web服务器。<font color = "red">Nginx工作在4层或7层。</font>  
2. **多进程：** Nginx启动时，会生成两种类型的进程，一个主进程master，一个（windows版本的目前只有一个）或多个工作进程worker。  
    * 主进程并不处理网络请求，主要负责调度工作进程：加载配置、启动工作进程、非停升级。  
    * **<font color = "red">`一般推荐worker进程数与CPU内核数一致，这样一来不存在大量的子进程生成和管理任务，避免了进程之间竞争CPU资源和进程切换的开销。`</font>**  

#### 1.20.2.2. Nginx使用
1. <font color = "red">Nginx服务器处理一个请求是按照两部分进行的。第一部分是IP和域名，由listen和server_name指令匹配server模块；第二部分是URL，匹配server模块里的location；最后就是location里的具体处理。</font>  
2. <font color = "red">Nginx使用场景：反向代理、虚拟主机、静态资源WEB服务、缓存、限流、黑白名单、防盗链、流量复制...</font>  
3. 负载均衡：  
    1. **<font color = "red">Nginx反向代理通过proxy_pass来配置；负载均衡使用Upstream模块实现。</font>**  
    2. **<font color = "red">Nginx支持的负载均衡调度算法方式如下：</font>**  
        * **<font color = "red">轮询（默认）</font>** 
        * **<font color = "red">weight：</font>** 指定权重。  
        * **<font color = "red">ip_hash</font>**  
        * **<font color = "red">url_hash（第三方）</font>**  
        * **<font color = "red">fair（第三方）：</font>** 智能调整调度算法，动态的根据后端服务器的请求处理到响应的时间进行均衡分配。  

## 1.21. Devops
### 1.21.1. CI/CD
&emsp; `CI/CD是两个独立过程的组合：持续集成和持续部署。`  
1. Continuous Integration（持续集成）  
&emsp; 持续集成（CI）是构建软件和完成初始测试的过程。  
2. Continuous Delivery（持续交付）  
3. Continuous Deployment（持续部署）  
&emsp; 持续部署（CD）是将代码与基础设施相结合的过程，确保完成所有测试并遵循策略，然后将代码部署到预期环境中。  

### 1.21.2. DevOps
1. DevOps框架  
&emsp; 以下是一个DevOps框架。这个框架只指出那些被认可的概念和它们在某种程度上的关系。
![image](https://gitee.com/wt1814/pic-host/raw/master/images/devops/devops/devops-8.png)  
&emsp; **<font color = "clime">敏捷开发指的是在 DevOps 中采用敏捷思想进行软件开发，敏捷宣言无疑是很重要的一项。有多种敏捷方法可以采用，比如Scrum、看板和极限编程。</font>**  
&emsp; **<font color = "clime">持续集成提供了让多个程序员可以同时运行应用程序的最佳实践，可以频繁合并源代码、验证代码(静态测试用例)、编译和测试代码(动态测试用例)。</font>**  
&emsp; **<font color = "clime">持续交忖关注从开发、测试、验收到生产环境的高频生产能力。基于高度的自动化，极端的发布上线时间可以达到分钟级。</font>**  
2. DevOps流程  
&emsp; 下图显示了一个DevOps流程。它不是DevOps流程的正式定义，而是表述了在大多数组织机构中，为了实现一个服务而会被循环执行的合乎逻辑顺序的一系列阶段。  
&emsp; 深色部分表示开发流程，浅色部分表示运维流程。这两个流程构成了DevOps方法的核心。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/devops/devops/devops-1.png)  
3. 工具集  
&emsp; **<font color = "clime">DevOps一般包括版本控制&协作开发工具、自动化构建和测试工具、持续集成&交付工具、部署工具、维护工具、监控，警告&分析工具等。</font>**  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/devops/devops/devops-3.png)  

### 1.21.3. 从上往下学Docker

#### 1.21.3.1. Docker使用教程
1. **<font color = "clime">镜像操作常用命令：pull(获取)、images(查看本地镜像)、inspect(查看镜像详细信息)、rmi(删除镜像)、commit(构建镜像)。</font>**  
2. **<font color = "clime">容器操作常用命令：run(创建并启动)、start(启动已有)、stop、exec(进入运行的容器)。</font>**  
3. **<font color = "clime">Dockerfile中包含：</font>** （# 为 Dockerfile中的注释）  
    * 基础镜像(FROM)    
    * 镜像元信息   
    * **<font color = "clime">镜像操作指令</font>** （RUN、COPY、ADD、EXPOSE、WORKDIR、ONBUILD、USER、VOLUME等）    
        * RUN命令：**run是在docker build构建镜像时，会执行的命令，** 比如安装一些软件、配置一些基础环境。  
    * **<font color = "clime">容器启动时执行指令</font>** （CMD、ENTRYPOINT）  
        * CMD命令： **cmd是在docker run启动容器时，会执行的命令，为启动的容器指定默认要运行的程序。** CMD指令指定的程序可被docker run命令行参数中指定要运行的程序所覆盖。 **<font color = "clime">注意：如果Dockerfile中如果存在多个CMD指令，仅最后一个生效。</font>**    
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/devops/docker/docker-9.png)  


#### 1.21.3.2. 镜像详解
1. Docker中镜像是分层的，最顶层是读写层（镜像与容器的区别），其底部依赖于Linux的UnionFS文件系统。  
2. **<font color = "red">利用联合文件系统UnionFS写时复制的特点，在启动一个容器时，Docker引擎实际上只是增加了一个可写层和构造了一个Linux容器。</font>**  

#### 1.21.3.3. 容器详解
1. 单个宿主机的多个容器是隔离的，其依赖于Linux的Namespaces、CGroups。  
2. 隔离的容器需要通信、文件共享（数据持久化）。  

### 1.21.4. Kubernetes
#### 1.21.4.1. k8s架构
1. 1). 一个容器或多个容器可以同属于一个Pod之中。 2). Pod是由Pod控制器进行管理控制，其代表性的Pod控制器有Deployment、StatefulSet等。 3). Pod组成的应用是通过Service或Ingress提供外部访问。  
2. **<font color = "red">每一个Kubernetes集群都由一组Master节点和一系列的Worker节点组成。</font>**  
    1. **<font color = "clime">Master的组件包括：API Server、controller-manager、scheduler和etcd等几个组件。</font>**  
        * **<font color = "red">API Server：K8S对外的唯一接口，提供HTTP/HTTPS RESTful API，即kubernetes API。</font>**  
        * **<font color = "red">controller-manager：负责管理集群各种资源，保证资源处于预期的状态。</font>** 
        * **<font color = "red">scheduler：资源调度，负责决定将Pod放到哪个Node上运行。</font>** 
    2. **<font color = "clime">Node节点主要由kubelet、kube-proxy、docker引擎等组件组成。</font>**  





