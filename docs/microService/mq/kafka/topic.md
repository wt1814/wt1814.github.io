<!-- TOC -->

- [1. 分区](#1-分区)
    - [1.1. 分区说明](#11-分区说明)
    - [1.2. 怎么分区？](#12-怎么分区)
        - [1.2.1. ★★★服务端物理分区分配](#121-★★★服务端物理分区分配)
            - [1.2.1.1. 分区策略](#1211-分区策略)
            - [1.2.1.2. 分区结构 / 分区存储数据(日志存储)](#1212-分区结构--分区存储数据日志存储)
        - [1.2.2. 生产者与分区](#122-生产者与分区)
            - [1.2.2.1. 官方分区策略](#1221-官方分区策略)
            - [1.2.2.2. 自定义分区策略](#1222-自定义分区策略)
        - [1.2.3. 消费者与分区](#123-消费者与分区)
            - [1.2.3.1. 消费者分组](#1231-消费者分组)
            - [1.2.3.2. 消费分区策略](#1232-消费分区策略)
                - [1.2.3.2.1. 轮询RoundRobin](#12321-轮询roundrobin)
                - [1.2.3.2.2. range策略](#12322-range策略)
    - [1.3. 如何选择合适的分区数？](#13-如何选择合适的分区数)
    - [1.4. 分区后保持有序](#14-分区后保持有序)

<!-- /TOC -->

&emsp; **<font color = "red">总结：</font>**  
1. 分区说明  
&emsp; 分区(Partition)的作用就是提供负载均衡的能力，单个topic的不同分区可存储在相同或不同节点机上，为实现系统的高伸缩性（Scalability），`不同的分区被放置到不同节点的机器上，`各节点机独立地执行各自分区的读写任务，如果性能不足，可通过添加新的节点机器来增加整体系统的吞吐量。  
2. 服务端物理分区分配
    1. 分区策略  
    在所有broker上均匀地分配分区副本； **<font color = " red">确保分区的每个副本分布在不同的broker上。</font>**  
    2. ~~分区存储数据~~
3. 客户端怎么分区？
    1. 生产者
        1. 分区策略  
        &emsp; 如果没有指定分区，但是 `消息的key不为空，则基于key的哈希值来选择一个分区；`  
        &emsp; 如果既没有指定分区，且 `消息的key也是空，则用轮询的方式选择一个分区。`
    2. 消费者  
        1. 消费者`分组消费`。同一时刻，`一条消息只能被组中的一个消费者实例消费。`  
        2. 消费者消费分区策略
            1. 轮询。  
            2. range策略。 
4. 分区数设置
5. 分区后保持有序，查看顺序消费。  



# 1. 分区
<!-- 
https://blog.51cto.com/u_15127499/2672673
-->

## 1.1. 分区说明  

&emsp; 分区规则指的是将每个Topic划分成多个分区（Partition），每个分区是一组有序的消息日志，`生产者生产的每条消息只会被发送到其中一个分区。`  
&emsp; 分区 (Partition) 都是一个有序的、不可变的数据序列，消息数据被不断的添加到序列的尾部。分区中的每一条消息数据都被赋予了一个连续的数字ID，即偏移量 (offset) ，用于唯一标识分区中的每条消息数据。  
&emsp; 分区(Partition)的作用就是提供负载均衡的能力，单个topic的不同分区可存储在相同或不同节点机上，为实现系统的高伸缩性（Scalability），不同的分区被放置到不同节点的机器上，各节点机独立地执行各自分区的读写任务，如果性能不足，可通过添加新的节点机器来增加整体系统的吞吐量。  


## 1.2. 怎么分区？  
<!--
https://www.cnblogs.com/cjsblog/p/9664536.html
 -->

### 1.2.1. ★★★服务端物理分区分配
#### 1.2.1.1. 分区策略
&emsp; **在创建主题时，Kafka会首先决定如何在broker间分配分区副本，** 它遵循以下原则：  

* 在所有broker上均匀地分配分区副本；  
* <font color = "clime">确保分区的每个副本分布在不同的broker上；</font>  
* 如果使用了broker.rack 参数为broker 指定了机架信息，那么会尽可能的把每个分区的副本分配到不同机架的broker上，以避免一个机架不可用而导致整个分区不可用。  

&emsp; 基于以上原因，如果在一个单节点上创建一个3副本的主题，通常会抛出下面的异常：  

```text
Error while executing topic command : org.apache.kafka.common.errors.InvalidReplicationFactor   
Exception: Replication factor: 3 larger than available brokers: 1.
```


#### 1.2.1.2. 分区结构 / 分区存储数据(日志存储)  
<!-- 深入理解kafka：核心设计 第5章 -->

<!-- 
https://segmentfault.com/a/1190000039010754

消息在分区上的存储（Partition、Replica、Log和LogSegment的关系）
&emsp; 假设有一个 Kafka 集群，Broker 个数为 3，Topic 个数为 1，Partition 个数为 3，Replica 个数为 2。Partition 的物理分布如下图所示。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/kafka/kafka-83.png)  
&emsp; 从上图可以看出，该 Topic 由三个 Partition 构成，并且每个 Partition 由主从两个副本构成。每个 Partition 的主从副本分布在不同的 Broker 上，通过这点也可以看出，当某个 Broker 宕机时，可以将分布在其他 Broker 上的从副本设置为主副本，因为只有主副本对外提供读写请求，当然在最新的 2.x 版本中从副本也可以对外读请求了。将主从副本分布在不同的Broker上从而提高系统的可用性。   
&emsp; Partition 的实际物理存储是以 Log 文件的形式展示的，而每个Log文件又以多个LogSegment组成。Kafka 为什么要这么设计呢？其实原因比较简单，随着消息的不断写入，Log 文件肯定是越来越大，Kafka 为了方便管理，将一个大文件切割成一个一个的LogSegment来进行管理；每个LogSegment由数据文件和索引文件构成，数据文件是用来存储实际的消息内容，而索引文件是为了加快消息内容的读取。  
&emsp; 可能又有朋友会问，Kafka本身消费是以Partition维度顺序消费消息的，磁盘在顺序读的时候效率很高完全没有必要使用索引啊。其实Kafka为了满足一些特殊业务需求，比如要随机消费 Partition 中的消息，此时可以先通过索引文件快速定位到消息的实际存储位置，然后进行处理。  

&emsp; **总结一下 Partition、Replica、Log 和 LogSegment 之间的关系。** 消息是以 Partition 维度进行管理的，为了提高系统的可用性，每个 Partition 都可以设置相应的 Replica 副本数，一般在创建 Topic 的时候同时指定 Replica 的个数；Partition 和 Replica 的实际物理存储形式是通过 Log 文件展现的，为了防止消息不断写入，导致 Log 文件大小持续增长，所以将 Log 切割成一个一个的 LogSegment 文件。  
&emsp; 注意： 在同一时刻，每个主 Partition 中有且只有一个 LogSegment 被标识为可写入状态，当一个 LogSegment 文件大小超过一定大小后（比如当文件大小超过 1G，这个就类似于 HDFS 存储的数据文件，HDFS 中数据文件达到 128M 的时候就会被分出一个新的文件来存储数据），就会新创建一个 LogSegment 来继续接收新写入的消息。 


&emsp; 在创建主题时，Kafka系统会将分区分配到各个代理节点（Broker）。例如，现有3个代理节点，准备创建一个包含6个分区、3 个副本的主题，那么Kafka系统就会有18个分区副本，这18个分区副本将被分配到3个代理节点中。  * 主题(Topic)：用来区分不同的业务消息，类似于数据库中的表。  

* 分区(Partition)：是主题物理意义上的分组。一个主题可以分为多个分区，每个分区是一个有序的队列。  
* 片段(Segment)：每个分区又可以分为多个片段文件。  
* 偏移量(Offset)：每个分区都由一系列有序的、不可修改的消息组成，这些消息被持续追加到分区中，分区中的每条消息记录都有一个连续的序号，即Offset值，Offset值用来标识这条消息的唯一性。  

-->

&emsp; 在Kafka系统中，消息以主题作为基本单位。不同的主题之间是相互独立、互不干扰的。每个主题又可以分为若干个分区，每个分区用来存储一部分消息。  
1. 分区文件存储  
&emsp; 在 Kafka 系统中，一个主题（Topic）下包含多个不同的分区（Partition），每个分区为单独的一个目录。分区的命名规则为：主题名+有序序号。第一个分区的序号从0开始，序号最大值等于分区总数减1。  
&emsp; 主题的存储路径由“log.dirs”属性决定。代理节点中主题分区的存储分布如下图所示。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/kafka/kafka-108.png)  
&emsp; 每个分区相当于一个超大的文件被均匀分割成的若干个大小相等的片段（Segment），但是每个片段的消息数据量不一定相等。因此，过期的片段数据才能被快速地删除。  
&emsp; 片段文件的生命周期由代理节点server.properties文件中配置的参数决定，这样，快速删除无用的数据可以有效地提高磁盘利用率。  

2. 片段文件存储  
&emsp; 片段文件由索引文件和数据文件组成：后缀为“.index”的是索引文件，后缀为“.log”的是数据文件。  
&emsp; 查看某一个分区的片段，输出结果如下图所示。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/kafka/kafka-109.png)  
&emsp; Kafka系统中，索引文件并没有给数据文件中的每条消息记录都建立索引，而是采用了稀疏存储的方式——每隔一定字节的数据建立一条索引，如下图所示。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/kafka/kafka-110.png)  
&emsp; 提示：  
&emsp; 稀疏存储索引避免了索引文件占用过多的磁盘空间。  
&emsp; 将索引文件存储在内存中，虽然没有建立索引的Message，不能一次就定位到所在的数据文件上的位置，但是稀疏索引的存在会极大地减少顺序扫描的范围。  

----------------

* Kafka分区下数据使用消息日志（Log）方式保存数据，具体方式是在磁盘上创建只能追加写（Append-only）消息的物理文件。因为只能追加写入，因此避免了缓慢的随机I/O操作，改为性能较好的顺序I/O写操作。Kafka日志文件分为多个日志段（Log Segment），消息被追加写到当前最新的日志段中，当写满一个日志段后Kafka会自动切分出一个新的日志段，并将旧的日志段封存。  
* Kafka将消息数据根据Partition进行存储，Partition分为若干Segment，每个Segment的大小相等。Segment由index file、log file、timeindex file等组成，后缀为".index"和".log"，分别表示为Segment索引文件、数据文件，每一个Segment存储着多条信息。   
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/kafka/kafka-125.png)  



### 1.2.2. 生产者与分区
<!-- 
https://blog.51cto.com/u_15127499/2672673
-->

#### 1.2.2.1. 官方分区策略
&emsp; 首先提出一个问题：生产者将消息投递到分区有没有规律？如果有，那么它是如何决定一条消息该投递到哪个分区的呢？  

```text
The default partitioning strategy:

If a partition is specified in the record, use it
If no partition is specified but a key is present choose a partition based on a hash of the key
If no partition or key is present choose a partition in a round-robin fashion

org.apache.kafka.clients.producer.internals.DefaultPartitioner
```

&emsp; 默认的分区策略是：  

* 如果在发消息的时候指定了分区，则消息投递到指定的分区
* 如果没有指定分区，但是消息的key不为空，则基于key的哈希值来选择一个分区
* 如果既没有指定分区，且消息的key也是空，则用轮询的方式选择一个分区


#### 1.2.2.2. 自定义分区策略

### 1.2.3. 消费者与分区
<!-- 
-->
#### 1.2.3.1. 消费者分组
&emsp; 消费者以组的名义订阅主题，主题有多个分区，消费者组中有多个消费者实例，那么消费者实例和分区之前的对应关系是怎样的呢？  
&emsp; 换句话说，就是组中的每一个消费者负责那些分区，这个分配关系是如何确定的呢？  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/kafka/kafka-124.png)  

&emsp; 同一时刻，一条消息只能被组中的一个消费者实例消费  
&emsp; 消费者组订阅这个主题，意味着主题下的所有分区都会被组中的消费者消费到，如果按照从属关系来说的话就是，主题下的每个分区只从属于组中的一个消费者，不可能出现组中的两个消费者负责同一个分区。  
&emsp; 那么，问题来了。如果分区数大于或者等于组中的消费者实例数，那自然没有什么问题，无非一个消费者会负责多个分区，（PS：当然，最理想的情况是二者数量相等，这样就相当于一个消费者负责一个分区）；但是，如果消费者实例的数量大于分区数，那么按照默认的策略（PS：之所以强调默认策略是因为你也可以自定义策略），有一些消费者是多余的，一直接不到消息而处于空闲状态。  
&emsp; 话又说回来，假设多个消费者负责同一个分区，那么会有什么问题呢？  
&emsp; 我们知道，Kafka它在设计的时候就是要保证分区下消息的顺序，也就是说消息在一个分区中的顺序是怎样的，那么消费者在消费的时候看到的就是什么样的顺序，那么要做到这一点就首先要保证消息是由消费者主动拉取的（pull），其次还要保证一个分区只能由一个消费者负责。倘若，两个消费者负责同一个分区，那么就意味着两个消费者同时读取分区的消息，由于消费者自己可以控制读取消息的offset，就有可能C1才读到2，而C1读到1，C1还没处理完，C2已经读到3了，则会造成很多浪费，因为这就相当于多线程读取同一个消息，会造成消息处理的重复，且不能保证消息的顺序，这就跟主动推送（push）无异。  

#### 1.2.3.2. 消费分区策略
<!-- 
https://blog.csdn.net/qq_36951116/article/details/100863502
https://www.cnblogs.com/cjsblog/p/9664536.html

-->

##### 1.2.3.2.1. 轮询RoundRobin
&emsp; 一个消费者组有多个消费者，会把一个消费者组里的所有消费者指定的全部主题拿出来，再统一按分区分配给该组里面的所有消费者进行消费（按照主题名+分区号排序，轮询分配给组里的所有消费者）。也就是说，轮询策略下，消费者组中的消费者无法特别指定自身要消费的主题。自己指定的主题会被拿出去到整个组中统一分配。自己也会消费到自己没有指定的主题(不过该主题肯定是由同组的其他消费者指定的)  

&emsp; 假设消费者组G有AB两个消费者，有T1 、T2两个主题，每个主题都有三个分区，分区好分别是0,1,2。  
&emsp; 其中A指定要消费T1 主题，而B指定要消费T2主题。由于A和B属于同一个消费者组G，那么G这个组就会消费AUB（A与B的并集）={T1,T2}，共两个主题，六个分区。  
&emsp; （1）也就是说，RoundRobin会让消费者组G的所有成员(A和B)一起轮询消费这六个分区(T1-0,T1-1,T1-2,T2-0,T2-1,T2-2)。  
&emsp; kafka会把六个分区按照主题名+分区号作为hash值进行排序，假设排序完是T1-0,T1-1,T1-2,T2-0,T2-1,T2-2共六个。  
&emsp; 然后按照轮询分配...A分配T1-0、B分配T1-1、A分配T1-2、B分配T2-0 ......  
&emsp; 最终：A分配了T1-0  T1-2    T2-1 三个分区。B则分配了剩下的三个分区。  
&emsp; （2）这样就会导致A可能会消费到T2主题的分区，B也可能会消费到T1主题的分区。而A并没有指定要消费T2分区，B也没有指定要消费T1分区。。这算是一种缺点。。消费到同组的其他消费者所指定的主题分区数据。  

&emsp; 由于有以上缺点，kafka没有把轮询策略作为默认策略。。而是把range作为默认的，range可以在一个消费者组中单独为指定消费者设置要消费的主题。  

&emsp; 那么什么情况下使用轮询分配策略呢？  

&emsp; 在同一个消费者组中的所有消费者各自指定要消费的主题都是一样的情况下，使用轮询分配更好，不会导致不同消费者之间所消费的分区数差距过大(最大差距不会超过1)，而下面的range策略虽然可以让同一个消费者组的不同消费者各自指定自己要消费的主题，但在同一个消费者组中的所有消费者各自指定要消费的主题都是一样的情况下，不同的消费者之间被分配的分区数可能会差距很大。  

&emsp; 好处，同一个消费者组的不同消费者之间所消费的分区数量相差最大不会超过1。  

&emsp; 缺点，就是一个消费者组中的消费者各自指定消费的主题并不会由这个消费者消费，而是拿出来作为整个组要消费的主题。  

##### 1.2.3.2.2. range策略
&emsp; 会按照主题来进行分配。一个主题的分区分配完了，再继续分配下一个主题。  
&emsp; 分配规则：同一个消费者组有哪些成员指定了相同的主题，则由这些成员去消费该主题的分区。其他未指定该主题的成员不会消费到这个主题。  
&emsp; 分区分配方式：假设一个主题分区为0~6共7个分区，然后在同一个消费者组中有两个消费者(B、D)消费该主题。  
&emsp; 在同一个组内的消费者也会有排序的，按先后顺序分配消费的分区，这里假设顺序是B、D，那么靠前的获取比较多的分区数，靠后的获取较少的分区数。。并且分区分配不是轮询了，而是按范围分配相邻的分区。。。那么7个分区两个消费者，7/2向下取整等于3，则按消费者顺序分配，B会分配4个分区，D会分配3个分区，然后是按范围分配相邻的给同一个消费者，则B会分到0~3这四个分区，D分到4~6这三个。  
&emsp; 按上面的情况，假设B和D又同时一起指定要消费另一个主题，这个主题也有7个分区。。那么还是按上面的规则。。B又拿到0~4分区，D又拿到4~6分区。。。此时B有8个分区要消费，而D只有6个。当B和D同时指定的主题数越多，他们俩所消费的分区数差距就会越来越大。。这就是range的缺点。  
&emsp; 具体举个例子(如果根据上面的描述就懂了，可以跳过该例子)：  
&emsp; 假设有主题T1和T2和T3，各自三个分区(0，1,2)。  
&emsp; 消费者组G，有两个消费者A和B。  
&emsp; 其中A指定要消费T1和T2，B要消费T2和T3.  
&emsp; 那么按照每个主题，一个主题一个主题分配给A和B进行消费。  
&emsp; 即假设按照T1  T2  T3的顺序来。  
&emsp; （1）先分配主题T1，由于T1只有A消费，那么就直接T1-0，T1-1，T1-2都分配给A消费了。  
&emsp; （2）然后分配主题T2，T2有A和B一起消费，A和B属于同一个消费者组，是Range策略。。。  
&emsp; 那么T2-0，T2-1，T2-2三个分区中，会按照轮询规则把三个分区分配给A和B两个消费者。A可能分配到两个分区，B可能分配到1额分区。  
&emsp; （3）最后分配T3主题，由于只有B消费，所有T3全部分区都分配给B消费。  

&emsp; 缺点，就是当同一个消费者组的多个消费者消费的主题相同，并且消费的相同主题比较多时，按照上面步骤(2)的情况，可能会导致消费者A消费十个分区，而消费者B只消费了五个分区，这样不平衡。   
但好处在于，同一个消费者组的不同消费者可以指定自己单独需要消费的主题。。只有当其他消费者与当前消费者指定的主题相同时，才会一起分配这个主题的不同分区。  


## 1.3. 如何选择合适的分区数？  
<!-- 
https://www.cnblogs.com/cjsblog/p/9664536.html
-->
&emsp; 在Kafka中，性能与分区数有着必然的关系，在设定分区数时一般也需要考虑性能的因素。对不同的硬件而言，其对应的性能也会不太一样。**可以使用Kafka 本身提供的用于生产者性能测试的kafka-producer-perf-test.sh和用于消费者性能测试的kafka-consumer-perf-test.sh来进行测试。**  
&emsp; 增加合适的分区数可以在一定程度上提升整体吞吐量，但超过对应的阈值之后吞吐量不升反降。如果应用对吞吐量有一定程度上的要求，则建议在投入生产环境之前对同款硬件资源做一个完备的吞吐量相关的测试，以找到合适的分区数阈值区间。  
&emsp; 分区数的多少还会影响系统的可用性。如果分区数非常多，如果集群中的某个broker节点宕机，那么就会有大量的分区需要同时进行leader角色切换，这个切换的过程会耗费一笔可观的时间，并且在这个时间窗口内这些分区也会变得不可用。  
&emsp; 分区数越多也会让Kafka的正常启动和关闭的耗时变得越长，与此同时，主题的分区数越多不仅会增加日志清理的耗时，而且在被删除时也会耗费更多的时间。  


## 1.4. 分区后保持有序  
&emsp; ......
