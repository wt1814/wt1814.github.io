<!-- TOC -->

- [1. mq](#1-mq)
    - [1.1. 消息队列简介](#11-消息队列简介)
    - [1.2. 为什么使用消息队列](#12-为什么使用消息队列)
        - [1.2.1. 消息队列优点](#121-消息队列优点)
        - [1.2.2. 消息队列缺点](#122-消息队列缺点)
    - [1.3. 消息队列中间件选型](#13-消息队列中间件选型)
    - [1.4. 保障可用性](#14-保障可用性)
    - [1.5. 丢失消息（可靠性传输）](#15-丢失消息可靠性传输)
    - [1.6. 重复消费](#16-重复消费)
    - [1.7. 顺序消费](#17-顺序消费)
    - [1.8. 消息积压](#18-消息积压)

<!-- /TOC -->


# 1. mq  
<!-- 
分布式消息队列面试题  
https://gitee.com/shishan100/Java-Interview-Advanced/tree/master#%E5%88%86%E5%B8%83%E5%BC%8F%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97
-->
&emsp; **<font color = "lime">总结：</font>**  
1. 为什么使用mq？
    * 优点：解耦、异步、削锋  
2. 消息队列选型  
3. 保障高可用  
4. 重复消费
    消费接口幂等性。  
5. 顺序消费  
    发送到单个queue或partition，单线程消费。  
6. 消息积压  
    多线程消费。修复消费者问题，临时增加消费者。  

## 1.1. 消息队列简介
&emsp; 消息队列中间件是分布式系统中最为重要的组件之一，主要解决应用耦合，异步消息，流量削锋等问题，是大型分布式系统不可缺少的中间件。消息队列技术是分布式应用间交换信息的一种技术，消息可驻留在内存或磁盘上，队列存储消息直到它们被应用程序读走。通过消息队列，应用程序可以相对独立地执行，它们不需要知道彼此的位置，只需要处理从消息队列发送来的消息和向消息队列发送消息。  
&emsp; 消息队列的主要特点是异步处理和解耦。其主要的使用场景就是将比较耗时而且不需要同步返回结果的操作作为消息放入消息队列。同时由于使用了消息队列，只要保证消息格式不变，消息的发送方和接受者并不需要彼此联系，也不需要受对方的影响，即解耦。  
&emsp; 消息中间件的发展：第一代以ActiveMQ为代表，遵循JMS（java消息服务）规范；第二代以RabbitMQ为代表是一个有Erlang语言开发的AMQP(高级消息队列协议)的开源实现；第三代以Kafka为代表，是一代高吞吐、高可用的消息中间件，以及RocketMQ；   

&emsp; 常用的几种信息交互技术：httpClient、hessian、dubbo、jms、webservice 。
&emsp; RPC和消息中间件的差异：  

* RPC同步请求、消息中间件异步消息；  
* RPC和消息中间件的场景的差异很大程度上在于就是“依赖”和“量”。  

## 1.2. 为什么使用消息队列

### 1.2.1. 消息队列优点  
&emsp; <font color = "lime">消息队列在实际应用中常用的使用场景：异步处理，应用解耦，流量削锋。</font>  
 
* **应用/业务解耦**  
&emsp; **<font color = "lime">使用多线程开发，并不能做到解耦。</font>**  
&emsp; 场景说明：用户下单后，订单系统需要通知库存系统。传统的做法是，订单系统调用库存系统的接口。  
&emsp; 传统模式的缺点：1）假如库存系统无法访问，则订单减库存将失败，从而导致订单失败；2）订单系统与库存系统耦合；  
&emsp; 引入应用消息队列方案，解决上述问题：   
&emsp; 订单系统：用户下单后，订单系统完成持久化处理，将消息写入消息队列，返回用户订单下单成功。  
&emsp; 库存系统：订阅下单的消息，采用拉/推的方式，获取下单信息，库存系统根据下单信息，进行库存操作。  
&emsp; 假如：在下单时库存系统不能正常使用。也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其他的后续操作了。实现订单系统与库存系统的应用解耦。  
* 异步处理  
&emsp; 引入消息队列，将不是必须的业务逻辑，异步处理。 
* 流量削锋/限流  
&emsp; 上游系统的吞吐能力高于下游系统，在流量洪峰时可能会冲垮下游系统，消息中间件可以在峰值时堆积消息，而在峰值过去后下游系统慢慢消费消息解决流量洪峰的问题。  
&emsp; 流量削锋是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。为解决这个问题，一般需要在应用前端加入消息队列。用户的请求，服务器接收后，首先写入消息队列。假如消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面。  
&emsp; 秒杀业务根据消息队列中的请求信息，再做后续处理。  
&emsp; 优点：可以控制活动的人数；可以缓解短时间内高流量压垮应用；  

----

&emsp; 先说一下消息队列的常见使用场景吧，其实场景有很多，但是比较核心的有3个：解耦、异步、削峰  

* 解耦：现场画个图来说明一下：  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/mq-6.png)  
    &emsp; A系统发送个数据到BCD三个系统，接口调用发送，那如果E系统也要这个数据呢？那如果C系统现在不需要了呢？现在A系统又要发送第二种数据了呢？A系统负责人濒临崩溃中。。。再来点更加崩溃的事儿，A系统要时时刻刻考虑BCDE四个系统如果挂了咋办？我要不要重发？我要不要把消息存起来？头发都白了啊。。。  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/mq-7.png)  
    &emsp; **<font color = "lime">你需要去考虑一下你负责的系统中是否有类似的场景，就是一个系统或者一个模块，调用了多个系统或者模块，互相之间的调用很复杂，维护起来很麻烦。但是其实这个调用是不需要直接同步调用接口的，如果用MQ给他异步化解耦，也是可以的，你就需要去考虑在你的项目里，是不是可以运用这个MQ去进行系统的解耦。在简历中体现出来这块东西，用MQ作解耦。</font>**  
* 异步：现场画个图来说明一下，  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/mq-8.png)  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/mq-9.png)  
    &emsp; A系统接收一个请求，需要在自己本地写库，还需要在BCD三个系统写库，自己本地写库要3ms，BCD三个系统分别写库要300ms、450ms、200ms。最终请求总延时是3 + 300 + 450 + 200 = 953ms，接近1s，用户感觉搞个什么东西，慢死了慢死了。  
* 削峰：  
    &emsp; 每天0点到11点，A系统风平浪静，每秒并发请求数量就100个。结果每次一到11点~1点，每秒并发请求数量突然会暴增到1万条。但是系统最大的处理能力就只能是每秒钟处理1000个请求啊。。。尴尬了，系统会死。。。  

        说明，一般的MySQL扛到每秒2000个请求就差不多了，如果每秒请求到5000点话，可能就直接把MySql给打死了。  

    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/mq-10.png)  
    ![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/mq-11.png)  

### 1.2.2. 消息队列缺点  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/mq-12.png)  
&emsp; **系统可用性降低：** 系统引入的外部依赖越多，越容易挂掉，本来你就是A系统调用BCD三个系统的接口就好了，人ABCD四个系统好好的，没啥问题，你偏加个MQ进来，万一MQ挂了咋整？MQ挂了，整套系统崩溃了，你不就完了么。  
&emsp; **系统复杂性提高：** 硬生生加个MQ进来，你怎么保证消息没有重复消费？怎么处理消息丢失的情况？怎么保证消息传递的顺序性？头大头大，问题一大堆，痛苦不已  
&emsp; **一致性问题：** A系统处理完了直接返回成功了，人都以为你这个请求就成功了；但是问题是，要是BCD三个系统那里，BD两个系统写库成功了，结果C系统写库失败了，咋整？你这数据就不一致了。  
&emsp; 所以消息队列实际是一种非常复杂的架构，你引入它有很多好处，但是也得针对它带来的坏处做各种额外的技术方案和架构来规避掉，最好之后，你会发现，妈呀，系统复杂度提升了一个数量级，也许是复杂了10倍。但是关键时刻，用，还是得用的。。。  


<!-- 
https://blog.csdn.net/caodongfang126/article/details/102570555
-->

## 1.3. 消息队列中间件选型  
&emsp; 电商使用RocketMQ，有序，事务；大数据使用Kafka。  

## 1.4. 保障可用性  
......
<!-- 
引入消息队列之后如何保证其高可用性
https://blog.csdn.net/zhaoziyun21/article/details/88376421
-->

## 1.5. 丢失消息（可靠性传输） 

![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/mq-13.png)  
&emsp; 消息队列丢失消息有3种情况：生产者丢失数据、mq客户端丢失数据、消费者丢失数据。  
&emsp; 一般解决方案：发送消息前保存mq表，发送成功后更新mq，消费成功后。  

<!-- 
我发到消息队列里面的数据怎么不见了？
https://blog.csdn.net/hanjungua8144/article/details/86240261
-->

----

## 1.6. 重复消费  
<!-- 
04 我为什么在消息队列里消费到了重复的数据？
https://blog.csdn.net/hanjungua8144/article/details/86239428
-->
&emsp; **消费消息的接口幂等。**  

## 1.7. 顺序消费  
<!-- 
我该怎么保证从消息队列里拿到的数据按顺序执行？
https://blog.csdn.net/hanjungua8144/article/details/86244930
https://www.cnblogs.com/jack1995/p/10908814.html
-->
&emsp; **<font color = "lime">发送到单个queue或partition，单线程消费。</font>**  

&emsp; 我举个例子，我们以前做过一个mysql binlog+同步的系统，压力还是非常大的，日同步数据要达到上亿。mysql -> mysql，常见的一点在于说大数据team，就需要同步一个mysql库过来，对公司的业务系统的数据做各种复杂的操作。  
&emsp; 你在mysql里增删改一条数据，对应出来了增删改3条binlog，接着这三条binlog发送到MQ里面，到消费出来依次执行，起码得保证人家是按照顺序来的吧？不然本来是：增加、修改、删除；你楞是换了顺序给执行成删除、修改、增加，不全错了么。  
&emsp; 本来这个数据同步过来，应该最后这个数据被删除了；结果你搞错了这个顺序，最后这个数据保留下来了，数据同步就出错了。  
&emsp; 先看看顺序会错乱的俩场景  
&emsp; （1）rabbitmq：一个queue，多个consumer，这不明显乱了  
&emsp; （2）kafka：一个topic，一个partition，一个consumer，内部多线程，这不也明显乱了  
&emsp; 那如何保证消息的顺序性呢？简单简单  
&emsp; （1）rabbitmq：拆分多个queue，每个queue一个consumer，就是多一些queue而已，确实是麻烦点；或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/mq-14.png)  
&emsp; （2）kafka：一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，然后N个线程分别消费一个内存queue即可  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/microService/mq/mq-15.png)  


## 1.8. 消息积压  
&emsp; **多线程消费。修复消费者问题，临时增加消费者。**   

&emsp; **如何解决消息队列的延时以及过期失效问题？消息队列满了以后该怎么处理？有几百万消息持续积压几小时，说说怎么解决？**

&emsp; 你看这问法，其实本质针对的场景，都是说，可能你的消费端出了问题，不消费了；或者消费的速度极其慢。接着就坑爹了，可能你的消息队列集群的磁盘都快写满了，都没人消费，这个时候怎么办？或者是这整个就积压了几个小时，你这个时候怎么办？或者是你积压的时间太长了，导致比如 RabbitMQ 设置了消息过期时间后就没了怎么办？  

&emsp; 所以就这事儿，其实线上挺常见的，一般不出，一出就是大 case。一般常见于，举个例子，消费端每次消费之后要写 mysql，结果 mysql 挂了，消费端 hang 那儿了，不动了；或者是消费端出了个什么岔子，导致消费速度极其慢。  

&emsp; **大量消息在 mq 里积压了几个小时了还没解决**   
&emsp; 几千万条数据在 MQ 里积压了七八个小时，从下午 4 点多，积压到了晚上 11 点多。这个是我们真实遇到过的一个场景，确实是线上故障了，这个时候要不然就是修复 consumer 的问题，让它恢复消费速度，然后傻傻的等待几个小时消费完毕。这个肯定不能在面试的时候说吧。  

&emsp; 一个消费者一秒是 1000 条，一秒 3 个消费者是 3000 条，一分钟就是 18 万条。所以如果你积压了几百万到上千万的数据，即使消费者恢复了，也需要大概 1 小时的时间才能恢复过来。  

&emsp; 一般这个时候，只能临时紧急扩容了，具体操作步骤和思路如下：  
- 先修复 consumer 的问题，确保其恢复消费速度，然后将现有 consumer 都停掉。  
- 新建一个 topic，partition 是原来的 10 倍，临时建立好原先 10 倍的 queue 数量。  
- 然后写一个临时的分发数据的 consumer 程序，这个程序部署上去消费积压的数据，**消费之后不做耗时的处理**，直接均匀轮询写入临时建立好的10倍数量的 queue。  
- 接着临时征用 10 倍的机器来部署 consumer，每一批 consumer 消费一个临时 queue 的数据。这种做法相当于是临时将 queue 资源和consumer资源扩大 10 倍，以正常的 10 倍速度来消费数据。  
- 等快速消费完积压数据之后，**得恢复原先部署的架构**，**重新**用原先的 consumer 机器来消费消息。  

&emsp; **mq 中的消息过期失效了**  
&emsp; 假设你用的是 RabbitMQ，RabbtiMQ 是可以设置过期时间的，也就是 TTL。如果消息在 queue 中积压超过一定的时间就会被 RabbitMQ 给清理掉，这个数据就没了。那这就是第二个坑了。这就不是说数据会大量积压在 mq 里，而是**大量的数据会直接搞丢**。  

&emsp; 这个情况下，就不是说要增加 consumer 消费积压的消息，因为实际上没啥积压，而是丢了大量的消息。我们可以采取一个方案，就是**批量重导**，这个我们之前线上也有类似的场景干过。就是大量积压的时候，我们当时就直接丢弃数据了，然后等过了高峰期以后，比如大家一起喝咖啡熬夜到晚上12点以后，用户都睡觉了。这个时候我们就开始写程序，将丢失的那批数据，写个临时程序，一点一点的查出来，然后重新灌入 mq 里面去，把白天丢的数据给他补回来。也只能是这样了。  

&emsp; 假设 1 万个订单积压在 mq 里面，没有处理，其中 1000 个订单都丢了，你只能手动写程序把那 1000 个订单给查出来，手动发到 mq 里去再补一次。  

&emsp; **mq 都快写满了**
&emsp; 如果消息积压在 mq 里，你很长时间都没有处理掉，此时导致 mq 都快写满了，咋办？这个还有别的办法吗？没有，谁让你第一个方案执行的太慢了，你临时写程序，接入数据来消费，**消费一个丢弃一个，都不要了**，快速消费掉所有的消息。然后走第二个方案，到了晚上再补数据吧。  




