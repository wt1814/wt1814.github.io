

<!-- TOC -->

- [1. 分库/分片、分表](#1-分库分片分表)
    - [1.1. ★★★如何设计才可以让系统从未分库分表动态切换到分库分表上](#11-★★★如何设计才可以让系统从未分库分表动态切换到分库分表上)
    - [1.2. 数据切分方式](#12-数据切分方式)
        - [1.2.1. 垂直(纵向)切分](#121-垂直纵向切分)
        - [1.2.2. 水平(横向)切分](#122-水平横向切分)
    - [1.3. 分库分表方案(路由算法)](#13-分库分表方案路由算法)
    - [1.4. 分库分表带来的分布式困境与解决方案](#14-分库分表带来的分布式困境与解决方案)
        - [1.4.1. 分库数量](#141-分库数量)
        - [1.4.2. ID问题](#142-id问题)
        - [1.4.3. 基本的数据库增删改功能](#143-基本的数据库增删改功能)
        - [1.4.4. 查询功能](#144-查询功能)
            - [1.4.4.1. 分库分表多维度查询](#1441-分库分表多维度查询)
            - [1.4.4.2. 跨分片的排序order by、分组group by以及聚合count等函数问题](#1442-跨分片的排序order-by分组group-by以及聚合count等函数问题)
            - [1.4.4.3. 跨分片的排序分页](#1443-跨分片的排序分页)
            - [1.4.4.4. 跨节点Join的问题](#1444-跨节点join的问题)
            - [1.4.4.5. 非partition key的查询问题](#1445-非partition-key的查询问题)
        - [1.4.5. 跨分片事务](#145-跨分片事务)
        - [1.4.6. 数据迁移，容量规划，扩容等问题](#146-数据迁移容量规划扩容等问题)

<!-- /TOC -->

# 1. 分库/分片、分表  
<!-- 
CTO：这四种情况下，才是考虑分库分表的时候！ 
https://mp.weixin.qq.com/s/aR53IsVYLKmx06_2zrG_Ig

-->
&emsp; **<font color = "clime">分库分表是为了支撑高并发、数据量大两个问题的。</font>**  

## 1.1. ★★★如何设计才可以让系统从未分库分表动态切换到分库分表上
&emsp; [如何设计才可以让系统从未分库分表动态切换到分库分表上？](/docs/projectImplement/implementation.md)  

* 停机迁移  
* 双写迁移  

---

## 1.2. 数据切分方式  
&emsp; 数据切分分为两种方式，垂直(纵向)切分和水平(横向)切分。先垂直后水平。  

### 1.2.1. 垂直(纵向)切分  
* 垂直分表  
&emsp; 也就是“大表拆小表”，基于列字段进行的。一般是表中的字段较多，将不常用的，数据较大，长度较长(比如text类型字段)的拆分到“扩展表“。 一般是针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题。  
* 垂直分库  
&emsp; 垂直分库针对的是一个系统中的不同业务进行拆分，比如用户User一个库，商品Producet一个库，订单Order一个库。 切分后，要放在多个服务器上，而不是一个服务器上。为什么？ 想象一下，一个购物网站对外提供服务，会有用户，商品，订单等的CRUD。没拆分之前，全部都是落到单一的库上的，这会让数据库的单库处理能力成为瓶颈。按垂直分库后，如果还是放在一个数据库服务器上， 随着用户量增大，这会让单个数据库的处理能力成为瓶颈，还有单个服务器的磁盘空间，内存，tps等非常吃紧。 所以要拆分到多个服务器上，这样上面的问题都解决了，以后也不会面对单机资源问题。  
&emsp; 数据库业务层面的拆分，和服务的“治理”，“降级”机制类似，也能对不同业务的数据分别的进行管理，维护，监控，扩展等。数据库往往最容易成为应用系统的瓶颈，而数据库本身属于“有状态”的，相对于Web和应用服务器来讲，是比较难实现“横向扩展”的。 数据库的连接资源比较宝贵且单机处理能力也有限，在高并发场景下，垂直分库一定程度上能够突破IO、连接数及单机硬件资源的瓶颈。  
&emsp; 垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。与"微服务治理"的做法相似，每个微服务使用单独的一个数据库。  

### 1.2.2. 水平(横向)切分  
* 水平分表  
&emsp; 针对数据量巨大的单张表(比如订单表)，按照某种规则(RANGE，HASH取模等)，切分到多张表里面去。但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。不建议采用。  
* 水平分库分表  
&emsp; 将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。  

## 1.3. 分库分表方案(路由算法)  
&emsp; **<font color = "red">分库分表步骤：根据容量(当前容量和增长量)评估分库或分表个数 -> 选key(均匀)-> 分表规则(hash或range等)-> 执行(一般双写)-> 扩容问题(尽量减少数据的移动)。</font>**   

&emsp; **<font color = "clime">常见的分片策略有随机分片和连续分片这两种，</font>** 如下图所示：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-13.png)  
&emsp; 当需要使用分片字段进行范围查找时，连续分片可以快速定位分片进行高效查询，大多数情况下可以有效避免跨分片查询的问题。后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移。但是，连续分片也有可能存在数据热点的问题，就像图中按时间字段分片的例子，有些节点可能会被频繁查询压力较大，热数据节点就成为了整个集群的瓶颈。而有些节点可能存的是历史数据，很少需要被查询到。  
&emsp; 随机分片其实并不是随机的，也遵循一定规则。通常，会采用Hash取模的方式进行分片拆分，所以有些时候也被称为离散分片。随机分片的数据相对比较均匀，不容易出现热点和并发访问的瓶颈。但是，后期分片集群扩容起来需要迁移旧的数据。使用一致性Hash算法能够很大程度的避免这个问题，所以很多中间件的分片集群都会采用一致性Hash算法。离散分片也很容易面临跨分片查询的复杂问题。  

## 1.4. 分库分表带来的分布式困境与解决方案  

### 1.4.1. 分库数量  
&emsp; 分库数量首先和单库能处理的记录数有关，一般来说，Mysql单库超过5000万条记录，Oracle单库超过1亿条记录，DB压力就很大(当然处理能力和字段数量/访问模式/记录长度有进一步关系)。  
&emsp; 在满足上述前提下，如果分库数量少，达不到分散存储和减轻DB性能压力的目的；如果分库的数量多，好处是每个库记录少，单库访问性能好，但对于跨多个库的访问，应用程序需要访问多个库，如果是并发模式，要消耗宝贵的线程资源；如果是串行模式，执行时间会急剧增加。  
&emsp; 最后分库数量还直接影响硬件的投入，一般每个分库跑在单独物理机上，多一个库意味多一台设备。所以具体分多少个库，要综合评估，一般初次分库建议分4-8个库。  
### 1.4.2. ID问题  
&emsp; 查看[分布式ID](/docs/microService/thinking/DistributedID.md)章节。  

### 1.4.3. 基本的数据库增删改功能  
&emsp; 批量插入：  

```sql
insert into user(id,name) values (1,"tianshouzhi"),(2,"huhuamin"), (3,"wanghanao"),(4,"luyang");
```
&emsp; **批量插入的sql是无法执行的，因为已经对库和表进行了拆分，这种sql语法只能操作mysql的单个库和单个表。** 所以必须将sql改成4条如下所示，然后分别到每个库上去执行。  

```sql
insert into user0(id,name) values  (4,"luyang");
insert into user1(id,name) values (1,"tianshouzhi");
insert into user2(id,name) values (2,"huhuamin");
insert into user3(id,name) values (3,"wanghanao");
```
&emsp; 具体流程可以用下图进行描述：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-14.png)  
1. sql解析：首先对sql进行解析，得到需要插入的四条记录的id字段的值分别为1,2,3,4。  
2. sql路由：sql路由包括库路由和表路由。库路由用于确定这条记录应该插入哪个库，表路由用于确定这条记录应该插入哪个表。  
3. sql改写：因为一条记录只能插入到一个库中，而上述批量插入的语法将会在 每个库中都插入四条记录，明显是不合适的，因此需要对sql进行改写，每个库只插入一条记录。  
4. sql执行：一条sql经过改写后变成了多条sql，为了提升效率应该并发的到不同的库上去执行，而不是按照顺序逐一执行。  
5. 结果集合并：每个sql执行之后，都会有一个执行结果，需要对分库分表的结果集进行合并，从而得到一个完整的结果。  

### 1.4.4. 查询功能

#### 1.4.4.1. 分库分表多维度查询  
&emsp; 查看[分库分表多维度查询](/docs/SQL/subSelect.md)章节。  

----

#### 1.4.4.2. 跨分片的排序order by、分组group by以及聚合count等函数问题  
&emsp; 这些是一类问题，因为它们<font color = "red">都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作，部分支持聚合函数MAX、MIN、COUNT、SUM。</font>  
&emsp; **<font color = "red">解决方案：与解决跨节点join问题类似，分别在各个节点上执行相应的函数处理得到结果后，在应用程序端进行合并。</font>** 和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-16.png)  

#### 1.4.4.3. 跨分片的排序分页  
&emsp; <font color = "red">一般来讲，分页时需要按照指定字段进行排序。当排序字段是分片字段时，通过分片规则可以比较容易定位到指定的分片；而当排序字段非分片字段时，情况就会变得比较复杂了。</font>为了最终结果的准确性，需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。如下图所示：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-17.png)  
&emsp; 上面图中所描述的只是最简单的一种情况(取第一页数据)，看起来对性能的影响并不大。但是，如果想取出第10页数据，情况又将变得复杂很多，如下图所示：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-18.png)  
&emsp; 有些读者可能并不太理解，为什么不能像获取第一页数据那样简单处理(排序取出前10条再合并、排序)。其实并不难理解，因为各分片节点中的数据可能是随机的，为了排序的准确性，必须把所有分片节点的前N页数据都排序好后做合并，最后再进行整体的排序。很显然，这样的操作是比较消耗资源的，用户越往后翻页，系统性能将会越差。 

----

#### 1.4.4.4. 跨节点Join的问题  


&emsp; 在单库单表的情况下，联合查询是非常容易的。但是，随着分库与分表的演变，联合查询就遇到跨库关联和跨表关系问题。在设计之初就应该尽量避免联合查询。  
&emsp; tddl、MyCAT等都支持跨分片join。如果中间不支持，跨库Join的几种解决思路：  

* 在程序中进行拼装。  
* 全局表：  
&emsp; 所谓全局表，就是有可能系统中所有模块都可能会依赖到的一些表。比较类似“数据字典”。为了避免跨库join查询，可以将这类表在其他每个数据库中均保存一份。同时，这类数据通常也很少发生修改(甚至几乎不会)，所以也不用太担心“一致性”问题。  
* 字段冗余：  
&emsp; 这是一种典型的反范式设计，在互联网行业中比较常见，通常是为了性能来避免join查询。  
&emsp; 举个电商业务中很简单的场景：“订单表”中保存“卖家 Id”的同时，将卖家的“Name”字段也冗余，这样查询订单详情的时候就不需要再去查询“卖家用户表”。  
&emsp; 字段冗余能带来便利，是一种“空间换时间”的体现。但其适用场景也比较有限，比较适合依赖字段较少的情况。最复杂的还是数据一致性问题，这点很难保证，可以借助数据库中的触发器或者在业务代码层面去保证。当然，也需要结合实际业务场景来看一致性的要求。就像上面例子，如果卖家修改了Name之后，是否需要在订单信息中同步更新呢？  

----
 
#### 1.4.4.5. 非partition key的查询问题  
(水平分库分表，拆分策略为常用的hash法)  
1. 端上除了partition key只有一个非partition key作为条件查询  
  * 映射法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-19.png)  
  * 基因法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-20.png)  
&emsp; 注：写入时，基因法生成user_id，如图。关于xbit基因，例如要分8张表，23=8，故x取3，即3bit基因。根据user_id查询时可直接取模路由到对应的分库或分表。根据user_name查询时，先通过user_name_code生成函数生成user_name_code再对其取模路由到对应的分库或分表。id生成常用snowflake算法。  
2. 端上除了partition key不止一个非partition key作为条件查询  
  * 映射法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-21.png)  
  * 冗余法    
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-22.png)  
&emsp; 注：按照order_id或buyer_id查询时路由到db_o_buyer库中，按照seller_id查询时路由到db_o_seller库中。感觉有点本末倒置！有其他好的办法吗？改变技术栈呢？  

3. 后台除了partition key还有各种非partition key组合条件查询  
* NoSQL法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-23.png)  
* 冗余法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-24.png)  

### 1.4.5. 跨分片事务  
&emsp; 分库分表、跨分片事务，即分布式事务。参考[分布式事务](/docs/microService/thinking/DistributedTransaction.md)章节。  

### 1.4.6. 数据迁移，容量规划，扩容等问题  
&emsp; 很少有项目会在初期就开始考虑分片设计的，一般都是在业务高速发展面临性能和存储的瓶颈时才会提前准备。因此，不可避免的就需要考虑历史数据迁移的问题。一般做法就是通过程序先读出历史数据，然后按照指定的分片规则再将数据写入到各个分片节点中。  
&emsp; 此外，需要根据当前的数据量和QPS等进行容量规划，综合成本因素，推算出大概需要多少分片(一般建议单个分片上的单表数据量不要超过1000W)。  
&emsp; 如果是采用随机分片，则需要考虑后期的扩容问题，相对会比较麻烦。如果是采用的范围分片，只需要添加节点就可以自动扩容。  
  

