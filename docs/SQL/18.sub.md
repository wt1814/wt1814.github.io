

<!-- TOC -->

- [1. 分库/分片、分表](#1-分库分片分表)
    - [1.1. 数据切分方式](#11-数据切分方式)
        - [1.1.1. 垂直（纵向）切分](#111-垂直纵向切分)
        - [1.1.2. 水平（横向）切分](#112-水平横向切分)
    - [1.2. 分库分表方案（路由算法）](#12-分库分表方案路由算法)
    - [1.3. ~~分库分表带来的分布式困境与解决方案~~](#13-分库分表带来的分布式困境与解决方案)
        - [1.3.1. 分库数量](#131-分库数量)
        - [1.3.2. ID问题](#132-id问题)
        - [1.3.3. 基本的数据库增删改功能](#133-基本的数据库增删改功能)
        - [1.3.4. 查询功能-1](#134-查询功能-1)
            - [1.3.4.1. 跨分片的排序order by、分组group by以及聚合count等函数问题](#1341-跨分片的排序order-by分组group-by以及聚合count等函数问题)
            - [1.3.4.2. 跨分片的排序分页](#1342-跨分片的排序分页)
            - [1.3.4.3. 非partition key的查询问题](#1343-非partition-key的查询问题)
            - [1.3.4.4. 跨节点Join的问题](#1344-跨节点join的问题)
        - [1.3.5. 跨分片事务](#135-跨分片事务)
        - [1.3.6. 数据迁移，容量规划，扩容等问题](#136-数据迁移容量规划扩容等问题)
    - [1.4. 分表和分区的区别与联系](#14-分表和分区的区别与联系)
    - [1.5. 分库分表与读写分离](#15-分库分表与读写分离)
- [2. 数据库中间件](#2-数据库中间件)
    - [2.1. 设计方案](#21-设计方案)
        - [2.1.1. 代理模式](#211-代理模式)
        - [2.1.2. 客户端分片模式](#212-客户端分片模式)
    - [2.2. 业界产品](#22-业界产品)
- [3. SpringAOP实现分布式数据源](#3-springaop实现分布式数据源)
- [4. MyBatis插件实现分布式数据源](#4-mybatis插件实现分布式数据源)

<!-- /TOC -->

# 1. 分库/分片、分表  
## 1.1. 数据切分方式  
&emsp; 数据切分分为两种方式，垂直（纵向）切分和水平（横向）切分。先垂直后水平。  
### 1.1.1. 垂直（纵向）切分  
* 垂直分表  
&emsp; 也就是“大表拆小表”，基于列字段进行的。一般是表中的字段较多，将不常用的，数据较大，长度较长（比如text类型字段）的拆分到“扩展表“。 一般是针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题。  
* 垂直分库  
&emsp; 垂直分库针对的是一个系统中的不同业务进行拆分，比如用户User一个库，商品Producet一个库，订单Order一个库。 切分后，要放在多个服务器上，而不是一个服务器上。为什么？ 想象一下，一个购物网站对外提供服务，会有用户，商品，订单等的CRUD。没拆分之前，全部都是落到单一的库上的，这会让数据库的单库处理能力成为瓶颈。按垂直分库后，如果还是放在一个数据库服务器上， 随着用户量增大，这会让单个数据库的处理能力成为瓶颈，还有单个服务器的磁盘空间，内存，tps等非常吃紧。 所以要拆分到多个服务器上，这样上面的问题都解决了，以后也不会面对单机资源问题。  
&emsp; 数据库业务层面的拆分，和服务的“治理”，“降级”机制类似，也能对不同业务的数据分别的进行管理，维护，监控，扩展等。数据库往往最容易成为应用系统的瓶颈，而数据库本身属于“有状态”的，相对于Web和应用服务器来讲，是比较难实现“横向扩展”的。 数据库的连接资源比较宝贵且单机处理能力也有限，在高并发场景下，垂直分库一定程度上能够突破IO、连接数及单机硬件资源的瓶颈。  
&emsp; 垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。与"微服务治理"的做法相似，每个微服务使用单独的一个数据库。  

### 1.1.2. 水平（横向）切分  
* 水平分表  
&emsp; 针对数据量巨大的单张表（比如订单表），按照某种规则（RANGE，HASH取模等），切分到多张表里面去。但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。不建议采用。  
* 水平分库分表  
&emsp; 将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。  

## 1.2. 分库分表方案（路由算法）  
&emsp; **<font color = "red">分库分表步骤：根据容量（当前容量和增长量）评估分库或分表个数 -> 选key（均匀）-> 分表规则（hash或range等）-> 执行（一般双写）-> 扩容问题（尽量减少数据的移动）。</font>**   

&emsp; 常见的分片策略有随机分片和连续分片这两种，如下图所示：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-13.png)  
&emsp; 当需要使用分片字段进行范围查找时，连续分片可以快速定位分片进行高效查询，大多数情况下可以有效避免跨分片查询的问题。后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移。但是，连续分片也有可能存在数据热点的问题，就像图中按时间字段分片的例子，有些节点可能会被频繁查询压力较大，热数据节点就成为了整个集群的瓶颈。而有些节点可能存的是历史数据，很少需要被查询到。  
&emsp; 随机分片其实并不是随机的，也遵循一定规则。通常，会采用Hash取模的方式进行分片拆分，所以有些时候也被称为离散分片。随机分片的数据相对比较均匀，不容易出现热点和并发访问的瓶颈。但是，后期分片集群扩容起来需要迁移旧的数据。使用一致性Hash算法能够很大程度的避免这个问题，所以很多中间件的分片集群都会采用一致性Hash算法。离散分片也很容易面临跨分片查询的复杂问题。  

## 1.3. ~~分库分表带来的分布式困境与解决方案~~  

### 1.3.1. 分库数量  
&emsp; 分库数量首先和单库能处理的记录数有关，一般来说，Mysql单库超过5000万条记录，Oracle单库超过1亿条记录，DB压力就很大(当然处理能力和字段数量/访问模式/记录长度有进一步关系)。  
&emsp; 在满足上述前提下，如果分库数量少，达不到分散存储和减轻DB性能压力的目的；如果分库的数量多，好处是每个库记录少，单库访问性能好，但对于跨多个库的访问，应用程序需要访问多个库，如果是并发模式，要消耗宝贵的线程资源；如果是串行模式，执行时间会急剧增加。  
&emsp; 最后分库数量还直接影响硬件的投入，一般每个分库跑在单独物理机上，多一个库意味多一台设备。所以具体分多少个库，要综合评估，一般初次分库建议分4-8个库。  
### 1.3.2. ID问题  
&emsp; 查看《分布式ID》章节。  

### 1.3.3. 基本的数据库增删改功能  
&emsp; 批量插入：  

```sql
insert into user(id,name) values (1,"tianshouzhi"),(2,"huhuamin"), (3,"wanghanao"),(4,"luyang");
```
&emsp; 这样的sql明显是无法执行的，因为已经对库和表进行了拆分，这种sql语法只能操作mysql的单个库和单个表。所以必须将sql改成4条如下所示，然后分别到每个库上去执行。  

```sql
insert into user0(id,name) values  (4,"luyang");
insert into user1(id,name) values (1,"tianshouzhi");
insert into user2(id,name) values (2,"huhuamin");
insert into user3(id,name) values (3,"wanghanao");
```
&emsp; 具体流程可以用下图进行描述：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-14.png)  
1. sql解析：首先对sql进行解析，得到需要插入的四条记录的id字段的值分别为1,2,3,4。  
2. sql路由：sql路由包括库路由和表路由。库路由用于确定这条记录应该插入哪个库，表路由用于确定这条记录应该插入哪个表。  
3. sql改写：因为一条记录只能插入到一个库中，而上述批量插入的语法将会在 每个库中都插入四条记录，明显是不合适的，因此需要对sql进行改写，每个库只插入一条记录。  
4. sql执行：一条sql经过改写后变成了多条sql，为了提升效率应该并发的到不同的库上去执行，而不是按照顺序逐一执行。  
5. 结果集合并：每个sql执行之后，都会有一个执行结果，需要对分库分表的结果集进行合并，从而得到一个完整的结果。  

### 1.3.4. 查询功能-1
#### 1.3.4.1. 跨分片的排序order by、分组group by以及聚合count等函数问题  
&emsp; 这些是一类问题，因为它们<font color = "red">都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作，部分支持聚合函数MAX、MIN、COUNT、SUM。</font>  
&emsp; **<font color = "red">解决方案：与解决跨节点join问题类似，分别在各个节点上执行相应的函数处理得到结果后，在应用程序端进行合并。</font>** 和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-16.png)  

#### 1.3.4.2. 跨分片的排序分页  
&emsp; <font color = "red">一般来讲，分页时需要按照指定字段进行排序。当排序字段是分片字段时，通过分片规则可以比较容易定位到指定的分片；而当排序字段非分片字段时，情况就会变得比较复杂了。</font>为了最终结果的准确性，需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。如下图所示：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-17.png)  
&emsp; 上面图中所描述的只是最简单的一种情况（取第一页数据），看起来对性能的影响并不大。但是，如果想取出第10页数据，情况又将变得复杂很多，如下图所示：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-18.png)  
&emsp; 有些读者可能并不太理解，为什么不能像获取第一页数据那样简单处理（排序取出前10条再合并、排序）。其实并不难理解，因为各分片节点中的数据可能是随机的，为了排序的准确性，必须把所有分片节点的前N页数据都排序好后做合并，最后再进行整体的排序。很显然，这样的操作是比较消耗资源的，用户越往后翻页，系统性能将会越差。 
 
#### 1.3.4.3. 非partition key的查询问题  
（水平分库分表，拆分策略为常用的hash法）  
1. 端上除了partition key只有一个非partition key作为条件查询  
  * 映射法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-19.png)  
  * 基因法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-20.png)  
&emsp; 注：写入时，基因法生成user_id，如图。关于xbit基因，例如要分8张表，23=8，故x取3，即3bit基因。根据user_id查询时可直接取模路由到对应的分库或分表。根据user_name查询时，先通过user_name_code生成函数生成user_name_code再对其取模路由到对应的分库或分表。id生成常用snowflake算法。  
2. 端上除了partition key不止一个非partition key作为条件查询  
  * 映射法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-21.png)  
  * 冗余法    
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-22.png)  
&emsp; 注：按照order_id或buyer_id查询时路由到db_o_buyer库中，按照seller_id查询时路由到db_o_seller库中。感觉有点本末倒置！有其他好的办法吗？改变技术栈呢？  

3. 后台除了partition key还有各种非partition key组合条件查询  
* NoSQL法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-23.png)  
* 冗余法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-24.png)  

#### 1.3.4.4. 跨节点Join的问题  
&emsp; 在单库单表的情况下，联合查询是非常容易的。但是，随着分库与分表的演变，联合查询就遇到跨库关联和跨表关系问题。在设计之初就应该尽量避免联合查询。  
&emsp; tddl、MyCAT等都支持跨分片join。如果中间不支持，跨库Join的几种解决思路：  

* 在程序中进行拼装。  
* 全局表：  
&emsp; 所谓全局表，就是有可能系统中所有模块都可能会依赖到的一些表。比较类似“数据字典”。为了避免跨库join查询，可以将这类表在其他每个数据库中均保存一份。同时，这类数据通常也很少发生修改（甚至几乎不会），所以也不用太担心“一致性”问题。  
* 字段冗余：  
&emsp; 这是一种典型的反范式设计，在互联网行业中比较常见，通常是为了性能来避免join查询。  
&emsp; 举个电商业务中很简单的场景：“订单表”中保存“卖家 Id”的同时，将卖家的“Name”字段也冗余，这样查询订单详情的时候就不需要再去查询“卖家用户表”。  
&emsp; 字段冗余能带来便利，是一种“空间换时间”的体现。但其适用场景也比较有限，比较适合依赖字段较少的情况。最复杂的还是数据一致性问题，这点很难保证，可以借助数据库中的触发器或者在业务代码层面去保证。当然，也需要结合实际业务场景来看一致性的要求。就像上面例子，如果卖家修改了Name之后，是否需要在订单信息中同步更新呢？  

### 1.3.5. 跨分片事务  
&emsp; 分库分表、跨分片事务，即分布式事务。参考《分布式事务》章节。  

### 1.3.6. 数据迁移，容量规划，扩容等问题  
&emsp; 很少有项目会在初期就开始考虑分片设计的，一般都是在业务高速发展面临性能和存储的瓶颈时才会提前准备。因此，不可避免的就需要考虑历史数据迁移的问题。一般做法就是通过程序先读出历史数据，然后按照指定的分片规则再将数据写入到各个分片节点中。  
&emsp; 此外，需要根据当前的数据量和QPS等进行容量规划，综合成本因素，推算出大概需要多少分片（一般建议单个分片上的单表数据量不要超过1000W）。  
&emsp; 如果是采用随机分片，则需要考虑后期的扩容问题，相对会比较麻烦。如果是采用的范围分片，只需要添加节点就可以自动扩容。  

## 1.4. 分表和分区的区别与联系
&emsp; **分表和分区的联系：**  
1. 实现方式上：
    * mysql的分表是真正的分表，一张表分成很多表后，每一个小表都是完正的一张表，都对应三个文件，一个.MYD数据文件，.MYI索引文件，.frm表结构文件。  
    * 分区不一样，一张大表进行分区后，还是一张表，不会变成多张表，但是存放数据的区块变多了。  
2. 数据处理上： 
    * 分表后，数据都是存放在分表里，总表只是一个外壳，存取数据发生在一个一个的分表里面。  
    * 分区不存在分表的概念，分区只不过把存放数据的文件分成了许多小块，分区后的表还是一张表。数据处理还是由自己来完成。  

&emsp; **分表和分区的联系：**  
1. 都能提高mysql的性高，在高并发状态下都有一个良好的表面。 
2. 分表和分区不矛盾，可以相互配合。对于那些大访问量，并且表数据比较多的表，可以采取分表和分区结合的方式（如果merge这种分表方式，不能和分区配合的话，可以用其他的分表试），访问量不大，但是表数据很多的表，可以采取分区的方式等。

## 1.5. 分库分表与读写分离  
&emsp; 分库分表的好处：<font color = "red">读写分离实现了数据库读能力的水平扩展，分库分表实现了写能力的水平扩展。</font>  
1. 存储能力的水平扩展：在读写分离的情况下，每个集群中的master和slave基本上数据是完全一致的，从存储能力来说，存在海量数据的情况下，可能由于磁盘空间的限制，无法存储所有的数据。而在分库分表的情况下，可以搭建多个mysql主从复制集群，每个集群只存储部分分片的数据，实现存储能力的水平扩展。  
2. 写能力的水平扩展：在读写分离的情况下，由于每个集群只有一个master，所有的写操作压力都集中在这一个节点上，在写入并发非常高的情况下，这里会成为整个系统的瓶颈。  

&emsp; 而在分库分表的情况下，每个分片所属的集群都有一个master节点，都可以执行写入操作，实现写能力的水平扩展。此外减小建立索引开销，降低写操作的锁操作耗时等，都会带来很多显然的好处。  

----

# 2. 数据库中间件  
&emsp; 数据库中间件的主要作用是向应用程序开发人员屏蔽读写分离和分库分表面临的挑战，并隐藏底层实现细节，使得开发人员可以像操作单库单表那样去操作数据。  

&emsp; **<font color = "lime">除了数据库中间件之外还可以使用SpringAOP、ORM框架代理来实现多数据源读写分离。</font>**  

## 2.1. 设计方案  
&emsp; 典型的数据库中间件设计方案有2种：代理proxy、客户端分片smart-client。下图演示了这两种方案的架构：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-25.png)  
&emsp; 不论是proxy还是smart-client，底层都操作了多个数据库实例。不论是分库分表，还是读写分离，都是在数据库中间件层面对业务开发同学进行屏蔽。  

### 2.1.1. 代理模式  
&emsp; 独立部署一个代理服务，这个代理服务背后管理多个数据库实例。而在应用中，通过一个普通的数据源(c3p0、druid、dbcp等)与代理服务器建立连接，所有的sql操作语句都是发送给这个代理，由这个代理去操作底层数据库，得到结果并返回给应用。在这种方案下，分库分表和读写分离的逻辑对开发人员是完全透明的。  

&emsp; **优点：**  
1. 多语言支持。不论使用的是php、java或是其他语言，都可以支持。以mysql数据库为例，如果proxy本身实现了mysql的通信协议，那么可以就将其看成一个mysql 服务器。mysql官方团队为不同语言提供了不同的客户端却动，如java语言的mysql-connector-java，python语言的mysql-connector-python等等。因此不同语言的开发者都可以使用mysql官方提供的对应的驱动来与这个代理服务器建通信。  
2. 对业务开发同学透明。由于可以把proxy当成mysql服务器，理论上业务同学不需要进行太多代码改造，既可以完成接入。  

&emsp; **缺点：**  
1. 实现复杂。因为proxy需要实现被代理的数据库server端的通信协议，实现难度较大。通常看到一些proxy模式的数据库中间件，实际上只能代理某一种数据库，如mysql。几乎没有数据库中间件可以同时代理多种数据库(sqlserver、PostgreSQL、Oracle)。  
2. proxy本身需要保证高可用。由于应用本来是直接访问数据库，现在改成了访问proxy，意味着proxy必须保证高可用。否则，数据库没有宕机，proxy挂了，导致数据库无法正常访问，就尴尬了。  
3. 租户隔离。可能有多个应用访问proxy代理的底层数据库，必然会对proxy自身的内存、网络、cpu等产生资源竞争，proxy需要需要具备隔离的能力。  

### 2.1.2. 客户端分片模式  
&emsp; 业务代码需要进行一些改造，引入支持读写分离或者分库分表的功能的sdk，这个就是smart-client。通常smart-client是在连接池或者driver的基础上进行了一层封装，smart-client内部与不同的库建立连接。应用程序产生的sql交给smart-client进行处理，其内部对sql进行必要的操作，例如在读写分离情况下，选择走从库还是主库；在分库分表的情况下，进行sql解析、sql改写等操作，然后路由到不同的分库，将得到的结果进行合并，返回给应用。  

&emsp; **优点：**  
1. 实现简单。proxy需要实现数据库的服务端协议，但是smart-client不需要实现客户端通信协议。原因在于，大多数据数据库厂商已经针对不同的语言提供了相应的数据库驱动driver，例如mysql针对java语言提供了mysql-connector-java驱动，针对python提供了mysql-connector-python驱动，客户端的通信协议已经在driver层面做过了。因此smart-client模式的中间件，通常只需要在此基础上进行封装即可。  
2. 天然去中心化。smart-client的方式，由于本身以sdk的方式，被应用直接引入，随着应用部署到不同的节点上，且直连数据库，中间不需要有代理层。因此相较于proxy而言，除了网络资源之外，基本上不存在任何其他资源的竞争，也不需要考虑高可用的问题。只要应用的节点没有全部宕机，就可以访问数据库。(这里的高可用是相比proxy而言，数据库本身的高可用还是需要保证的)  

&emsp; **缺点：**  
1. 通常仅支持某一种语言。例如tddl、zebra、sharding-jdbc都是使用java语言开发，因此对于使用其他语言的用户，就无法使用这些中间件。如果其他语言要使用，那么就要开发多语言客户端。  
2. 版本升级困难。因为应用使用数据源代理就是引入一个jar包的依赖，在有多个应用都对某个版本的jar包产生依赖时，一旦这个版本有bug，所有的应用都需要升级。而数据库代理升级则相对容易，因为服务是单独部署的，只要升级这个代理服务器，所有连接到这个代理的应用自然也就相当于都升级了。  

## 2.2. 业界产品  
&emsp; 无论是proxy，还是smart-client，二者的作用都是类似的。以下列出了这两种方案目前已有的实现以及各自的优缺点：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-26.png)  
&emsp; proxy实现，目前的已有的实现方案有：  

    阿里巴巴开源的cobar  
    阿里云上的drds  
    mycat团队在cobar基础上开发的mycat  
    mysql官方提供的mysql-proxy  
    奇虎360在mysql-proxy基础开发的atlas(只支持分表，不支持分库)  
    当当网开源的sharing-sphere  
    目前除了mycat、sharing-sphere，其他几个开源项目基本已经没有维护。  

&emsp; smart-client实现，目前的实现方案有：  

    阿里巴巴开源的tddl，已很久没维护
    大众点评开源的zebra，大众点评的zebra开源版本代码已经很久没有更新，不过最近美团上市，重新开源大量内部新的功能特性，并计划长期维持。
    当当网开源的sharding-jdbc，目前算是做的比较好的，文档资料比较全。和sharding-sphere一起进入了Apache孵化器。
    蚂蚁金服的zal

&emsp; 综上，现在其实建议考量的，就是sharding-jdbc和mycat，这两个都可以去考虑使用。  
&emsp; sharding-jdbc这种client层方案的优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合sharding-jdbc的依赖；  
&emsp; mycat这种proxy层方案的缺点在于需要部署，自己运维一套中间件，运维成本高，但是好处在于对于各个项目是透明的，如果遇到升级之类的都是自己中间件那里搞就行了。  
&emsp; 通常来说，这两个方案其实都可以选用，但是个人建议中小型公司选用 sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 mycat，然后大量项目直接透明使用即可。  

---
# 3. SpringAOP实现分布式数据源   
&emsp; [AOP多数据源动态切换](/docs/SQL/6.multiDataSource.md)  

---
# 4. MyBatis插件实现分布式数据源   
...

