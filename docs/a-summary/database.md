

<!-- TOC -->

- [1. 数据库](#1-数据库)
    - [SQL](#sql)
    - [1.1. SQL面试题](#11-sql面试题)
    - [1.5. 索引事物锁](#15-索引事物锁)
        - [1.5.1. 索引底层原理](#151-索引底层原理)
        - [1.5.2. ~~各种索引~~（还需要总结）](#152-各种索引还需要总结)
        - [1.5.3. MySql事务（还需要总结）](#153-mysql事务还需要总结)
        - [1.5.4. MVCC](#154-mvcc)
        - [1.5.5. MySql锁](#155-mysql锁)
        - [1.5.6. MySql死锁和锁表](#156-mysql死锁和锁表)
    - [1.2. ~~MySql优化~~](#12-mysql优化)
        - [1.2.1. SQL分析](#121-sql分析)
            - [1.2.1.1. Expain](#1211-expain)
        - [1.2.3. 索引优化](#123-索引优化)
        - [1.2.2. SQL语句优化](#122-sql语句优化)
        - [1.2.4. 碎片优化](#124-碎片优化)
        - [~~Sql优化的一些案例~~](#sql优化的一些案例)
    - [1.3. 数据库分布式](#13-数据库分布式)
        - [1.3.1. 大数据量操作](#131-大数据量操作)
        - [1.3.2. MySql瓶颈](#132-mysql瓶颈)
        - [1.3.3. 数据库分布式](#133-数据库分布式)
        - [1.3.4. 主从复制](#134-主从复制)
            - [1.3.4.1. 主从复制原理](#1341-主从复制原理)
            - [1.3.4.2. 主从复制实现](#1342-主从复制实现)
            - [1.3.4.3. 主从复制问题](#1343-主从复制问题)
            - [1.3.4.4. 高可用实现](#1344-高可用实现)
            - [1.3.4.5. 读写分离实现](#1345-读写分离实现)
        - [1.3.5. 分区](#135-分区)
        - [1.3.6. ~~分库分表~~](#136-分库分表)
            - [1.3.6.1. 分库分表](#1361-分库分表)
            - [1.3.6.2. 分库分表查询](#1362-分库分表查询)
                - [1.3.6.2.1. 非partition key的查询 / 分库分表多维度查询](#13621-非partition-key的查询--分库分表多维度查询)
                    - [1.3.6.2.1.1. 跨分片的分组group by以及聚合count等函数](#136211-跨分片的分组group-by以及聚合count等函数)
                    - [1.3.6.2.1.2. 跨分片的排序分页](#136212-跨分片的排序分页)
                - [1.3.6.2.2. 跨节点Join的问题](#13622-跨节点join的问题)
                - [1.3.6.2.3. ~~**<font color = "blue">小结：分库分表分片键设计</font>**~~](#13623-font-color--blue小结分库分表分片键设计font)
        - [1.3.7. 数据迁移](#137-数据迁移)
        - [1.3.8. 大数据量](#138-大数据量)
        - [1.3.9. 数据库分布式实现](#139-数据库分布式实现)
        - [ShardingSphere](#shardingsphere)
    - [1.4. MySql架构](#14-mysql架构)
        - [1.4.1. MySql运行流程](#141-mysql运行流程)
        - [1.4.2. Server层之binLog日志](#142-server层之binlog日志)
        - [1.4.3. 存储引擎层](#143-存储引擎层)
        - [1.4.4. InnoDB体系结构](#144-innodb体系结构)
            - [1.4.4.1. InnoDB内存结构-性能](#1441-innodb内存结构-性能)
                - [1.4.4.1.1. BufferPool](#14411-bufferpool)
                - [1.4.4.1.2. BufferPool落盘表空间](#14412-bufferpool落盘表空间)
                - [1.4.4.1.3. 写缓冲ChangeBuffer](#14413-写缓冲changebuffer)
                - [1.4.4.1.4. AdaptiveHashIndex](#14414-adaptivehashindex)
            - [1.4.4.2. InnoDB磁盘结构-可靠性](#1442-innodb磁盘结构-可靠性)
                - [1.4.4.2.1. undoLog](#14421-undolog)
                - [1.4.4.2.2. redoLog](#14422-redolog)
                - [1.4.4.2.3. DoubleWrite](#14423-doublewrite)
            - [1.4.4.3. ~~两阶段提交和崩溃恢复~~](#1443-两阶段提交和崩溃恢复)

<!-- /TOC -->

# 1. 数据库

## SQL  
1. Goup by分组  
&emsp; 查询结果集中有统计数据时，就需要使用分组函数。  
&emsp; <font color = "red">Group By分组函数中，查询只能得到组相关的信息。组相关的信息(统计信息)：count,sum,max,min,avg。</font> `在select指定的字段要么包含在Group By语句的后面，作为分组的依据；要么被包含在聚合函数中`。group by是`对结果集分组，而不是查询字段分组`。  
&emsp; **<font color = "red">Group By含有去重效果。</font>**  


## 1.1. SQL面试题
[★★★SQL面试题](/docs/SQL/SQLInterview.md)  
case when 高级语法


## 1.5. 索引事物锁
### 1.5.1. 索引底层原理 
1. **<font color = "clime">评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中`磁盘I/O`操作次数的渐进复杂度。</font>**  
&emsp; 操作系统中以页这种结构作为读写的基本单位。操作系统IO消耗：<font color = "red">一般来说，索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储在磁盘上。</font>这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级，所以 **<font color = "clime">评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。</font>** 换句话说，索引的结构组织要尽量减少查找过程中磁盘I/O的存取次数。  
2. InnoDB使用的数据结构选择：  
    * Hash索引适合精确查找，但是范围查找不适合。  
    * 二叉查找树，可能退化成单链表，相当于全表扫描。    
    * 平衡二叉树的不足：  
        &emsp; 平衡二叉树解决了存在线性链表的问题，数据查询的效率好像也还可以，基本能达到O(log2(n))， 那为什么mysql不选择平衡二叉树作为索引存储结构，`平衡二叉树又存在什么样的问题呢？`    
        * **<font color = "red">存储的数据内容太少。</font>** 没有很好利用操作系统和磁盘数据交换特性，也没有利用好磁盘IO的预读能力。因为操作系统和磁盘之间一次数据交换是以页为单位的，一页大小为 4K，即每次IO操作系统会将4K数据加载进内存。但是，在二叉树每个节点的结构只保存一个关键字，一个数据区，两个子节点的引用，并不能够填满4K的内容。幸幸苦苦做了一次的IO操作，却只加载了一个关键字。在树的高度很高，恰好又搜索的关键字位于叶子节点或者支节点的时候，取一个关键字要做很多次的IO。  
        * **<font color = "red">搜索效率不足。</font>** 一般来说，在树结构中，数据所处的深度，决定了搜索时的IO次数（MySql中将每个节点大小设置为一页大小，一次IO读取一页 / 一个节点）。如上图中搜索id = 8的数据，需要进行3次IO。当数据量到达几百万的时候，树的高度就会很恐怖。
        * **<font color = "red">查询不稳定。</font>** 如果查询的数据落在根节点，只需要一次IO，如果是叶子节点或者是支节点，会需要多次IO才可以。
    * B树：
        1. B树中每个节点中不仅包含数据的key值，还有data值。 **<font color = "red">而每一个页的存储空间是有限的，如果data数据较大时将会导致每个节点（即一个页）能存储的key的数量很小。当存储的数据量很大时同样会导致B树的深度较大，</font>** 增大查询时的磁盘I/O次数进而影响查询效率。  
        2. `范围查询，磁盘I/O高。`
    * B+树  
        1. B+Tree中间节点不存储数据，因此B+Tree能够在同样大小的节点中，存储更多的key。
        2. `叶子节点之间会有个指针指向，这个也是B+树的核心点，可以大大提升范围查询效率，也方便遍历整个树。`  
        3. `B+tree的查询效率更加稳定。`  
3. InnoDB索引实现  
    1.  
    2. 联合索引    
    &emsp; **<font color = "red">联合索引底层还是使用B+树索引，并且还是只有一棵树，只是此时的排序：首先按照第一个索引排序，在第一个索引相同的情况下，再按第二个索引排序，依此类推。</font>**  
    &emsp; 联合索引(col1, col2,col3)也是一棵B+Tree，其`非叶子节点存储的是第一个关键字的索引`，而叶节点存储的则是三个关键字col1、col2、col3三个关键字的数据，且按照col1、col2、col3的顺序进行排序。  
4. InnoDB索引查找  
&emsp; 无索引时的数据查询：查询数据时从磁盘中依次加载数据页到InnoDB的缓冲池中，然后对缓冲池中缓存页的每行数据，通过数据页的单向链表一个一个去遍历查找，如果没有找到，那么就会顺着数据页的双向链表数据结构，依次遍历加载磁盘中的其他数据页到缓冲池中遍历查询。 

### 1.5.2. ~~各种索引~~（还需要总结）
1. 聚簇索引和非聚簇索引  
    1. 什么是？  
    2. 非聚簇索引一定会回表查询吗?(覆盖索引)

2. 普通索引和唯一索引的区别？  
    &emsp; 唯一索引和普通索引的区别？  

    * 查询过程：  
    &emsp; 执行查询的语句是`select id from T where k=5`。  
    &emsp; 对于普通索引来说，查找到满足条件的第一个记录(5,500)后，需要查找下一个记录，直到碰到第一个不满足k=5条件的记录。  
    &emsp; 对于唯一索引来说，<font color = "red">由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。</font>  
    * 更新过程：  
    &emsp; **<font color = "clime">普通索引会使用[ChangeBuffer](/docs/SQL/ChangeBuffer.md)提升性能。而change buffer不适用于唯一索引。</font>**  

    * 索引选择和实践：  
    &emsp; 其实，这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以，建议尽量选择普通索引。  
    &emsp; **<font color = "clime">如果所有的更新后面，都马上伴随着对这个记录的查询，那么应该关闭change buffer。而在其他情况下，change buffer都能提升更新性能。</font>**  
    &emsp; 在实际使用中，普通索引和change buffer的配合使用，对于数据量大的表的更新优化还是很明显的。  

### 1.5.3. MySql事务（还需要总结）  
1. ★★★小结：并发的问题（为什么要有事务？） --- 事务的四大特性 --- 四个隔离级别/隔离性（分别解决了什么问题？）  --- Innodb事务实现原理（怎么解决的？）   
2. 并发带来的问题：脏读、丢失修改、不可重复读、幻读。  
    * 脏`读`：一个事务读了另一个事务未提交的数据。
    * 丢失`修改`：一个事务覆盖了另一个事务的数据。  
    * 不可重复读：一个事务多次读，另一事务中间修改了数据。  
    * 幻读：一个事务多次读，另一事务中间新增了数据。  
3. 事务的四大特性（ACID）：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。  
4. SQL标准定义了四个隔离级别/隔离性（分别解决了什么问题？）：读取未提交、读取已提交、可重复读（可以阻止脏读和不可重复读，幻读仍有可能发生，但MySql的可重复读解决了幻读）、可串行化。  
5. Innodb事务实现原理（怎么解决的？）  
    * 原子性的实现：采用[undo log](/docs/SQL/undoLog.md)实现。  
    * 持久性的实现：采用[redo log](/docs/SQL/redoLog.md)实现。  
    * 隔离性(事务的隔离级别)的实现：  
        &emsp; 在MySQL中，默认的隔离级别是REPEATABLE-READ（可重复读），阻止脏读和不可重复读，并且解决了幻读问题。  
        &emsp; 隔离性(事务的隔离级别)的实现，利用的是锁和MVCC机制。 
        * **<font color = "blue">快照读：生成一个事务快照（ReadView），之后都从这个快照获取数据。</font>** 普通select语句就是快照读。  
        &emsp; <font color = "blue">对于快照读，MVCC因为从ReadView读取，所以必然不会看到新插入的行，所以天然就解决了幻读的问题。</font>  
        * **<font color = "clime">当前读：读取数据的最新版本。</font>** 常见的update/insert/delete、还有 select ... for update、select ... lock in share mode都是当前读。  
        &emsp; 对于当前读的幻读，MVCC是无法解决的。需要使用Gap Lock或Next-Key Lock（Gap Lock + Record Lock）来解决。  
    * 一致性的实现   
        &emsp; Mysql怎么保证一致性的？这个问题分为两个层面来说。  
        1. 从数据库层面，数据库通过原子性、隔离性、持久性来保证一致性。也就是说ACID四大特性之中，C(一致性)是目的，A(原子性)、I(隔离性)、D(持久性)是手段，是为了保证一致性，数据库提供的手段。数据库必须要实现AID三大特性，才有可能实现一致性。例如，原子性无法保证，显然一致性也无法保证。  
        2. 从应用层面，通过代码判断数据库数据是否有效，然后决定回滚还是提交数据！如果在事务里故意写出违反约束的代码，一致性还是无法保证的。  


### 1.5.4. MVCC
1. ★★★小结：简介 --- 两个非常重要的模块 --- 在读取已提交、可重复读两种隔离级别下会使用MVCC --- 可重复读解决了幻读吗？    
1. **<font color = "clime">多版本并发控制（MVCC）是一种用来解决读-写冲突的无锁并发控制。</font>**  
&emsp; <font color = "clime">MVCC与锁：MVCC主要解决读写问题，锁解决写写问题。两者结合才能更好的控制数据库隔离性，保证事务正确提交。</font>  
2. **<font color = "clime">InnoDB有`【两个非常重要的模块（版本链，Read View）】`来实现MVCC。一个是`undo log`，用于记录数据的变化轨迹（`版本链`），用于数据回滚；另外一个是`Read View`，用于判断一个session对哪些数据可见，哪些不可见。</font>**   
    1. 版本链的生成：在数据库中的每一条记录实际都会存在三个隐藏列：事务ID、行ID、回滚指针，指向undo log记录。  
    2. **<font color = "red">Read View是用来判断每一个读语句有资格读取版本链中的哪个记录。所以在读之前，都会生成一个Read View。然后根据生成的Read View再去读取记录。</font>**  
    3. ~~Read View判断：~~  
    &emsp; ![image](http://182.92.69.8:8081/img/SQL/sql-154.png)  
    &emsp; 如果被访问版本的trx_id小于ReadView中的up_limit_id（最大事务ID）值，表明生成该版本的事务在当前事务生成ReadView前已经提交，所以该版本可以被当前事务访问。  
    &emsp; <font color = "red">如果被访问版本的trx_id属性值在ReadView的up_limit_id和low_limit_id之间，那就需要判断一下trx_id属性值是不是在trx_ids列表中。</font>如果在，说明创建ReadView时生成该版本的事务还是活跃的，该版本不可以被访问；<font color = "clime">如果不在，说明创建ReadView时生成该版本的事务已经被提交，该版本可以被访问。</font>  
4. 在读取已提交、可重复读两种隔离级别下会使用MVCC。  
    * 读取已提交READ COMMITTED是在`每次执行select操作时`都会生成一次Read View。所以解决不了幻读问题。 
    * 可重复读REPEATABLE READ只有在第一次执行select操作时才会生成Read View，后续的select操作都将使用第一次生成的Read View。
5. 可重复读解决了幻读没有？  
        当前读：select...lock in share mode; select...for update;
        当前读：update、insert、delete
&emsp; 对于当前读的幻读，MVCC是无法解决的。需要使用 Gap Lock 或 Next-Key Lock（Gap Lock + Record Lock）来解决。</font>其实原理也很简单，用上面的例子稍微修改下以触发当前读：select * from user where id < 10 for update。`若只有MVCC，当事务1执行第二次查询时，操作的数据集已经发生变化，所以结果也会错误；`当使用了Gap Lock时，Gap锁会锁住id < 10的整个范围，因此其他事务无法插入id < 10的数据，从而防止了幻读。  


### 1.5.5. MySql锁
1. 解决写写问题。  
2. ![image](http://182.92.69.8:8081/img/SQL/sql-42.png)  
    * 乐观锁：添加字段（版本号）  
    * 悲观锁：数据库层面加锁。    
0. 数据库锁  
    1. 全局锁
    2. 表级锁
        1. 表锁
            1. 表共享读锁
            2. 表独占写锁
        2. 元数据锁
        3. 意向锁
            1. 意向共享锁
            2. 意向排他锁
    3. 行级锁
        1. 行锁
            1. 共享锁
            2. 排他锁
        2. 间隙锁
        3. 临键锁

1. 数据库锁  
    &emsp; **锁的分类：**  
    ![image](http://182.92.69.8:8081/img/SQL/sql-42.png)  

    * 按使用方式：乐观锁、悲观锁。乐观锁，开发自定义；悲观锁，Mysql内置。     
    * 按粒度：锁的粒度的不同可以分为表锁、页锁、行锁。  
    * 锁类别：有共享锁(读锁)和排他锁(写锁)。锁类别取决于存储引擎执行的sql语句。  
    ![image](http://182.92.69.8:8081/img/SQL/sql-47.png)  
2. ~~InnoDB共有七种类型的锁：共享/排它锁、意向锁、记录锁（Record lock）、间隙锁（Gap lock）、临键锁（Next-key lock）、插入意向锁、自增锁。~~  
3. **<font color = "red">InnoDB存储引擎的锁的算法有三种：</font>**  
    1. Record lock：单个行记录上的锁。  
    2. Gap lock：间隙锁，锁定一个范围，不包括记录本身。  
    &emsp; **<font color = "red">当使用范围条件（> 、< 、between...）检索数据，InnoDB会给符合条件的已有数据记录的索引项加锁。对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP）”，InnoDB也会对这个“间隙”加锁，这就是间隙锁。</font>**  
    &emsp; **<font color = "red">InnoDB除了通过范围条件加锁时使用间隙锁外，如果使用相等条件请求给一个不存在的记录加锁，InnoDB也会使用间隙锁。</font>**  
    3. Next-key lock：record+gap锁定一个范围，包含记录本身。  
    &emsp; 临键锁，是记录锁与间隙锁的组合，它的封锁范围，既包含索引记录，又包含索引区间。  
    &emsp; <font color = "red">默认情况下，innodb使用next-key locks来锁定记录。</font><font color = "clime">但当查询的索引含有唯一属性的时候，Next-Key Lock会进行优化，将其降级为Record Lock，即仅锁住索引本身，不是范围。</font>  



### 1.5.6. MySql死锁和锁表
&emsp; ~~胡扯，死锁，mysql检测后，回滚一条事务，抛出异常。~~  
1. 服务器报错：`Deadlock found when trying to get to lock; try restarting transaction`。  
2. **<font color = "clime"> 死锁发生了如何解决，MySQL有没有提供什么机制去解决死锁？</font>**  
    1. 发起死锁检测，主动回滚其中一条事务，让其他事务继续执行。  
    2. 设置超时时间，超时后自动释放。  
    &emsp; `在涉及外部锁，或涉及表锁的情况下，InnoDB并不能完全自动检测到死锁，`这需要通过设置锁等待超时参数 innodb_lock_wait_timeout来解决。</font>   
3. **<font color = "clime">如果出现死锁</font>** ，<font color = "clime">可以用`show engine innodb status;`命令来确定最后一个死锁产生的原因。</font>  

## 1.2. ~~MySql优化~~
&emsp; <font color = "red">MySql性能由综合因素决定，抛开业务复杂度，影响程度依次是硬件配置、MySQL配置、数据表设计、索引优化。</font>  
1. SQL语句的优化。  
    &emsp; `对查询语句的监控、分析、优化是SQL优化的一般步骤。`常规调优思路：  
    1. 查看慢查询日志slowlog，分析slowlog，分析出查询慢的语句。  
    2. 按照一定优先级，进行一个一个的排查所有慢语句。  
    3. 分析top sql，进行explain调试，查看语句执行时间。  
    4. 调整[索引](/docs/SQL/7.index.md)或语句本身。 
2. 存储数据量较大： **<font color = "red">单库单表无法满足时，可以拆分表结构（主从复制、分库分表），或者使用ES搜索引擎。</font>**  
3. 服务器的优化。  

### 1.2.1. SQL分析
1. **<font color = "clime">6个关键字从各个维度分析SQL语句：profiling（消耗资源）、trace（优化器如何选择执行计划）、EXPLAIN与explain extended、show warnings、proceduer analyse。</font>**  
2. profiling（资料搜集）  
&emsp; 使用profiling命令可以了解SQL语句`消耗资源`的详细信息，每个执行步骤的开销。可以清楚了解到SQL到底慢在哪个环节。   
3. trace  
&emsp; 查看优化器如何选择执行计划，获取每个可能的索引选择的代价。  
4. <font color = "red">用explain extended查看执行计划会比explain多一列filtered。filtered列给出了一个百分比的值，这个百分比值和rows列的值一起使用，可以估计出那些将要和explain中的前一个表进行连接的行的数目。前一个表就是指explain的id列的值比当前表的id小的表。</font>  
&emsp; mysql中有一个explain 命令可以用来分析select 语句的运行效果，例如explain可以获得select语句使用的索引情况、排序的情况等等。除此以外，explain 的extended 扩展能够在原本explain的基础上额外的提供一些查询优化的信息，这些信息可以通过mysql的show warnings命令得到。  

#### 1.2.1.1. Expain
&emsp; expain信息列分别是id、select_type、table、partitions、 **<font color = "red">type（使用什么类型的锁）</font>** 、possible_keys、 **<font color = "red">key（索引）</font>** 、 **<font color = "red">key_len</font>** 、ref、rows、filtered、 **<font color = "red">Extra（额外信息）</font>** 。  
* **<font color = "clime">type单表查询类型要达到range级别（只检索给定范围的行，使用一个索引来选择行，非全表扫描）。</font>**  
* key_len表示使用的索引长度，key_len可以衡量索引的好坏，key_len越小，索引效果越好。 **<font color = "blue">可以根据key_len来判断联合索引是否生效。</font>**  
* **<font color = "red">extra：额外的信息，该列包含MySQL解决查询的详细信息。注意，常见的不太友好的值，如Using filesort（额外排序）、Using temporary（使用了临时表），意思MYSQL根本不能使用索引，常出现在使用order by。</font>**  


### 1.2.3. 索引优化
1. 创建索引：为了使索引的使用效率更高，在创建索引时，必须考虑在哪些字段上创建索引和创建什么类型的索引。  
    * 多表连接的字段、where条件字段、分组字段、排序字段、联合UNION字段、去重distinct字段上建立索引。  
    * 尽量选择区分度高的列作为索引。  
    * ...  

2. 索引失效（避免全表查询）：进行null值运算、进行运算、隐式转换、对索引列使用函数 导致索引失效，进行模糊查询like时可能使索引失效(以%开头)，不满足联合索引最左前缀匹配原则。    

3. 【索引条件】下推：  
&emsp; 理解索引条件下推：1. 【什么是索引条件？】 2. 什么是下推？  
&emsp; 索引下推简而言之就是在复合索引由于某些条件（比如 like %aa）失效的情况下，当存在失效的过滤字段在索引覆盖范围内，使用比较的方式在不回表的情况下进一步缩小查询的范围。其实就是对索引失效的进一步修复。  
&emsp; **<font color = "clime">~~MySQL 5.6 引入了「索引下推优化」，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。~~</font>**  
    * 关闭ICP：索引--->回表--->条件过滤。  
    * 开启ICP：索引--->条件过滤--->回表。</font>在支持ICP后，`MySQL在取出索引数据的同时，判断是否可以进行where条件过滤，`<font color = "blue">将where的部分过滤操作放在存储引擎层提前过滤掉不必要的数据，</font>减少了不必要数据被扫描带来的IO开销。  


### 1.2.2. SQL语句优化
1. 基本查询优化：  
2. 子查询优化：
2. 关联查询优化：使用索引、 **<font color = "bllue">驱动表选择、`条件谓词下推`</font>** ......  
&emsp; 条件谓词下推，就是在将过滤条件下推到离数据源更近的地方，最好就是在table_scan时就能过滤掉不需要的数据。  

### 1.2.4. 碎片优化

### ~~Sql优化的一些案例~~



## 1.3. 数据库分布式


### 1.3.1. 大数据量操作

### 1.3.2. MySql瓶颈
1. MySql性能
	* 最大并发数：并发数是指同一时刻数据库能处理多少个请求，由max_connections和max_user_connections决定。max_connections是指MySQL实例的最大连接数，上限值是16384，max_user_connections是指每个数据库用户的最大连接数。  
	* 查询耗时0.5秒，0.5秒是个经验值。  
	* 最大数据量：《阿里巴巴Java开发手册》提出单表行数超过500万行或者单表容量超过2GB，才推荐分库分表。  
2. 数据库瓶颈  
	&emsp; <font color = "clime">`不管是IO瓶颈，还是CPU瓶颈，最终都会导致数据库的活跃连接数增加，进而逼近甚至达到数据库可承载活跃连接数的阈值。在业务Service来看就是，可用数据库连接少甚至无连接可用。`</font>   
	1. IO瓶颈：  
	&emsp; 第一种：磁盘读IO瓶颈，热点数据太多，数据库缓存放不下，每次查询时会产生大量的IO，降低查询速度。解决方案：分库和垂直分表。  
	&emsp; 第二种：网络IO瓶颈，请求的数据太多（MySql一般并发数200～5000），网络带宽不够。 解决方案：分库。  
	2. CPU瓶颈：  
	&emsp; 第一种：SQL问题，如SQL中包含join，group by，order by，非索引字段条件查询等，增加CPU运算的操作。解决方案：SQL优化，建立合适的索引，在业务Service层进行业务计算。  
	&emsp; 第二种：单表数据量太大（达到1000W或100G以后），查询时扫描的行太多，SQL效率低，CPU率先出现瓶颈。解决方案：水平分表。  

### 1.3.3. 数据库分布式
&emsp; **`数据库拆分过程基本遵循的顺序是：`1).垂直拆分（业务拆分） ---> 2).读写分离 ---> 3).分库分表（水平拆分）。每个拆分过程都能解决业务上的一些问题，但同时也面临了一些挑战。**  
1. **分库分表与读写分离：**   
    &emsp; `读写分离实现了数据库读能力的水平扩展，分库分表实现了写能力的水平扩展。`  
    1. 存储能力的水平扩展：在读写分离的情况下，每个集群中的master和slave基本上数据是完全一致的，从存储能力来说，存在海量数据的情况下，可能由于磁盘空间的限制，无法存储所有的数据。而在分库分表的情况下，可以搭建多个mysql主从复制集群，每个集群只存储部分分片的数据，实现存储能力的水平扩展。  
    2. 写能力的水平扩展：在读写分离的情况下，由于每个集群只有一个master，所有的写操作压力都集中在这一个节点上，在写入并发非常高的情况下，这里会成为整个系统的瓶颈。而在分库分表的情况下，每个分片所属的集群都有一个master节点，都可以执行写入操作，实现写能力的水平扩展。此外减小建立索引开销，降低写操作的锁操作耗时等，都会带来很多显然的好处。  
2. 分表和分区  
    1.  **分表和分区的区别：**  
        1. 实现方式上：
            * mysql的分表是真正的分表，一张表分成很多表后，每一个小表都是完整的一张表，都对应三个文件，一个.MYD数据文件，.MYI索引文件，.frm表结构文件。  
            * 分区不一样，一张大表进行分区后，还是一张表，不会变成多张表，但是存放数据的区块变多了。  
        2. 数据处理上： 
            * 分表后，数据都是存放在分表里，总表只是一个外壳，存取数据发生在一个一个的分表里面。  
            * 分区不存在分表的概念，分区只不过把存放数据的文件分成了许多小块，分区后的表还是一张表。数据处理还是由自己来完成。  
    2. **分表和分区的联系：**  
        1. 都能提高mysql的性能，在高并发状态下都有一个良好的表面。 
        2. **<font color = "clime">分表和分区不矛盾，可以相互配合。</font>** 
            * 对于那些大访问量，并且表数据比较多的表，可以`采取分表和分区结合的方式`（如果merge这种分表方式，不能和分区配合的话，可以用其他的分表试）。  
            * `访问量不大，但是表数据很多的表，可以采取分区的方式等。`  
    3. **分库分表与读写分离：** `读写分离`实现了数据库`读能力`的水平扩展，`分库分表`实现了`写能力`的`水平扩展`。  
        1. 存储能力的水平扩展：在读写分离的情况下，每个集群中的master和slave基本上数据是完全一致的，从存储能力来说，存在海量数据的情况下，可能由于磁盘空间的限制，无法存储所有的数据。而在分库分表的情况下，可以搭建多个mysql主从复制集群，每个集群只存储部分分片的数据，实现存储能力的水平扩展。  
        2. 写能力的水平扩展：在读写分离的情况下，由于每个集群只有一个master，所有的写操作压力都集中在这一个节点上，在写入并发非常高的情况下，这里会成为整个系统的瓶颈。  

### 1.3.4. 主从复制
#### 1.3.4.1. 主从复制原理  
1. 对于每一个主从复制的连接，都有三个线程。  
    * 拥有多个从库的主库为每一个连接到主库的从库创建一个binlog输出线程。  
    * 每一个从库都有它自己的I/O线程和SQL线程。  
        * `I/O线程与主库进行连接，请求主库的binlog。接收到binlog后，会存储到relay log中（中继日志）。`  
        * SQL线程会解析中继日志，并在从库上进行应用。  
2. 同步方式可以划分为：异步、半同步和同步。`在MySQL5.7中，带来了全新的多线程复制技术。`  
3. 复制类型有三种：基于行的复制、基于语句的复制、混合模式复制。  
    * 并非所有修改数据的语句都可以使用基于语句的复制进行复制。使用基于语句的复制时，任何非确定性行为都难以复制。  
    * 基于行的复制会产生大量的日志。  
    &emsp; 注：Mysql到Elasticsearch实时增量同步，多采用基于行复制。    
    * MySQL5.1及其以后的版本推荐使用混合模式的复制，它是<font color = "clime">根据事件的类型实时的改变binlog的格式。当设置为混合模式时，默认为基于语句的格式，但在特定的情况下它会自动转变为基于行的模式。</font>  

#### 1.3.4.2. 主从复制实现


#### 1.3.4.3. 主从复制问题
1. 复制过程
	1. 大对象blog,text传输： **<font color = "clime">解决的办法就是在主从库上增加max_allowed_packet参数的大小。</font>**  
2. 错误
	1. 主从不一致后锁表 
	2. 跳过错误
	3. 数据损坏或丢失  
		1. 主库意外关闭  
		2. 备库意外关闭
		3. 主库二进制日志损坏
		4. 备库中继日志损坏
		5. 二进制日志与InnoDB事务日志不同步
	4. 未定义的服务器ID
3. 性能
	1. ~~如何查看主从延迟？~~  
	2. `【产生延迟的两种方式：】`  
		1. `突然产生延迟，然后再跟上。可以通过备库上的慢查询日志来进行优化。`在备库上开启log_slow_slave_statement选项，可以在慢查询日志中记录复制线程执行的语句。
		2. 稳定的延迟增大
	3. 并行复制  
4. <font color = "red">复制问题要分清楚是master的问题，还是slave的问题。master问题找二进制日志binlog，slave问题找中继日志relaylog。</font>  

#### 1.3.4.4. 高可用实现


#### 1.3.4.5. 读写分离实现
&emsp; 读写分离的实现，`可以在应用层解决，也可以通过中间件实现。`  
1. 应用层解决方案：  
    1. 驱动实现
        * com.mysql.jdbc.ReplicationDriver
        * Sharding-jdbc
    2. MyBatis plugin（sqlType: select,update,insert）  
    3. SpringAOP + mybatis plugin + 注解
    4. Spring动态数据源 + mybatis plugin
2. 常见代理中间件有MyCat...  

### 1.3.5. 分区
&emsp; Why Not 分区？  
&emsp; 分区的原理：  

    分区表是由多个相关的底层表实现，这些底层表也是由句柄对象表示，所以我们也可以直接访问各个分区，存储引擎管理分区的各个底层表和管理普通表一样（所有的底层表都必须使用相同的存储引擎），分区表的索引只是在各个底层表上各自加上一个相同的索引，从存储引擎的角度来看，底层表和一个普通表没有任何不同，存储引擎也无须知道这是一个普通表还是一个分区表的一

&emsp; 事实上，这个方案也不错，它对用户屏蔽了sharding的细节，即使查询条件没有sharding column，它也能正常工作（只是这时候性能一般）。不过它的缺点很明显：很多的资源都受到单机的限制，例如连接数，网络吞吐等！虽然每个分区可以独立存储，但是分区表的总入口还是一个MySQL示例。从而导致它的并发能力非常一般，远远达不到互联网高并发的要求！  
&emsp; 至于网上提到的一些其他缺点比如：无法使用外键，不支持全文索引。我认为这都不算缺点，21世纪的项目如果还是使用外键和数据库的全文索引，我都懒得吐槽了！  
&emsp; 所以，如果使用分区表，你的业务应该具备如下两个特点：  

* 数据不是海量（分区数有限，存储能力就有限）；
* 并发能力要求不高；


### 1.3.6. ~~分库分表~~
#### 1.3.6.1. 分库分表
1. 数据切分方式：  
    * 垂直分库，一般根据业务维度拆分，分布式项目中单项目单库。  
    * **<font color = "clime">`水平分库`主要根据`用户属性（如地市）`拆分物理数据库。一种常见的方式是将全省划分为多个大区。`可以复合分片字段拆分，即按照用户属性（如地市）拆分后，再按照时间拆分。`</font>**  
    * 垂直分表，基于列字段进行的。一般是表中的字段较多，将不常用的，数据较大，长度较长（比如text类型字段）的拆分到“扩展表”。  
    * ~~水平分表：针对数据量比较大的单张表。~~ **<font color = "red">MySql水平分表必须使用MyISAM引擎。</font>**  
2. 水平分库无论怎么分，只要能通过拆分字段和分片策略，找到具体的库就可以。  
3. `水平分表面临的一系列问题：切分策略、库节点路由、表路由、全局主键生成、跨节点排序、分组、分页、表关联等操作、多数据源事务处理、数据库扩容等。`  

#### 1.3.6.2. 分库分表查询
##### 1.3.6.2.1. 非partition key的查询 / 分库分表多维度查询  

* 冗余法
* 基因法  
&emsp; 如果拆分成16张表，则需要截取二进制订单id的最后LOG(16,2)=4位，作为分库/分表基因，订单id的最后4位采用从用户id那边获取的4位基因。这样就满足按照订单号和用户（买家、卖家）id查询。   
* 映射法
* NoSQL法：ES、Hbase等。  
    
    <font color = "blue">B2B模式（有买家、卖家），订单表采用`冗余法（买家库和卖家库）和基因法`结合。</font>  

###### 1.3.6.2.1.1. 跨分片的分组group by以及聚合count等函数  
&emsp; 这些是一类问题，因为它们<font color = "red">都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作，部分支持聚合函数MAX、MIN、COUNT、SUM。</font>  
&emsp; **<font color = "red">解决方案：分别在各个节点上执行相应的函数处理得到结果后，在应用程序端进行合并。</font>** 每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。  

###### 1.3.6.2.1.2. 跨分片的排序分页  
&emsp; <font color = "red">一般来讲，分页时需要按照指定字段进行排序。`当排序字段是分片字段时，通过分片规则可以比较容易定位到指定的分片；`而当排序字段非分片字段时，情况就会变得比较复杂了。</font>为了最终结果的准确性，需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。  


------------

&emsp; 常见的分片策略有随机分片和连续分片这两种。“跨库分页”的四种方案：     
1. 全局视野法
	1. 流程  
        &emsp; （1）将order by time offset X limit Y，改写成order by time offset 0 limit X+Y  
        &emsp; （2）服务层对得到的N*(X+Y)条数据进行内存排序，内存排序后再取偏移量X后的Y条记录   
		1. 如果要获取第N页的数据（每页S条数据），则将每一个子库的前N页（offset 0,limit N*S）的所有数据都先查出来（有筛选条件或排序规则的话都包含）。  
		2. 然后将各个子库的结果合并起来之后，再做一次分页查询（可不用带上相同的筛选条件，但还要带上排序规则）即可得出最终结果，这种方式类似es分页的逻辑。  
	2. 优点：数据准确，可以跳页  
	3. 缺点：  
	（1）每个分库需要返回更多的数据，增大了网络传输量（耗网络）；  
	（2）服务层还需要进行二次排序，增大了服务层的计算量（耗CPU）；   	
    （3）最致命的，这个算法随着页码的增大，性能会急剧下降，这是因为SQL改写后每个分库要返回X+Y行数据：返回第3页，offset中的X=200；假如要返回第100页，offset中的X=9900，即每个分库要返回100页数据，数据量和排序量都将大增，性能平方级下降。     
2. 方法二：业务折衷法-禁止跳页查询（对应es中的scroll方法）   
	1. 流程：  
        &emsp; （1）用正常的方法取得第一页数据，并得到第一页记录的time_max  
        &emsp; （2）每次翻页，将order by time offset X limit Y，改写成order by time where time>$time_max limit Y  
		1. 如果要获取第N页的数据，第一页时，是和全局视野法一致。  
		2. 但第二页开始后，需要在每一个子库查询时，加上可以排除上一页的过滤条件(如按时间排序时，获取上一页的最大时间后，需要加上time > ${maxTime_lastPage}的条件，然后再limit S。即可获取各个子库的结果。  
		3. 之后再合并后top S即可得到最终结果。  
	2. 优点: 数据准确，性能良好  
	3. 缺点: 不能跳页    
3. 方法三：业务折衷法-允许模糊数据  
	1. 前提：数据库分库-数据均衡原理  
	使用patition key进行分库，在数据量较大，数据分布足够随机的情况下，各分库所有非patition key属性，在各个分库上的数据分布，统计概率情况是一致的。  
	2. 流程：将order by time offset X limit Y，改写成order by time offset X/N limit Y/N    
	3. 优点: 性能良好，可以跳页
	4. 缺点: 数据不准确
4. 终极武器-二次查询法  
    &emsp; 第一次查询：按照`limit 总数据/分库数,分页数`查询，获取到最小排序字段值和每个分库的最大排序字段值。  
    &emsp; 第二次查询：`between` 最小排序字段值，最大排序字段值。  
    
        （1）将order by time offset X limit Y，改写成order by time offset X/N limit Y   
        （2）找到最小值time_min   
        （3）between二次查询，order by time between $time_min and $time_i_max    
        （4）设置虚拟time_min，找到time_min在各个分库的offset，从而得到time_min在全局的offset    
        （5）得到了time_min在全局的offset，自然得到了全局的offset X limit Y    

------------------
查询二次改写   
这也是"业界难题-跨库分页”中提到的一个方法，大致思路如下：在某 1 页的数据均摊到各分表的前提下（注：这个前提很重要，也就是说不会有一个分表的数据特别多或特别少），换句话说：这个方案`不适用分段法`。    
第一次改写的SQL语句是select * from T order by time offset 333 limit 5  
第二次要改写成一个between语句，between的起点是time_min，`between的终点是原来每个分库各自返回数据的最大值`：  
第一个分库，第一次返回数据的最大值是1487501523  
所以查询改写为select * from T order by time where time between time_min and 1487501523  

第二个分库，第一次返回数据的最大值是1487501323  
所以查询改写为select * from T order by time where time between time_min and 1487501323  

第三个分库，第一次返回数据的最大值是1487501553  
所以查询改写为select * from T order by time where time between time_min and 1487501553  

相对第一次查询，第二次查询条件放宽了，故第二次查询会返回比第一次查询结果集更多的数据  


##### 1.3.6.2.2. 跨节点Join的问题  

&emsp; tddl、MyCAT等都支持跨分片join。如果中间不支持，跨库Join的几种解决思路：  
* `在程序中进行拼装。`  
* 全局表  
&emsp; 所谓全局表，就是有可能系统中所有模块都可能会依赖到的一些表。比较类似“数据字典”。为了避免跨库join查询，可以将这类表在其他每个数据库中均保存一份。同时，这类数据通常也很少发生修改（甚至几乎不会），所以也不用太担心“一致性”问题。  
* 字段冗余 

##### 1.3.6.2.3. ~~**<font color = "blue">小结：分库分表分片键设计</font>**~~  
&emsp; ~~分库分表的分片键设计多数参考查询场景。因此分库分表时设计拆分字段考虑因素：1). 是否有必要按照地区、时间拆分表；2)参考B2B模式（有买家、卖家），订单表采用`冗余法（买家库和卖家库）和基因法`结合。~~  

### 1.3.7. 数据迁移
1. 现在有一个未分库分表的系统，未来要分库分表，如何设计才可以让系统从未分库分表**动态切换**到分库分表上？
    * 停机迁移方案
    * 双写迁移方案 

### 1.3.8. 大数据量 
1. 亿级订单系统  
2. 冷热数据分离  

### 1.3.9. 数据库分布式实现  
### ShardingSphere
sharding-jdbc与sharding-proxy比较：  
两者的主要区别在于ShardingJDBC更加注重数据库的分片和分布式事务，而Proxy更加注重数据库的负载均衡和故障转移。  


## 1.4. MySql架构
### 1.4.1. MySql运行流程
1. MySQL整个查询执行过程，总的来说分为5个步骤：  
    1. 客户端请求 ---> 连接器（验证用户身份，给予权限）；  
    2. 查询缓存（存在缓存则直接返回，不存在则执行后续操作）；
    3. 分析器（对SQL进行词法分析和语法分析操作）  ---> 优化器（主要对执行的sql优化选择最优的执行方案方法）；  
    4. 执行器（执行时会先看用户是否有执行权限，有才去使用这个引擎提供的接口）；  
    5. 去引擎层获取数据返回（如果开启查询缓存则会缓存查询结果）。   
2. **<font color = "clime">MySQL服务器主要分为Server层和存储引擎层。</font>**  
	1. <font color = "red">Server层包括连接器、查询缓存、分析器、优化器、执行器等。</font>涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等，还有 **<font color = "clime">一个通用的日志模块binglog日志模块。</font>**   
	2. `存储引擎：主要负责数据的存储和读取，`采用可以替换的插件式架构，支持 InnoDB、MyISAM、Memory等多个存储引擎，其中InnoDB引擎有自有的日志模块redolog模块。  
3. `MySQL更新流程：（2大事务日志（redo log、undo log）和bin log）`  
    1. 事务提交前 --- **<font color = "clime">内存操作</font>** ：  
        1. 数据加载到缓冲池buffer poll；  
        2. `写回滚日志undo log；`  
        3. 更新（update 语句）缓冲池数据；  
        4. 写redo log buffer。  
    2. 事务提交：`redo log与bin log两阶段提交。`  
    3. 事务提交后：后台线程将buffer poll中数据落盘。  
    ![image](http://182.92.69.8:8081/img/SQL/sql-174.png)  
    ![image](http://182.92.69.8:8081/img/SQL/sql-183.png)  

### 1.4.2. Server层之binLog日志  
1. **<font color = "clime">binlog是mysql的逻辑日志，并且由Server层进行记录，`使用任何存储引擎的mysql数据库都会记录binlog日志`。</font>**  
2. 在实际应用中，主要用在两个场景：主从复制和数据恢复。  
3. 写入流程：SQL修改语句先写Binlog Buffer，事务提交时，按照一定的格式刷到磁盘中。  
&emsp; binlog刷盘时机：对于InnoDB存储引擎而言，mysql通过sync_binlog参数控制binlog的刷盘时机。  

### 1.4.3. 存储引擎层
1. 常见的几个MySQL存储引擎：  

2. **<font color = "red">InnoDB的特性：</font>**    
    * [支持事务](/docs/SQL/transaction.md)  
    * [支持行锁](/docs/SQL/lock.md)，采用[MVCC](/docs/SQL/MVCC.md)来支持高并发  
    * 支持外键  
    * 支持崩溃后的安全恢复  
    * 不支持全文索引  
    * InnoDB 不保存表的具体行数，执行`select count(*) from table`时需要全表扫描。  
3. 选择合适的存储引擎  

    * 如果对数据一致性要求比较高，需要事务支持，可以选择 InnoDB。比如OA自动化办公系统。  
    * 如果数据查询多更新少，对查询性能要求比较高，可以选择 MyISAM。比如博客系统、新闻门户网站。  

    ![image](http://182.92.69.8:8081/img/SQL/sql-50.png)  

### 1.4.4. InnoDB体系结构
&emsp; Innodb体系结构包含后台线程、内存池和磁盘上的结构。  
![image](http://182.92.69.8:8081/img/SQL/sql-147.png)  
1. `如果从内存上来看，Change Buffer和Adaptive Hash Index占用的内存都属于Buffer Pool`；redo Log Buffer占用的内存与Buffer Pool独立。`即InnoDB内存主要有两大部分：缓冲池、重做日志缓冲。`  
2. `Buffer Pool有Changer Buffer；Redo Log有Double Write。`  


#### 1.4.4.1. InnoDB内存结构-性能
&emsp; 内存中的结构主要包括Buffer Pool，Change Buffer、Adaptive Hash Index以及redo Log Buffer四部分。 **<font color = "blue">如果从内存上来看，[Change Buffer](/docs/SQL/ChangeBuffer.md)和[Adaptive Hash Index](/docs/SQL/AdaptiveHashIndex.md)占用的内存都属于Buffer Pool，redo Log Buffer占用的内存与 [Buffer Pool](/docs/SQL/bufferPoolNew.md)独立。</font>** `即InnoDB内存主要有两大部分：缓冲池、重做日志缓冲。`  

&emsp; 内存数据落盘整体思路分析：  
![image](http://182.92.69.8:8081/img/SQL/sql-173.png)  
&emsp; InnoDB`内存缓冲池中的数据page要完成持久化`的话，是通过两个流程来完成的，`一个是脏页落盘；一个是预写redo log日志`。  

##### 1.4.4.1.1. BufferPool
1. 缓冲池是主内存中的一个区域，在InnoDB访问表和索引数据时会在其中进行高速缓存。**在专用服务器上，通常将多达80％的物理内存分配给缓冲池。**  
1. **预读：**   
&emsp; 数据访问，通常都遵循“集中读写”的原则，使用一些数据，大概率会使用附近的数据，这就是所谓的“局部性原理”，它表明提前加载是有效的，确实能够减少磁盘IO。  
&emsp; **<font color = "clime">预读机制能把一些“可能要访问”的页提前加入缓冲池，避免未来的磁盘IO操作；</font>**  
2. **预读失效与缓存污染：**    
&emsp; 预读失效：读取连续的缓存页，将lru链表尾部经常被访问的页清除了。缓存污染：当执行一条 SQL 语句时，如果扫描了大量数据或是进行了全表扫描，从而将缓冲池中已存在的所有页替换出去。  
3. **读操作：改进的lru算法：**    
&emsp; **<font color = "clime">为了提高缓存命中率，InnoDB 在传统 Lru 算法的基础上做了优化，解决了两个问题：1、预读失效 2、缓存池污染。</font>**   
&emsp; `将LRU链表分为两部分，一部分为热数据区域，一部分为冷数据区域。`当数据页第一次被加载到缓冲池中的时候，先将其放到冷数据区域的链表头部，1s（由 innodb_old_blocks_time 参数控制） 后该缓存页被访问了再将其移至热数据区域的链表头部。  
5. **写操作：**    
&emsp; **Buffer pool 另一个主要的功能是「加速写」，即当需要修改一个页面的时候，先将这个页面在缓冲池中进行修改，记下相关的重做日志，这个页面的修改就算已经完成了。**  


##### 1.4.4.1.2. BufferPool落盘表空间
1. 从InnoDb存储引擎的逻辑存储结构看，所有数据都被逻辑地存放在一个空间中，称之为表空间tablespace。表空间又由段segment，区extent，页page组成。  
2. **<font color = "clime">相比较之下，使用独占表空间的效率以及性能会更高一点。</font>**  
3. **<font color = "clime">在InnoDB存储引擎中，默认每个页的大小为16KB（在操作系统中默认页大小是4KB）。</font>**  

##### 1.4.4.1.3. 写缓冲ChangeBuffer
1. 在「非唯一」「普通」索引页（即非聚集索引）不在缓冲池中，对页进行了写操作， 1). 并不会立刻将磁盘页加载到缓冲池，而仅仅记录缓冲变更， 2).`等未来数据被读取时，再将数据合并(merge)恢复到缓冲池中`的技术。  
2. **~~<font color = "red">如果辅助索引页已经在缓冲区了，则直接修改即可；如果不在，则先将修改保存到 Change Buffer。</font><font color = "blue">Change Buffer的数据在对应辅助索引页读取到缓冲区时合并到真正的辅助索引页中。Change Buffer 内部实现也是使用的 B+ 树。</font>~~**  

##### 1.4.4.1.4. AdaptiveHashIndex
&emsp;对于InnoDB的哈希索引，确切的应该这么说：  
&emsp;(1)InnoDB用户无法手动创建哈希索引，这一层上说，InnoDB确实不支持哈希索引；  
&emsp;(2)InnoDB会自调优(self-tuning)，如果判定建立自适应哈希索引(Adaptive Hash Index, AHI)，能够提升查询效率，InnoDB自己会建立相关哈希索引，这一层上说，InnoDB又是支持哈希索引的。  

#### 1.4.4.2. InnoDB磁盘结构-可靠性
##### 1.4.4.2.1. undoLog
1. **<font color = "clime">Undo log，回滚日志，是`逻辑日记`。undo log解决了事务原子性。</font>** 主要有两个作用，事务回滚和MVCC（Mutil-Version Concurrency Control）。      
2. undo log主要记录了数据的逻辑变化，比如一条INSERT语句，对应一条DELETE的undo log，对于每个UPDATE语句，对应一条相反的UPDATE的undo log，这样在发生错误时，就能回滚到事务之前的数据状态。
3. 事务开始之前，将当前的版本生成undo log。

##### 1.4.4.2.2. redoLog
1. redo log，物理格式的日志，记录的是物理数据页面的修改的信息。 **<font color = "red">`redo log实际上记录数据页的变更，而这种变更记录是没必要全部保存，`因此redo log实现上采用了大小固定，`循环写入`的方式，当写到结尾时，会回到开头循环写日志。</font>**    
2. 解决事务的一致性，持久化数据。  
3. 写入流程：`(Write-Ahead Logging，‘日志’先行)`   
&emsp; 在计算机体系中，CPU处理速度和硬盘的速度，是不在同一个数量级上的，为了让它们速度匹配，从而催生了内存模块，但是内存有一个特点，就是掉电之后，数据就会丢失，不是持久的，我们需要持久化的数据，最后都需要存储到硬盘上。InnoDB引擎设计者也利用了类似的设计思想。   
&emsp; 当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log(redolog buffer)里面，并更新内存(buffer pool)，这个时候更新就算完成了。`同时，InnoDB引擎会在适当的时候，`将这个redoLog操作记录更新到磁盘里面（刷脏页）。  
![image](http://182.92.69.8:8081/img/SQL/sql-184.png)  
4. 刷盘时机：重做日志的写盘，并不一定是随着事务的提交才写入重做日志文件的，而是随着事务的开始，逐步开始的。先写入redo log buffer。  

##### 1.4.4.2.3. DoubleWrite
&emsp; double write：<font color = "blue">如果说写缓冲change buffer带给InnoDB存储引擎的是性能，那么两次写Double Write带给InnoDB存储引擎的是数据的可靠性。</font>  
1. MySQL将buffer中一页数据刷入磁盘，要写4个文件系统里的页。  
2. 在应用(apply)重做日志(redo log)前，需要一个页的副本，当`写入失效发生时`，`先通过页的副本来还原该页，再进行重做`，这就是doublewrite。即doublewrite是页的副本。  
    1. 在异常崩溃时，如果不出现“页数据损坏”，能够通过redo恢复数据；
    2. 在出现“页数据损坏”时，能够通过double write buffer恢复页数据； 
3. doublewrite分为内存和磁盘的两层架构。当有页数据要刷盘时：  
    1. 第一步：页数据先memcopy到doublewrite buffer的内存里；
    2. 第二步：doublewrite buffe的内存里，会先刷到`doublewrite buffe的磁盘`上；
    3. 第三步：doublewrite buffe的内存里，再刷到`数据磁盘`存储上； 

#### 1.4.4.3. ~~两阶段提交和崩溃恢复~~
1. 两阶段提交
    1. **<font color = "clime">redo log和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。两阶段提交保证解决binlog和redo log的数据一致性。</font>**    
    2. `两阶段提交是很典型的分布式事务场景，因为redolog和binlog两者本身就是两个独立的个体，`要想保持一致，就必须使用分布式事务的解决方案来处理。 **<font color = "blue">而将redolog分成了两步，其实就是使用了两阶段提交协议(Two-phaseCommit，2PC)。</font>**  
    &emsp; 事务的提交过程有两个阶段，就是将redolog的写入拆成了两个步骤：prepare和commit，中间再穿插写入binlog。  
        1. 记录redolog，InnoDB事务进入prepare状态；
        2. 写入binlog；
        3. 将redolog这个事务相关的记录状态设置为commit状态。
2. 崩溃恢复： **<font color = "red">当重启数据库实例的时候，数据库做2个阶段性操作：redo log处理，undo log及binlog 处理。在崩溃恢复中还需要回滚没有提交的事务，提交没有提交成功的事务。由于回滚操作需要undo日志的支持，undo日志的完整性和可靠性需要redo日志来保证，所以崩溃恢复`先做redo前滚，然后做undo回滚`。</font>**    
