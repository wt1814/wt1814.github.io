
<!-- TOC -->

- [1. 缓存、Redis、Mq](#1-缓存redismq)
    - [1.1. 缓存](#11-缓存)
        - [1.1.1. 二级缓存](#111-二级缓存)
        - [1.1.2. ~~分布式缓存问题~~](#112-分布式缓存问题)
            - [1.1.2.1. 查询缓存](#1121-查询缓存)
            - [1.1.2.2. 更新缓存](#1122-更新缓存)
        - [1.1.3. 数据结构：bitMap、布隆、布谷鸟](#113-数据结构bitmap布隆布谷鸟)
            - [1.1.3.1. bitMap](#1131-bitmap)
            - [1.1.3.2. 布隆、计数布隆过滤器](#1132-布隆计数布隆过滤器)
            - [1.1.3.3. 布谷鸟](#1133-布谷鸟)
            - [1.1.3.4. Redis热点key](#1134-redis热点key)
    - [1.2. Redis](#12-redis)
        - [1.2.1. Redis数据类型](#121-redis数据类型)
            - [1.2.1.1. Redis基本数据类型](#1211-redis基本数据类型)
            - [1.2.1.2. Redis扩展数据类型](#1212-redis扩展数据类型)
            - [1.2.1.3. redis使用：bigKey](#1213-redis使用bigkey)
            - [1.2.1.4. ~~Redis底层实现~~](#1214-redis底层实现)
                - [1.2.1.4.1. 数据结构](#12141-数据结构)
                - [1.2.1.4.2. SDS详解](#12142-sds详解)
                - [1.2.1.4.3. Dictht](#12143-dictht)
                - [1.2.1.4.4. 数据类型](#12144-数据类型)
        - [1.2.2. Redis内置功能](#122-redis内置功能)
            - [1.2.2.1. RedisPipeline/批处理](#1221-redispipeline批处理)
            - [1.2.2.2. Redis事务](#1222-redis事务)
            - [1.2.2.3. Redis和Lua](#1223-redis和lua)
            - [1.2.2.4. Redis实现消息队列](#1224-redis实现消息队列)
            - [1.2.2.5. Redis发布订阅](#1225-redis发布订阅)
        - [1.2.3. Redis高可用](#123-redis高可用)
            - [1.2.3.1. Redis高可用方案](#1231-redis高可用方案)
            - [1.2.3.2. Redis主从复制](#1232-redis主从复制)
            - [1.2.3.3. Redis哨兵模式](#1233-redis哨兵模式)
            - [1.2.3.4. Redis读写分离](#1234-redis读写分离)
            - [1.2.3.5. Redis集群模式](#1235-redis集群模式)
        - [1.2.4. Redis原理](#124-redis原理)
            - [1.2.4.1. 内存](#1241-内存)
                - [1.2.4.1.1. Redis过期键删除](#12411-redis过期键删除)
                - [1.2.4.1.2. Redis内存淘汰](#12412-redis内存淘汰)
                - [1.2.4.1.3. Redis【虚拟内存】机制](#12413-redis虚拟内存机制)
            - [1.2.4.2. 磁盘](#1242-磁盘)
                - [1.2.4.2.1. Redis持久化，磁盘操作](#12421-redis持久化磁盘操作)
                - [1.2.4.2.2. ~~AOF重写阻塞~~](#12422-aof重写阻塞)
            - [1.2.4.3. 网络](#1243-网络)
                - [1.2.4.3.1. Redis事件/Reactor（IO多路复用）](#12431-redis事件reactorio多路复用)
                - [1.2.4.3.2. Redis多线程模型](#12432-redis多线程模型)
                - [1.2.4.3.3. Redis协议](#12433-redis协议)
        - [1.2.5. Redis常见问题与优化](#125-redis常见问题与优化)
    - [1.3. 分布式消息队列](#13-分布式消息队列)
        - [1.3.1. MQ常见面试题](#131-mq常见面试题)
        - [1.3.2. Kafka](#132-kafka)
            - [1.3.2.1. kafka基本概念](#1321-kafka基本概念)
                - [1.3.2.1.1. kafka生产者](#13211-kafka生产者)
                - [1.3.2.1.2. 消息分区](#13212-消息分区)
                - [1.3.2.1.3. kafka消费者](#13213-kafka消费者)
                - [1.3.2.1.4. kafka服务端](#13214-kafka服务端)
            - [1.3.2.2. kafka特性](#1322-kafka特性)
                - [1.3.2.2.1. 【高性能】-内存](#13221-高性能-内存)
                - [1.3.2.2.2. 【高性能】-持久化/磁盘IO-顺序读写](#13222-高性能-持久化磁盘io-顺序读写)
                - [1.3.2.2.3. 【高性能】-网络IO零拷贝](#13223-高性能-网络io零拷贝)
                - [1.3.2.2.4. 【高可用】-副本机制](#13224-高可用-副本机制)
                - [1.3.2.2.5. 【高一致】-消息丢失（可靠性传输）](#13225-高一致-消息丢失可靠性传输)
                - [1.3.2.2.6. 【高一致】-分区保持顺序（顺序消费）](#13226-高一致-分区保持顺序顺序消费)
                - [1.3.2.2.7. 【高一致】-kafka幂等性（重复消费）](#13227-高一致-kafka幂等性重复消费)
                - [1.3.2.2.8. 【高一致】-kafka事务](#13228-高一致-kafka事务)
                - [1.3.2.2.9. 【高一致】-~~消息积压~~](#13229-高一致-消息积压)

<!-- /TOC -->

# 1. 缓存、Redis、Mq  

## 1.1. 缓存

### 1.1.1. 二级缓存  
1. J2Cache是一个两级缓存框架，第1级为JVM堆内缓存（通常选用caffeine），第2级为堆外缓存（Redis）。   
2. 缓存更新：  
&emsp; active:主动清除，二级缓存过期主动通知各节点清除，优点在于所有节点可以同时收到缓存清除  
&emsp; passive:被动清除，一级缓存过期进行通知各节点清除一二级缓存  

&emsp; redis里面并不会存太多的数据，但是访问量会比较高，所以可能会出现，redis机器内存占用不高，但是带宽满了的情况。而如果要解决这个问题，就需要用redis集群，让请求分散到不同的redis节点，但是这样很明显就需要更多的redis机器，提高了成本。  


&emsp; j2cache还提供了缓存过期、广播等机制，能实现数据过期、本地缓存数据同步等功能。


### 1.1.2. ~~分布式缓存问题~~
1. 对数据的操作：curd。  
2. 缓存预热/新增缓存
3. **查询缓存（缓存穿透、缓存击穿和缓存雪崩）：**  
4. 更新缓存  

#### 1.1.2.1. 查询缓存
1. **查询缓存（缓存穿透、缓存击穿和缓存雪崩）：**  
&emsp; <font color="red">缓存穿透、缓存击穿和缓存雪崩都是缓存失效导致大量请求直接访问数据库而出现的情况。</font>  
&emsp; <font color="red">不同的是缓存穿透是数据库和缓存都不存在相关数据；而缓存击穿和缓存雪崩是缓存和数据库都存在相应数据，</font><font color = "clime">只是缓存失效了而已。</font>  
2. 缓存穿透（数据不存在）：  
&emsp; 缓存穿透是指，请求访问的数据在缓存中没有命中，到数据库中查询也没有，导致此次查询失败；当大量请求针对此类数据时，由于缓存不能命中，请求直接穿透缓存，直击数据库，给数据库造成巨大的访问压力。    
&emsp; 解决方案：空值缓存；`设置布隆过滤器`，若布隆过滤器中无，则直接返回，若存在，则查找缓存redis。  
3. 缓存`击穿`(`热点缓存`/缓存存在)：  
&emsp; 当缓存中不存在但是数据库中存在的数据（`一般来说指缓存失效`），在短时间内针对这种数据产生大量的请求，由于缓存不能命中，直击数据库，给数据库造成较大压力。  
&emsp; **<font color = "clime">解决方案：key永不过期，使用互斥锁或队列，双缓存。</font>**   
&emsp; 互斥锁方案：多个线程同时去查询数据库的这条数据，那么可以在第一个查询数据的请求上使用一个互斥锁来锁住它。其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。单机使用互斥锁，集群使用分布式锁。   
4. 缓存雪崩（数据存在）：  
&emsp; 缓存雪崩是指某一时间段内缓存中数据大批量过期失效，但是查询数据量巨大，引起数据库压力过大甚至宕机。和缓存击穿不同的是，缓存击穿指并发查同一条数据，缓存雪崩是不同数据都过期了，导致大量请求直达数据库。缓存雪崩有两种情况：  
    * 缓存批量过期：缓存批量过期这样的雪崩只是对数据库产生周期性的压力，数据还是扛得住的。解决方案：`key随机值，` **<font color = "clime">key永不过期，使用互斥锁或队列，双缓存。</font>**
    * 缓存服务器宕机：缓存服务器的某个节点宕机或断网，对数据库产生的压力是致命的。解决方案：服务器高可用。  
5. 互斥锁  
&emsp; <font color="red">第三种方法：使用互斥锁，</font> **<font color="clime">抢到锁的线程读数据库并写入缓存，</font>**<font color="red">抢不到线程的话也不阻塞，而是直接去读缓存，如果缓存中依然读不到数据（抢到锁的可能还没有将缓存写入成功），就等一会再试试读缓存。</font>  

```java
public String getCacheData(){
    String result = "";
    //读 Redis
    result = getDataFromRedis();
    if (result.isEmpty()) {
        if (reenLock.tryLock()) {
            try {
                //读数据库
                result = getDataFromDB();
                //写Redis
                setDataToCache(result);
            }catch(Exception e){
                //...
            }finally {
                reenLock.unlock();//释放锁
            }
        } else {
            //抢不到锁的去查询二级缓存
            //读 Redis
            result = getDataFromRedis();
            if (result.isEmpty()) {
                try {
                    Thread.sleep(100);
                } catch (InterruptedException e) {
                    //...
                }
                return getCacheData();
            }
        }
    }
    return result;
}
```

#### 1.1.2.2. 更新缓存 
1. **同时修改数据库和缓存中的数据有四种更新策略：**  

    * 先更新数据库，再更新缓存  
    * 先更新缓存，再更新数据库  
    * 先删除缓存，再更新数据库  
    * 先更新数据库，再删除缓存（推荐）  
2. 「先更新数据库，再删缓存」的策略，原因是这个策略即使在并发读写时，也能最大程度保证数据一致性。  
3. `先更新数据库，再删除缓存，非原子操作。可以采用异步双删延迟策略，进行兜底。` **<font color = "clime">第二次删除前线程休眠冗余的读写时间，如果读从库，再加上延迟时间。</font>**  
    * **<font color = "clime">同步方式会降低吞吐量，可以采用异步。</font>**  
    * **<font color = "clime">第二次删除可能失败，提供一个保障的重试机制。</font>** 方案一：采用消息队列，缺点对业务线代码造成大量的侵入；方案二：订阅binlog，订阅程序提取出所需要的数据以及key，另起一段非业务代码，获得该信息，尝试删除缓存操作，发现删除失败，将这些信息发送至消息队列，重新从消息队列中获得该数据，重试操作。


### 1.1.3. 数据结构：bitMap、布隆、布谷鸟
#### 1.1.3.1. bitMap
&emsp; [BitMap实现签到](/docs/microService/Redis/BitMap.md)  

#### 1.1.3.2. 布隆、计数布隆过滤器
&emsp; BloomFilter是由一个固定大小的二进制向量或者位图(bitmap)和一系列(通常好几个)映射函数组成的。  
1. 布隆过滤器的原理：   
    &emsp; **<font color = "red">当一个变量被加入集合时，通过K个映射函数将这个变量映射成位图中的 K 个点，把它们置为1。</font>**  
    ![image](http://www.wt1814.com/static/view/algorithm/function-2.png)  

    &emsp; 查询某个变量的时候，只要看看这些点是不是都是1，就可以大概率知道集合中有没有它了。  

    * 如果这些点有任何一个0，则被查询变量一定不在；
    * 如果都是1，则被查询变量很可能在。  

    &emsp; 注意，这里是<font color = "clime">可能存在，而不是一定存在！</font>  
2. 布隆过滤器的特点：  
    * 优点：占用内存少，新增、查询效率高。  
    * 缺点： **<font color = "red">误判率和不能删除。</font>**  

            布隆过滤器的误判是指多个输入经过哈希之后在相同的bit位置1了，这样就无法判断究竟是哪个输入产生的，因此误判的根源在于相同的bit位被多次映射且置1。  
            这种情况也造成了布隆过滤器的删除问题，因为布隆过滤器的每一个bit并不是独占的，很有可能多个元素共享了某一位。如果直接删除这一位的话，会影响其他的元素。  

    * 特点总结：  
        * **<font color = "clime">一个元素如果判断结果为存在的时候元素不一定存在（可能存在），但是判断结果为不存在的时候则一定不存在。</font>**  
        * **<font color = "red">布隆过滤器可以添加元素，但是不能删除元素。</font><font color = "clime">因为删掉元素会导致误判率增加。</font>**  

3. 布隆过滤器的使用场景：布隆过滤器适合于一些需要去重，但不一定要完全精确的场景。比如：  
    &emsp; 1. 黑名单 2. URL去重 3. 单词拼写检查 4. Key-Value缓存系统的Key校验 5. ID校验，比如订单系统查询某个订单ID是否存在，如果不存在就直接返回。
3. bitmap和布隆过滤器的区别：  
&emsp; bitmap虽然好用，可是对于不少实际状况下的大数据处理它仍是远远不够的， **<font color = "clime">例如若是要进行64bit的long型数据去重，那咱们须要含有2^61个byte的byte数组来存储，这显然是不现实的。</font>** 那咱们如何来优化呢，很明显假如咱们申请了这么大的byte数组来标记数据，可想而知其空间利用率是极地的。布隆过滤器正是经过`提升空间利用率`来进行标记的。 


#### 1.1.3.3. 布谷鸟
1. 布谷鸟哈希  
&emsp; 谷鸟哈希算法会帮这些受害者（被挤走的蛋）寻找其它的窝。因为每一个元素都可以放在两个位置，只要任意一个有空位置，就可以塞进去。所以这个伤心的被挤走的蛋会看看自己的另一个位置有没有空，如果空了，自己挪过去也就皆大欢喜了。但是如果这个位置也被别人占了呢？好，那么它会再来一次「鸠占鹊巢」，将受害者的角色转嫁给别人。然后这个新的受害者还会重复这个过程直到所有的蛋都找到了自己的巢为止。  
&emsp; 但是会遇到一个问题，那就是如果数组太拥挤了，连续踢来踢去几百次还没有停下来，这时候会严重影响插入效率。这时候布谷鸟哈希会设置一个阈值，当连续占巢行为超出了某个阈值，就认为这个数组已经几乎满了。这时候就需要对它进行扩容，重新放置所有元素。  
2. 布谷鸟算法  
	1. 基本结构  
	&emsp; 哈希表由一个桶数组组成，其中一个桶可以有多个条目（比如上述图c中有四个条目）。而每个桶中有四个指纹位置，意味着一次哈希计算后布谷鸟有四个“巢“可用，而且四个巢是连续位置，可以更好的利用cpu高速缓存。也就是说每个桶的大小是4*8bits。  

#### 1.1.3.4. Redis热点key


## 1.2. Redis
### 1.2.1. Redis数据类型
#### 1.2.1.1. Redis基本数据类型
1. **<font color = "red">小结：</font>** 5大基本数据类型：String、Hash、List（列表）、Set（无序集合，可以用作标签、点赞、签到）、Zset（有序集合，排行榜）。   
1. Key操作命令：expire，为给定key设置生存时间；TTL key，以秒为单位，返回给定key的剩余生存时间（TTL, time to live）。  
2.  **<font color = "clime">Redis各个数据类型的使用场景：分析存储类型和可用的操作。</font>**  
    * 有序列表list：`列表不但是有序的，同时支持按照索引范围获取元素。`  
    &emsp; 可以用作栈、文章列表。  
    * 无序集合set：集合内操作，可以用作标签、点赞、签到；集合间操作，可以用作社交需求； spop/srandmember命令生成随机数。  
    * 有序集合ZSet：有序的集合，每个元素有个 score。  
    &emsp; 可以用作排行榜、延迟队列。  
3. **ZSet实现多维排序：**  
&emsp; <font color = "red">将涉及排序的多个维度的列通过一定的方式转换成一个特殊的列</font>，即result = function(x, y, z)，即x，y，z是三个排序因子，例如下载量、时间等，通过自定义函数function()计算得到result，将result作为ZSet中的score的值，就能实现任意维度的排序需求了。 



#### 1.2.1.2. Redis扩展数据类型
1. <font color = "clime">Bitmap、HyperLogLog都是作为Redis的Value值。`用于统计信息。`</font>  
2. <font color = "clime">Bitmap：二值状态统计。Redis中的Bitmap，key可以为某一天或某一ID，Bitmap中bit可以存储用户的任意信息。所以Redis Bitmap可以用作统计信息。`常用场景：用户签到、统计活跃用户、用户在线状态`。</font>  
&emsp; `BitMap实现签到`：**<font color = "clime">考虑到每月初需要重置连续签到次数，最简单的方式是按用户每月存一条签到数据（也可以每年存一条数据）。`Key的格式为u :sign :uid :yyyyMM`，`Value则采用长度为4个字节（32位）的【位图】（最大月份只有31天）。位图的每一位代表一天的签到，1表示已签，0表示未签。`</font>**  
3. <font color = "clime">HyperLogLog用于基数统计，例如UV（独立访客数）。</font>  
    * 基数统计是指找出集合中不重复元素，用于去重。例如： 统计每个网页的UV(独立访客，每个用户每天只记录一次，需要对每天对浏览去重) 。  
    * 使用Redis统计集合的基数一般有三种方法，分别是使用Redis的Hash，BitMap和HyperLogLog。  
    * HyperLogLog内存空间消耗少，但存在误差0.81%。  
4. Streams消息队列：支持多播的可持久化的消息队列，用于实现发布订阅功能，借鉴了kafka的设计。 
5. [布隆过滤器](/docs/function/otherStructure.md)作为一个插件加载到Redis Server中，就会给Redis提供了强大的布隆去重功能。  


#### 1.2.1.3. redis使用：bigKey


#### 1.2.1.4. ~~Redis底层实现~~
1. 很重要的思想：redis设计比较复杂的对象系统，都是为了缩减内存占有！！！  

##### 1.2.1.4.1. 数据结构
1. 很重要的思想：redis设计比较复杂的对象系统，都是为了缩减内存占用！！！  
2. <font color = "red">目前有8种数据结构：int、raw、embstr(SDS)、ziplist、hashtable、quicklist、intset、skiplist。</font>  
&emsp; **<font color = "clime">Redis数据类型的底层实现如下：</font>**  

|Redis数据结构|底层数据结构|
|---|---|
|String	|int、embstr(即SDS)、raw|
|Hash	|ziplist(压缩列表)或者dictht(字典)|
|List	|quicklist(快速列表，是ziplist压缩列表和linkedlist双端链表的组合)|
|Set	|intset(整数集合)或者dictht(字典)|
|ZSet	|skiplist(跳跃表)或者ziplist(压缩列表)|
  
3. 3种链表：  
    * 双端链表LinkedList  
        &emsp; Redis的链表在双向链表上扩展了头、尾节点、元素数等属性。Redis的链表结构如下：
        ![image](http://182.92.69.8:8081/img/microService/Redis/redis-62.png)  
    * 压缩列表Ziplist  
        &emsp; 在双端链表中，如果在一个链表节点中存储一个小数据，比如一个字节。那么对应的就要保存头节点，前后指针等额外的数据。这样就浪费了空间，同时由于反复申请与释放也容易导致内存碎片化。这样内存的使用效率就太低了。  
        &emsp; Redis设计了压缩列表  
        ![image](http://182.92.69.8:8081/img/microService/Redis/redis-110.png)  
        &emsp; ziplist是一组连续内存块组成的顺序的数据结构， **<font color = "red">是一个经过特殊编码的双向链表，它不存储指向上一个链表节点和指向下一个链表节点的指针，而是存储上一个节点长度和当前节点长度，通过牺牲部分读写性能，来换取高效的内存空间利用率，节省空间，是一种时间换空间的思想。</font>** 只用在字段个数少，字段值小的场景里。  
    * 快速列表Quicklist  
        &emsp; QuickList其实就是结合了ZipList和LinkedList的优点设计出来的。quicklist存储了一个双向链表，每个节点都是一个ziplist。  
        ![image](http://182.92.69.8:8081/img/microService/Redis/redis-63.png)  
4. 整数集合inset  
&emsp; inset的数据结构：  
![image](http://182.92.69.8:8081/img/microService/Redis/redis-7.png)  
&emsp; inset也叫做整数集合，用于保存整数值的数据结构类型，它可以保存int16_t、int32_t 或者int64_t 的整数值。  
&emsp; 在整数集合中，有三个属性值encoding、length、contents[]，分别表示编码方式、整数集合的长度、以及元素内容，length就是记录contents里面的大小。  
5. 跳跃表SkipList  
&emsp; skiplist也叫做「跳跃表」，跳跃表是一种有序的数据结构，它通过每一个节点维持多个指向其它节点的指针，从而达到快速访问的目的。  
![image](http://182.92.69.8:8081/img/microService/Redis/redis-85.png)  
&emsp; SkipList分为两部分，dict部分是由字典实现，Zset部分使用跳跃表实现，从图中可以看出，dict和跳跃表都存储了数据，实际上dict和跳跃表最终使用指针都指向了同一份数据，即数据是被两部分共享的，为了方便表达将同一份数据展示在两个地方。  

##### 1.2.1.4.2. SDS详解
1. **<font color = "clime">对于SDS中的定义在Redis的源码中有的三个属性int len、int free、char buf[]。</font>**  
    ![image](http://182.92.69.8:8081/img/microService/Redis/redis-77.png)  
    * len保存了字符串的长度；
    * free表示buf数组中未使用的字节数量；
    * buf数组则是保存字符串的每一个字符元素。  
2. Redis字符串追加会做以下三个操作：  
    1. 计算出大小是否足够；  
    2. 开辟空间至满足所需大小；  
    3. **<font color = "red">如果len < 1M，开辟与已使用大小len相同长度的空闲free空间；如果len >= 1M，开辟1M长度的空闲free空间。</font>**  
3. **Redis字符串的性能优势：**  
    * 动态扩展：拼接字符串时，计算出大小是否足够，开辟空间至满足所需大小。  
    * 避免缓冲区溢出。「c语言」中两个字符串拼接，若是没有分配足够长度的内存空间就「会出现缓冲区溢出的情况」。  
    * （内存分配优化）降低空间分配次数，提升内存使用效率。 **<font color = "blue">空间预分配和惰性空间回收。</font>** 
        * 空间预分配：对于追加操作来说，Redis不仅会开辟空间至够用，<font color = "red">而且还会预分配未使用的空间(free)来用于下一次操作。</font>  
        * 惰性空间回收：与上面情况相反，<font color = "red">惰性空间回收适用于字符串缩减操作。</font>比如有个字符串s1="hello world"，对s1进行sdstrim(s1," world")操作，<font color = "red">执行完该操作之后Redis不会立即回收减少的部分，而是会分配给下一个需要内存的程序。</font>  
    * 快速获取字符串长度。
    * 二进制安全。

##### 1.2.1.4.3. Dictht
1. **<font color = "red">rehash：</font>**  
&emsp; dictEntry有ht[0]和ht[1]两个对象。  
&emsp; 扩展操作：ht[1]扩展的大小是比当前 ht[0].used 值的二倍大的第一个2的整数幂；收缩操作：ht[0].used 的第一个大于等于的 2 的整数幂。  
&emsp; **<font color = "clime">当ht[0]上的所有的键值对都rehash到ht[1]中，会重新计算所有的数组下标值，当数据迁移完后，ht[0]就会被释放，然后将ht[1]改为ht[0]，并新创建ht[1]，为下一次的扩展和收缩做准备。</font>**  
2. **<font color = "red">渐进式rehash：</font>**  
&emsp; **<font color = "clime">Redis将所有的rehash的操作分成多步进行，直到都rehash完成。</font>**  
&emsp; **<font color = "red">在渐进式rehash的过程「更新、删除、查询会在ht[0]和ht[1]中都进行」，比如更新一个值先更新ht[0]，然后再更新ht[1]。</font>**   
&emsp; **<font color = "clime">而新增操作直接就新增到ht[1]表中，ht[0]不会新增任何的数据，</font><font color = "red">这样保证「ht[0]只减不增，直到最后的某一个时刻变成空表」，这样rehash操作完成。</font>**  


##### 1.2.1.4.4. 数据类型  
&emsp; Redis会根据当前值的类型和长度决定使用哪种内部编码实现。 **<font color = "clime">Redis根据不同的使用场景和内容大小来判断对象使用哪种数据结构，从而优化对象在不同场景下的使用效率和内存占用。</font>**   
![image](http://182.92.69.8:8081/img/microService/Redis/redis-106.png)  

* String字符串类型的内部编码有三种：
    1. int，存储8个字节的长整型(long，2^63-1)。当int数据不再是整数，或大小超过了long的范围(2^63-1=9223372036854775807)时，自动转化为embstr。  
    2. embstr，代表 embstr 格式的 SDS(Simple Dynamic String 简单动态字符串)，存储小于44个字节的字符串。  
    3. raw，存储大于 44 个字节的字符串(3.2 版本之前是 39 字节)。  
* Hash由ziplist(压缩列表)或者dictht(字典)组成；  
* List，「有序」「可重复」集合，由ziplist压缩列表或linkedlist双端链表组成，在 3.2 之后采用QuickList；  
* Set，「无序」「不可重复」集合， **<font color = "clime">是特殊的Hash结构(value为null)，</font>** 由intset(整数集合)或者dictht(字典)组成；
* ZSet，「有序」「不可重复」集合，由skiplist(跳跃表)或者ziplist(压缩列表)组成。  

### 1.2.2. Redis内置功能
#### 1.2.2.1. RedisPipeline/批处理
1. Redis主要提供了以下几种批量操作方式：  
    * 批量get/set(multi get/set)。⚠️注意：Redis中有删除单个Key的指令DEL，但没有批量删除 Key 的指令。  
    * 管道(pipelining)
    * 事务(transaction)
    * 基于事务的管道(transaction in pipelining)
2. 批量get/set(multi get/set)与管道：  
    1. 原生批命令（mset, mget）是原子性，pipeline是非原子性。  
    2. 原生批命令一命令多个key，但pipeline支持多命令（存在事务），非原子性。  
    3. 原生批命令是服务端实现，而pipeline需要服务端与客户端共同完成。  
3. Pipeline指的是管道技术，指的是客户端允许将多个请求依次发给服务器，过程中而不需要等待请求的回复，在最后再一并读取结果即可。  


#### 1.2.2.2. Redis事务
1. **<font color = "clime">Redis事务的三个阶段：</font>**  
    * 开始事务：以MULTI开启一个事务。   
    * **<font color = "clime">命令入队：将多个命令入队到事务中，接到这些命令不会立即执行，而是放到等待执行的事务队列里。</font>**    
    * 执行事务(exec)或取消事务(discard)：由EXEC/DISCARD命令触发事务。  
2. **使用Redis事务的时候，可能会遇上以下两种错误：**  
    1. **<font color = "red">（类似于Java中的编译错误）事务在执行EXEC之前，入队的命令可能会出错。</font>** 比如说，命令可能会产生语法错误(参数数量错误，参数名错误等等)，或者其他更严重的错误，比如内存不足(如果服务器使用maxmemory设置了最大内存限制的话)。  
    2. **<font color = "red">（类似于Java中的运行错误）命令可能在 EXEC 调用之后失败。</font>** 举个例子，事务中的命令可能处理了错误类型的键，比如将列表命令用在了字符串键上面，诸如此类。  

    &emsp; Redis 针对如上两种错误采用了不同的处理策略，对于发生在 EXEC 执行之前的错误，服务器会对命令入队失败的情况进行记录，并在客户端调用 EXEC 命令时，拒绝执行并自动放弃这个事务（Redis 2.6.5 之前的做法是检查命令入队所得的返回值：如果命令入队时返回 QUEUED ，那么入队成功；否则，就是入队失败）  
    &emsp; 对于那些在 EXEC 命令执行之后所产生的错误，并没有对它们进行特别处理：即使事务中有某个/某些命令在执行时产生了错误，事务中的其他命令仍然会继续执行。 
3. **带Watch的事务：**  
&emsp; Redis Watch 命令给事务提供check-and-set (CAS) 机制。被Watch的Key被持续监控，如果key在Exec命令执行前有改变，那么整个事务被取消。   
&emsp; WATCH命令用于在事务开始之前监视任意数量的键：当调用EXEC命令执行事务时，如果任意一个被监视的键已经被其他客户端修改了，那么整个事务将被打断，不再执行，直接返回失败。 

#### 1.2.2.3. Redis和Lua


#### 1.2.2.4. Redis实现消息队列
&emsp; redis中实现消息队列的几种方案：  

* 基于List的 LPUSH+BRPOP 的实现
* PUB/SUB，订阅/发布模式
* 基于Sorted-Set的实现
* 基于Stream类型的实现

#### 1.2.2.5. Redis发布订阅

### 1.2.3. Redis高可用
#### 1.2.3.1. Redis高可用方案
1. **<font color = "clime">考虑资源：</font>**    
&emsp; Redis集群最少6个节点，每个节点20G，总共120G。因此Redis集群比较耗资源。小型公司可以采用哨兵模式。    
2. **<font color = "clime">考虑QPS：</font>**  
&emsp; **单机的redis一般是支持上万甚至几万，具体的性能取决于数据操作的复杂性，如果仅仅是简单的kv操作的话，可以达到数万，如果是运行复杂的lua脚本的话，就可能只能到一万左右。**  
&emsp; 缓存一般是用来支撑读的高并发，一般比较少用来支撑读的操作，一般读的操作是比较频繁的，甚至达到几万几十万，但是写的操作每秒才几千，这就需要读写分离了。  

&emsp; `小型公司，可以采用哨兵，主从复制-单副本模式。`  


#### 1.2.3.2. Redis主从复制
1. **<font color = "red">Redis主从复制架构常见的是`单副本`、双副本模式。</font>**  
2. <font color = "red">主从复制`过程`大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段。</font>  
    1. 连接建立阶段：1. 保存主节点(master)信息。2. 从节点(slave)内部通过每秒运行的定时任务维护复制相关逻辑，当定时任务发现存在新的主节点后，会尝试与该节点建立网络连接。</font>3. 发送ping命令。  
    2. 数据同步阶段：5. 同步数据集。有两种复制方式：全量复制和部分复制。  
    &emsp; redis 2.8之前使用sync [runId] [offset]同步命令，redis2.8之后使用psync [runId] [offset]命令。两者不同在于，sync命令仅支持全量复制过程，psync支持全量和部分复制。    
    3. 命令传播阶段：6. 命令持续复制。  
4. **主从复制`问题`：**
    * **<font color = "red">传输延迟，提供了repl-disable-tcp-nodelay参数用于控制是否关闭TCP_NODELAY，默认关闭。</font>**    
        * `当关闭时，主节点产生的命令数据无论大小都会及时地发送给从节点，这样主从之间延迟会变小，但增加了网络带宽的消耗。` **<font color = "blue">适用于主从之间的网络环境良好的场景，如同机架或同机房部署。</font>** 
        * **<font color = "blue">当开启时，主节点会合并较小的TCP数据包从而节省带宽。</font>** 默认发送时间间隔取决于Linux的内核，一般默认为40毫秒。这种配置节省了带宽但增大主从之间的延迟。 **<font color = "blue">适用于主从网络环境复杂或带宽紧张的场景，如跨机房部署。</font>**  
    * 规避全量复制
        * 节点运行ID不匹配。提供故障转移的功能；如果修改了主节点的配置，需要重启才能够生效，可以选择安全重启的方式(debug reload)。  
        * 复制偏移量offset不在复制积压缓冲区中。需要根据中断时长来调整复制积压缓冲区的大小。  

#### 1.2.3.3. Redis哨兵模式
1. <font color="clime">【监控和自动故障转移】使得Sentinel能够完成主节点【故障发现和自动转移】，配置提供者和通知则是实现通知客户端主节点变更的关键。</font>  
2. <font color = "clime">Redis哨兵架构中主要包括两个部分：Redis Sentinel集群和Redis数据集群。</font>  
3. **<font color = "clime">哨兵原理：</font>**  
    * **<font color = "red">心跳检查：Sentinel通过三个定时任务来完成对各个节点的发现和监控，这是保证Redis高可用的重要机制。</font>**  
        * 每隔10秒，每个Sentinel节点会向主节点和从节点发送`info命令` **<font color = "clime">获取最新的拓扑结构。</font>**   
        * 每隔2秒，每个Sentinel节点会向Redis数据节点的`__sentinel__：hello频道`上发送该Sentinel节点对于主节点的判断以及当前Sentinel节点的信息，同时每个Sentinel节点也会订阅该频道， **<font color = "clime">了解其他Sentinel节点以及它们对主节点的判断。</font>**  
        * 每隔1秒，每个Sentinel节点会向主节点、从节点、其余Sentinel节点发送一条`ping命令` **<font color = "clime">做一次心跳检测。</font>**  
    * **<font color = "red">主观下线和客观下线：</font>** 首先单个Sentinel节点认为数据节点主观下线，询问其他Sentinel节点，Sentinel多数节点认为主节点存在问题，这时该 Sentinel节点会对主节点做客观下线的决定。
    * **<font color = "red">故障转移/主节点选举：</font>** Sentinel节点的领导者根据策略在从节点中选择主节点。    
    * **<font color = "red">Sentinel选举：</font>** Sentinel集群是集中式架构，基于raft算法。  

#### 1.2.3.4. Redis读写分离
&emsp; 读写分离是一种使用方式，可以基于主从复制、哨兵模式实现。  

#### 1.2.3.5. Redis集群模式
1. **<font color = "red">根据执行分片的位置，可以分为三种分片方式：</font>** 客户端分片、代理分片、服务器分片：官方Redis Cluster。  
2. **<font color = "clime">Redis集群的服务端：</font>**  
    * 数据分布
        * Redis数据分区
        * 集群限制
            1. <font color = "red">key批量操作支持有限。</font>如mset、mget，目前只支持具有相同slot值的key执行批量操作。对于映射为不同slot值的key由于执行mset、mget等操作可能存在于多个节点上因此不被支持。   
            2. key事务操作支持有限。同理只支持多key在同一节点上的事务操作，当多个key分布在不同的节点上时无法使用事务功能。     
            5. 复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。  
    * 故障转移：
        * 故障发现：主观下线(pfail)和客观下线(fail)。  
        * 故障恢复：当从节点通过内部定时任务发现自身复制的主节点进入客观下线；从节点发起选举；其余主节点选举投票。  
3. **<font color = "clime">Redis集群的客户端：</font>**  
&emsp; Redis集群对客户端通信协议做了比较大的修改，为了追求性能最大化，并没有采用代理的方式，而是采用客户端直连节点的方式。    
    * 请求重定向：在集群模式下，Redis接收任何键相关命令时首先计算键对应的槽，再根据槽找出所对应的节点，如果节点是自身，则处理键命令；否则回复MOVED重定向错误，通知客户端请求正确的节点。这个过程称为MOVED重定向。  
    * ASK重定向：Redis集群支持在线迁移槽(slot)和数据来完成水平伸缩，当slot对应的数据从源节点到目标节点迁移过程中，客户端需要做到智能识别，保证键命令可正常执行。例如当一个slot数据从源节点迁移到目标节点时，期间可能出现一部分数据在源节点，而另一部分在目标节点。  
        1. 客户端根据本地slots缓存发送命令到源节点，如果存在键对象则直接执行并返回结果给客户端。  
        2. **<font color = "clime">如果键对象不存在，则可能存在于目标节点，这时源节点会回复ASK重定向异常。格式如下：(error)ASK{slot}{targetIP}：{targetPort}。</font>**   
        3. 客户端从ASK重定向异常提取出目标节点信息，发送asking命令到目标节点打开客户端连接标识，再执行键命令。如果存在则执行，不存在则返回不存在信息。   

    &emsp; **<font color = "clime">ASK与MOVED虽然都是对客户端的重定向控制，但是有着本质区别。ASK重定向说明集群正在进行slot数据迁移，客户端无法知道什么时候迁移完成，因此只能是临时性的重定向，客户端不会更新slots缓存。但是MOVED重定向说明键对应的槽已经明确指定到新的节点，因此需要更新slots缓存。</font>**  


### 1.2.4. Redis原理
&emsp; 从`内存、磁盘、网络IO、CPU`分析。  
&emsp; Redis的性能非常之高，每秒可以承受10W+的QPS，它如此优秀的性能主要取决于以下几个方面：  
1. 内存  
    * [Redis虚拟内存机制](/docs/microService/Redis/RedisVM.md)  
    * [Redis内存淘汰](/docs/microService/Redis/RedisEliminate.md)    
    * [Redis过期键删除](/docs/microService/Redis/Keydel.md)  
2. 磁盘I/O：  
    * 合理的数据编码  
    * [Redis持久化](/docs/microService/Redis/RedisPersistence.md)  
        * [AOF重写阻塞](/docs/microService/Redis/Rewrite.md)  
3. 网络I/O：  
    * [使用IO多路复用技术](/docs/microService/Redis/RedisEvent.md) 
    * [Redis事件/Reactor](/docs/microService/Redis/RedisEvent.md)   
    * [Redis多线程模型](/docs/microService/Redis/RedisMultiThread.md)   
    * [简单快速的Redis协议](/docs/microService/Redis/RESP.md)  
4. ......

#### 1.2.4.1. 内存 
##### 1.2.4.1.1. Redis过期键删除
1. 过期键常见的删除策略有3种：定时删除(主动)、惰性删除(被动)、定期删除(主动)。<font color = "red">Redis服务器使用的是惰性删除策略和定期删除策略。</font>  
    * 定时删除策略，在设置键的过期时间的同时，创建一个定时器，让定时器在键的过期时间来临时，立即执行对键的删除操作。  
    * <font color = "clime">惰性删除策略，只有当访问一个key时，才会判断该key是否已过期，过期则清除。</font>  
    * <font color = "red">`定期删除策略，每隔一段时间执行一次删除过期键操作`</font>，并通过<font color = "clime">`限制删除操作执行的时长和频率来减少删除操作对CPU时间的影响`</font>，同时，通过定期删除过期键，也有效地减少了因为过期键而带来的内存浪费。  


##### 1.2.4.1.2. Redis内存淘汰
1. **Redis内存淘汰使用的算法有4种：**  
    * random，随机删除。  
    * TTL，删除过期时间最少的键。  
    * <font color = "clime">LRU，Least Recently Used：最近最少使用（访问时间）。</font>判断最近被使用的时间，离目前最远的数据优先被淘汰。  
    &emsp; **<font color = "red">`如果基于传统LRU算法实现，Redis LRU会有什么问题？需要额外的数据结构存储，消耗内存。`</font>**  
    &emsp; **<font color = "blue">Redis LRU对传统的LRU算法进行了改良，通过`随机采样`来调整算法的精度。</font>** 如果淘汰策略是LRU，则根据配置的采样值maxmemory_samples(默认是 5 个)，随机从数据库中选择m个key，淘汰其中热度最低的key对应的缓存数据。所以采样参数m配置的数值越大，就越能精确的查找到待淘汰的缓存数据，但是也消耗更多的CPU计算，执行效率降低。  
    * <font color = "clime">LFU，Least Frequently Used，最不常用（`访问频率`），4.0版本新增。</font>  
2. **~~内存淘汰策略选择：~~**  
&emsp; **<font color = "clime">volatile和allkeys规定了是对已设置过期时间的key淘汰数据还是从全部key淘汰数据。volatile-xxx策略只会针对带过期时间的key进行淘汰，allkeys-xxx策略会对所有的key进行淘汰。</font>**  
    * 如果只是拿Redis做缓存，那应该使用allkeys-xxx，客户端写缓存时不必携带过期时间。  
    * `如果还想同时使用Redis的持久化功能，那就使用volatile-xxx策略，这样可以保留没有设置过期时间的key，它们是永久的key不会被LRU算法淘汰。`  

    1. 如果数据呈现幂律分布，也就是一部分数据访问频率高，一部分数据访问频率低，或者无法预测数据的使用频率时，则使用allkeys-lru/allkeys-lfu。  
    2. 如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random。
    3. 如果研发者需要通过设置不同的ttl来判断数据过期的先后顺序，此时可以选择volatile-ttl策略。
    4. `如果希望一些数据能长期被保存，而一些数据可以被淘汰掉，选择volatile-lru/volatile-lfu或volatile-random都是比较不错的。`
    5. 由于设置expire会消耗额外的内存，如果计划避免Redis内存在此项上的浪费，可以选用allkeys-lru/volatile-lfu策略，这样就可以不再设置过期时间，高效利用内存了。 


##### 1.2.4.1.3. Redis【虚拟内存】机制
&emsp; **<font color = "clime">通过VM功能可以实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘。这样就可以避免因为内存不足而造成访问速度下降的问题。</font>**  
&emsp; 使用虚拟内存把那些不经常访问的数据交换到磁盘上。需要特别注意的是Redis并没有使用OS提供的Swap，而是自己实现。  
&emsp; **<font color = "clime">Redis为了保证查找的速度，只会将value交换出去，而在内存中保留所有的Key。</font>**  


#### 1.2.4.2. 磁盘
##### 1.2.4.2.1. Redis持久化，磁盘操作
1. RDB，快照；保存某一时刻的全部数据；缺点是间隔长（配置文件中默认最少60s）。  
&emsp; Redis 提供了两个命令来生成 RDB 快照文件，分别是 save 和 bgsave。save 命令在主线程中执行，会导致阻塞。而 bgsave 命令则会创建一个子进程，用于写入 RDB 文件的操作，避免了对主线程的阻塞，这也是 Redis RDB 的默认配置。fork子进程也会造成阻塞。    
2. AOF，文件追加；记录所有操作命令；优点是默认间隔1s，丢失数据少；缺点是文件比较大，通过重写机制来压缩文件体积。  
    1. `AOF采用的是【写后日志】的方式`，Redis先执行命令把数据写入内存，然后再记录日志到文件中。AOF日志记录的是操作命令，不是实际的数据，如果采用AOF方法做故障恢复时需要将全量日志都执行一遍。  
        ![image](http://182.92.69.8:8081/img/microService/Redis/redis-121.png)  

        &emsp; `平时用的MySQL则采用的是 “写前日志”，`那 Redis为什么要先执行命令，再把数据写入日志呢？  

        &emsp; 这个主要是由于Redis在写入日志之前，不对命令进行语法检查，所以只记录执行成功的命令，避免出现记录错误命令的情况，而且在命令执行后再写日志不会阻塞当前的写操作。  

        &emsp; 后写日志主要有两个风险可能会发生：  

        * 数据可能会丢失：如果 Redis 刚执行完命令，此时发生故障宕机，会导致这条命令存在丢失的风险。  
        * 可能阻塞其他操作：AOF 日志其实也是在主线程中执行，所以当 Redis 把日志文件写入磁盘的时候，还是会阻塞后续的操作无法执行。
    1. **<font color = "clime">重写后的AOF文件为什么可以变小？有如下原因：</font>**  
        1. <font color = "red">进程内已经超时的数据不再写入文件。</font>   
        2. <font color = "red">旧的AOF文件含有无效命令，</font>如del key1、hdel key2、srem keys、set a111、set a222等。重写使用进程内数据直接生成，这样新的AOF文件只保留最终数据的写入命令。  
        3. <font color = "red">多条写命令可以合并为一个，</font>如：lpush list a、lpush list b、lpush list c可以转化为：lpush list a b c。为了防止单条命令过大造成客户端缓冲区溢出，对于list、set、hash、zset等类型操作，以64个元素为界拆分为多条。  
    2. **<font color = "red">AOF重写降低了文件占用空间，除此之外，另一个目的是：更小的AOF 文件可以更快地被Redis加载。</font>**  
    3. 在写入AOF日志文件时，如果Redis服务器宕机，则AOF日志文件文件会出格式错误。在重启Redis服务器时，Redis服务器会拒绝载入这个AOF文件，可以修复AOF 并恢复数据。 
3. Redis4.0混合持久化，先RDB，后AOF。  
4. ~~**<font color = "clime">RDB方式bgsave指令中fork子进程、AOF方式重写bgrewriteaof都会造成阻塞。</font>**~~  

##### 1.2.4.2.2. ~~AOF重写阻塞~~
1. AOF重写阻塞：
    1. **<font color = "clime">当Redis执行完一个写命令之后，它会`同时将这个写命令发送给AOF缓冲区和AOF重写缓冲区`。</font>**  
	2. **<font color = "clime">当子进程完成AOF重写工作之后，它会向父进程发送一个信号，父进程在接收到该信号之后，`会调用一个信号处理函数，并执行相应工作：将AOF重写缓冲区中的所有内容写入到新的AOF文件中。`</font>**  
	3. **<font color = "clime">在整个AOF后台重写过程中，`只有信号处理函数执行时会对Redis主进程造成阻塞，`在其他时候，AOF后台重写都不会阻塞主进程。</font>** 如果信号处理函数执行时间较长，即造成AOF阻塞时间长，就会对性能有影响。  
2. 解决方案：  
	* **<font color = "red">将no-appendfsync-on-rewrite设置为yes。</font>** 
	* master节点关闭AOF。  
    
    &emsp; 可以采取比较折中的方式：  
    * 在master节点设置将no-appendfsync-on-rewrite设置为yes（`表示在日志重写时，不进行命令追加操作，而只是将命令放在重写缓冲区里，避免与命令的追加造成磁盘IO上的冲突`），同时auto-aof-rewrite-percentage参数设置为0关闭主动重写。  
    * 在重写时为了避免硬盘空间不足或者IO使用率高影响重写功能，还添加了硬盘空间报警和IO使用率报警保障重写的正常进行。
4. 虽然在everysec配置下aof的fsync是由子线程进行操作的，但是主线程会监控fsync的执行进度。  
&emsp; **<font color = "clime">主线程在执行时候如果发现上一次的fsync操作还没有返回，那么主线程就会阻塞。</font>**  

#### 1.2.4.3. 网络
##### 1.2.4.3.1. Redis事件/Reactor（IO多路复用）
&emsp; 参考[Redis事件/Reactor](/docs/microService/Redis/RedisEvent.md)  
&emsp; Redis基于Reactor模式开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）：文件事件处理器使用I/O多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。  
&emsp; 下图展示了文件事件处理器的四个组成部分，它们分别是套接字、I/O多路复用程序、文件事件分派器（dispatcher），以及事件处理器。  
![image](http://182.92.69.8:8081/img/microService/Redis/redis-56.png)    

##### 1.2.4.3.2. Redis多线程模型
1. 为什么Redis一开始使用单线程？  
&emsp; 基于内存而且使用多路复用技术，单线程速度很快，又保证了多线程的特点。因此没有必要使用多线程。  
2. 为什么引入多线程？  
&emsp; **<font color = "clime">因为读写网络的read/write系统调用（网络I/O）在Redis执行期间占用了大部分CPU时间，如果把网络读写做成多线程的方式对性能会有很大提升。</font>**  
&emsp; **<font color = "clime">Redis的多线程部分只是用来处理网络数据的读写和协议解析，执行命令仍然是单线程。</font>** 
3. 官方建议：4核的机器建议设置为2或3个线程，8核的建议设置为6个线程， **<font color = "clime">`线程数一定要小于机器核数，尽量不超过8个。`</font>**   

##### 1.2.4.3.3. Redis协议
&emsp; RESP是Redis Serialization Protocol的简称，也就是专门为redis设计的一套序列化协议。这个协议其实在redis的1.2版本时就已经出现了，但是到了redis2.0才最终成为redis通讯协议的标准。  
&emsp; 这个序列化协议听起来很高大上， 但实际上就是一个文本协议。根据官方的说法，这个协议是基于以下几点(而妥协)设计的：  
1. 实现简单。可以减低客户端出现bug的机率。  
2. `解析速度快。`由于RESP能知道返回数据的固定长度，所以不用像json那样扫描整个payload去解析，所以它的性能是能跟解析二进制数据的性能相媲美的。  
3. 可读性好。  


### 1.2.5. Redis常见问题与优化



## 1.3. 分布式消息队列
### 1.3.1. MQ常见面试题
1. 为什么使用mq？/应用场景   
    * 优点：解耦（调用多个系统，非同步调用）、异步、削锋（削qps）  
    * 日志处理：将消息队列用在日志处理中，比如 Kafka 的应用，解决大量日志传输的问题。  
    * 消息通讯：消息队列一般都内置了高效的通信机制，因此也可以用在纯消息通讯，比如实现聊天室等。  
    * 消息广播：如果没有消息队列，每当一个新业务方接入，都要接入一次新接口。有了消息队列，只需要关心消息是否送达了队列，至于谁订阅，是下游的事，无疑极大地减少了开发和联调的工作量。  
2. 消息队列选型  
    * RabbitMQ  
    * Kafka， 一开始的目的就是用于日志收集和传输，适合有大量数据产生的互联网业务，特别是大数据领域的实时计算、日志采集等场景，用 Kafka 绝对没错，社区活跃度高，业内标准。  
    * RocketMQ，特别适用于金融互联网领域这类对于可靠性要求很高的场景，比如订单交易等，而且 RocketMQ 是阿里出品的，经历过那么多次淘宝双十一的考验，大品牌，在稳定性值得信赖。但如果阿里不再维护这个技术了，社区有可能突然黄掉的风险。因此如果公司对自己的技术实力有自信，基础架构研发实力较强，推荐用 RocketMQ。 
3. 消息队列使用事项  
    1. 架构  
        1. 保障高可用  
    2. 生产者  
        1. 消息队列丢失消息有3种情况：生产者丢失数据、mq客户端丢失数据、消费者丢失数据。提供两种方案解决。    
    3. 消费者  
        1. 重复消费  
            消费接口幂等性。  
        2. 顺序消费  
            发送到单个queue或partition，单线程消费。  
        3. **<font color = "red">~~消息积压~~</font>**  
            `修复消费者问题` ---> ~~将原topic下的消息迁移到一个新的扩容的topic下（分区/队列扩容）~~ ---> 扩容消费者  

### 1.3.2. Kafka
#### 1.3.2.1. kafka基本概念
&emsp; Apache Kafka是一个分布式流处理平台。支持百万级TPS。    

##### 1.3.2.1.1. kafka生产者
1. Producer发送消息的过程：需要经过拦截器，序列化器和分区器，最终由累加器批量发送至Broker。  
&emsp; Kafka分区策略查看[消息分区](/docs/microService/mq/kafka/topic.md)。  
2. **<font color = "clime">如何提升Producer的性能？异步，批量，压缩。</font>**  
3. 多线程处理：  
&emsp; 多线程单KafkaProducer实例（可以理解为单例模式）、多线程多KafkaProducer实例（可以理解为多例，原型模式）。  
&emsp; **<font color = "clime">如果是对分区数不多的Kafka集群而言，比较推荐使用第一种方法，即在多个producer用户线程中共享一个KafkaProducer实例。若是对那些拥有超多分区的集群而言，釆用第二种方法具有较高的可控性，方便producer的后续管理。</font>**   

##### 1.3.2.1.2. 消息分区
1. 分区说明  
&emsp; 分区（Partition）的作用就是提供负载均衡的能力，单个topic的不同分区可存储在相同或不同节点机上，为实现系统的高伸缩性（Scalability），`不同的分区被放置到不同节点的机器上，`各节点机独立地执行各自分区的读写任务，如果性能不足，可通过添加新的节点机器来增加整体系统的吞吐量。  
2. 服务端物理分区分配
    1. ★★★分区策略  
    在所有broker上均匀地分配分区副本； **<font color = " red">确保分区的每个副本分布在不同的broker上。</font>**  
    2. ~~分区存储数据~~
3. 客户端怎么分区？
    1. 生产者
        1. 分区策略  
        &emsp; 如果没有指定分区，但是 `消息的key不为空，则基于key的哈希值来选择一个分区；`  
        &emsp; 如果既没有指定分区，且 `消息的key也是空，则用轮询的方式选择一个分区。`
    2. 消费者  
        1. 消费者`分组消费`。同一时刻，`一条消息只能被组中的一个消费者实例消费。`  
        2. 消费者消费分区策略
            1. 轮询。  
            2. range策略。 
4. 分区数设置
5. 分区后保持有序，查看顺序消费。    

##### 1.3.2.1.3. kafka消费者
1. 消费者/消费者组/消费者组重平衡  
    1. `消费者组：Kafka消费端确保一个Partition在一个消费者组内只能被一个消费者消费。`  
    2. **<font color = "red">消费者组重平衡：</font>**  
    &emsp; **什么是重平衡？ 假设组内某个实例挂掉了，Kafka能够自动检测到，然后把这个`Failed实例之前负责的分区转移给其他活着的消费者`，这个过程称之为重平衡(Rebalance)。**  
    &emsp; 重平衡触发条件：组成员发生变更、组订阅topic数发生变更、组订阅topic的分区数发生变更。
    3.  **重平衡流程：**  
    &emsp; 引入协调者（每一台Broker上都有一个协调者组件），由协调者为消费组服务，为消费者们做好协调工作。一个消费组只需一个协调者进行服务。  
    &emsp; 1. 当消费者收到协调者的再均衡开始通知时，需要立即提交偏移量；  
    &emsp; **2. 消费者在收到提交偏移量成功的响应后，再发送JoinGroup请求，重新申请加入组，请求中会含有订阅的主题信息；**  
    &emsp; **<font color = "red">3. 当协调者收到第一个JoinGroup请求时，会把发出请求的消费者指定为Leader消费者，</font>**  
    &emsp; **<font color = "red">4. Leader消费者收到JoinGroup响应后，根据消费者的订阅信息制定分配方案，把方案放在SyncGroup请求中，发送给协调者。</font>**  
    &emsp; **<font color = "red">5. 协调者收到分配方案后，再通过SyncGroup响应把分配方案发给所有消费组。</font>**  
    4. **如何避免重平衡？**  
    &emsp; **<font color = "clime">其实只需要避免实例减少的情况就行了。</font>** ~~消费时间过长~~  
2. 消费者位移管理  
    &emsp; **<font color = "red">位移提交有两种方式：</font><font color = "clime">自动提交、手动提交。</font>**  
3. 怎样消费  
    * 消费者分区分配策略：轮询RoundRobin、range策略。
    * 消费语义：至少一次、至多一次、正好一次。

##### 1.3.2.1.4. kafka服务端


#### 1.3.2.2. kafka特性
* 高并发：支持百万级TPS。    
    * 高性能：磁盘I/O-顺序读写、基于Sendfile实现零拷贝。  
    * 高可用：Kafka副本机制。  
* 分布式：  
    * 可靠性：副本的一致性保证、可以保证消息队列不丢失、幂等（重复消费）和事务。  
    * 如何让Kafka的消息有序？  

##### 1.3.2.2.1. 【高性能】-内存
&emsp; 为了优化读写性能，Kafka利用了操作系统本身的Page Cache，就是利用操作系统自身的内存而不是JVM空间内存。这样做的好处有：  

* 避免Object消耗：如果是使用 Java 堆，Java对象的内存消耗比较大，通常是所存储数据的两倍甚至更多。
* 避免GC问题：随着JVM中数据不断增多，垃圾回收将会变得复杂与缓慢，使用系统缓存就不会存在GC问题

&emsp; 相比于使用JVM或in-memory cache等数据结构，利用操作系统的Page Cache更加简单可靠。

##### 1.3.2.2.2. 【高性能】-持久化/磁盘IO-顺序读写


##### 1.3.2.2.3. 【高性能】-网络IO零拷贝



##### 1.3.2.2.4. 【高可用】-副本机制
1. **<font color = "blue">`Kafka副本中只有Leader可以和客户端交互，进行读写，`其他副本是只能同步，不能分担读写压力。</font>**  
2. 服务端Leader的选举：从ISR（保持同步的副本）集合副本中选取。  
3. 服务端副本消息的同步：  
&emsp; LEO，低水位，记录了日志的下一条消息偏移量，即当前最新消息的偏移量加一；HW，高水位，界定了消费者可见的消息，是ISR队列中最小的LEO。  
    1. Follower副本更新LEO和HW：  
    &emsp; 更新LEO和HW的时机： **<font color = "clime">Follower向Leader拉取了消息之后。(⚠️注意：Follower副本只和Leader副本交互。)</font>**  
    &emsp; **<font color = "red">会用获取的偏移量加1来更新LEO，并且用Leader的HW值和当前LEO的最小值来更新HW。</font>**  
    2. Leader副本上LEO和HW的更新：  
        * 正常情况下Leader副本的更新时机有两个：一、收到生产者的消息；二、被Follower拉取消息。(⚠️注意：Leader副本即和Follower副本交互，也和生产者交互。)  
            * 当收到生产者消息时，会用当前偏移量加1来更新LEO，然后取LEO和远程ISR副本中LEO的最小值更新HW。 
            * 当Follower拉取消息时，会更新Leader上存储的Follower副本LEO，然后判断是否需要更新HW，更新的方式和上述相同。 
        * 除了这两种正常情况，当发生故障时，例如Leader宕机，Follower被选为新的Leader，会尝试更新HW。还有副本被踢出ISR时，也会尝试更新HW。 
4. 在服务端Leader切换时，会存在数据丢失和数据不一致的问题。  
    1. 主从切换，数据不一致的情况如下：  
    &emsp; A作为Leader，A已写入m0、m1两条消息，且HW为2，而B作为Follower，只有m0消息，且HW为1。若A、B同时宕机，且B重启时，A还未恢复，则B被选为Leader。  
    &emsp; 在B重启作为Leader之后，收到消息m2。A宕机重启后向成为Leader的B发送Fetch请求，发现自己的HW和B的HW一致，都是2，因此不会进行消息截断，而这也造成了数据不一致。  
    2. 引入Leader Epoch机制：  
    &emsp; **<font color = "blue">为了解决HW可能造成的数据丢失和数据不一致问题，Kafka引入了Leader Epoch机制。</font>** 在每个副本日志目录下都有一个leader-epoch-checkpoint文件，用于保存Leader Epoch信息。  
    &emsp; Leader Epoch，分为两部分，前者Epoch，表示Leader版本号，是一个单调递增的正整数，每当Leader变更时，都会加1；`后者StartOffset，为每一代Leader写入的第一条消息的位移。`   
5. 客户端数据请求：  
&emsp; 集群中的每个broker都会缓存所有主题的分区副本信息，客户端会定期发送元数据请求，然后将获取的集群元数据信息进行缓存。  

##### 1.3.2.2.5. 【高一致】-消息丢失（可靠性传输）
1. 在Producer端、Broker端、Consumer端都有可能丢失消息。  
2. Producer端：  
&emsp; 为防止Producer端丢失消息， **<font color = "red">除了将ack设置为all，表明所有副本 Broker 都要接收到消息，才算“已提交”。</font>**  
&emsp; `还可以使用带有回调通知的发送API，即producer.send(msg, callback)`。  
3. Broker端:  
&emsp; Kafka没有提供同步刷盘的方式。要完全让kafka保证单个broker不丢失消息是做不到的，只能通过调整刷盘机制的参数缓解该情况。  
&emsp; 为了解决该问题，kafka通过producer和broker协同处理单个broker丢失参数的情况。 **<font color = "red">`一旦producer发现broker消息丢失，即可自动进行retry。`</font>** 除非retry次数超过阀值（可配置），消息才会丢失。此时需要生产者客户端手动处理该情况。  
4. ~~Consumer端：~~  
&emsp; 采用手动提交位移。  
5. `方案二：使用补偿机制`  
&emsp; 服务端丢失消息处理：建立消息表，发送消息前保存表记录，发送后更新表记录。  
&emsp; 客户端丢失消息处理：服务端提供查询接口。 


##### 1.3.2.2.6. 【高一致】-分区保持顺序（顺序消费）
1. Apache Kafka官方保证了partition内部的数据有效性（追加写、offset读）。为了提高Topic的并发吞吐能力，可以提高Topic的partition数，并通过设置partition的replica来保证数据高可靠。但是在多个Partition时，不能保证Topic级别的数据有序性。  
2. 顺序消费
    1. 前提：[消息分区](/docs/microService/mq/kafka/topic.md)  
    2. 针对消息有序的业务需求，还分为全局有序和局部有序：  
        * 全局有序：一个Topic下的所有消息都需要按照生产顺序消费。
        * 局部有序：一个Topic下的消息，只需要满足同一业务字段的要按照生产顺序消费。例如：Topic消息是订单的流水表，包含订单orderId，业务要求同一个orderId的消息需要按照生产顺序进行消费。
3. 全局有序：  
&emsp; 一个生产者、一个分区、一个消费者（或使用分布式锁），并严格到一个消费线程。   
4. 局部有序：    
&emsp; 多分区时，要满足局部有序，只需要在发消息的时候指定Partition Key，Kafka对其进行Hash计算，根据计算结果决定放入哪个Partition。这样Partition Key相同的消息会放在同一个Partition。此时，Partition的数量仍然可以设置多个，提升Topic的整体吞吐量。   
5. ~~注意事项：~~  
    1. 消息重试对顺序消息，无影响。   
    2. 分区/队列变更导致非顺序问题如何处理？  
    
6. `业务上实现有序消费（***着重看看）`  
    &emsp; 除了消息队列自身的顺序消费机制，可以合理地对消息进行改造，从业务上实现有序的目的。具体的方式有以下几种。  

    1. 根据不同的业务场景，以发送端或者消费端时间戳为准  
    &emsp; 比如在电商大促的秒杀场景中，如果要对秒杀的请求进行排队，就可以使用秒杀提交时服务端的时间戳，虽然服务端不一定保证时钟一致，但是在这个场景下，不需要保证绝对的有序。  
    2. 每次消息发送时生成唯一递增的 ID  
    &emsp; 在每次写入消息时，可以考虑添加一个单调递增的序列 ID，在消费端进行消费时，缓存最大的序列 ID，只消费超过当前最大的序列 ID 的消息。这个方案和分布式算法中的 Paxos 很像，虽然无法实现绝对的有序，但是可以保证每次只处理最新的数据，避免一些业务上的不一致问题。  
    3. 通过缓存时间戳的方式  
    &emsp; 这种方式的机制和递增 ID 是一致的，即当生产者在发送消息时，添加一个时间戳，消费端在处理消息时，通过缓存时间戳的方式，判断消息产生的时间是否最新，如果不是则丢弃，否则执行下一步。  



##### 1.3.2.2.7. 【高一致】-kafka幂等性（重复消费） 
1. **幂等又称为exactly once（精确传递一次。消息被处理且只会被处理一次。不丢失不重复就一次）。**  
&emsp; `Kafka幂等是针对生产者角度的特性。`kafka只保证producer单个会话中的单个分区幂等。  
2. **<font color = "red">Kafka`生产者幂等性`实现机制：（`producer_id和序列号，进行比较`）</font>**  
    1. `每一个producer在初始化时会生成一个producer_id，并为每个目标partition维护一个"序列号"；`
    2. producer每发送一条消息，会将 \<producer_id,分区\> 对应的“序列号”加1；  
    3. broker端会为每一对 \<producer_id,分区\> 维护一个序列号，对于每收到的一条消息，会判断服务端的SN_old和接收到的消息中的SN_new进行对比：  

        * 如果SN_old < SN_new+1，说明是重复写入的数据，直接丢弃。    
        * 如果SN_old > SN_new+1，说明中间有数据尚未写入，或者是发生了乱序，或者是数据丢失，将抛出严重异常：OutOfOrderSeqenceException。 
3. Kafka`消费者幂等性`（kafka怎样保证消息仅被消费一次？）  
    &emsp; 在使用kafka时，大多数场景对于数据少量的不一致(重复或者丢失)并不关注，比如日志，因为不会影响最终的使用或者分析，但是在某些应用场景(比如业务数据)，需要对任何一条消息都要做到精确一次的消费，才能保证系统的正确性，`kafka并不提供准确一致的消费API，需要在实际使用时借用外部的一些手段来保证消费的精确性。`    
    &emsp; 当消费者消费到了重复的数据的时候，消费者需要去过滤这部分的数据。主要有以下两种思路：  
    1. 将消息的offset存在消费者应用中或者第三方存储的地方  
    &emsp; 可以将这个数据存放在redis或者是内存中，消费消息时，如果有这条数据的话，就不会去做后续操作  
    2. 数据落库的时候，根据主键去过滤  
    &emsp; 在落库时，如果不不在这条数据，则去新增，如果存在则去修改  

##### 1.3.2.2.8. 【高一致】-kafka事务 


##### 1.3.2.2.9. 【高一致】-~~消息积压~~
&emsp; 一般这种比较着急的问题，最好的办法就是临时扩容，用更快的速度来消费数据  

1. 临时建立一个新的Topic，然后调整queue的数量为原来的10倍或者20倍，根据堆积情况来决定。  
2. 然后写一个临时分发消息的consumer程序，这个程序部署上去消费积压的消息，消费的就是刚刚新建的Topic，消费之后不做耗时的处理，只需要直接均匀的轮询将这些消息轮询的写入到临时创建的queue里面即可。  
3. 然后增加相应倍数的机器来部署真正的consumer消费，注意这里的Topic，然后让这些consumer去真正的消费这些临时的queue里面的消息。  


