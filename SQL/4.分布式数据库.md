---
title: 分布式数据库
date: 2020-02-27 00:00:00
tags:
    - SQL
---
<!-- TOC -->

- [1. 数据库瓶颈](#1-数据库瓶颈)
- [2. 主从复制、读写分离](#2-主从复制读写分离)
    - [2.1. 主从复制拓扑结构](#21-主从复制拓扑结构)
    - [2.2. MySql主从复制原理](#22-mysql主从复制原理)
        - [2.2.1. 复制流程：](#221-复制流程)
        - [2.2.2. 复制方式：](#222-复制方式)
            - [2.2.2.1. 基于语句的复制](#2221-基于语句的复制)
            - [2.2.2.2. 基于行的复制：](#2222-基于行的复制)
            - [2.2.2.3. 混合模式复制：](#2223-混合模式复制)
- [3. 读写分离](#3-读写分离)
    - [3.1. 主从复制、读写分离带来的问题](#31-主从复制读写分离带来的问题)
- [4. 分区](#4-分区)
    - [4.1. 什么是分区：](#41-什么是分区)
    - [4.2. 怎么分区：](#42-怎么分区)
        - [4.2.1. 分区键：](#421-分区键)
        - [4.2.2. 分区路由（MySql分区类型）：](#422-分区路由mysql分区类型)
    - [4.3. 管理分区（增、删分区）：](#43-管理分区增删分区)
    - [4.4. 分区表使用](#44-分区表使用)
- [5. 分库/分片、分表](#5-分库分片分表)
    - [5.1. 数据切分方式](#51-数据切分方式)
        - [5.1.1. 垂直（纵向）切分](#511-垂直纵向切分)
        - [5.1.2. 水平（横向）切分](#512-水平横向切分)
    - [5.2. 分库分表方案（路由算法）：](#52-分库分表方案路由算法)
    - [5.3. ~~分库分表带来的分布式困境与解决方案~~](#53-分库分表带来的分布式困境与解决方案)
        - [5.3.1. 分库数量：](#531-分库数量)
        - [5.3.2. ID问题](#532-id问题)
        - [5.3.3. 基本的数据库增删改功能](#533-基本的数据库增删改功能)
        - [5.3.4. 查询功能](#534-查询功能)
            - [5.3.4.1. 跨节点的order by、group by以及count等聚合函数问题](#5341-跨节点的order-bygroup-by以及count等聚合函数问题)
            - [5.3.4.2. 跨分片的排序分页](#5342-跨分片的排序分页)
            - [5.3.4.3. 非partition key的查询问题](#5343-非partition-key的查询问题)
            - [5.3.4.4. 跨节点Join的问题](#5344-跨节点join的问题)
            - [5.3.4.5. 跨分片事务](#5345-跨分片事务)
            - [5.3.4.6. 数据迁移，容量规划，扩容等问题](#5346-数据迁移容量规划扩容等问题)
    - [5.4. 分表和分区的区别与联系：](#54-分表和分区的区别与联系)
    - [5.5. 分库分表与读写分离：](#55-分库分表与读写分离)
- [6. 数据库中间件](#6-数据库中间件)
    - [6.1. 设计方案](#61-设计方案)
        - [6.1.1. proxy模式](#611-proxy模式)
        - [6.1.2. smart-client模式](#612-smart-client模式)
    - [6.2. 业界产品](#62-业界产品)

<!-- /TOC -->

&emsp; 本文基于MySQL讲解。  

# 1. 数据库瓶颈  

&emsp; 不管是IO瓶颈，还是CPU瓶颈，最终都会导致数据库的活跃连接数增加，进而逼近甚至达到数据库可承载活跃连接数的阈值。在业务Service来看就是，可用数据库连接少甚至无连接可用。  
1. IO瓶颈：  
&emsp; 第一种：磁盘读IO瓶颈，热点数据太多，数据库缓存放不下，每次查询时会产生大量的IO，降低查询速度 -> 分库和垂直分表。  
&emsp; 第二种：网络IO瓶颈，请求的数据太多，网络带宽不够 -> 分库。  
2. CPU瓶颈：  
&emsp; 第一种：SQL问题，如SQL中包含join，group by，order by，非索引字段条件查询等，增加CPU运算的操作 -> SQL优化，建立合适的索引，在业务Service层进行业务计算。  
&emsp; 第二种：单表数据量太大，查询时扫描的行太多，SQL效率低，CPU率先出现瓶颈 -> 水平分表。  
&emsp; 根据业务特点，单表 > 分区 > 单库分表 > 分库分表，在满足业务前提下，优先级从左到右。  

&emsp; MySql一般并发数200～500。  
&emsp; 单表的数据量达到1000W或100G以后，性能下降严重。此时考虑对数据库切分。数据库拆分过程基本遵循的顺序是：1).垂直拆分（业务拆分）、2).读写分离、3).分库分表(水平拆分)。每个拆分过程都能解决业务上的一些问题，但同时也面临了一些挑战。  
&emsp; 数据库分布式核心内容是数据切分（Sharding），以及切分后对数据的定位、整合。数据切分就是将数据分散存储到多个数据库中，使得单一数据库中的数据量变小，通过扩充主机的数量缓解单一数据库的性能问题，从而达到提升数据库操作性能的目的。  

-----

# 2. 主从复制、读写分离  
## 2.1. 主从复制拓扑结构  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-11.png)  

* 一主一从：  
&emsp; 主备架构。只有主库提供读写服务；备库冗余作故障转移，即主库挂了，keepalive（一种工具）会自动切换到备库。  
* 一主多从：  
&emsp; 一台Slave承受不住读请求压力时，可以添加多台，进行负载均衡，分散读压力。还可以对多台Slave进行分工，服务于不同的系统，例如一部分Slave负责网站前台的读请求，另一部分Slave负责后台统计系统的请求。因为不同系统的查询需求不同，对Slave分工后，可以创建不同的索引，使其更好的服务于目标系统。  
&emsp; 主库单点，从库高可用。一旦主库挂了，写服务也就无法提供。  
&emsp; 存在问题：存在数据一致性问题。请看，一致性解决方案。  
* 双主复制：  
&emsp; 一主多从，Master存在下线的可能，例如故障或者维护，需要把Slave切换为Master。在原来的Master恢复可用后，由于其数据已经不是最新的了，不能再做主，需要作为Slave添加进来。那么就需要对其重新搭建复制环境，需要耗费一定的工作量。  
&emsp; 双主架构，两个主库同时提供服务，负载均衡。高可用，一个主库挂了，不影响另一台主库提供服务。这个过程对业务层是透明的，无需修改代码或配置。  

&emsp; 存在问题：第一，数据一致性问题，一致性解决方案可解决问题。第二，主键冲突问题，ID统一地由分布式ID生成服务来生成可解决问题。  

* 从库级联复制  
&emsp; 当直接从属于Master的Slave过多时，连到Master的Slave IO线程就比较多，对Master的压力是很大的。  
&emsp; 级联结构就是通过减少直接从属于Master的Slave数量，减轻Master的压力，分散复制请求，从而提高整体的复制效率。  
* 双主+主从架构  
&emsp; 存在问题：数据一致性问题、主键冲突问题。数据同步又多了一层，数据延迟更严重。  
* 双主+级联  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-12.png)  
## 2.2. MySql主从复制原理  
### 2.2.1. 复制流程：  
&emsp; 复制是MySQL数据库提供的一种高可用性能的解决方案，一般用来建立大型的应用。总体来说，replication的工作原理分为以下3个步骤：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-27.png)  
1. 主服务器（master）把数据更改记录到二进制日志（binlog）中。  
2. 从服务器（slave）把主服务器的二进制日志复制到自己的中继日志（relay log）中。  
3. 从服务器重做日志中的日志，把更改应用到自己的数据库上，以达到数据的最终一致性。  
  
        同步方式可以划分为：异步、半同步和同步。  
        * 同步复制：指当主库执行完一个事务，所有的从库都执行了该事务才返回给客户端。因为需要等待所有从库执行完该事务才能返回，所以全同步复制的性能必然会收到严重的影响。需要有超时时间。  
        * 异步复制：MySQL默认的复制即是异步的，主库在执行完客户端提交的事务后会立即将结果返给给客户端，并不关心从库是否已经接收并处理，这样就会有一个问题，主如果crash掉了，此时主上已经提交的事务可能并没有传到从上，如果此时，强行将从提升为主，可能导致新主上的数据不完整。  
        * 半同步复制：介于异步复制和全同步复制之间，主库在执行完客户端提交的事务后不是立刻返回给客户端，而是等待至少一个从库接收到并写到relay log中才返回给客户端。相对于异步复制，半同步复制提高了数据的安全性，同时它也造成了一定程度的延迟，这个延迟最少是一个TCP/IP往返的时间。所以，半同步复制最好在低延时的网络中使用。  

### 2.2.2. 复制方式：  
&emsp; 复制方式有三种：基于行的复制、基于语句的复制、混合模式复制。  

#### 2.2.2.1. 基于语句的复制  
&emsp; 基于SQL语句的复制(statement-based replication, SBR)，每一条会修改数据的sql语句会记录到binlog中。  
&emsp; ***优点：*** 不需要记录每一条SQL语句与每行的数据变化（不记录select操作），这样子binlog的日志也会比较少，减少了磁盘IO，提高性能。  
&emsp; ***缺点：*** 并非所有修改数据的语句都可以使用基于语句的复制进行复制。使用基于语句的复制时，任何非确定性行为都难以复制。此类数据修改语言（DML）语句的示例包括以下内容：  
        
        依赖于UDF或不确定的存储程序的语句，因为这样的UDF或存储程序返回的值取决于提供给它的参数以外的因素。  
        不带ORDER BY的LIMIT子句的DELETE和UPDATE语句是不确定的。 
 
#### 2.2.2.2. 基于行的复制：  
&emsp; 不记录每一条SQL语句的上下文信息，仅需记录哪条数据被修改了，修改成了什么样子了。  
&emsp; ***优点：*** 没有基于行的复制模式无法处理的场景。  
&emsp; ***缺点：*** 会产生大量的日志。  

#### 2.2.2.3. 混合模式复制：  
&emsp; 混合模式复制(mixed-based replication, MBR)：以上两种模式的混合使用，一般的复制使用STATEMENT模式保存binlog，对于STATEMENT模式无法复制的操作使用ROW模式保存binlog，MySQL会根据执行的SQL语句选择日志保存方式。  

# 3. 读写分离  
&emsp; 读写分离在数据库主从复制技术基础上实现（主从复制针对写入数据，读写分离主要针对读取数据）。  

## 3.1. 主从复制、读写分离带来的问题  
* 数据不一致问题（主从数据同步延迟问题）：当主库的TPS并发较高时，由于主库上面是多线程写入的，而从库的SQL线程是单线程的，导致从库SQL可能会跟不上主库的处理速度。因此有可能出现在master节点中已经插入了数据，但是从slave节点却读取不到的问题。对于一些强一致性的业务场景，要求插入后必须能读取到，对于这种情况，需要提供一种方式，让读请求也可以走主库，而主库上的数据必然是最新的。  
&emsp; 延迟的解决：    
1). 网络方面：将从库分布在相同局域网内或网络延迟较小的环境中。  
2). 硬件方面：从库配置更好的硬件，提升随机写的性能。  
3). 配置方面：从库配置sync_binlog=0，innodb_flush_log_at_trx_commit=2，logs-slave-updates=0，增大innodb_buffer_pool_size，让更多操作在Mysql内存中完成，减少磁盘操作。或者升级Mysql5.7版本使用并行复制。  
4). 架构方面：比如在事务当中尽量对主库读写，其他非事务中的读在从库。消除一部分延迟带来的数据库不一致。增加缓存降低一些从库的负载。  
* 事务问题：读写分离属于分布式事务的范畴。但是对于读写分离，目前主流的做法是，事务中的所有sql统一都走主库，由于只涉及到一个库，本地事务就可以搞定。  
* 感知集群信息变更：如果访问的数据库集群信息变更了，例如主从切换了，写流量就要到新的主库上；又例如增加了从库数量，流量需要可以打到新的从库上；又或者某个从库延迟或者失败率比较高，应该将这个从库进行隔离，读流量尽量打到正常的从库上。  
* 运维：例如集群搭建、主从切换、从库扩容、缩容等。例如master配置了多个slave节点，如果其中某个slave节点挂了，那么之后的读请求，应用将其转发到正常工作的slave节点上。另外，如果新增了slave节点，应用也应该感知到，可以将读请求转发到新的slave节点上。  

---

# 4. 分区  
## 4.1. 什么是分区：  
&emsp; 数据分区是一种物理数据库的设计技术，它的目的是为了在特定的SQL操作中减少数据读写的总量以缩减响应时间。分区把存放数据的文件分成了许多小块。例如mysql中myisam的一张表对应三个文件MYD、MYI、frm，根据一定的规则把数据文件(MYD)和索引文件(MYI)进行了分割。  
&emsp; 分区并不是生成新的数据表，而是将表的数据均衡分摊到不同的硬盘、系统或是不同服务器存储介子中。就访问数据库应用而言，逻辑上就只有一个表或者一个索引，但实际上这个表可能有N个物理分区对象组成，每个分区都是一个独立的对象，可以独立处理，可以作为表的一部分进行处理。分区对应用来说是完全透明的，不影响应用的业务逻辑。  

&emsp; ***分区使用的场景（优点）：***  
1).表非常大以至于无法全部都放在内存中，或者只在表的最后部分有热点数据，其他都是历史数据。  
2).分区表的数据容易维护，如：想批量删除数据可以清楚整个分区的方式，另外，还可以对一个独立分区进行优化、检查、修复等操作。  
3).分区的数据可以分布在不同物理设备上，分区可以存储更多的数据，高效地利用多个硬件设备。  
4).可以使用分区表来避免某些特殊的瓶颈，如InnoDB单个索引的互斥访问。  
5).如果需要，还可以备份和恢复独立的分页去，这在非常大的数据集场景下效果非常有效。  
6).优化查询，在where字句中包含分区列时，可以只使用必要的分区来提高查询效率，同时在涉及sum()和count()这类聚合函数的查询时，可以在每个分区上面并行处理，最终只需要汇总所有分区得到的结果。  

&emsp; ***分区限制（缺点）：***  
1).一个表最多只能有1024个分区（mysql5.6之后支持8192个分区）。  
2).在mysql5.1中分区表达式必须是整数，或者返回整数表达式，在5.5之后，某些场景可以直接使用字符串和日期类型列进行分区。  
3).如果分区字段中有主键或者唯一索引列，那么所有主键列和唯一索引列都必须包含进来，如果表中有主键或唯一索引，那么分区键必须是主键或唯一索引。  
4).分区表中无法使用外键约束。  
5).mysql数据库支持的分区类型为水平分区，并不支持垂直分区，因此，mysql数据库的分区中索引是局部分区索引，一个分区中既存放了数据又存放了索引，而全局分区是指的数据库放在各个分区中，但是所有的数据的索引放在另外一个对象中。  
6).目前mysql不支持空间类型和临时表类型进行分区。不支持全文索引。  


## 4.2. 怎么分区：  
### 4.2.1. 分区键：  
&emsp; 分区依据的字段必须是主键的一部分，分区是为了快速定位数据，因此该字段的搜索频次较高应作为强检索字段，否则依照该字段分区毫无意义。  

### 4.2.2. 分区路由（MySql分区类型）：  
&emsp; range分区、list分区、columns分区、hash分区、key分区、子分区。  

&emsp; ***1).range分区***  
&emsp; 按照RANGE分区的表，每个分区包含那些分区表达式的值位于一个给定的连续区间内的行。一般使用这种分区方式大都是对连续的值进行分区，常见的如：按年份，日期, 连续的数字进行分区。  

```sql
-- 语法
create table <table> (
   // 字段
) ENGINE=MyISAM  DEFAULT CHARSET=utf8 AUTO_INCREMENT=1
partition by range (分区字段) (
  partition <分区名称> values less than (Value),
  partition <分区名称> values less than (Value),
  ...
  partition <分区名称> values less than maxvalue
);
```

    range：表示按范围分区；  
    分区字段：表示要按照哪个字段进行分区，可以是一个字段名，也可以是对某个字段进行表达式运算如year(create_time)，使用range最终的值必须是数字；  
    分区名称: 要保证不同，也可以采用p0、p1、p2 这样的分区名称；  
    less than : 表示小于；  
    Value : 表示要小于某个具体的值，如 less than (10) 那么分区字段的值小于10的都会被分到这个分区；  
    maxvalue: 表示一个最大的值；  

&emsp; 分区可以在创建表的时候进行分区，也可以在创建表之后进行分区。  

```sql
alter table <table> partition by RANGE(id) (
    PARTITION p0 VALUES LESS THAN (value1),
    PARTITION p1 VALUES LESS THAN (value2),
    PARTITION p4 VALUES LESS THAN MAXVALUE 
);
```
&emsp; 在创建分区的时候经常会遇到这个错误：A PRIMARY KEY must include all columns in the table’s partitioning function。意思是说分区的字段必须是要包含在主键当中。可以使用PRIMARY KEY (id,xxx)来将多个字段作为主键。在做分区表时，选择分区的依据字段时要谨慎，需要仔细斟酌这个字段拿来做为分区依据是否合适，这个字段加入到主键中做为复合主键是否适合。  
&emsp; 使用range分区时表结构要么没有主键，要么分区字段必须是主键。  

&emsp; ***4).hash分区***  
&emsp; HASH分区主要用来分散热点读取，确保数据在预先确定数目的分区中平均分布，所要做的只是基于将要被哈希的列值指定一个列值或表达式，以及指定被分区的表将要被分割成的分区数量。一个表执行hash分区，mysql会对分区键应用一个散列函数，以此确定数据应该放在n个分区中的哪一个分区。  
&emsp; mysql支持两种hash分区：  

* 常规hash分区和线性hash分区(linear hash分区)，常规hash分区使用的是取模算法，对应一个表达式expr是可以计算出它被保存到哪个分区中，N = MOD(expr, num)  
* 线性hash分区使用的是一个线性的2的幂运算法则。  
&emsp; 常规hash分区方式，通过取模的方式来数据尽可能平均分布在每个分区，让每个分区管理的数据都减少，提高查询效率，可是当要增加分区时或者合并分区，会有问题，假设原来是5个常规hash分区，现在需要增加一个常规分区，原来的取模算法是MOD(expr, 5), 根据余数0~4分布在5个分区中，现在新增一个分区后，取模算法变成MOD(expr, 6),根据余数0~6分区在6个分区中，原来5个分区的数据大部分都需要通过重新计算进行重新分区。  
&emsp; 常规hash分区在管理上带来了的代价太大，不适合需要灵活变动分区的需求。为了降低分区管理上的代价，mysql提供了线性hash分区，分区函数是一个线性的2的幂的运算法则。同样线性hash分区的记录被存在那个分区也是能被计算出来的。线性hash分区的优点是在分区维护(增加、删除、合并、拆分分区)时，mysql能够处理的更加迅速，缺点是：对比常规hash分区，线性hash各个分区之间数据的分布不太均衡。  

```sql
-- HASH
create table <table> (
   // 字段
) ENGINE=数据库引擎  DEFAULT CHARSET=utf8 AUTO_INCREMENT=1
PARTITION BY HASH(expr)
PARTITIONS <num>;
```
&emsp; hash分区只需要指定要分区的字段和要分成几个分区。expr是一个字段值或者基于某列值云散返回的一个整数，expr可以是mysql中有效的任何函数或者其它表达式，只要它们返回一个即非常熟也非随机数的整数。num表示分区数量。  

&emsp; ***6).子分区***  
&emsp; 子分区(subpartition)：是分区表中对每个分区的再次分割，又被称为复合分区，支持对range和list进行子分区，子分区即可以使用hash分区也可以使用key分区。复合分区适用于保存非常大量的数据记录。  
1. 如果一个分区中创建了子分区，其他分区也要有子分区；  
2. 如果创建了了分区，每个分区中的子分区数必有相同；  
3. 同一分区内的子分区，名字不相同，不同分区内的子分区名子可以相同；  

```sql
-- 根据年进行分区
-- 再根据天数分区
-- 3个range分区(p0,p1,p2)又被进一步分成2个子分区，实际上整个分区被分成了 3 x 2 = 6个分区
create table ts (
   id int, 
   purchased date
) 
partition by range(year(purchased))
subpartition by hash(to_days(purchased)) subpartitions 2 
(
   partition p0 values less than (1990),
   partition p0 values less than (2000),
   partition p0 values less than maxvalue
);
```

## 4.3. 管理分区（增、删分区）：  
&emsp; mysql不禁止在分区键值上使用null,分区键可能是一个字段或者一个用户定义的表达式，一般情况下，mysql的分区把null值当做零值或者一个最小值进行处理。range分区中，null值会被当做最小值来处理；list分区中null值必须出现在枚举列表中，否则不被接受；hash/key分区中，null值会被当做领值来处理。  
&emsp; mysql提供了添加、删除、重定义、合并、拆分分区的命令，这些操作都可以通过alter table命令来实现。  

```sql
-- 删除list或者range分区(同时删除分区对应的数据)
alter table <table> drop partition <分区名称>;
-- 新增分区
-- range添加新分区
alter table <table> add partition(partition p4 values less than MAXVALUE);
-- hash重新分区
alter table <table> add partition partitions 4;
```
&emsp; 删除分区：删除分区后，分区中原有的数据也会随之删除！  

```sql
alter table article_range drop PARTITION p201808
```

&emsp; 销毁分区：  

```sql
alter table article_key coalesce partition 6
```
&emsp; key/hash分区的管理不会删除数据，但是每一次调整（新增或销毁分区）都会将所有的数据重写分配到新的分区上。==效率极低==，最好在设计阶段就考虑好分区策略。  

## 4.4. 分区表使用  
&emsp; 在where条件带入分区列。  



----
# 5. 分库/分片、分表  
## 5.1. 数据切分方式  
&emsp; 数据切分分为两种方式，垂直（纵向）切分和水平（横向）切分。先垂直后水平。  
### 5.1.1. 垂直（纵向）切分  
* 垂直分表  
&emsp; 也就是“大表拆小表”，基于列字段进行的。一般是表中的字段较多，将不常用的，数据较大，长度较长（比如text类型字段）的拆分到“扩展表“。 一般是针对那种几百列的大表，也避免查询时，数据量太大造成的“跨页”问题。  
* 垂直分库  
&emsp; 垂直分库针对的是一个系统中的不同业务进行拆分，比如用户User一个库，商品Producet一个库，订单Order一个库。 切分后，要放在多个服务器上，而不是一个服务器上。为什么？ 想象一下，一个购物网站对外提供服务，会有用户，商品，订单等的CRUD。没拆分之前，全部都是落到单一的库上的，这会让数据库的单库处理能力成为瓶颈。按垂直分库后，如果还是放在一个数据库服务器上， 随着用户量增大，这会让单个数据库的处理能力成为瓶颈，还有单个服务器的磁盘空间，内存，tps等非常吃紧。 所以要拆分到多个服务器上，这样上面的问题都解决了，以后也不会面对单机资源问题。  
&emsp; 数据库业务层面的拆分，和服务的“治理”，“降级”机制类似，也能对不同业务的数据分别的进行管理，维护，监控，扩展等。数据库往往最容易成为应用系统的瓶颈，而数据库本身属于“有状态”的，相对于Web和应用服务器来讲，是比较难实现“横向扩展”的。 数据库的连接资源比较宝贵且单机处理能力也有限，在高并发场景下，垂直分库一定程度上能够突破IO、连接数及单机硬件资源的瓶颈。  
&emsp; 垂直分库就是根据业务耦合性，将关联度低的不同表存储在不同的数据库。做法与大系统拆分为多个小系统类似，按业务分类进行独立划分。与"微服务治理"的做法相似，每个微服务使用单独的一个数据库。  

### 5.1.2. 水平（横向）切分  
* 水平分表  
&emsp; 针对数据量巨大的单张表（比如订单表），按照某种规则（RANGE，HASH取模等），切分到多张表里面去。但是这些表还是在同一个库中，所以库级别的数据库操作还是有IO瓶颈。不建议采用。  
* 水平分库分表  
&emsp; 将单张表的数据切分到多个服务器上去，每个服务器具有相应的库与表，只是表中数据集合不同。水平分库分表能够有效的缓解单机和单库的性能瓶颈和压力，突破IO、连接数、硬件资源等的瓶颈。  

## 5.2. 分库分表方案（路由算法）：  
&emsp; 分库分表步骤：根据容量（当前容量和增长量）评估分库或分表个数 -> 选key（均匀）-> 分表规则（hash或range等）-> 执行（一般双写）-> 扩容问题（尽量减少数据的移动）。   

&emsp; 常见的分片策略有随机分片和连续分片这两种，如下图所示：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-13.png)  
&emsp; 当需要使用分片字段进行范围查找时，连续分片可以快速定位分片进行高效查询，大多数情况下可以有效避免跨分片查询的问题。后期如果想对整个分片集群扩容时，只需要添加节点即可，无需对其他分片的数据进行迁移。但是，连续分片也有可能存在数据热点的问题，就像图中按时间字段分片的例子，有些节点可能会被频繁查询压力较大，热数据节点就成为了整个集群的瓶颈。而有些节点可能存的是历史数据，很少需要被查询到。  
&emsp; 随机分片其实并不是随机的，也遵循一定规则。通常，会采用Hash取模的方式进行分片拆分，所以有些时候也被称为离散分片。随机分片的数据相对比较均匀，不容易出现热点和并发访问的瓶颈。但是，后期分片集群扩容起来需要迁移旧的数据。使用一致性Hash算法能够很大程度的避免这个问题，所以很多中间件的分片集群都会采用一致性Hash算法。离散分片也很容易面临跨分片查询的复杂问题。  

## 5.3. ~~分库分表带来的分布式困境与解决方案~~  

### 5.3.1. 分库数量：  
&emsp; 分库数量首先和单库能处理的记录数有关，一般来说，Mysql单库超过5000万条记录，Oracle单库超过1亿条记录，DB压力就很大(当然处理能力和字段数量/访问模式/记录长度有进一步关系)。  
&emsp; 在满足上述前提下，如果分库数量少，达不到分散存储和减轻DB性能压力的目的；如果分库的数量多，好处是每个库记录少，单库访问性能好，但对于跨多个库的访问，应用程序需要访问多个库，如果是并发模式，要消耗宝贵的线程资源；如果是串行模式，执行时间会急剧增加。  
&emsp; 最后分库数量还直接影响硬件的投入，一般每个分库跑在单独物理机上，多一个库意味多一台设备。所以具体分多少个库，要综合评估，一般初次分库建议分4-8个库。  
### 5.3.2. ID问题  
&emsp; 查看《分布式ID》章节。  

### 5.3.3. 基本的数据库增删改功能  
&emsp; 批量插入：  

```sql
insert into user(id,name) values (1,”tianshouzhi”),(2,”huhuamin”), (3,”wanghanao”),(4,”luyang”);
```
&emsp; 这样的sql明显是无法执行的，因为已经对库和表进行了拆分，这种sql语法只能操作mysql的单个库和单个表。所以必须将sql改成4条如下所示，然后分别到每个库上去执行。  

```sql
insert into user0(id,name) values  (4,”luyang”);
insert into user1(id,name) values (1,”tianshouzhi”);
insert into user2(id,name) values (2,”huhuamin”);
insert into user3(id,name) values (3,”wanghanao”);
```
&emsp; 具体流程可以用下图进行描述：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-14.png)  
1). sql解析：首先对sql进行解析，得到需要插入的四条记录的id字段的值分别为1,2,3,4。  
2). sql路由：sql路由包括库路由和表路由。库路由用于确定这条记录应该插入哪个库，表路由用于确定这条记录应该插入哪个表。  
3). sql改写：因为一条记录只能插入到一个库中，而上述批量插入的语法将会在 每个库中都插入四条记录，明显是不合适的，因此需要对sql进行改写，每个库只插入一条记录。  
4). sql执行：一条sql经过改写后变成了多条sql，为了提升效率应该并发的到不同的库上去执行，而不是按照顺序逐一执行。  
5). 结果集合并：每个sql执行之后，都会有一个执行结果，需要对分库分表的结果集进行合并，从而得到一个完整的结果。  

### 5.3.4. 查询功能
#### 5.3.4.1. 跨节点的order by、group by以及count等聚合函数问题  
&emsp; 这些是一类问题，因为它们都需要基于全部数据集合进行计算。多数的代理都不会自动处理合并工作，部分支持聚合函数MAX、MIN、COUNT、SUM。解决方案：与解决跨节点join问题类似，分别在各个节点上执行相应的函数处理得到结果后，在应用程序端进行合并。和join不同的是每个结点的查询可以并行执行，因此很多时候它的速度要比单一大表快很多。但如果结果集很大，对应用程序内存的消耗是一个问题。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-16.png)  


#### 5.3.4.2. 跨分片的排序分页  
&emsp; 一般来讲，分页时需要按照指定字段进行排序。当排序字段是分片字段时，通过分片规则可以比较容易定位到指定的分片；而当排序字段非分片字段时，情况就会变得比较复杂了。为了最终结果的准确性，需要在不同的分片节点中将数据进行排序并返回，并将不同分片返回的结果集进行汇总和再次排序，最后再返回给用户。如下图所示：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-17.png)  
&emsp; 上面图中所描述的只是最简单的一种情况（取第一页数据），看起来对性能的影响并不大。但是，如果想取出第10页数据，情况又将变得复杂很多，如下图所示：
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-18.png)  
&emsp; 有些读者可能并不太理解，为什么不能像获取第一页数据那样简单处理（排序取出前10条再合并、排序）。其实并不难理解，因为各分片节点中的数据可能是随机的，为了排序的准确性，必须把所有分片节点的前N页数据都排序好后做合并，最后再进行整体的排序。很显然，这样的操作是比较消耗资源的，用户越往后翻页，系统性能将会越差。  
#### 5.3.4.3. 非partition key的查询问题  
（水平分库分表，拆分策略为常用的hash法）  
1. 端上除了partition key只有一个非partition key作为条件查询  
  * 映射法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-19.png)  
  * 基因法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-20.png)  
&emsp; 注：写入时，基因法生成user_id，如图。关于xbit基因，例如要分8张表，23=8，故x取3，即3bit基因。根据user_id查询时可直接取模路由到对应的分库或分表。根据user_name查询时，先通过user_name_code生成函数生成user_name_code再对其取模路由到对应的分库或分表。id生成常用snowflake算法。  
2. 端上除了partition key不止一个非partition key作为条件查询  
  * 映射法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-21.png)  
  * 冗余法    
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-22.png)  
&emsp; 注：按照order_id或buyer_id查询时路由到db_o_buyer库中，按照seller_id查询时路由到db_o_seller库中。感觉有点本末倒置！有其他好的办法吗？改变技术栈呢？  

3. 后台除了partition key还有各种非partition key组合条件查询  
* NoSQL法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-23.png)  
* 冗余法  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-24.png)  

#### 5.3.4.4. 跨节点Join的问题  
&emsp; 在单库单表的情况下，联合查询是非常容易的。但是，随着分库与分表的演变，联合查询就遇到跨库关联和跨表关系问题。在设计之初就应该尽量避免联合查询。  
&emsp; tddl、MyCAT等都支持跨分片join。如果中间不支持，跨库Join的几种解决思路：  
* 在程序中进行拼装。  
* 全局表：  
&emsp; 所谓全局表，就是有可能系统中所有模块都可能会依赖到的一些表。比较类似“数据字典”。为了避免跨库join查询，可以将这类表在其他每个数据库中均保存一份。同时，这类数据通常也很少发生修改（甚至几乎不会），所以也不用太担心“一致性”问题。  
* 字段冗余：  
&emsp; 这是一种典型的反范式设计，在互联网行业中比较常见，通常是为了性能来避免join查询。  
&emsp; 举个电商业务中很简单的场景：“订单表”中保存“卖家 Id”的同时，将卖家的“Name”字段也冗余，这样查询订单详情的时候就不需要再去查询“卖家用户表”。  
&emsp; 字段冗余能带来便利，是一种“空间换时间”的体现。但其适用场景也比较有限，比较适合依赖字段较少的情况。最复杂的还是数据一致性问题，这点很难保证，可以借助数据库中的触发器或者在业务代码层面去保证。当然，也需要结合实际业务场景来看一致性的要求。就像上面例子，如果卖家修改了Name之后，是否需要在订单信息中同步更新呢？  

#### 5.3.4.5. 跨分片事务  
&emsp; 分库分表、跨分片事务，即分布式事务。参考《分布式事务》章节。  

#### 5.3.4.6. 数据迁移，容量规划，扩容等问题  
&emsp; 很少有项目会在初期就开始考虑分片设计的，一般都是在业务高速发展面临性能和存储的瓶颈时才会提前准备。因此，不可避免的就需要考虑历史数据迁移的问题。一般做法就是通过程序先读出历史数据，然后按照指定的分片规则再将数据写入到各个分片节点中。  
&emsp; 此外，需要根据当前的数据量和QPS等进行容量规划，综合成本因素，推算出大概需要多少分片（一般建议单个分片上的单表数据量不要超过1000W）。  
&emsp; 如果是采用随机分片，则需要考虑后期的扩容问题，相对会比较麻烦。如果是采用的范围分片，只需要添加节点就可以自动扩容。  

## 5.4. 分表和分区的区别与联系：
&emsp; ***分表和分区的联系：***  
1. 实现方式上：
a) mysql的分表是真正的分表，一张表分成很多表后，每一个小表都是完正的一张表，都对应三个文件，一个.MYD数据文件，.MYI索引文件，.frm表结构文件。
b) 分区不一样，一张大表进行分区后，还是一张表，不会变成多张表，但是存放数据的区块变多了。
2. 数据处理上： 
a) 分表后，数据都是存放在分表里，总表只是一个外壳，存取数据发生在一个一个的分表里面。 
b) 分区不存在分表的概念，分区只不过把存放数据的文件分成了许多小块，分区后的表还是一张表。数据处理还是由自己来完成。

&emsp; ***分表和分区的联系：***  
1. 都能提高mysql的性高，在高并发状态下都有一个良好的表面。 
2. 分表和分区不矛盾，可以相互配合。对于那些大访问量，并且表数据比较多的表，可以采取分表和分区结合的方式（如果merge这种分表方式，不能和分区配合的话，可以用其他的分表试），访问量不大，但是表数据很多的表，可以采取分区的方式等。

## 5.5. 分库分表与读写分离：  
&emsp; 分库分表的好处：读写分离实现了数据库读能力的水平扩展，分库分表实现了写能力的水平扩展。  
1. 存储能力的水平扩展：在读写分离的情况下，每个集群中的master和slave基本上数据是完全一致的，从存储能力来说，存在海量数据的情况下，可能由于磁盘空间的限制，无法存储所有的数据。而在分库分表的情况下，可以搭建多个mysql主从复制集群，每个集群只存储部分分片的数据，实现存储能力的水平扩展。  
2. 写能力的水平扩展：在读写分离的情况下，由于每个集群只有一个master，所有的写操作压力都集中在这一个节点上，在写入并发非常高的情况下，这里会成为整个系统的瓶颈。  
&emsp; 而在分库分表的情况下，每个分片所属的集群都有一个master节点，都可以执行写入操作，实现写能力的水平扩展。此外减小建立索引开销，降低写操作的锁操作耗时等，都会带来很多显然的好处。  

---

# 6. 数据库中间件  
&emsp; 数据库中间件的主要作用是向应用程序开发人员屏蔽读写分离和分库分表面临的挑战，并隐藏底层实现细节，使得开发人员可以像操作单库单表那样去操作数据。  

&emsp; ***除了数据库中间件之外还可以使用SpringAOP、ORM框架代理来实现多数据源读写分离。***  

## 6.1. 设计方案  
&emsp; 典型的数据库中间件设计方案有2种：proxy、smart-client。下图演示了这两种方案的架构：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-25.png)  
&emsp; 不论是proxy还是smart-client，底层都操作了多个数据库实例。不论是分库分表，还是读写分离，都是在数据库中间件层面对业务开发同学进行屏蔽。  
### 6.1.1. proxy模式  
&emsp; 独立部署一个代理服务，这个代理服务背后管理多个数据库实例。而在应用中，通过一个普通的数据源(c3p0、druid、dbcp等)与代理服务器建立连接，所有的sql操作语句都是发送给这个代理，由这个代理去操作底层数据库，得到结果并返回给应用。在这种方案下，分库分表和读写分离的逻辑对开发人员是完全透明的。  

&emsp; ***优点：***  
1. 多语言支持。不论使用的是php、java或是其他语言，都可以支持。以mysql数据库为例，如果proxy本身实现了mysql的通信协议，那么可以就将其看成一个mysql 服务器。mysql官方团队为不同语言提供了不同的客户端却动，如java语言的mysql-connector-java，python语言的mysql-connector-python等等。因此不同语言的开发者都可以使用mysql官方提供的对应的驱动来与这个代理服务器建通信。  
2. 对业务开发同学透明。由于可以把proxy当成mysql服务器，理论上业务同学不需要进行太多代码改造，既可以完成接入。  

&emsp; ***缺点：***  
1. 实现复杂。因为proxy需要实现被代理的数据库server端的通信协议，实现难度较大。通常看到一些proxy模式的数据库中间件，实际上只能代理某一种数据库，如mysql。几乎没有数据库中间件可以同时代理多种数据库(sqlserver、PostgreSQL、Oracle)。  
2. proxy本身需要保证高可用。由于应用本来是直接访问数据库，现在改成了访问proxy，意味着proxy必须保证高可用。否则，数据库没有宕机，proxy挂了，导致数据库无法正常访问，就尴尬了。  
3. 租户隔离。可能有多个应用访问proxy代理的底层数据库，必然会对proxy自身的内存、网络、cpu等产生资源竞争，proxy需要需要具备隔离的能力。  

### 6.1.2. smart-client模式  
&emsp; 业务代码需要进行一些改造，引入支持读写分离或者分库分表的功能的sdk，这个就是smart-client。通常smart-client是在连接池或者driver的基础上进行了一层封装，smart-client内部与不同的库建立连接。应用程序产生的sql交给smart-client进行处理，其内部对sql进行必要的操作，例如在读写分离情况下，选择走从库还是主库；在分库分表的情况下，进行sql解析、sql改写等操作，然后路由到不同的分库，将得到的结果进行合并，返回给应用。  

&emsp; ***优点：***  
1. 实现简单。proxy需要实现数据库的服务端协议，但是smart-client不需要实现客户端通信协议。原因在于，大多数据数据库厂商已经针对不同的语言提供了相应的数据库驱动driver，例如mysql针对java语言提供了mysql-connector-java驱动，针对python提供了mysql-connector-python驱动，客户端的通信协议已经在driver层面做过了。因此smart-client模式的中间件，通常只需要在此基础上进行封装即可。  
2. 天然去中心化。smart-client的方式，由于本身以sdk的方式，被应用直接引入，随着应用部署到不同的节点上，且直连数据库，中间不需要有代理层。因此相较于proxy而言，除了网络资源之外，基本上不存在任何其他资源的竞争，也不需要考虑高可用的问题。只要应用的节点没有全部宕机，就可以访问数据库。(这里的高可用是相比proxy而言，数据库本身的高可用还是需要保证的)  

&emsp; ***缺点：***  
1. 通常仅支持某一种语言。例如tddl、zebra、sharding-jdbc都是使用java语言开发，因此对于使用其他语言的用户，就无法使用这些中间件。如果其他语言要使用，那么就要开发多语言客户端。  
2. 版本升级困难。因为应用使用数据源代理就是引入一个jar包的依赖，在有多个应用都对某个版本的jar包产生依赖时，一旦这个版本有bug，所有的应用都需要升级。而数据库代理升级则相对容易，因为服务是单独部署的，只要升级这个代理服务器，所有连接到这个代理的应用自然也就相当于都升级了。  

## 6.2. 业界产品  
&emsp; 无论是proxy，还是smart-client，二者的作用都是类似的。以下列出了这两种方案目前已有的实现以及各自的优缺点：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/SQL/sql-26.png)  
&emsp; proxy实现，目前的已有的实现方案有：  

    阿里巴巴开源的cobar  
    阿里云上的drds  
    mycat团队在cobar基础上开发的mycat  
    mysql官方提供的mysql-proxy  
    奇虎360在mysql-proxy基础开发的atlas(只支持分表，不支持分库)  
    当当网开源的sharing-sphere  
    目前除了mycat、sharing-sphere，其他几个开源项目基本已经没有维护。  

&emsp; smart-client实现，目前的实现方案有：  

    阿里巴巴开源的tddl，已很久没维护
    大众点评开源的zebra，大众点评的zebra开源版本代码已经很久没有更新，不过最近美团上市，重新开源大量内部新的功能特性，并计划长期维持。
    当当网开源的sharding-jdbc，目前算是做的比较好的，文档资料比较全。和sharding-sphere一起进入了Apache孵化器。
    蚂蚁金服的zal

&emsp; 综上，现在其实建议考量的，就是sharding-jdbc和mycat，这两个都可以去考虑使用。  
&emsp; sharding-jdbc这种client层方案的优点在于不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但是如果遇到升级啥的需要各个系统都重新升级版本再发布，各个系统都需要耦合sharding-jdbc的依赖；  
&emsp; mycat这种proxy层方案的缺点在于需要部署，自己运维一套中间件，运维成本高，但是好处在于对于各个项目是透明的，如果遇到升级之类的都是自己中间件那里搞就行了。  
&emsp; 通常来说，这两个方案其实都可以选用，但是个人建议中小型公司选用 sharding-jdbc，client 层方案轻便，而且维护成本低，不需要额外增派人手，而且中小型公司系统复杂度会低一些，项目也没那么多；但是中大型公司最好还是选用 mycat 这类 proxy 层方案，因为可能大公司系统和项目非常多，团队很大，人员充足，那么最好是专门弄个人来研究和维护 mycat，然后大量项目直接透明使用即可。  




