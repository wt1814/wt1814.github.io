---
title: 分布式服务追踪：Spring Cloud Sleuth
date: 2020-03-19 00:00:00
tags:
    - Spring Cloud Netflix
---
## 全链路监控功能模块  
一般的全链路监控系统，大致可分为四大功能模块：
1.埋点与生成日志
埋点即系统在当前节点的上下文信息，可以分为客户端埋点、服务端埋点，以及客户端和服务端双向型埋点。埋点日志通常要包含以下内容traceId、spanId、调用的开始时间，协议类型、调用方ip和端口，请求的服务名、调用耗时，调用结果，异常信息等，同时预留可扩展字段，为下一步扩展做准备；

不能造成性能负担：一个价值未被验证，却会影响性能的东西，是很难在公司推广的！
因为要写log，业务QPS越高，性能影响越重。通过采样和异步log解决。

2.收集和存储日志
主要支持分布式日志采集的方案，同时增加MQ作为缓冲；
1).每个机器上有一个 deamon 做日志收集，业务进程把自己的Trace发到daemon，daemon把收集Trace往上一级发送；
2).多级的collector，类似pub/sub架构，可以负载均衡；
3).对聚合的数据进行 实时分析和离线存储；
4).离线分析 需要将同一条调用链的日志汇总在一起；
3.分析和统计调用链路数据，以及时效性
调用链跟踪分析：把同一TraceID的Span收集起来，按时间排序就是timeline。把ParentID串起来就是调用栈。
抛异常或者超时，在日志里打印TraceID。利用TraceID查询调用链情况，定位问题。
依赖度量：
            强依赖：调用失败会直接中断主流程
            高度依赖：一次链路中调用某个依赖的几率高
            频繁依赖：一次链路调用同一个依赖的次数多
离线分析：按TraceID汇总，通过Span的ID和ParentID还原调用关系，分析链路形态。
实时分析：对单条日志直接分析，不做汇总，重组。得到当前QPS，延迟。

4.展现以及决策支持

## Sleuth实现追踪  
&emsp; 在服务提供者和服务消费者引入spring-cloud-starter-sleuth依赖。
```xml
<dependency>
  <groupId>org.springframework.cloud</groupId>
  <artifactId>spring-cloud-starter-sleuth</artifactId>
</dependency>
```
访问消费者接口，控制台日志显示  
消费者(springcloud-consumer-sleuth)打印的日志：  

```text
2019-12-05 12:30:20.178  INFO [springcloud-consumer-sleuth,f6fb983680aab32b,f6fb983680aab32b,false] 8992 --- [nio-9090-exec-1] c.s.controller.SleuthConsumerController  : === consumer service ===
```
提供者(springcloud-provider-sleuth)打印的日志  

```text
2019-12-05 12:30:20.972  INFO [springcloud-provider-sleuth,f6fb983680aab32b,c70932279d3b3a54,false] 788 --- [nio-8080-exec-1] c.s.controller.SleuthProviderController  : === provider service ===
```
&emsp; INFO[]标签中为链路追踪信息。每个值的含义如下所述：  
* 第一个值: springcloud-consumer-sleuth,它记录了应用的名称,也就是application properties 中spring.application.name参数配置的属性  
* 第二个值:f6fb983680aab32b, Spring Cloud Sleuth生成的一个ID,称为Trace ID, 它用来标识一条请求链路。一条请求链路中包含一个Trace ID,多个Span ID  
* 第三个值:c70932279d3b3a54, Spring Cloud Sleuth生成的另外一个ID,称为Span ID,它表示一个基本的工作单元,比如发送一个HTTP请求  
* 第四个值: false,表示是否要将该信息输出到Zipkin等服务中来收集和展示。上面四个值中的Trace ID和Span ID是Spring Cloud Sleuth实现分布式服务跟踪的核心，在一次服务请求链路的调用过程中,会保持并传递同一个Trace ID,从而将整个分布于不同微服务进程中的请求跟踪信息串联起来。以上面输出内容为例springcloud-consumer-sleuth和springcloud-provider-sleuth同属于一个前端服务请求资源，所以他们的Trace ID是相同的，处于同一条请求链路中。  

## 跟踪原理：  
&emsp; 分布式系统服务跟踪原理主要包括下面两个关键点：  
&emsp; 为了实现请求跟踪,当请求发送到分布式系统的入口端点时,只需要服务跟踪框架为该请求创建一个唯一的跟踪标识,同时在分布式系统内部流转的时候,框架始终保持传递该唯一标识,直到返回给请求方为止,这个唯一标识就是前文中提到的Trace ID。通过Trace ID的记录,我们就能将所有请求过程的日志关联起来。  
&emsp; 为了统计各处理单元的时间延迟,当请求到达各个服务组件时,或是处理逻辑到达某个状态时,也通过一个唯一标识来标记它的开始、具体过程以及结束,该标识就是前面提到的Span ID。对于每个Span来说,它必须有开始和结束两个节点,通过记录开始Span和结束Span的时间戳,就能统计出该Span的时间延迟,除了时间 戳记录之外,它还可以包含一些其他元数据,比如事件名称、请求信息等。  

&emsp; 在SpringBoot应用中中引入spring-cloud-starter-sleuth依赖之后，sluth会自动为当前应用构建起各通信通道的跟踪机制，比如：  
* 通过RabbitMQ、Kafka(或者其他任何Spring Cloud Stream绑定器实现的消息中间件)传递的请求  
* 通过Zuul代理传递的请求  
* 通过RestTemplate发起的请求  



## spring-cloud-starter-sleuth功能点  
### 获取sleuth信息  

&emsp; 在示例中,由于springcloud-consumer-sleuth对springcloud-provider-sleuth发起的请求是通过RestTemplate实现的,所以spring-cloud-starter-sleuth组件会对该请求进行处理。在发送到springcloud-provider-sleuth之前,Sleuth会在该请求的Header中增加实现跟踪需要的重要信息,主要有下面这几个(更多关于头信息的定义可以通过查看org.springframework.cloud.sleuth.Span的源码获取)。
    X-B3-TraceId:一条请求链路( Trace)的唯一标识,必需的值。

    X-B3- SpanId:一个工作单元(Span)的唯一标识,必需的值。

    X-B3- ParentSpanId:标识当前工作单元所属的上一个工作单元, Root Span(请求链路的第一个工作单元)的该值为空。

    X-B3-Sampled:是否被抽样输出的标志，1表示需要被输出，0表示不需要被输出。

    X-B3-Name:工作单元的名称

&emsp; 可以通过对springcloud-provider-sleuth的实现做一些修改来输出这些头信息，具体如下：

```text
private final Logger logger = Logger.getLogger(SleuthProviderController.class.getName());

@RequestMapping("/hello")
public String hello(HttpServletRequest request){
    logger.info("=== provider hello ===,Traced={"+request.getHeader("X-B3-TraceId")+"},SpanId={"+request.getHeader("X-B3- SpanId")+"}");
    return "Trace";
}
```
&emsp; 通过上面的改造，再次重启案例，然后查看日志，可以看到提供者输出了正在处理的TraceId和SpanId信息。  

&emsp; 消费者(springcloud-consumer-sleuth)打印的日志

```text
2019-12-05 13:15:01.457  INFO [springcloud-consumer-sleuth,41697d7fa118c150,41697d7fa118c150,false] 10036 --- [nio-9090-exec-2] c.s.controller.SleuthConsumerController  : === consumer hello ===
```

&emsp; 提供者(springcloud-provider-sleuth)打印的日志
```text
2019-12-05 13:15:01.865  INFO [springcloud-provider-sleuth,41697d7fa118c150,863a1245c86b580e,false] 11088 --- [nio-8080-exec-1] c.s.controller.SleuthProviderController  : === provider hello ===,Traced={41697d7fa118c150},SpanId={863a1245c86b580e}
```

### 抽样收集  
&emsp; 如果服务的流量很大，全部采集对传输、存储压力比较大。这个时候可以设置采样率，sleuth可以通过配置 spring.sleuth.sampler.probability=X.Y(如配置为1.0，则采样率为100%，采集服务的全部追踪数据)，若不配置默认采样率是0.1(即10%)。也可以通过实现bean的方式来设置采样为全部采样(AlwaysSampler)或者不采样(NeverSampler)：如  

```java
@Bean 
public Sampler defaultSampler() { 
    return new AlwaysSampler(); 
}
```
### 获取当前traceId  
在项目中获取traceId，可以参考下述的方式  

```java
import brave.Tracer;

@Service
public class Breadcrumb {

    @Autowired
    private Tracer tracer;

    public String breadcrumbId() {
        return tracer.currentSpan().context().traceIdString();
    }
}
```

### 日志获取traceId  
如果日志文件是有做过格式设置的，可能看不到traceId的输出，可以使用下述的日志格式。  
```xml
<configuration>
    <!-- TraceId:%X{X-B3-TraceId:-} SpanId：%X{X-B3-SpanId:-}-->
    <property name="CONSOLE_LOG_PATTERN"
              value="%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [traceId= %X{X-B3-TraceId:-}] [SpanId= %X{X-B3-SpanId:-}] %logger{5} - %msg%n"/>

    <appender name="rollingAppender" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_PATH}/billmanager.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>/logs/heuristic-%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <!-- 必须指定，否则不会往文件输出内容 -->
        <encoder>
            <pattern>${CONSOLE_LOG_PATTERN}</pattern>
            <charset>utf8</charset>
        </encoder>
        <append>false</append>
        <prudent>false</prudent>
    </appender>

    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>${CONSOLE_LOG_PATTERN}</pattern>
            <charset>utf8</charset>
        </encoder>
    </appender>


    <root level="info">
        <appender-ref ref="STDOUT"/>
        <appender-ref ref="rollingAppender"/>
    </root>
   
</configuration>
```
## 与Zipkin整合  
