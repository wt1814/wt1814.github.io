---
title: 分布式服务追踪：Spring Cloud Sleuth
date: 2020-03-21 00:00:00
tags:
    - Spring Cloud Netflix
---
- [1. 全链路监控功能模块](#1-%e5%85%a8%e9%93%be%e8%b7%af%e7%9b%91%e6%8e%a7%e5%8a%9f%e8%83%bd%e6%a8%a1%e5%9d%97)
- [2. Sleuth实现追踪](#2-sleuth%e5%ae%9e%e7%8e%b0%e8%bf%bd%e8%b8%aa)
- [3. 跟踪原理：](#3-%e8%b7%9f%e8%b8%aa%e5%8e%9f%e7%90%86)
- [4. spring-cloud-starter-sleuth功能点](#4-spring-cloud-starter-sleuth%e5%8a%9f%e8%83%bd%e7%82%b9)
  - [4.1. 抽样收集](#41-%e6%8a%bd%e6%a0%b7%e6%94%b6%e9%9b%86)
  - [4.2. 获取当前traceId](#42-%e8%8e%b7%e5%8f%96%e5%bd%93%e5%89%8dtraceid)
  - [4.3. 日志获取traceId](#43-%e6%97%a5%e5%bf%97%e8%8e%b7%e5%8f%96traceid)
  - [4.4. 传递traceId到异步线程池](#44-%e4%bc%a0%e9%80%92traceid%e5%88%b0%e5%bc%82%e6%ad%a5%e7%ba%bf%e7%a8%8b%e6%b1%a0)
  - [4.5. 子线程或线程池中获取 Zipkin traceId 并打印](#45-%e5%ad%90%e7%ba%bf%e7%a8%8b%e6%88%96%e7%ba%bf%e7%a8%8b%e6%b1%a0%e4%b8%ad%e8%8e%b7%e5%8f%96-zipkin-traceid-%e5%b9%b6%e6%89%93%e5%8d%b0)
  - [4.6. 监控本地方法](#46-%e7%9b%91%e6%8e%a7%e6%9c%ac%e5%9c%b0%e6%96%b9%e6%b3%95)
  - [4.7. 计划任务](#47-%e8%ae%a1%e5%88%92%e4%bb%bb%e5%8a%a1)
  - [4.8. TracingFilter](#48-tracingfilter)
  - [4.9. 过滤不想跟踪的请求](#49-%e8%bf%87%e6%bb%a4%e4%b8%8d%e6%83%b3%e8%b7%9f%e8%b8%aa%e7%9a%84%e8%af%b7%e6%b1%82)
  - [4.10. 用RabbitMq代替Http发送调用链数据](#410-%e7%94%a8rabbitmq%e4%bb%a3%e6%9b%bfhttp%e5%8f%91%e9%80%81%e8%b0%83%e7%94%a8%e9%93%be%e6%95%b0%e6%8d%ae)
- [5. 与Zipkin整合](#5-%e4%b8%8ezipkin%e6%95%b4%e5%90%88)
  - [5.1. 链路信息收集：](#51-%e9%93%be%e8%b7%af%e4%bf%a1%e6%81%af%e6%94%b6%e9%9b%86)
    - [5.1.1. HTTP收集：](#511-http%e6%94%b6%e9%9b%86)
    - [5.1.2. 消息中间件收集](#512-%e6%b6%88%e6%81%af%e4%b8%ad%e9%97%b4%e4%bb%b6%e6%94%b6%e9%9b%86)
  - [5.2. 在Zipkin中图形化展示分布式链接监控数据：](#52-%e5%9c%a8zipkin%e4%b8%ad%e5%9b%be%e5%bd%a2%e5%8c%96%e5%b1%95%e7%a4%ba%e5%88%86%e5%b8%83%e5%bc%8f%e9%93%be%e6%8e%a5%e7%9b%91%e6%8e%a7%e6%95%b0%e6%8d%ae)
  - [5.3. 数据持久化：](#53-%e6%95%b0%e6%8d%ae%e6%8c%81%e4%b9%85%e5%8c%96)
    - [5.3.1. 将链路数据存储在Mysql数据库](#531-%e5%b0%86%e9%93%be%e8%b7%af%e6%95%b0%e6%8d%ae%e5%ad%98%e5%82%a8%e5%9c%a8mysql%e6%95%b0%e6%8d%ae%e5%ba%93)
    - [5.3.2. 将链路数据存储在ElasticSearch](#532-%e5%b0%86%e9%93%be%e8%b7%af%e6%95%b0%e6%8d%ae%e5%ad%98%e5%82%a8%e5%9c%a8elasticsearch)

# 1. 全链路监控功能模块  
&emsp; 一般的全链路监控系统，大致可分为四大功能模块：
1. 埋点与生成日志  
&emsp; 埋点即系统在当前节点的上下文信息，可以分为客户端埋点、服务端埋点，以及客户端和服务端双向型埋点。埋点日志通常要包含以下内容traceId、spanId、调用的开始时间，协议类型、调用方ip和端口，请求的服务名、调用耗时，调用结果，异常信息等，同时预留可扩展字段，为下一步扩展做准备；  
2. 收集和存储日志  
&emsp; 主要支持分布式日志采集的方案，同时增加MQ作为缓冲；  
3. 分析和统计调用链路数据以及时效性  
&emsp; 调用链跟踪分析：把同一TraceID的Span收集起来，按时间排序就是timeline。把ParentID串起来就是调用栈。  
&emsp; 抛异常或者超时，在日志里打印TraceID。利用TraceID查询调用链情况，定位问题。  
4. 展现以及决策支持  

# 2. Sleuth实现追踪  
&emsp; 在服务提供者和服务消费者引入spring-cloud-starter-sleuth依赖。  

```xml
<dependency>
  <groupId>org.springframework.cloud</groupId>
  <artifactId>spring-cloud-starter-sleuth</artifactId>
</dependency>
```
&emsp; 访问消费者接口，控制台日志显示  
&emsp; 消费者(springcloud-consumer-sleuth)打印的日志：  

```text
2019-12-05 12:30:20.178  INFO [springcloud-consumer-sleuth,f6fb983680aab32b,f6fb983680aab32b,false] 8992 --- [nio-9090-exec-1] c.s.controller.SleuthConsumerController  : === consumer service ===
```
&emsp; 提供者(springcloud-provider-sleuth)打印的日志  

```text
2019-12-05 12:30:20.972  INFO [springcloud-provider-sleuth,f6fb983680aab32b,c70932279d3b3a54,false] 788 --- [nio-8080-exec-1] c.s.controller.SleuthProviderController  : === provider service ===
```
&emsp; INFO[]标签中为链路追踪信息。每个值的含义如下所述：  
* 第一个值: springcloud-consumer-sleuth,它记录了应用的名称,也就是application properties 中spring.application.name参数配置的属性  
* 第二个值:f6fb983680aab32b, Spring Cloud Sleuth生成的一个ID,称为Trace ID, 它用来标识一条请求链路。一条请求链路中包含一个Trace ID,多个Span ID  
* 第三个值:c70932279d3b3a54, Spring Cloud Sleuth生成的另外一个ID,称为Span ID,它表示一个基本的工作单元,比如发送一个HTTP请求  
* 第四个值: false,表示是否要将该信息输出到Zipkin等服务中来收集和展示。
  
&emsp; 上面四个值中的Trace ID和Span ID是Spring Cloud Sleuth实现分布式服务跟踪的核心，在一次服务请求链路的调用过程中,会保持并传递同一个Trace ID,从而将整个分布于不同微服务进程中的请求跟踪信息串联起来。以上面输出内容为例springcloud-consumer-sleuth和springcloud-provider-sleuth同属于一个前端服务请求资源，所以他们的Trace ID是相同的，处于同一条请求链路中。  

# 3. 跟踪原理：  
&emsp; 分布式系统服务跟踪原理主要包括下面两个关键点：  
&emsp; 为了实现请求跟踪,当请求发送到分布式系统的入口端点时,只需要服务跟踪框架为该请求创建一个唯一的跟踪标识,同时在分布式系统内部流转的时候,框架始终保持传递该唯一标识,直到返回给请求方为止,这个唯一标识就是前文中提到的Trace ID。通过Trace ID的记录,我们就能将所有请求过程的日志关联起来。  
&emsp; 为了统计各处理单元的时间延迟,当请求到达各个服务组件时,或是处理逻辑到达某个状态时,也通过一个唯一标识来标记它的开始、具体过程以及结束,该标识就是前面提到的Span ID。对于每个Span来说,它必须有开始和结束两个节点,通过记录开始Span和结束Span的时间戳,就能统计出该Span的时间延迟,除了时间 戳记录之外,它还可以包含一些其他元数据,比如事件名称、请求信息等。  

&emsp; 在SpringBoot应用中中引入spring-cloud-starter-sleuth依赖之后，***sluth会自动为当前应用构建起各通信通道的跟踪机制***，比如：  
* 通过RabbitMQ、Kafka(或者其他任何Spring Cloud Stream绑定器实现的消息中间件)传递的请求  
* 通过Zuul代理传递的请求  
* 通过RestTemplate发起的请求  


# 4. spring-cloud-starter-sleuth功能点  

## 4.1. 抽样收集  
&emsp; 如果服务的流量很大，全部采集对传输、存储压力比较大。这个时候可以设置采样率，sleuth可以通过配置 spring.sleuth.sampler.probability=X.Y(如配置为1.0，则采样率为100%，采集服务的全部追踪数据)，若不配置默认采样率是0.1(即10%)。也可以通过实现bean的方式来设置采样为全部采样(AlwaysSampler)或者不采样(NeverSampler)：如  

```java
@Bean 
public Sampler defaultSampler() { 
    return new AlwaysSampler(); 
}
```
## 4.2. 获取当前traceId  
&emsp; 在项目中获取traceId，可以参考下述的方式  

```java
import brave.Tracer;

@Service
public class Breadcrumb {

    @Autowired
    private Tracer tracer;

    public String breadcrumbId() {
        return tracer.currentSpan().context().traceIdString();
    }
}
```

## 4.3. 日志获取traceId  
&emsp; 如果日志文件是有做过格式设置的，可能看不到traceId的输出，可以使用下述的日志格式。  
```xml
<configuration>
    <!-- TraceId:%X{X-B3-TraceId:-} SpanId：%X{X-B3-SpanId:-}-->
    <property name="CONSOLE_LOG_PATTERN"
              value="%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level [traceId= %X{X-B3-TraceId:-}] [SpanId= %X{X-B3-SpanId:-}] %logger{5} - %msg%n"/>

    <appender name="rollingAppender" class="ch.qos.logback.core.rolling.RollingFileAppender">
        <file>${LOG_PATH}/billmanager.log</file>
        <rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy">
            <fileNamePattern>/logs/heuristic-%d{yyyy-MM-dd}.log</fileNamePattern>
            <maxHistory>30</maxHistory>
        </rollingPolicy>
        <!-- 必须指定，否则不会往文件输出内容 -->
        <encoder>
            <pattern>${CONSOLE_LOG_PATTERN}</pattern>
            <charset>utf8</charset>
        </encoder>
        <append>false</append>
        <prudent>false</prudent>
    </appender>

    <appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender">
        <encoder>
            <pattern>${CONSOLE_LOG_PATTERN}</pattern>
            <charset>utf8</charset>
        </encoder>
    </appender>


    <root level="info">
        <appender-ref ref="STDOUT"/>
        <appender-ref ref="rollingAppender"/>
    </root>
   
</configuration>
```
## 4.4. 传递traceId到异步线程池  
1. Sleuth对异步任务是支持的，使用@Async开启一个异步任务后，Sleuth会为这个调用新创建一个Span。  
2. 如果自定义了异步任务的线程池，会导致无法新创建一个 Span，需要使用 Sleuth提供的LazyTraceExecutor来包装下。代码如下所示。  

```java
@Configuration
@EnableAutoConfiguration
public class CustomExecutorConfig extends AsyncConfigurerSupport {
    @Autowired
    BeanFactory beanFactory;
    @Override
    public Executor getAsyncExecutor() {
        ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
        executor.setCorePoolSize(7);
        executor.setMaxPoolSize(42);
        executor.setQueueCapacity(11);
        executor.setThreadNamePrefix("zhangsan-");
        executor.initialize();
        return new LazyTraceExecutor(this.beanFactory, executor);
    }
}
```
&emsp; 如果直接return executor就不会新Span，也就不会有save-log这个 Span。如下图所示。  
![](https://gitee.com/wt1814/pic-host/raw/master/images/microService/SpringCloudNetflix/cloud-21.png)  

## 4.5. 子线程或线程池中获取 Zipkin traceId 并打印  
......

## 4.6. 监控本地方法  
&emsp; 异步执行和远程调用都会新开启一个Span，如果想监控本地的方法耗时时间，可以采用埋点的方式监控本地方法，也就是开启一个新的Span。代码如下所示。   

```java
@Autowired
Tracer tracer;

@Override
public void saveLog2(String log) {
    ScopedSpan span = tracer.startScopedSpan("saveLog2");
    try {
        Thread.sleep(2000);
    } catch (Exception | Error e) {
        span.error(e);
    } finally {
        span.finish();
    }
}
```
&emsp; 通过手动埋点的方式可以创建新的Span，在 Zipkin的UI中也可以看到这个本地方法执行所消耗的时间，可以看到savelog2花费了2秒的时间，如下图所示。
![](https://gitee.com/wt1814/pic-host/raw/master/images/microService/SpringCloudNetflix/cloud-22.png)  
&emsp; 除了使用代码手动创建 Span，还有一种更简单的方式，那就是在方法上加上下面的注解：  

```java
@NewSpan(name = "saveLog2")
```  

## 4.7. 计划任务  
......  

## 4.8. TracingFilter  
......  

## 4.9. 过滤不想跟踪的请求  
......  

## 4.10. 用RabbitMq代替Http发送调用链数据  
......

# 5. 与Zipkin整合  
&emsp; 为了实现对分布式系统做延迟监控等与时间消耗相关等需求，引入了Zipkin。  
&emsp; Zipkin的基础架构主要由4个核心组件构成。  
![](https://gitee.com/wt1814/pic-host/raw/master/images/microService/SpringCloudNetflix/cloud-13.png)  
* Collector: 收集器组件，它主要处理从外部系统发送过来的跟踪信息， 将这些信息转换为Zipkin内部处理的Span格式， 以支待后续的存储、 分析、 展示等功能。  
* Storage: 存储组件， 它主要处理收集器接收到的跟踪信息， 默认会将这些信息存储在内存中。 我们也可以修改此存储策略， 通过使用其他存储组件将跟踪信息存储到数据库中。  
* RESTful API: API组件， 它主要用来提供外部访问接口。 比如给客户端展示跟踪信息， 或是外接系统访问以实现监控等。  
* Web UI: UI组件， 基于API组件实现的上层应用。 通过UI组件， 用户可以方便而又直观地查询和分析跟踪信息。  

&emsp; Zipkin的设计基于Google Dapper论文。核心术语如下：  
* Trace，Zipkin使用Trace结构表示对一次请求的跟踪，一次请求可能由后台的若干服务负责处理，每个服务的处理是一个Span，Span之间有依赖关系，Trace就是树结构的Span集合；  
* Span，每个服务的处理跟踪是一个Span，可以理解为一个基本的工作单元，包含了一些描述信息：id，parentId，name，timestamp，duration，annotations等，例如：  

```json
{
  "traceId": "bd7a977555f6b982", //标记一次请求的跟踪，相关的Spans都有相同的traceId
  "name": "get-traces", //span的名称，一般是接口方法的名称
  "id": "ebf33e1a81dc6f71", //span id
  "parentId": "bd7a977555f6b982", //可选的id，当前Span的父Span id，通过parentId来保证Span之间的依赖关系，如果没有parentId，表示当前Span为根Span
  "timestamp": 1458702548478000, //Span创建时的时间戳，使用的单位是微秒（而不是毫秒），所有时间戳都有错误，包括主机之间的时钟偏差以及时间服务重新设置时钟的可能性，出于这个原因，Span应尽可能记录其duration
  "duration": 354374, //持续时间使用的单位是微秒（而不是毫秒）
  "annotations": [ //
    {
      "endpoint": {
        "serviceName": "zipkin-query",
        "ipv4": "192.168.1.2",
        "port": 9411
      },
      "timestamp": 1458702548786000,
      "value": "cs"
    }
  ],
  "binaryAnnotations": [ //二进制注释，旨在提供有关RPC的额外信息
    {
      "key": "lc",
      "value": "JDBCSpanStore",
      "endpoint": {
        "serviceName": "zipkin-query",
        "ipv4": "192.168.1.2",
        "port": 9411
      }
    }
  ]
}
```
* Annotation：它用来及时地记录一个事件的存在。对于一个HTTP请求来说，在Sleuth中定义了下面四个核心Annotation来标识一个请求的开始和结束：  
  * cs（Client Send）：该Annotation用来记录客户端发起了一个请求，同时它也标识了这个HTTP请求的开始。  
  * sr（Server Received）：该Annotation用来记录服务端接收到了请求，并准备开始处理它。通过计算sr与cs两个Annotation的时间戳之差，我们可以得到当前HTTP请求的网络延迟。  
  * ss（Server Send）：该Annotation用来记录服务端处理完请求后准备发送请求响应信息。通过计算ss与sr两个Annotation的时间戳之差，我们可以得到当前服务端处理请求的时间消耗。  
  * cr（Client Received）：该Annotation用来记录客户端接收到服务端的回复，同时它也标识了这个HTTP请求的结束。通过计算cr与cs两个Annotation的时间戳之差，我们可以得到该HTTP请求从客户端发起开始到接收服务端响应的总时间消耗。  
* BinaryAnnotation：它用来对跟踪信息添加一些额外的补充说明，一般以键值对方式出现。比如：在记录HTTP请求接收后执行具体业务逻辑时，此时并没有默认的Annotation来标识该事件状态，但是有BinaryAnnotation信息对其进行补充。  


## 5.1. 链路信息收集：  
### 5.1.1. HTTP收集：  
......

### 5.1.2. 消息中间件收集  
......

## 5.2. 在Zipkin中图形化展示分布式链接监控数据：
&emsp; 访问zipkin服务端http://ip:port，即可展示微服务链路。  
&emsp; 如果一个服务的调用关系如下：  
![](https://gitee.com/wt1814/pic-host/raw/master/images/microService/SpringCloudNetflix/cloud-14.png)  
&emsp; 那么此时将Span和Trace在一个系统中使用Zipkin注解的过程图形化：  
![](https://gitee.com/wt1814/pic-host/raw/master/images/microService/SpringCloudNetflix/cloud-15.png)  
&emsp; 每个颜色的表明一个span(总计7个spans，从A到G)，每个span有类似的信息  

```text
Trace Id = X
Span Id = D
Client Sent
```

&emsp; 此span表示span的Trance Id是X，Span Id是D，同时它发送一个Client Sent事件。  
&emsp; spans的parent/child关系图形化如下：  
![](https://gitee.com/wt1814/pic-host/raw/master/images/microService/SpringCloudNetflix/cloud-16.png)  

***1. spans在zipkin界面的信息解读***  
&emsp; 在Zipkin中展示了上图的跟踪信息，红框里是对上图调用span的跟踪
![](https://gitee.com/wt1814/pic-host/raw/master/images/microService/SpringCloudNetflix/cloud-17.png)  
&emsp; 但是当点击这个trace时，只看到4个span
![](https://gitee.com/wt1814/pic-host/raw/master/images/microService/SpringCloudNetflix/cloud-18.png)  
&emsp; 为什么两个界面显示的span数量不同，一个是7，一个4。
* 1个spans：来自servier1的接口http:/start 被调用，分别是Server Received (SR) 和 Server Sent (SS) annotations。  
* 2个spans：来自service1调用service2的http:/foo接口。service1端有两个span，分别为Client Sent (CS)和Client Received (CR) annotations。service2端也有两个span，分别为Server Received (SR) 和Server Sent (SS) 。物理上他有2个span，但是从逻辑上说这个他们组成一个RPC调用的span。  
* 2个span：来自service2调用service3的http:/bar接口，service2端有两个span，分别为Client Sent (CS) 和 Client Received (CR) annotations。service3 端也有两个span，分别为Server Received (SR) 和Server Sent (SS) 。物理上他有2个span，但是从逻辑上说它们都是同一个RPC调用的span。  
* 2个span：来自service2调用service4的http:/bar接口，service2端有两个span，分别为Client Sent (CS)和Client Received (CR) annotations。service4端也有两个span，分别为Server Received (SR) and Server Sent (SS) 。物理上他有2个span，但是从逻辑上说这个它们都是同一个RPC调用的span。  

&emsp; 所以计算物理spans有7个：  
    1个来自 http:/start 被请求  
    2个来自 service1调用service2  
    2个来自 service2调用service3  
    2个来自 service2调用service4  
&emsp; 从逻辑上说，只看到4个span:  
    1个来自service1的接口http:/start 被请求  
    3个来自服务之前的RCP接口调用  
    
***2. Zipkin可视化错误***  
&emsp; 如果调用链路中发生接口调用失败，zipkin会默认使用红色展示信息。  
![](https://gitee.com/wt1814/pic-host/raw/master/images/microService/SpringCloudNetflix/cloud-19.png)  
&emsp; 点击红色的span，可以看到详细的失败信息：  
![](https://gitee.com/wt1814/pic-host/raw/master/images/microService/SpringCloudNetflix/cloud-20.png)  


## 5.3. 数据持久化：  
&emsp; 默认情况下， Zipkin Server会将跟踪信息存储在内存中，每次重启 Zipkin Server都会使之前收集的跟踪信息丢失， 并且当有大量跟踪信息时，内存存储也会成为瓶颈，所以通常情况下需要将跟踪信息对接到外部存储组件中去。  

### 5.3.1. 将链路数据存储在Mysql数据库  
......

### 5.3.2. 将链路数据存储在ElasticSearch  
......

