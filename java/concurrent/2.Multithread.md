---
title: 多线程编程
date: 2020-01-07 00:00:00
tags:
    - 并发编程
---

# 多线程基本概念  

## 父子线程  
&emsp; 某线程a中启动另外一个线程t，那么称线程t是线程a的一个子线程，而线程a是线程t的父线程。最典型的是在main方法中启动一个线程去执行。其中main方法隐含的main线程为父线程。  
&emsp; ***与进程相比，创建的子线程从主线程那继承了什么？***  
&emsp; 对于线程而言，并没有继承数据段和代码段，包括栈，而线程最大的优势是，多线程是共享地址空间的，从一个线程切换到同一个进程下的另一个线程运行，页表、数据区等很多都已经在内存或缓存里，而从一个进程切换到另一个进程，由于进程的空间都是独立的，所以切换就涉及到开销。这一点其实对于现在的硬件来讲，尤其是程序员来说，整体速度上影响不大，只是不方便同步。所以线程并不会继承那些看得见的东西（比如变量、代码等）。 

## 线程死锁、饥饿、活锁：  
&emsp; 死锁、饥饿和活锁都属于多线程的活跃性问题，如果发现这几种情况，那么相关线程可能就不再活跃，也就说它可能很难再继续往下执行了。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-1.png)  

* 死锁：死锁应该是最糟糕的一种情况了。指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。  

* 饥饿：指某一个或者多个线程因为种种原因无法获得所需要的资源，导致一直无法执行。比如：  
&emsp; 1）它的线程优先级可能太低，而高优先级的线程不断抢占它需要的资源，导致低优先级的线程无法工作。  
&emsp; 2）另外一种可能是，某一个线程一直占着关键资源不放，导致其他需要这个资源的线程无法正常执行，这种情况也是饥饿的一种。  
&emsp; 与死锁相比，饥饿还是有可能在未来一段时间内解决的（比如高优先级的线程已经完成任务，不再疯狂的执行）  

* 活锁：指任务或者执行者没有被阻塞，由于某些条件没有满足，导致一直重复尝试，失败，尝试，失败。活锁可以认为是一种特殊的饥饿。线程都秉承着"谦让"的原则，主动将资源释放给他人使用，那么就会出现资源不断在两个线程之间跳动，而没有一个线程可以同时拿到所有资源而正常执行。  


# JMM  
## 并发问题及含义  
&emsp; 并发编程存在原子性、可见性、有序性问题。  

* 原子性，即一系列操作要么都执行，要么都不执行。线程切换会导致原子性问题。  
* 可见性，一个线程对共享变量的修改，另一个线程可能不会马上看到。由于多核CPU，每个CPU核都有高速缓存，会缓存共享变量，某个线程对共享变量的修改会改变高速缓存中的值，但却不会马上写入内存。另一个线程读到的是另一个核缓存的共享变量的值，出现缓存不一致问题。  
* 有序性，即程序执行的顺序按照代码的先后顺序执行。编译器和处理器会对指令进行重排，以优化指令执行性能，重排不会改变单线程执行结果，但在多线程中可能会引起各种各样的问题。  

&emsp; ***总结：***
&emsp; 出现线程安全问题的原因：线程切换带来的原子性问题；缓存不能及时刷新导致的可见性问题；编译器优化带来的有序性问题。  
&emsp; “缓存不能及时刷新“和“编译器为了优化性能而改变程序中语句的先后顺序”都是重排序的一种。  

## Java并发原因：重排序  
### 为什么代码会重排序？  
&emsp; 在执行程序时，为了提供性能，处理器和编译器常常会对指令进行重排序，但是不能随意重排序，它需要满足以下两个条件：  

* 在单线程环境下不能改变程序运行的结果；  
* 存在数据依赖关系的不允许重排序。  

&emsp; 需要注意的是：重排序不会影响单线程环境的执行结果，但是会破坏多线程的执行语义。  

### 指令重排序分类  
&emsp; 从Java源代码到最终实际执行的指令序列，会分别经历下面三种重排序：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-2.png)  

1. 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。  
&emsp; 编译器优化：对于没有数据依赖关系的操作，编译器在编译的过程中会进行一定程度的重排。  
2. 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。  
&emsp; 指令重排序：CPU优化行为，也是会对不存在数据依赖关系的指令进行一定程度的重排。  
3. 内存系统的重排序。由于处理器使用缓存和读／写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。  
&emsp; 内存系统重排序：内存系统没有重排序，但是由于有缓存的存在，使得程序整体上会表现出乱序的行为。  

&emsp; 上面的这些重排序都可能导致多线程程序出现内存可见性问题。对于编译器，JMM的编译器重排序规则会禁止特定类型的编译器重排序（不是所有的编译器重排序都要禁止）。对于处理器重排序，JMM的处理器重排序规则会要求Java编译器在生成指令序列时，插入特定类型的内存屏障指令，通过内存屏障指令来禁止特定类型的处理器重排序（不是所有的处理器重排序都要禁止）。  
&emsp; JMM属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。  

### 重排序规则  
#### 重排序遵守数据依赖性  
&emsp; 如果两个操作访问同一个变量，且这两个操作中有一个为写操作，此时这两个操作之间就存在数据依赖性。数据依赖分下列三种类型：  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-3.png)  
&emsp; 上面三种情况，只要重排序两个操作的执行顺序，程序的执行结果将会被改变。  

&emsp; 编译器和处理器可能会对操作做重排序。编译器和处理器在重排序时，会遵守数据依赖性，编译器和处理器不会改变存在数据依赖关系的两个操作的执行顺序。  
&emsp; 注意，这里所说的数据依赖性仅针对单个处理器中执行的指令序列和单个线程中执行的操作，不同处理器之间和不同线程之间的数据依赖性不被编译器和处理器考虑。  

#### 重排序遵守as-if-serial语义  
&emsp; as-if-serial 语义的意思指：不管怎么重排序(编译器和处理器为了提高并行度)，(单线程)程序的执行结果不能被改变。编译器，runtime和处理器都必须遵守as-if-serial语义。  

### 重排序对多线程的影响  
&emsp; 示例代码：  

```
class Demo {
    int a = 0;
    boolean flag = false;

    public void write() {
        a = 1;            //1
        flag = true;    //2
    }

    public void read() {
        if(flag) {            //3
            int i = a * a;    //4
        }
    }
}
```
&emsp; 由于操作1和2没有数据依赖关系，编译器和处理器可以对这两个操作重排序；操作3和操作4没有数据依赖关系，编译器和处理器也可以对这两个操作重排序。  
1. 当操作1和操作2重排序时，可能会产生什么效果？  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-4.png)  
&emsp; 如上图所示，操作1和操作2做了重排序。程序执行时，线程A首先写标记变量flag，随后线程B读这个变量。由于条件判断为真，线程B将读取变量a。此时，变量a还根本没有被线程A写入，在这里多线程程序的语义被重排序破坏了！  
2. 当操作3和操作4重排序时会产生什么效果（借助这个重排序，可以顺便说明控制依赖性）。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-5.png)  
&emsp; 在程序中，操作3和操作4存在控制依赖关系。当代码中存在控制依赖性时，会影响指令序列执行的并行度。为此，编译器和处理器会采用猜测（Speculation）执行来克服控制相关性对并行度的影响。以处理器的猜测执行为例，执行线程B 的处理器可以提前读取并计算a * a，然后把计算结果临时保存到一个名为重排序缓冲（reorder buffer ROB）的硬件缓存中。当接下来操作3的条件判断为真时，就把该计算结果写入变量i中。  
&emsp; 从图中可以看出，猜测执行实质上对操作3和4做了重排序。重排序在这里破坏了多线程程序的语义！  
&emsp; 在单线程程序中，对存在控制依赖的操作重排序，不会改变执行结果（这也是as-if-serial语义允许对存在控制依赖的操作做重排序的原因）；但在多线程程序中，对存在控制依赖的操作重排序，可能会改变程序的执行结果。  

## 了解计算机硬件内存模型  
......

## Java内存模型的抽象  

    顺序一致内存模型：为了保证共享内存的正确性（原子性、可见性、有序性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。内存模型解决并发问题主要采用两种方式：限制处理器优化和使用内存屏障。
&emsp; Java内存模型（Java Memory Model，JMM）是一种符合顺序一致内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-6.png)  
&emsp; JMM定义了Java虚拟机（JVM）在计算机内存（RAM）中的工作方式。JMM主要规定了以下两点：  
* 规定了一个线程如何以及何时可以看到其他线程修改过后的共享变量的值，即线程之间共享变量的可见性。  
* 如何在需要的时候对共享变量进行同步。  

&emsp; 在并发编程需要处理的两个关键问题是：线程之间如何通信和线程之间如何同步，即两条标准的体现。  
&emsp; 线程通信是一种手段，而线程同步是一种目的，即线程通信的主要目的是用于线程同步。线程同步是为了解决线程安全问题。

* 线程通信  

    通信是指线程之间以何种机制来交换信息。在命令式编程中，线程之间的通信机制有两种：共享内存和消息传递。
    在共享内存的并发模型里，线程之间共享程序的公共状态，线程之间通过写-读内存中的公共状态来隐式进行通信。
    在消息传递的并发模型里，线程之间没有公共状态，线程之间必须通过明确的发送消息来显式进行通信。

* 线程同步  

    同步是指程序用于控制不同线程之间操作发生相对顺序的机制。
    在共享内存的并发模型里，同步是显式进行的。程序员必须显式指定某个方法或某段代码需要在线程之间互斥执行。
    在消息传递的并发模型里，由于消息的发送必须在消息的接收之前，因此同步是隐式进行的。    

&emsp; Java的并发采用的是共享内存模型，Java线程之间的通信总是隐式进行，整个通信过程对程序员完全透明。  

### JMM中内存划分  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-7.png)   

* 主内存：Java 内存模型规定了所有变量都存储在主内存(Main Memory)中（此处的主内存与物理硬件的主内存RAM 名字一样，两者可以互相类比，但此处仅是虚拟机内存的一部分）。  
* 工作内存：每条线程都有自己的工作内存(Working Memory，又称本地内存，可与CPU高速缓存类比)，线程的工作内存中保存了该线程使用到的主内存中的共享变量的副本拷贝。线程对变量的所有操作都必须在工作内存进行，而不能直接读写主内存中的变量。工作内存是 JMM 的一个抽象概念，并不真实存在。  

&emsp; 从上图来看，如果线程A和线程B要通信的话，要如下两个步骤：  
1. 线程A需要将本地内存A中的共享变量副本刷新到主内存去；  
2. 线程B去主内存读取线程A之前已更新过的共享变量。  

### 内存间的交互操作  
![image](https://gitee.com/wt1814/pic-host/raw/master/images/java/concurrent/multi-8.png)   
&emsp; Java内存模型为主内存和工作内存间的变量拷贝及同步定义8种原子性操作指令。  
* lock（锁定）：作用于主内存的变量，把一个变量标识为一条线程独占状态。  
* unlock（解锁）：作用于主内存变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。  
* read（读取）：作用于主内存变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用。  
* load（载入）：作用于工作内存的变量，它把通过read操作从主内存中得到的变量值放入工作内存的变量副本中。  
* use（使用）：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎，每当虚拟机遇到一个需要使用变量的值的字节码指令时将会执行这个操作。assign（赋值）：作用于工作内存的变量它把一个从执行引擎接收到的值赋值给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时执行这个操作。  
* store（存储）：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作使用。  
* write（写入）：作用于主内存的变量，它把通过store操作从工作内存中得到的变量的值放入主内存的变量中。  

&emsp; 要把一个变量从主内存中复制到工作内存，就需要按顺寻地执行read和load操作，如果把变量从工作内存中同步回主内存中，就要按顺序地执行store和write操作。  
&emsp; Java内存模型只要求上述两个操作必须按顺序执行，而没有保证必须是连续执行。也就是read和load之间，store和write之间是可以插入其他指令的。  

&emsp; Java内存模型还规定了在执行上述八种基本操作时，必须满足如下规则：  
* 不允许read和load、store和write操作之一单独出现。  
* 不允许一个线程丢弃它的最近assign的操作，即变量在工作内存中改变了之后必须同步到主内存中。  
* 不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中。  
* 一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或assign）的变量。即就是对一个变量实施use和store操作之前，必须先执行过了assign和load操作。  
* 一个变量在同一时刻只允许一条线程对其进行lock操作，lock和unlock必须成对出现  
* 如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量前需要重新执行load或assign操作初始化变量的值  
* 如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。  
* 对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）。  

### JMM中的happens-before原则  
&emsp; JSR-133内存模型使用happens-before的概念来阐述操作之间的内存可见性。在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须要存在happens-before关系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。  
&emsp; Happens-before规则主要用来约束两个操作，两个操作之间具有 happens-before关系, 并不意味着前一个操作必须要在后一个操作之前执行，happens-before 仅仅要求前一个操作(执行的结果)对后一个操作可见, (the first is visible to and ordered before the second，前一个操作的结果可以被后续的操作获取)。  
&emsp; happens-before关系的分析需要分为单线程和多线程的情况：  
* 单线程下的 happens-before 字节码的先后顺序天然包含happens-before关系：因为单线程内共享一份工作内存，不存在数据一致性的问题。在程序控制流路径中靠前的字节码 happens-before 靠后的字节码，即靠前的字节码执行完之后操作结果对靠后的字节码可见。然而，这并不意味着前者一定在后者之前执行。实际上，如果后者不依赖前者的运行结果，那么它们可能会被重排序。  
* 多线程下的 happens-before 多线程由于每个线程有共享变量的副本，如果没有对共享变量做同步处理，线程1更新执行操作A共享变量的值之后，线程2开始执行操作B，此时操作A产生的结果对操作B不一定可见。  


&emsp; 为了方便程序开发，Java 内存模型实现了下述的先行发生关系：  
* 程序次序规则： 一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作。  
* 管程锁定规则： 一个unLock操作先行发生于后面对同一个锁的lock操作。  
* volatile变量规则： 对一个变量的写操作 happens-before 后面对这个变量的读操作。  
* 传递规则： 如果操作A 先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A 先行发生于操作C。  
* 线程启动规则： Thread对象的start()方法先行发生于此线程的每个一个动作。  
* 线程中断规则： 对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生。  
* 线程终结规则： 线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束 、Thread.isAlive()的返回值手段检测到线程已经终止执行。  
* 对象终结规则： 一个对象的初始化完成先行发生于它的 finalize()方法的开始  

            as-if-serial规则和happens-before规则的区别：  
            as-if-serial语义保证单线程内程序的执行结果不被改变，happens-before关系保证正确同步的多线程程序的执行结果不被改变。  
            as-if-serial语义给编写单线程程序的程序员创造了一个幻境：单线程程序是按程序的顺序来执行的。happens-before关系给编写正确同步的多线程程序的程序员创造了一个幻境：正确同步的多线程程序是按happens-before指定的顺序来执行的。  
            as-if-serial语义和happens-before这么做的目的，都是为了在不改变程序执行结果的前提下，尽可能地提高程序执行的并行度。  

### 内存屏障  
&emsp; ***Java中如何保证底层操作的有序性和可见性？可以通过内存屏障。***  

&emsp; 内存屏障是被插入两个 CPU 指令之间的一种指令，用来禁止处理器指令发生重排序（像屏障一样），从而保障有序性的。另外，为了达到屏障的效果，它也会使处理器写入、读取值之前，将主内存的值写入高速缓存，清空无效队列，从而保障可见性。  
eg：

    Store1;
    Store2;
    Load1;
    StoreLoad;  //内存屏障
    Store3;
    Load2;
    Load3;

&emsp; 对于上面的一组 CPU 指令（Store表示写入指令，Load表示读取指令），StoreLoad 屏障之前的 Store 指令无法与StoreLoad 屏障之后的 Load 指令进行交换位置，即重排序。但是 StoreLoad 屏障之前和之后的指令是可以互换位置的，即 Store1 可以和 Store2 互换，Load2 可以和 Load3 互换。  

&emsp; 常见的 4 种屏障：  
* LoadLoad 屏障：对于这样的语句 Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。  
* StoreStore 屏障：对于这样的语句 Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。  
* LoadStore 屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被执行前，保证Load1要读取的数据被读取完毕。  
* StoreLoad 屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的（冲刷写缓冲器，清空无效化队列）。在大多数处理器的实现中，这个屏障也被称为全能屏障，兼具其它三种内存屏障的功能。  

&emsp; Java 中对内存屏障的使用在一般的代码中不太容易见到，常见的有 volatile 和 synchronized 关键字修饰的代码块，还可以通过 Unsafe 这个类来使用内存屏障。  


